



************************************************************
************************************************************
n_length: 16, base_filters: 8, kernel_size: 2, n_block: 2
************************************************************
************************************************************
(2000, 1, 16) Counter({1: 1000, 0: 1000})
(2000, 1, 16) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1                [-1, 8, 16]              24
   MyConv1dPadSame-2                [-1, 8, 16]               0
       BatchNorm1d-3                [-1, 8, 16]              16
              ReLU-4                [-1, 8, 16]               0
            Conv1d-5                [-1, 8, 16]              24
   MyConv1dPadSame-6                [-1, 8, 16]               0
       BatchNorm1d-7                [-1, 8, 16]              16
              ReLU-8                [-1, 8, 16]               0
           Dropout-9                [-1, 8, 16]               0
           Conv1d-10                [-1, 8, 16]              24
  MyConv1dPadSame-11                [-1, 8, 16]               0
       Bottleneck-12                [-1, 8, 16]               0
      BatchNorm1d-13                [-1, 8, 16]              16
             ReLU-14                [-1, 8, 16]               0
          Dropout-15                [-1, 8, 16]               0
           Conv1d-16               [-1, 16, 16]              48
  MyConv1dPadSame-17               [-1, 16, 16]               0
      BatchNorm1d-18               [-1, 16, 16]              32
             ReLU-19               [-1, 16, 16]               0
          Dropout-20               [-1, 16, 16]               0
           Conv1d-21               [-1, 16, 16]              80
  MyConv1dPadSame-22               [-1, 16, 16]               0
       Bottleneck-23               [-1, 16, 16]               0
      BatchNorm1d-24               [-1, 16, 16]              32
             ReLU-25               [-1, 16, 16]               0
           Linear-26                    [-1, 2]              34
================================================================
Total params: 346
Trainable params: 346
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.03
Params size (MB): 0.00
Estimated Total Size (MB): 0.04
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 8, kernel_size: 2, n_block: 4
************************************************************
************************************************************
(2000, 1, 16) Counter({1: 1000, 0: 1000})
(2000, 1, 16) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1                [-1, 8, 16]              24
   MyConv1dPadSame-2                [-1, 8, 16]               0
       BatchNorm1d-3                [-1, 8, 16]              16
              ReLU-4                [-1, 8, 16]               0
            Conv1d-5                [-1, 8, 16]              24
   MyConv1dPadSame-6                [-1, 8, 16]               0
       BatchNorm1d-7                [-1, 8, 16]              16
              ReLU-8                [-1, 8, 16]               0
           Dropout-9                [-1, 8, 16]               0
           Conv1d-10                [-1, 8, 16]              24
  MyConv1dPadSame-11                [-1, 8, 16]               0
       Bottleneck-12                [-1, 8, 16]               0
      BatchNorm1d-13                [-1, 8, 16]              16
             ReLU-14                [-1, 8, 16]               0
          Dropout-15                [-1, 8, 16]               0
           Conv1d-16               [-1, 16, 16]              48
  MyConv1dPadSame-17               [-1, 16, 16]               0
      BatchNorm1d-18               [-1, 16, 16]              32
             ReLU-19               [-1, 16, 16]               0
          Dropout-20               [-1, 16, 16]               0
           Conv1d-21               [-1, 16, 16]              80
  MyConv1dPadSame-22               [-1, 16, 16]               0
       Bottleneck-23               [-1, 16, 16]               0
      BatchNorm1d-24               [-1, 16, 16]              32
             ReLU-25               [-1, 16, 16]               0
          Dropout-26               [-1, 16, 16]               0
           Conv1d-27               [-1, 32, 16]             160
  MyConv1dPadSame-28               [-1, 32, 16]               0
      BatchNorm1d-29               [-1, 32, 16]              64
             ReLU-30               [-1, 32, 16]               0
          Dropout-31               [-1, 32, 16]               0
           Conv1d-32               [-1, 32, 16]             288
  MyConv1dPadSame-33               [-1, 32, 16]               0
       Bottleneck-34               [-1, 32, 16]               0
      BatchNorm1d-35               [-1, 32, 16]              64
             ReLU-36               [-1, 32, 16]               0
          Dropout-37               [-1, 32, 16]               0
           Conv1d-38               [-1, 64, 16]             576
  MyConv1dPadSame-39               [-1, 64, 16]               0
      BatchNorm1d-40               [-1, 64, 16]             128
             ReLU-41               [-1, 64, 16]               0
          Dropout-42               [-1, 64, 16]               0
           Conv1d-43               [-1, 64, 16]           1,088
  MyConv1dPadSame-44               [-1, 64, 16]               0
       Bottleneck-45               [-1, 64, 16]               0
      BatchNorm1d-46               [-1, 64, 16]             128
             ReLU-47               [-1, 64, 16]               0
           Linear-48                    [-1, 2]             130
================================================================
Total params: 2,938
Trainable params: 2,938
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.16
Params size (MB): 0.01
Estimated Total Size (MB): 0.17
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 8, kernel_size: 2, n_block: 8
************************************************************
************************************************************
(2000, 1, 16) Counter({1: 1000, 0: 1000})
(2000, 1, 16) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1                [-1, 8, 16]              24
   MyConv1dPadSame-2                [-1, 8, 16]               0
       BatchNorm1d-3                [-1, 8, 16]              16
              ReLU-4                [-1, 8, 16]               0
            Conv1d-5                [-1, 8, 16]              24
   MyConv1dPadSame-6                [-1, 8, 16]               0
       BatchNorm1d-7                [-1, 8, 16]              16
              ReLU-8                [-1, 8, 16]               0
           Dropout-9                [-1, 8, 16]               0
           Conv1d-10                [-1, 8, 16]              24
  MyConv1dPadSame-11                [-1, 8, 16]               0
       Bottleneck-12                [-1, 8, 16]               0
      BatchNorm1d-13                [-1, 8, 16]              16
             ReLU-14                [-1, 8, 16]               0
          Dropout-15                [-1, 8, 16]               0
           Conv1d-16                [-1, 8, 16]              24
  MyConv1dPadSame-17                [-1, 8, 16]               0
      BatchNorm1d-18                [-1, 8, 16]              16
             ReLU-19                [-1, 8, 16]               0
          Dropout-20                [-1, 8, 16]               0
           Conv1d-21                [-1, 8, 16]              24
  MyConv1dPadSame-22                [-1, 8, 16]               0
       Bottleneck-23                [-1, 8, 16]               0
      BatchNorm1d-24                [-1, 8, 16]              16
             ReLU-25                [-1, 8, 16]               0
          Dropout-26                [-1, 8, 16]               0
           Conv1d-27               [-1, 16, 16]              48
  MyConv1dPadSame-28               [-1, 16, 16]               0
      BatchNorm1d-29               [-1, 16, 16]              32
             ReLU-30               [-1, 16, 16]               0
          Dropout-31               [-1, 16, 16]               0
           Conv1d-32               [-1, 16, 16]              80
  MyConv1dPadSame-33               [-1, 16, 16]               0
       Bottleneck-34               [-1, 16, 16]               0
      BatchNorm1d-35               [-1, 16, 16]              32
             ReLU-36               [-1, 16, 16]               0
          Dropout-37               [-1, 16, 16]               0
           Conv1d-38               [-1, 16, 16]              80
  MyConv1dPadSame-39               [-1, 16, 16]               0
      BatchNorm1d-40               [-1, 16, 16]              32
             ReLU-41               [-1, 16, 16]               0
          Dropout-42               [-1, 16, 16]               0
           Conv1d-43               [-1, 16, 16]              80
  MyConv1dPadSame-44               [-1, 16, 16]               0
       Bottleneck-45               [-1, 16, 16]               0
      BatchNorm1d-46               [-1, 16, 16]              32
             ReLU-47               [-1, 16, 16]               0
          Dropout-48               [-1, 16, 16]               0
           Conv1d-49               [-1, 32, 16]             160
  MyConv1dPadSame-50               [-1, 32, 16]               0
      BatchNorm1d-51               [-1, 32, 16]              64
             ReLU-52               [-1, 32, 16]               0
          Dropout-53               [-1, 32, 16]               0
           Conv1d-54               [-1, 32, 16]             288
  MyConv1dPadSame-55               [-1, 32, 16]               0
       Bottleneck-56               [-1, 32, 16]               0
      BatchNorm1d-57               [-1, 32, 16]              64
             ReLU-58               [-1, 32, 16]               0
          Dropout-59               [-1, 32, 16]               0
           Conv1d-60               [-1, 32, 16]             288
  MyConv1dPadSame-61               [-1, 32, 16]               0
      BatchNorm1d-62               [-1, 32, 16]              64
             ReLU-63               [-1, 32, 16]               0
          Dropout-64               [-1, 32, 16]               0
           Conv1d-65               [-1, 32, 16]             288
  MyConv1dPadSame-66               [-1, 32, 16]               0
       Bottleneck-67               [-1, 32, 16]               0
      BatchNorm1d-68               [-1, 32, 16]              64
             ReLU-69               [-1, 32, 16]               0
          Dropout-70               [-1, 32, 16]               0
           Conv1d-71               [-1, 64, 16]             576
  MyConv1dPadSame-72               [-1, 64, 16]               0
      BatchNorm1d-73               [-1, 64, 16]             128
             ReLU-74               [-1, 64, 16]               0
          Dropout-75               [-1, 64, 16]               0
           Conv1d-76               [-1, 64, 16]           1,088
  MyConv1dPadSame-77               [-1, 64, 16]               0
       Bottleneck-78               [-1, 64, 16]               0
      BatchNorm1d-79               [-1, 64, 16]             128
             ReLU-80               [-1, 64, 16]               0
          Dropout-81               [-1, 64, 16]               0
           Conv1d-82               [-1, 64, 16]           1,088
  MyConv1dPadSame-83               [-1, 64, 16]               0
      BatchNorm1d-84               [-1, 64, 16]             128
             ReLU-85               [-1, 64, 16]               0
          Dropout-86               [-1, 64, 16]               0
           Conv1d-87               [-1, 64, 16]           1,088
  MyConv1dPadSame-88               [-1, 64, 16]               0
       Bottleneck-89               [-1, 64, 16]               0
      BatchNorm1d-90               [-1, 64, 16]             128
             ReLU-91               [-1, 64, 16]               0
           Linear-92                    [-1, 2]             130
================================================================
Total params: 6,378
Trainable params: 6,378
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.32
Params size (MB): 0.02
Estimated Total Size (MB): 0.34
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 8, kernel_size: 2, n_block: 16
************************************************************
************************************************************
(2000, 1, 16) Counter({1: 1000, 0: 1000})
(2000, 1, 16) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1                [-1, 8, 16]              24
   MyConv1dPadSame-2                [-1, 8, 16]               0
       BatchNorm1d-3                [-1, 8, 16]              16
              ReLU-4                [-1, 8, 16]               0
            Conv1d-5                [-1, 8, 16]              24
   MyConv1dPadSame-6                [-1, 8, 16]               0
       BatchNorm1d-7                [-1, 8, 16]              16
              ReLU-8                [-1, 8, 16]               0
           Dropout-9                [-1, 8, 16]               0
           Conv1d-10                [-1, 8, 16]              24
  MyConv1dPadSame-11                [-1, 8, 16]               0
       Bottleneck-12                [-1, 8, 16]               0
      BatchNorm1d-13                [-1, 8, 16]              16
             ReLU-14                [-1, 8, 16]               0
          Dropout-15                [-1, 8, 16]               0
           Conv1d-16                 [-1, 8, 8]              24
  MyConv1dPadSame-17                 [-1, 8, 8]               0
      BatchNorm1d-18                 [-1, 8, 8]              16
             ReLU-19                 [-1, 8, 8]               0
          Dropout-20                 [-1, 8, 8]               0
           Conv1d-21                 [-1, 8, 8]              24
  MyConv1dPadSame-22                 [-1, 8, 8]               0
        MaxPool1d-23                 [-1, 8, 8]               0
MyMaxPool1dPadSame-24                 [-1, 8, 8]               0
       Bottleneck-25                 [-1, 8, 8]               0
      BatchNorm1d-26                 [-1, 8, 8]              16
             ReLU-27                 [-1, 8, 8]               0
          Dropout-28                 [-1, 8, 8]               0
           Conv1d-29                 [-1, 8, 8]              24
  MyConv1dPadSame-30                 [-1, 8, 8]               0
      BatchNorm1d-31                 [-1, 8, 8]              16
             ReLU-32                 [-1, 8, 8]               0
          Dropout-33                 [-1, 8, 8]               0
           Conv1d-34                 [-1, 8, 8]              24
  MyConv1dPadSame-35                 [-1, 8, 8]               0
       Bottleneck-36                 [-1, 8, 8]               0
      BatchNorm1d-37                 [-1, 8, 8]              16
             ReLU-38                 [-1, 8, 8]               0
          Dropout-39                 [-1, 8, 8]               0
           Conv1d-40                 [-1, 8, 4]              24
  MyConv1dPadSame-41                 [-1, 8, 4]               0
      BatchNorm1d-42                 [-1, 8, 4]              16
             ReLU-43                 [-1, 8, 4]               0
          Dropout-44                 [-1, 8, 4]               0
           Conv1d-45                 [-1, 8, 4]              24
  MyConv1dPadSame-46                 [-1, 8, 4]               0
        MaxPool1d-47                 [-1, 8, 4]               0
MyMaxPool1dPadSame-48                 [-1, 8, 4]               0
       Bottleneck-49                 [-1, 8, 4]               0
      BatchNorm1d-50                 [-1, 8, 4]              16
             ReLU-51                 [-1, 8, 4]               0
          Dropout-52                 [-1, 8, 4]               0
           Conv1d-53                [-1, 16, 4]              48
  MyConv1dPadSame-54                [-1, 16, 4]               0
      BatchNorm1d-55                [-1, 16, 4]              32
             ReLU-56                [-1, 16, 4]               0
          Dropout-57                [-1, 16, 4]               0
           Conv1d-58                [-1, 16, 4]              80
  MyConv1dPadSame-59                [-1, 16, 4]               0
       Bottleneck-60                [-1, 16, 4]               0
      BatchNorm1d-61                [-1, 16, 4]              32
             ReLU-62                [-1, 16, 4]               0
          Dropout-63                [-1, 16, 4]               0
           Conv1d-64                [-1, 16, 2]              80
  MyConv1dPadSame-65                [-1, 16, 2]               0
      BatchNorm1d-66                [-1, 16, 2]              32
             ReLU-67                [-1, 16, 2]               0
          Dropout-68                [-1, 16, 2]               0
           Conv1d-69                [-1, 16, 2]              80
  MyConv1dPadSame-70                [-1, 16, 2]               0
        MaxPool1d-71                [-1, 16, 2]               0
MyMaxPool1dPadSame-72                [-1, 16, 2]               0
       Bottleneck-73                [-1, 16, 2]               0
      BatchNorm1d-74                [-1, 16, 2]              32
             ReLU-75                [-1, 16, 2]               0
          Dropout-76                [-1, 16, 2]               0
           Conv1d-77                [-1, 16, 2]              80
  MyConv1dPadSame-78                [-1, 16, 2]               0
      BatchNorm1d-79                [-1, 16, 2]              32
             ReLU-80                [-1, 16, 2]               0
          Dropout-81                [-1, 16, 2]               0
           Conv1d-82                [-1, 16, 2]              80
  MyConv1dPadSame-83                [-1, 16, 2]               0
       Bottleneck-84                [-1, 16, 2]               0
      BatchNorm1d-85                [-1, 16, 2]              32
             ReLU-86                [-1, 16, 2]               0
          Dropout-87                [-1, 16, 2]               0
           Conv1d-88                [-1, 16, 1]              80
  MyConv1dPadSame-89                [-1, 16, 1]               0
      BatchNorm1d-90                [-1, 16, 1]              32
             ReLU-91                [-1, 16, 1]               0
          Dropout-92                [-1, 16, 1]               0
           Conv1d-93                [-1, 16, 1]              80
  MyConv1dPadSame-94                [-1, 16, 1]               0
        MaxPool1d-95                [-1, 16, 1]               0
MyMaxPool1dPadSame-96                [-1, 16, 1]               0
       Bottleneck-97                [-1, 16, 1]               0
      BatchNorm1d-98                [-1, 16, 1]              32
             ReLU-99                [-1, 16, 1]               0
         Dropout-100                [-1, 16, 1]               0
          Conv1d-101                [-1, 32, 1]             160
 MyConv1dPadSame-102                [-1, 32, 1]               0
     BatchNorm1d-103                [-1, 32, 1]              64
            ReLU-104                [-1, 32, 1]               0
         Dropout-105                [-1, 32, 1]               0
          Conv1d-106                [-1, 32, 1]             288
 MyConv1dPadSame-107                [-1, 32, 1]               0
      Bottleneck-108                [-1, 32, 1]               0
     BatchNorm1d-109                [-1, 32, 1]              64
            ReLU-110                [-1, 32, 1]               0
         Dropout-111                [-1, 32, 1]               0
          Conv1d-112                [-1, 32, 1]             288
 MyConv1dPadSame-113                [-1, 32, 1]               0
     BatchNorm1d-114                [-1, 32, 1]              64
            ReLU-115                [-1, 32, 1]               0
         Dropout-116                [-1, 32, 1]               0
          Conv1d-117                [-1, 32, 1]             288
 MyConv1dPadSame-118                [-1, 32, 1]               0
       MaxPool1d-119                [-1, 32, 1]               0
MyMaxPool1dPadSame-120                [-1, 32, 1]               0
      Bottleneck-121                [-1, 32, 1]               0
     BatchNorm1d-122                [-1, 32, 1]              64
            ReLU-123                [-1, 32, 1]               0
         Dropout-124                [-1, 32, 1]               0
          Conv1d-125                [-1, 32, 1]             288
 MyConv1dPadSame-126                [-1, 32, 1]               0
     BatchNorm1d-127                [-1, 32, 1]              64
            ReLU-128                [-1, 32, 1]               0
         Dropout-129                [-1, 32, 1]               0
          Conv1d-130                [-1, 32, 1]             288
 MyConv1dPadSame-131                [-1, 32, 1]               0
      Bottleneck-132                [-1, 32, 1]               0
     BatchNorm1d-133                [-1, 32, 1]              64
            ReLU-134                [-1, 32, 1]               0
         Dropout-135                [-1, 32, 1]               0
          Conv1d-136                [-1, 32, 1]             288
 MyConv1dPadSame-137                [-1, 32, 1]               0
     BatchNorm1d-138                [-1, 32, 1]              64
            ReLU-139                [-1, 32, 1]               0
         Dropout-140                [-1, 32, 1]               0
          Conv1d-141                [-1, 32, 1]             288
 MyConv1dPadSame-142                [-1, 32, 1]               0
       MaxPool1d-143                [-1, 32, 1]               0
MyMaxPool1dPadSame-144                [-1, 32, 1]               0
      Bottleneck-145                [-1, 32, 1]               0
     BatchNorm1d-146                [-1, 32, 1]              64
            ReLU-147                [-1, 32, 1]               0
         Dropout-148                [-1, 32, 1]               0
          Conv1d-149                [-1, 64, 1]             576
 MyConv1dPadSame-150                [-1, 64, 1]               0
     BatchNorm1d-151                [-1, 64, 1]             128
            ReLU-152                [-1, 64, 1]               0
         Dropout-153                [-1, 64, 1]               0
          Conv1d-154                [-1, 64, 1]           1,088
 MyConv1dPadSame-155                [-1, 64, 1]               0
      Bottleneck-156                [-1, 64, 1]               0
     BatchNorm1d-157                [-1, 64, 1]             128
            ReLU-158                [-1, 64, 1]               0
         Dropout-159                [-1, 64, 1]               0
          Conv1d-160                [-1, 64, 1]           1,088
 MyConv1dPadSame-161                [-1, 64, 1]               0
     BatchNorm1d-162                [-1, 64, 1]             128
            ReLU-163                [-1, 64, 1]               0
         Dropout-164                [-1, 64, 1]               0
          Conv1d-165                [-1, 64, 1]           1,088
 MyConv1dPadSame-166                [-1, 64, 1]               0
       MaxPool1d-167                [-1, 64, 1]               0
MyMaxPool1dPadSame-168                [-1, 64, 1]               0
      Bottleneck-169                [-1, 64, 1]               0
     BatchNorm1d-170                [-1, 64, 1]             128
            ReLU-171                [-1, 64, 1]               0
         Dropout-172                [-1, 64, 1]               0
          Conv1d-173                [-1, 64, 1]           1,088
 MyConv1dPadSame-174                [-1, 64, 1]               0
     BatchNorm1d-175                [-1, 64, 1]             128
            ReLU-176                [-1, 64, 1]               0
         Dropout-177                [-1, 64, 1]               0
          Conv1d-178                [-1, 64, 1]           1,088
 MyConv1dPadSame-179                [-1, 64, 1]               0
      Bottleneck-180                [-1, 64, 1]               0
     BatchNorm1d-181                [-1, 64, 1]             128
            ReLU-182                [-1, 64, 1]               0
         Dropout-183                [-1, 64, 1]               0
          Conv1d-184                [-1, 64, 1]           1,088
 MyConv1dPadSame-185                [-1, 64, 1]               0
     BatchNorm1d-186                [-1, 64, 1]             128
            ReLU-187                [-1, 64, 1]               0
         Dropout-188                [-1, 64, 1]               0
          Conv1d-189                [-1, 64, 1]           1,088
 MyConv1dPadSame-190                [-1, 64, 1]               0
       MaxPool1d-191                [-1, 64, 1]               0
MyMaxPool1dPadSame-192                [-1, 64, 1]               0
      Bottleneck-193                [-1, 64, 1]               0
     BatchNorm1d-194                [-1, 64, 1]             128
            ReLU-195                [-1, 64, 1]               0
          Linear-196                    [-1, 2]             130
================================================================
Total params: 13,258
Trainable params: 13,258
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.08
Params size (MB): 0.05
Estimated Total Size (MB): 0.13
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 8, kernel_size: 4, n_block: 2
************************************************************
************************************************************
(2000, 1, 16) Counter({1: 1000, 0: 1000})
(2000, 1, 16) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1                [-1, 8, 16]              40
   MyConv1dPadSame-2                [-1, 8, 16]               0
       BatchNorm1d-3                [-1, 8, 16]              16
              ReLU-4                [-1, 8, 16]               0
            Conv1d-5                [-1, 8, 16]              40
   MyConv1dPadSame-6                [-1, 8, 16]               0
       BatchNorm1d-7                [-1, 8, 16]              16
              ReLU-8                [-1, 8, 16]               0
           Dropout-9                [-1, 8, 16]               0
           Conv1d-10                [-1, 8, 16]              40
  MyConv1dPadSame-11                [-1, 8, 16]               0
       Bottleneck-12                [-1, 8, 16]               0
      BatchNorm1d-13                [-1, 8, 16]              16
             ReLU-14                [-1, 8, 16]               0
          Dropout-15                [-1, 8, 16]               0
           Conv1d-16               [-1, 16, 16]              80
  MyConv1dPadSame-17               [-1, 16, 16]               0
      BatchNorm1d-18               [-1, 16, 16]              32
             ReLU-19               [-1, 16, 16]               0
          Dropout-20               [-1, 16, 16]               0
           Conv1d-21               [-1, 16, 16]             144
  MyConv1dPadSame-22               [-1, 16, 16]               0
       Bottleneck-23               [-1, 16, 16]               0
      BatchNorm1d-24               [-1, 16, 16]              32
             ReLU-25               [-1, 16, 16]               0
           Linear-26                    [-1, 2]              34
================================================================
Total params: 490
Trainable params: 490
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.03
Params size (MB): 0.00
Estimated Total Size (MB): 0.04
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 8, kernel_size: 4, n_block: 4
************************************************************
************************************************************
(2000, 1, 16) Counter({1: 1000, 0: 1000})
(2000, 1, 16) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1                [-1, 8, 16]              40
   MyConv1dPadSame-2                [-1, 8, 16]               0
       BatchNorm1d-3                [-1, 8, 16]              16
              ReLU-4                [-1, 8, 16]               0
            Conv1d-5                [-1, 8, 16]              40
   MyConv1dPadSame-6                [-1, 8, 16]               0
       BatchNorm1d-7                [-1, 8, 16]              16
              ReLU-8                [-1, 8, 16]               0
           Dropout-9                [-1, 8, 16]               0
           Conv1d-10                [-1, 8, 16]              40
  MyConv1dPadSame-11                [-1, 8, 16]               0
       Bottleneck-12                [-1, 8, 16]               0
      BatchNorm1d-13                [-1, 8, 16]              16
             ReLU-14                [-1, 8, 16]               0
          Dropout-15                [-1, 8, 16]               0
           Conv1d-16               [-1, 16, 16]              80
  MyConv1dPadSame-17               [-1, 16, 16]               0
      BatchNorm1d-18               [-1, 16, 16]              32
             ReLU-19               [-1, 16, 16]               0
          Dropout-20               [-1, 16, 16]               0
           Conv1d-21               [-1, 16, 16]             144
  MyConv1dPadSame-22               [-1, 16, 16]               0
       Bottleneck-23               [-1, 16, 16]               0
      BatchNorm1d-24               [-1, 16, 16]              32
             ReLU-25               [-1, 16, 16]               0
          Dropout-26               [-1, 16, 16]               0
           Conv1d-27               [-1, 32, 16]             288
  MyConv1dPadSame-28               [-1, 32, 16]               0
      BatchNorm1d-29               [-1, 32, 16]              64
             ReLU-30               [-1, 32, 16]               0
          Dropout-31               [-1, 32, 16]               0
           Conv1d-32               [-1, 32, 16]             544
  MyConv1dPadSame-33               [-1, 32, 16]               0
       Bottleneck-34               [-1, 32, 16]               0
      BatchNorm1d-35               [-1, 32, 16]              64
             ReLU-36               [-1, 32, 16]               0
          Dropout-37               [-1, 32, 16]               0
           Conv1d-38               [-1, 64, 16]           1,088
  MyConv1dPadSame-39               [-1, 64, 16]               0
      BatchNorm1d-40               [-1, 64, 16]             128
             ReLU-41               [-1, 64, 16]               0
          Dropout-42               [-1, 64, 16]               0
           Conv1d-43               [-1, 64, 16]           2,112
  MyConv1dPadSame-44               [-1, 64, 16]               0
       Bottleneck-45               [-1, 64, 16]               0
      BatchNorm1d-46               [-1, 64, 16]             128
             ReLU-47               [-1, 64, 16]               0
           Linear-48                    [-1, 2]             130
================================================================
Total params: 5,002
Trainable params: 5,002
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.16
Params size (MB): 0.02
Estimated Total Size (MB): 0.18
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 8, kernel_size: 4, n_block: 8
************************************************************
************************************************************
(2000, 1, 16) Counter({1: 1000, 0: 1000})
(2000, 1, 16) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1                [-1, 8, 16]              40
   MyConv1dPadSame-2                [-1, 8, 16]               0
       BatchNorm1d-3                [-1, 8, 16]              16
              ReLU-4                [-1, 8, 16]               0
            Conv1d-5                [-1, 8, 16]              40
   MyConv1dPadSame-6                [-1, 8, 16]               0
       BatchNorm1d-7                [-1, 8, 16]              16
              ReLU-8                [-1, 8, 16]               0
           Dropout-9                [-1, 8, 16]               0
           Conv1d-10                [-1, 8, 16]              40
  MyConv1dPadSame-11                [-1, 8, 16]               0
       Bottleneck-12                [-1, 8, 16]               0
      BatchNorm1d-13                [-1, 8, 16]              16
             ReLU-14                [-1, 8, 16]               0
          Dropout-15                [-1, 8, 16]               0
           Conv1d-16                [-1, 8, 16]              40
  MyConv1dPadSame-17                [-1, 8, 16]               0
      BatchNorm1d-18                [-1, 8, 16]              16
             ReLU-19                [-1, 8, 16]               0
          Dropout-20                [-1, 8, 16]               0
           Conv1d-21                [-1, 8, 16]              40
  MyConv1dPadSame-22                [-1, 8, 16]               0
       Bottleneck-23                [-1, 8, 16]               0
      BatchNorm1d-24                [-1, 8, 16]              16
             ReLU-25                [-1, 8, 16]               0
          Dropout-26                [-1, 8, 16]               0
           Conv1d-27               [-1, 16, 16]              80
  MyConv1dPadSame-28               [-1, 16, 16]               0
      BatchNorm1d-29               [-1, 16, 16]              32
             ReLU-30               [-1, 16, 16]               0
          Dropout-31               [-1, 16, 16]               0
           Conv1d-32               [-1, 16, 16]             144
  MyConv1dPadSame-33               [-1, 16, 16]               0
       Bottleneck-34               [-1, 16, 16]               0
      BatchNorm1d-35               [-1, 16, 16]              32
             ReLU-36               [-1, 16, 16]               0
          Dropout-37               [-1, 16, 16]               0
           Conv1d-38               [-1, 16, 16]             144
  MyConv1dPadSame-39               [-1, 16, 16]               0
      BatchNorm1d-40               [-1, 16, 16]              32
             ReLU-41               [-1, 16, 16]               0
          Dropout-42               [-1, 16, 16]               0
           Conv1d-43               [-1, 16, 16]             144
  MyConv1dPadSame-44               [-1, 16, 16]               0
       Bottleneck-45               [-1, 16, 16]               0
      BatchNorm1d-46               [-1, 16, 16]              32
             ReLU-47               [-1, 16, 16]               0
          Dropout-48               [-1, 16, 16]               0
           Conv1d-49               [-1, 32, 16]             288
  MyConv1dPadSame-50               [-1, 32, 16]               0
      BatchNorm1d-51               [-1, 32, 16]              64
             ReLU-52               [-1, 32, 16]               0
          Dropout-53               [-1, 32, 16]               0
           Conv1d-54               [-1, 32, 16]             544
  MyConv1dPadSame-55               [-1, 32, 16]               0
       Bottleneck-56               [-1, 32, 16]               0
      BatchNorm1d-57               [-1, 32, 16]              64
             ReLU-58               [-1, 32, 16]               0
          Dropout-59               [-1, 32, 16]               0
           Conv1d-60               [-1, 32, 16]             544
  MyConv1dPadSame-61               [-1, 32, 16]               0
      BatchNorm1d-62               [-1, 32, 16]              64
             ReLU-63               [-1, 32, 16]               0
          Dropout-64               [-1, 32, 16]               0
           Conv1d-65               [-1, 32, 16]             544
  MyConv1dPadSame-66               [-1, 32, 16]               0
       Bottleneck-67               [-1, 32, 16]               0
      BatchNorm1d-68               [-1, 32, 16]              64
             ReLU-69               [-1, 32, 16]               0
          Dropout-70               [-1, 32, 16]               0
           Conv1d-71               [-1, 64, 16]           1,088
  MyConv1dPadSame-72               [-1, 64, 16]               0
      BatchNorm1d-73               [-1, 64, 16]             128
             ReLU-74               [-1, 64, 16]               0
          Dropout-75               [-1, 64, 16]               0
           Conv1d-76               [-1, 64, 16]           2,112
  MyConv1dPadSame-77               [-1, 64, 16]               0
       Bottleneck-78               [-1, 64, 16]               0
      BatchNorm1d-79               [-1, 64, 16]             128
             ReLU-80               [-1, 64, 16]               0
          Dropout-81               [-1, 64, 16]               0
           Conv1d-82               [-1, 64, 16]           2,112
  MyConv1dPadSame-83               [-1, 64, 16]               0
      BatchNorm1d-84               [-1, 64, 16]             128
             ReLU-85               [-1, 64, 16]               0
          Dropout-86               [-1, 64, 16]               0
           Conv1d-87               [-1, 64, 16]           2,112
  MyConv1dPadSame-88               [-1, 64, 16]               0
       Bottleneck-89               [-1, 64, 16]               0
      BatchNorm1d-90               [-1, 64, 16]             128
             ReLU-91               [-1, 64, 16]               0
           Linear-92                    [-1, 2]             130
================================================================
Total params: 11,162
Trainable params: 11,162
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.32
Params size (MB): 0.04
Estimated Total Size (MB): 0.36
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 8, kernel_size: 4, n_block: 16
************************************************************
************************************************************
(2000, 1, 16) Counter({0: 1000, 1: 1000})
(2000, 1, 16) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1                [-1, 8, 16]              40
   MyConv1dPadSame-2                [-1, 8, 16]               0
       BatchNorm1d-3                [-1, 8, 16]              16
              ReLU-4                [-1, 8, 16]               0
            Conv1d-5                [-1, 8, 16]              40
   MyConv1dPadSame-6                [-1, 8, 16]               0
       BatchNorm1d-7                [-1, 8, 16]              16
              ReLU-8                [-1, 8, 16]               0
           Dropout-9                [-1, 8, 16]               0
           Conv1d-10                [-1, 8, 16]              40
  MyConv1dPadSame-11                [-1, 8, 16]               0
       Bottleneck-12                [-1, 8, 16]               0
      BatchNorm1d-13                [-1, 8, 16]              16
             ReLU-14                [-1, 8, 16]               0
          Dropout-15                [-1, 8, 16]               0
           Conv1d-16                 [-1, 8, 8]              40
  MyConv1dPadSame-17                 [-1, 8, 8]               0
      BatchNorm1d-18                 [-1, 8, 8]              16
             ReLU-19                 [-1, 8, 8]               0
          Dropout-20                 [-1, 8, 8]               0
           Conv1d-21                 [-1, 8, 8]              40
  MyConv1dPadSame-22                 [-1, 8, 8]               0
        MaxPool1d-23                 [-1, 8, 8]               0
MyMaxPool1dPadSame-24                 [-1, 8, 8]               0
       Bottleneck-25                 [-1, 8, 8]               0
      BatchNorm1d-26                 [-1, 8, 8]              16
             ReLU-27                 [-1, 8, 8]               0
          Dropout-28                 [-1, 8, 8]               0
           Conv1d-29                 [-1, 8, 8]              40
  MyConv1dPadSame-30                 [-1, 8, 8]               0
      BatchNorm1d-31                 [-1, 8, 8]              16
             ReLU-32                 [-1, 8, 8]               0
          Dropout-33                 [-1, 8, 8]               0
           Conv1d-34                 [-1, 8, 8]              40
  MyConv1dPadSame-35                 [-1, 8, 8]               0
       Bottleneck-36                 [-1, 8, 8]               0
      BatchNorm1d-37                 [-1, 8, 8]              16
             ReLU-38                 [-1, 8, 8]               0
          Dropout-39                 [-1, 8, 8]               0
           Conv1d-40                 [-1, 8, 4]              40
  MyConv1dPadSame-41                 [-1, 8, 4]               0
      BatchNorm1d-42                 [-1, 8, 4]              16
             ReLU-43                 [-1, 8, 4]               0
          Dropout-44                 [-1, 8, 4]               0
           Conv1d-45                 [-1, 8, 4]              40
  MyConv1dPadSame-46                 [-1, 8, 4]               0
        MaxPool1d-47                 [-1, 8, 4]               0
MyMaxPool1dPadSame-48                 [-1, 8, 4]               0
       Bottleneck-49                 [-1, 8, 4]               0
      BatchNorm1d-50                 [-1, 8, 4]              16
             ReLU-51                 [-1, 8, 4]               0
          Dropout-52                 [-1, 8, 4]               0
           Conv1d-53                [-1, 16, 4]              80
  MyConv1dPadSame-54                [-1, 16, 4]               0
      BatchNorm1d-55                [-1, 16, 4]              32
             ReLU-56                [-1, 16, 4]               0
          Dropout-57                [-1, 16, 4]               0
           Conv1d-58                [-1, 16, 4]             144
  MyConv1dPadSame-59                [-1, 16, 4]               0
       Bottleneck-60                [-1, 16, 4]               0
      BatchNorm1d-61                [-1, 16, 4]              32
             ReLU-62                [-1, 16, 4]               0
          Dropout-63                [-1, 16, 4]               0
           Conv1d-64                [-1, 16, 2]             144
  MyConv1dPadSame-65                [-1, 16, 2]               0
      BatchNorm1d-66                [-1, 16, 2]              32
             ReLU-67                [-1, 16, 2]               0
          Dropout-68                [-1, 16, 2]               0
           Conv1d-69                [-1, 16, 2]             144
  MyConv1dPadSame-70                [-1, 16, 2]               0
        MaxPool1d-71                [-1, 16, 2]               0
MyMaxPool1dPadSame-72                [-1, 16, 2]               0
       Bottleneck-73                [-1, 16, 2]               0
      BatchNorm1d-74                [-1, 16, 2]              32
             ReLU-75                [-1, 16, 2]               0
          Dropout-76                [-1, 16, 2]               0
           Conv1d-77                [-1, 16, 2]             144
  MyConv1dPadSame-78                [-1, 16, 2]               0
      BatchNorm1d-79                [-1, 16, 2]              32
             ReLU-80                [-1, 16, 2]               0
          Dropout-81                [-1, 16, 2]               0
           Conv1d-82                [-1, 16, 2]             144
  MyConv1dPadSame-83                [-1, 16, 2]               0
       Bottleneck-84                [-1, 16, 2]               0
      BatchNorm1d-85                [-1, 16, 2]              32
             ReLU-86                [-1, 16, 2]               0
          Dropout-87                [-1, 16, 2]               0
           Conv1d-88                [-1, 16, 1]             144
  MyConv1dPadSame-89                [-1, 16, 1]               0
      BatchNorm1d-90                [-1, 16, 1]              32
             ReLU-91                [-1, 16, 1]               0
          Dropout-92                [-1, 16, 1]               0
           Conv1d-93                [-1, 16, 1]             144
  MyConv1dPadSame-94                [-1, 16, 1]               0
        MaxPool1d-95                [-1, 16, 1]               0
MyMaxPool1dPadSame-96                [-1, 16, 1]               0
       Bottleneck-97                [-1, 16, 1]               0
      BatchNorm1d-98                [-1, 16, 1]              32
             ReLU-99                [-1, 16, 1]               0
         Dropout-100                [-1, 16, 1]               0
          Conv1d-101                [-1, 32, 1]             288
 MyConv1dPadSame-102                [-1, 32, 1]               0
     BatchNorm1d-103                [-1, 32, 1]              64
            ReLU-104                [-1, 32, 1]               0
         Dropout-105                [-1, 32, 1]               0
          Conv1d-106                [-1, 32, 1]             544
 MyConv1dPadSame-107                [-1, 32, 1]               0
      Bottleneck-108                [-1, 32, 1]               0
     BatchNorm1d-109                [-1, 32, 1]              64
            ReLU-110                [-1, 32, 1]               0
         Dropout-111                [-1, 32, 1]               0
          Conv1d-112                [-1, 32, 1]             544
 MyConv1dPadSame-113                [-1, 32, 1]               0
     BatchNorm1d-114                [-1, 32, 1]              64
            ReLU-115                [-1, 32, 1]               0
         Dropout-116                [-1, 32, 1]               0
          Conv1d-117                [-1, 32, 1]             544
 MyConv1dPadSame-118                [-1, 32, 1]               0
       MaxPool1d-119                [-1, 32, 1]               0
MyMaxPool1dPadSame-120                [-1, 32, 1]               0
      Bottleneck-121                [-1, 32, 1]               0
     BatchNorm1d-122                [-1, 32, 1]              64
            ReLU-123                [-1, 32, 1]               0
         Dropout-124                [-1, 32, 1]               0
          Conv1d-125                [-1, 32, 1]             544
 MyConv1dPadSame-126                [-1, 32, 1]               0
     BatchNorm1d-127                [-1, 32, 1]              64
            ReLU-128                [-1, 32, 1]               0
         Dropout-129                [-1, 32, 1]               0
          Conv1d-130                [-1, 32, 1]             544
 MyConv1dPadSame-131                [-1, 32, 1]               0
      Bottleneck-132                [-1, 32, 1]               0
     BatchNorm1d-133                [-1, 32, 1]              64
            ReLU-134                [-1, 32, 1]               0
         Dropout-135                [-1, 32, 1]               0
          Conv1d-136                [-1, 32, 1]             544
 MyConv1dPadSame-137                [-1, 32, 1]               0
     BatchNorm1d-138                [-1, 32, 1]              64
            ReLU-139                [-1, 32, 1]               0
         Dropout-140                [-1, 32, 1]               0
          Conv1d-141                [-1, 32, 1]             544
 MyConv1dPadSame-142                [-1, 32, 1]               0
       MaxPool1d-143                [-1, 32, 1]               0
MyMaxPool1dPadSame-144                [-1, 32, 1]               0
      Bottleneck-145                [-1, 32, 1]               0
     BatchNorm1d-146                [-1, 32, 1]              64
            ReLU-147                [-1, 32, 1]               0
         Dropout-148                [-1, 32, 1]               0
          Conv1d-149                [-1, 64, 1]           1,088
 MyConv1dPadSame-150                [-1, 64, 1]               0
     BatchNorm1d-151                [-1, 64, 1]             128
            ReLU-152                [-1, 64, 1]               0
         Dropout-153                [-1, 64, 1]               0
          Conv1d-154                [-1, 64, 1]           2,112
 MyConv1dPadSame-155                [-1, 64, 1]               0
      Bottleneck-156                [-1, 64, 1]               0
     BatchNorm1d-157                [-1, 64, 1]             128
            ReLU-158                [-1, 64, 1]               0
         Dropout-159                [-1, 64, 1]               0
          Conv1d-160                [-1, 64, 1]           2,112
 MyConv1dPadSame-161                [-1, 64, 1]               0
     BatchNorm1d-162                [-1, 64, 1]             128
            ReLU-163                [-1, 64, 1]               0
         Dropout-164                [-1, 64, 1]               0
          Conv1d-165                [-1, 64, 1]           2,112
 MyConv1dPadSame-166                [-1, 64, 1]               0
       MaxPool1d-167                [-1, 64, 1]               0
MyMaxPool1dPadSame-168                [-1, 64, 1]               0
      Bottleneck-169                [-1, 64, 1]               0
     BatchNorm1d-170                [-1, 64, 1]             128
            ReLU-171                [-1, 64, 1]               0
         Dropout-172                [-1, 64, 1]               0
          Conv1d-173                [-1, 64, 1]           2,112
 MyConv1dPadSame-174                [-1, 64, 1]               0
     BatchNorm1d-175                [-1, 64, 1]             128
            ReLU-176                [-1, 64, 1]               0
         Dropout-177                [-1, 64, 1]               0
          Conv1d-178                [-1, 64, 1]           2,112
 MyConv1dPadSame-179                [-1, 64, 1]               0
      Bottleneck-180                [-1, 64, 1]               0
     BatchNorm1d-181                [-1, 64, 1]             128
            ReLU-182                [-1, 64, 1]               0
         Dropout-183                [-1, 64, 1]               0
          Conv1d-184                [-1, 64, 1]           2,112
 MyConv1dPadSame-185                [-1, 64, 1]               0
     BatchNorm1d-186                [-1, 64, 1]             128
            ReLU-187                [-1, 64, 1]               0
         Dropout-188                [-1, 64, 1]               0
          Conv1d-189                [-1, 64, 1]           2,112
 MyConv1dPadSame-190                [-1, 64, 1]               0
       MaxPool1d-191                [-1, 64, 1]               0
MyMaxPool1dPadSame-192                [-1, 64, 1]               0
      Bottleneck-193                [-1, 64, 1]               0
     BatchNorm1d-194                [-1, 64, 1]             128
            ReLU-195                [-1, 64, 1]               0
          Linear-196                    [-1, 2]             130
================================================================
Total params: 23,482
Trainable params: 23,482
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.08
Params size (MB): 0.09
Estimated Total Size (MB): 0.17
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 8, kernel_size: 8, n_block: 2
************************************************************
************************************************************
(2000, 1, 16) Counter({1: 1000, 0: 1000})
(2000, 1, 16) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1                [-1, 8, 16]              72
   MyConv1dPadSame-2                [-1, 8, 16]               0
       BatchNorm1d-3                [-1, 8, 16]              16
              ReLU-4                [-1, 8, 16]               0
            Conv1d-5                [-1, 8, 16]              72
   MyConv1dPadSame-6                [-1, 8, 16]               0
       BatchNorm1d-7                [-1, 8, 16]              16
              ReLU-8                [-1, 8, 16]               0
           Dropout-9                [-1, 8, 16]               0
           Conv1d-10                [-1, 8, 16]              72
  MyConv1dPadSame-11                [-1, 8, 16]               0
       Bottleneck-12                [-1, 8, 16]               0
      BatchNorm1d-13                [-1, 8, 16]              16
             ReLU-14                [-1, 8, 16]               0
          Dropout-15                [-1, 8, 16]               0
           Conv1d-16               [-1, 16, 16]             144
  MyConv1dPadSame-17               [-1, 16, 16]               0
      BatchNorm1d-18               [-1, 16, 16]              32
             ReLU-19               [-1, 16, 16]               0
          Dropout-20               [-1, 16, 16]               0
           Conv1d-21               [-1, 16, 16]             272
  MyConv1dPadSame-22               [-1, 16, 16]               0
       Bottleneck-23               [-1, 16, 16]               0
      BatchNorm1d-24               [-1, 16, 16]              32
             ReLU-25               [-1, 16, 16]               0
           Linear-26                    [-1, 2]              34
================================================================
Total params: 778
Trainable params: 778
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.03
Params size (MB): 0.00
Estimated Total Size (MB): 0.04
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 8, kernel_size: 8, n_block: 4
************************************************************
************************************************************
(2000, 1, 16) Counter({1: 1000, 0: 1000})
(2000, 1, 16) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1                [-1, 8, 16]              72
   MyConv1dPadSame-2                [-1, 8, 16]               0
       BatchNorm1d-3                [-1, 8, 16]              16
              ReLU-4                [-1, 8, 16]               0
            Conv1d-5                [-1, 8, 16]              72
   MyConv1dPadSame-6                [-1, 8, 16]               0
       BatchNorm1d-7                [-1, 8, 16]              16
              ReLU-8                [-1, 8, 16]               0
           Dropout-9                [-1, 8, 16]               0
           Conv1d-10                [-1, 8, 16]              72
  MyConv1dPadSame-11                [-1, 8, 16]               0
       Bottleneck-12                [-1, 8, 16]               0
      BatchNorm1d-13                [-1, 8, 16]              16
             ReLU-14                [-1, 8, 16]               0
          Dropout-15                [-1, 8, 16]               0
           Conv1d-16               [-1, 16, 16]             144
  MyConv1dPadSame-17               [-1, 16, 16]               0
      BatchNorm1d-18               [-1, 16, 16]              32
             ReLU-19               [-1, 16, 16]               0
          Dropout-20               [-1, 16, 16]               0
           Conv1d-21               [-1, 16, 16]             272
  MyConv1dPadSame-22               [-1, 16, 16]               0
       Bottleneck-23               [-1, 16, 16]               0
      BatchNorm1d-24               [-1, 16, 16]              32
             ReLU-25               [-1, 16, 16]               0
          Dropout-26               [-1, 16, 16]               0
           Conv1d-27               [-1, 32, 16]             544
  MyConv1dPadSame-28               [-1, 32, 16]               0
      BatchNorm1d-29               [-1, 32, 16]              64
             ReLU-30               [-1, 32, 16]               0
          Dropout-31               [-1, 32, 16]               0
           Conv1d-32               [-1, 32, 16]           1,056
  MyConv1dPadSame-33               [-1, 32, 16]               0
       Bottleneck-34               [-1, 32, 16]               0
      BatchNorm1d-35               [-1, 32, 16]              64
             ReLU-36               [-1, 32, 16]               0
          Dropout-37               [-1, 32, 16]               0
           Conv1d-38               [-1, 64, 16]           2,112
  MyConv1dPadSame-39               [-1, 64, 16]               0
      BatchNorm1d-40               [-1, 64, 16]             128
             ReLU-41               [-1, 64, 16]               0
          Dropout-42               [-1, 64, 16]               0
           Conv1d-43               [-1, 64, 16]           4,160
  MyConv1dPadSame-44               [-1, 64, 16]               0
       Bottleneck-45               [-1, 64, 16]               0
      BatchNorm1d-46               [-1, 64, 16]             128
             ReLU-47               [-1, 64, 16]               0
           Linear-48                    [-1, 2]             130
================================================================
Total params: 9,130
Trainable params: 9,130
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.16
Params size (MB): 0.03
Estimated Total Size (MB): 0.19
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 8, kernel_size: 8, n_block: 8
************************************************************
************************************************************
(2000, 1, 16) Counter({1: 1000, 0: 1000})
(2000, 1, 16) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1                [-1, 8, 16]              72
   MyConv1dPadSame-2                [-1, 8, 16]               0
       BatchNorm1d-3                [-1, 8, 16]              16
              ReLU-4                [-1, 8, 16]               0
            Conv1d-5                [-1, 8, 16]              72
   MyConv1dPadSame-6                [-1, 8, 16]               0
       BatchNorm1d-7                [-1, 8, 16]              16
              ReLU-8                [-1, 8, 16]               0
           Dropout-9                [-1, 8, 16]               0
           Conv1d-10                [-1, 8, 16]              72
  MyConv1dPadSame-11                [-1, 8, 16]               0
       Bottleneck-12                [-1, 8, 16]               0
      BatchNorm1d-13                [-1, 8, 16]              16
             ReLU-14                [-1, 8, 16]               0
          Dropout-15                [-1, 8, 16]               0
           Conv1d-16                [-1, 8, 16]              72
  MyConv1dPadSame-17                [-1, 8, 16]               0
      BatchNorm1d-18                [-1, 8, 16]              16
             ReLU-19                [-1, 8, 16]               0
          Dropout-20                [-1, 8, 16]               0
           Conv1d-21                [-1, 8, 16]              72
  MyConv1dPadSame-22                [-1, 8, 16]               0
       Bottleneck-23                [-1, 8, 16]               0
      BatchNorm1d-24                [-1, 8, 16]              16
             ReLU-25                [-1, 8, 16]               0
          Dropout-26                [-1, 8, 16]               0
           Conv1d-27               [-1, 16, 16]             144
  MyConv1dPadSame-28               [-1, 16, 16]               0
      BatchNorm1d-29               [-1, 16, 16]              32
             ReLU-30               [-1, 16, 16]               0
          Dropout-31               [-1, 16, 16]               0
           Conv1d-32               [-1, 16, 16]             272
  MyConv1dPadSame-33               [-1, 16, 16]               0
       Bottleneck-34               [-1, 16, 16]               0
      BatchNorm1d-35               [-1, 16, 16]              32
             ReLU-36               [-1, 16, 16]               0
          Dropout-37               [-1, 16, 16]               0
           Conv1d-38               [-1, 16, 16]             272
  MyConv1dPadSame-39               [-1, 16, 16]               0
      BatchNorm1d-40               [-1, 16, 16]              32
             ReLU-41               [-1, 16, 16]               0
          Dropout-42               [-1, 16, 16]               0
           Conv1d-43               [-1, 16, 16]             272
  MyConv1dPadSame-44               [-1, 16, 16]               0
       Bottleneck-45               [-1, 16, 16]               0
      BatchNorm1d-46               [-1, 16, 16]              32
             ReLU-47               [-1, 16, 16]               0
          Dropout-48               [-1, 16, 16]               0
           Conv1d-49               [-1, 32, 16]             544
  MyConv1dPadSame-50               [-1, 32, 16]               0
      BatchNorm1d-51               [-1, 32, 16]              64
             ReLU-52               [-1, 32, 16]               0
          Dropout-53               [-1, 32, 16]               0
           Conv1d-54               [-1, 32, 16]           1,056
  MyConv1dPadSame-55               [-1, 32, 16]               0
       Bottleneck-56               [-1, 32, 16]               0
      BatchNorm1d-57               [-1, 32, 16]              64
             ReLU-58               [-1, 32, 16]               0
          Dropout-59               [-1, 32, 16]               0
           Conv1d-60               [-1, 32, 16]           1,056
  MyConv1dPadSame-61               [-1, 32, 16]               0
      BatchNorm1d-62               [-1, 32, 16]              64
             ReLU-63               [-1, 32, 16]               0
          Dropout-64               [-1, 32, 16]               0
           Conv1d-65               [-1, 32, 16]           1,056
  MyConv1dPadSame-66               [-1, 32, 16]               0
       Bottleneck-67               [-1, 32, 16]               0
      BatchNorm1d-68               [-1, 32, 16]              64
             ReLU-69               [-1, 32, 16]               0
          Dropout-70               [-1, 32, 16]               0
           Conv1d-71               [-1, 64, 16]           2,112
  MyConv1dPadSame-72               [-1, 64, 16]               0
      BatchNorm1d-73               [-1, 64, 16]             128
             ReLU-74               [-1, 64, 16]               0
          Dropout-75               [-1, 64, 16]               0
           Conv1d-76               [-1, 64, 16]           4,160
  MyConv1dPadSame-77               [-1, 64, 16]               0
       Bottleneck-78               [-1, 64, 16]               0
      BatchNorm1d-79               [-1, 64, 16]             128
             ReLU-80               [-1, 64, 16]               0
          Dropout-81               [-1, 64, 16]               0
           Conv1d-82               [-1, 64, 16]           4,160
  MyConv1dPadSame-83               [-1, 64, 16]               0
      BatchNorm1d-84               [-1, 64, 16]             128
             ReLU-85               [-1, 64, 16]               0
          Dropout-86               [-1, 64, 16]               0
           Conv1d-87               [-1, 64, 16]           4,160
  MyConv1dPadSame-88               [-1, 64, 16]               0
       Bottleneck-89               [-1, 64, 16]               0
      BatchNorm1d-90               [-1, 64, 16]             128
             ReLU-91               [-1, 64, 16]               0
           Linear-92                    [-1, 2]             130
================================================================
Total params: 20,730
Trainable params: 20,730
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.32
Params size (MB): 0.08
Estimated Total Size (MB): 0.40
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 8, kernel_size: 8, n_block: 16
************************************************************
************************************************************
(2000, 1, 16) Counter({0: 1000, 1: 1000})
(2000, 1, 16) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1                [-1, 8, 16]              72
   MyConv1dPadSame-2                [-1, 8, 16]               0
       BatchNorm1d-3                [-1, 8, 16]              16
              ReLU-4                [-1, 8, 16]               0
            Conv1d-5                [-1, 8, 16]              72
   MyConv1dPadSame-6                [-1, 8, 16]               0
       BatchNorm1d-7                [-1, 8, 16]              16
              ReLU-8                [-1, 8, 16]               0
           Dropout-9                [-1, 8, 16]               0
           Conv1d-10                [-1, 8, 16]              72
  MyConv1dPadSame-11                [-1, 8, 16]               0
       Bottleneck-12                [-1, 8, 16]               0
      BatchNorm1d-13                [-1, 8, 16]              16
             ReLU-14                [-1, 8, 16]               0
          Dropout-15                [-1, 8, 16]               0
           Conv1d-16                 [-1, 8, 8]              72
  MyConv1dPadSame-17                 [-1, 8, 8]               0
      BatchNorm1d-18                 [-1, 8, 8]              16
             ReLU-19                 [-1, 8, 8]               0
          Dropout-20                 [-1, 8, 8]               0
           Conv1d-21                 [-1, 8, 8]              72
  MyConv1dPadSame-22                 [-1, 8, 8]               0
        MaxPool1d-23                 [-1, 8, 8]               0
MyMaxPool1dPadSame-24                 [-1, 8, 8]               0
       Bottleneck-25                 [-1, 8, 8]               0
      BatchNorm1d-26                 [-1, 8, 8]              16
             ReLU-27                 [-1, 8, 8]               0
          Dropout-28                 [-1, 8, 8]               0
           Conv1d-29                 [-1, 8, 8]              72
  MyConv1dPadSame-30                 [-1, 8, 8]               0
      BatchNorm1d-31                 [-1, 8, 8]              16
             ReLU-32                 [-1, 8, 8]               0
          Dropout-33                 [-1, 8, 8]               0
           Conv1d-34                 [-1, 8, 8]              72
  MyConv1dPadSame-35                 [-1, 8, 8]               0
       Bottleneck-36                 [-1, 8, 8]               0
      BatchNorm1d-37                 [-1, 8, 8]              16
             ReLU-38                 [-1, 8, 8]               0
          Dropout-39                 [-1, 8, 8]               0
           Conv1d-40                 [-1, 8, 4]              72
  MyConv1dPadSame-41                 [-1, 8, 4]               0
      BatchNorm1d-42                 [-1, 8, 4]              16
             ReLU-43                 [-1, 8, 4]               0
          Dropout-44                 [-1, 8, 4]               0
           Conv1d-45                 [-1, 8, 4]              72
  MyConv1dPadSame-46                 [-1, 8, 4]               0
        MaxPool1d-47                 [-1, 8, 4]               0
MyMaxPool1dPadSame-48                 [-1, 8, 4]               0
       Bottleneck-49                 [-1, 8, 4]               0
      BatchNorm1d-50                 [-1, 8, 4]              16
             ReLU-51                 [-1, 8, 4]               0
          Dropout-52                 [-1, 8, 4]               0
           Conv1d-53                [-1, 16, 4]             144
  MyConv1dPadSame-54                [-1, 16, 4]               0
      BatchNorm1d-55                [-1, 16, 4]              32
             ReLU-56                [-1, 16, 4]               0
          Dropout-57                [-1, 16, 4]               0
           Conv1d-58                [-1, 16, 4]             272
  MyConv1dPadSame-59                [-1, 16, 4]               0
       Bottleneck-60                [-1, 16, 4]               0
      BatchNorm1d-61                [-1, 16, 4]              32
             ReLU-62                [-1, 16, 4]               0
          Dropout-63                [-1, 16, 4]               0
           Conv1d-64                [-1, 16, 2]             272
  MyConv1dPadSame-65                [-1, 16, 2]               0
      BatchNorm1d-66                [-1, 16, 2]              32
             ReLU-67                [-1, 16, 2]               0
          Dropout-68                [-1, 16, 2]               0
           Conv1d-69                [-1, 16, 2]             272
  MyConv1dPadSame-70                [-1, 16, 2]               0
        MaxPool1d-71                [-1, 16, 2]               0
MyMaxPool1dPadSame-72                [-1, 16, 2]               0
       Bottleneck-73                [-1, 16, 2]               0
      BatchNorm1d-74                [-1, 16, 2]              32
             ReLU-75                [-1, 16, 2]               0
          Dropout-76                [-1, 16, 2]               0
           Conv1d-77                [-1, 16, 2]             272
  MyConv1dPadSame-78                [-1, 16, 2]               0
      BatchNorm1d-79                [-1, 16, 2]              32
             ReLU-80                [-1, 16, 2]               0
          Dropout-81                [-1, 16, 2]               0
           Conv1d-82                [-1, 16, 2]             272
  MyConv1dPadSame-83                [-1, 16, 2]               0
       Bottleneck-84                [-1, 16, 2]               0
      BatchNorm1d-85                [-1, 16, 2]              32
             ReLU-86                [-1, 16, 2]               0
          Dropout-87                [-1, 16, 2]               0
           Conv1d-88                [-1, 16, 1]             272
  MyConv1dPadSame-89                [-1, 16, 1]               0
      BatchNorm1d-90                [-1, 16, 1]              32
             ReLU-91                [-1, 16, 1]               0
          Dropout-92                [-1, 16, 1]               0
           Conv1d-93                [-1, 16, 1]             272
  MyConv1dPadSame-94                [-1, 16, 1]               0
        MaxPool1d-95                [-1, 16, 1]               0
MyMaxPool1dPadSame-96                [-1, 16, 1]               0
       Bottleneck-97                [-1, 16, 1]               0
      BatchNorm1d-98                [-1, 16, 1]              32
             ReLU-99                [-1, 16, 1]               0
         Dropout-100                [-1, 16, 1]               0
          Conv1d-101                [-1, 32, 1]             544
 MyConv1dPadSame-102                [-1, 32, 1]               0
     BatchNorm1d-103                [-1, 32, 1]              64
            ReLU-104                [-1, 32, 1]               0
         Dropout-105                [-1, 32, 1]               0
          Conv1d-106                [-1, 32, 1]           1,056
 MyConv1dPadSame-107                [-1, 32, 1]               0
      Bottleneck-108                [-1, 32, 1]               0
     BatchNorm1d-109                [-1, 32, 1]              64
            ReLU-110                [-1, 32, 1]               0
         Dropout-111                [-1, 32, 1]               0
          Conv1d-112                [-1, 32, 1]           1,056
 MyConv1dPadSame-113                [-1, 32, 1]               0
     BatchNorm1d-114                [-1, 32, 1]              64
            ReLU-115                [-1, 32, 1]               0
         Dropout-116                [-1, 32, 1]               0
          Conv1d-117                [-1, 32, 1]           1,056
 MyConv1dPadSame-118                [-1, 32, 1]               0
       MaxPool1d-119                [-1, 32, 1]               0
MyMaxPool1dPadSame-120                [-1, 32, 1]               0
      Bottleneck-121                [-1, 32, 1]               0
     BatchNorm1d-122                [-1, 32, 1]              64
            ReLU-123                [-1, 32, 1]               0
         Dropout-124                [-1, 32, 1]               0
          Conv1d-125                [-1, 32, 1]           1,056
 MyConv1dPadSame-126                [-1, 32, 1]               0
     BatchNorm1d-127                [-1, 32, 1]              64
            ReLU-128                [-1, 32, 1]               0
         Dropout-129                [-1, 32, 1]               0
          Conv1d-130                [-1, 32, 1]           1,056
 MyConv1dPadSame-131                [-1, 32, 1]               0
      Bottleneck-132                [-1, 32, 1]               0
     BatchNorm1d-133                [-1, 32, 1]              64
            ReLU-134                [-1, 32, 1]               0
         Dropout-135                [-1, 32, 1]               0
          Conv1d-136                [-1, 32, 1]           1,056
 MyConv1dPadSame-137                [-1, 32, 1]               0
     BatchNorm1d-138                [-1, 32, 1]              64
            ReLU-139                [-1, 32, 1]               0
         Dropout-140                [-1, 32, 1]               0
          Conv1d-141                [-1, 32, 1]           1,056
 MyConv1dPadSame-142                [-1, 32, 1]               0
       MaxPool1d-143                [-1, 32, 1]               0
MyMaxPool1dPadSame-144                [-1, 32, 1]               0
      Bottleneck-145                [-1, 32, 1]               0
     BatchNorm1d-146                [-1, 32, 1]              64
            ReLU-147                [-1, 32, 1]               0
         Dropout-148                [-1, 32, 1]               0
          Conv1d-149                [-1, 64, 1]           2,112
 MyConv1dPadSame-150                [-1, 64, 1]               0
     BatchNorm1d-151                [-1, 64, 1]             128
            ReLU-152                [-1, 64, 1]               0
         Dropout-153                [-1, 64, 1]               0
          Conv1d-154                [-1, 64, 1]           4,160
 MyConv1dPadSame-155                [-1, 64, 1]               0
      Bottleneck-156                [-1, 64, 1]               0
     BatchNorm1d-157                [-1, 64, 1]             128
            ReLU-158                [-1, 64, 1]               0
         Dropout-159                [-1, 64, 1]               0
          Conv1d-160                [-1, 64, 1]           4,160
 MyConv1dPadSame-161                [-1, 64, 1]               0
     BatchNorm1d-162                [-1, 64, 1]             128
            ReLU-163                [-1, 64, 1]               0
         Dropout-164                [-1, 64, 1]               0
          Conv1d-165                [-1, 64, 1]           4,160
 MyConv1dPadSame-166                [-1, 64, 1]               0
       MaxPool1d-167                [-1, 64, 1]               0
MyMaxPool1dPadSame-168                [-1, 64, 1]               0
      Bottleneck-169                [-1, 64, 1]               0
     BatchNorm1d-170                [-1, 64, 1]             128
            ReLU-171                [-1, 64, 1]               0
         Dropout-172                [-1, 64, 1]               0
          Conv1d-173                [-1, 64, 1]           4,160
 MyConv1dPadSame-174                [-1, 64, 1]               0
     BatchNorm1d-175                [-1, 64, 1]             128
            ReLU-176                [-1, 64, 1]               0
         Dropout-177                [-1, 64, 1]               0
          Conv1d-178                [-1, 64, 1]           4,160
 MyConv1dPadSame-179                [-1, 64, 1]               0
      Bottleneck-180                [-1, 64, 1]               0
     BatchNorm1d-181                [-1, 64, 1]             128
            ReLU-182                [-1, 64, 1]               0
         Dropout-183                [-1, 64, 1]               0
          Conv1d-184                [-1, 64, 1]           4,160
 MyConv1dPadSame-185                [-1, 64, 1]               0
     BatchNorm1d-186                [-1, 64, 1]             128
            ReLU-187                [-1, 64, 1]               0
         Dropout-188                [-1, 64, 1]               0
          Conv1d-189                [-1, 64, 1]           4,160
 MyConv1dPadSame-190                [-1, 64, 1]               0
       MaxPool1d-191                [-1, 64, 1]               0
MyMaxPool1dPadSame-192                [-1, 64, 1]               0
      Bottleneck-193                [-1, 64, 1]               0
     BatchNorm1d-194                [-1, 64, 1]             128
            ReLU-195                [-1, 64, 1]               0
          Linear-196                    [-1, 2]             130
================================================================
Total params: 43,930
Trainable params: 43,930
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.08
Params size (MB): 0.17
Estimated Total Size (MB): 0.24
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 8, kernel_size: 16, n_block: 2
************************************************************
************************************************************
(2000, 1, 16) Counter({0: 1000, 1: 1000})
(2000, 1, 16) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1                [-1, 8, 16]             136
   MyConv1dPadSame-2                [-1, 8, 16]               0
       BatchNorm1d-3                [-1, 8, 16]              16
              ReLU-4                [-1, 8, 16]               0
            Conv1d-5                [-1, 8, 16]             136
   MyConv1dPadSame-6                [-1, 8, 16]               0
       BatchNorm1d-7                [-1, 8, 16]              16
              ReLU-8                [-1, 8, 16]               0
           Dropout-9                [-1, 8, 16]               0
           Conv1d-10                [-1, 8, 16]             136
  MyConv1dPadSame-11                [-1, 8, 16]               0
       Bottleneck-12                [-1, 8, 16]               0
      BatchNorm1d-13                [-1, 8, 16]              16
             ReLU-14                [-1, 8, 16]               0
          Dropout-15                [-1, 8, 16]               0
           Conv1d-16               [-1, 16, 16]             272
  MyConv1dPadSame-17               [-1, 16, 16]               0
      BatchNorm1d-18               [-1, 16, 16]              32
             ReLU-19               [-1, 16, 16]               0
          Dropout-20               [-1, 16, 16]               0
           Conv1d-21               [-1, 16, 16]             528
  MyConv1dPadSame-22               [-1, 16, 16]               0
       Bottleneck-23               [-1, 16, 16]               0
      BatchNorm1d-24               [-1, 16, 16]              32
             ReLU-25               [-1, 16, 16]               0
           Linear-26                    [-1, 2]              34
================================================================
Total params: 1,354
Trainable params: 1,354
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.03
Params size (MB): 0.01
Estimated Total Size (MB): 0.04
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 8, kernel_size: 16, n_block: 4
************************************************************
************************************************************
(2000, 1, 16) Counter({1: 1000, 0: 1000})
(2000, 1, 16) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1                [-1, 8, 16]             136
   MyConv1dPadSame-2                [-1, 8, 16]               0
       BatchNorm1d-3                [-1, 8, 16]              16
              ReLU-4                [-1, 8, 16]               0
            Conv1d-5                [-1, 8, 16]             136
   MyConv1dPadSame-6                [-1, 8, 16]               0
       BatchNorm1d-7                [-1, 8, 16]              16
              ReLU-8                [-1, 8, 16]               0
           Dropout-9                [-1, 8, 16]               0
           Conv1d-10                [-1, 8, 16]             136
  MyConv1dPadSame-11                [-1, 8, 16]               0
       Bottleneck-12                [-1, 8, 16]               0
      BatchNorm1d-13                [-1, 8, 16]              16
             ReLU-14                [-1, 8, 16]               0
          Dropout-15                [-1, 8, 16]               0
           Conv1d-16               [-1, 16, 16]             272
  MyConv1dPadSame-17               [-1, 16, 16]               0
      BatchNorm1d-18               [-1, 16, 16]              32
             ReLU-19               [-1, 16, 16]               0
          Dropout-20               [-1, 16, 16]               0
           Conv1d-21               [-1, 16, 16]             528
  MyConv1dPadSame-22               [-1, 16, 16]               0
       Bottleneck-23               [-1, 16, 16]               0
      BatchNorm1d-24               [-1, 16, 16]              32
             ReLU-25               [-1, 16, 16]               0
          Dropout-26               [-1, 16, 16]               0
           Conv1d-27               [-1, 32, 16]           1,056
  MyConv1dPadSame-28               [-1, 32, 16]               0
      BatchNorm1d-29               [-1, 32, 16]              64
             ReLU-30               [-1, 32, 16]               0
          Dropout-31               [-1, 32, 16]               0
           Conv1d-32               [-1, 32, 16]           2,080
  MyConv1dPadSame-33               [-1, 32, 16]               0
       Bottleneck-34               [-1, 32, 16]               0
      BatchNorm1d-35               [-1, 32, 16]              64
             ReLU-36               [-1, 32, 16]               0
          Dropout-37               [-1, 32, 16]               0
           Conv1d-38               [-1, 64, 16]           4,160
  MyConv1dPadSame-39               [-1, 64, 16]               0
      BatchNorm1d-40               [-1, 64, 16]             128
             ReLU-41               [-1, 64, 16]               0
          Dropout-42               [-1, 64, 16]               0
           Conv1d-43               [-1, 64, 16]           8,256
  MyConv1dPadSame-44               [-1, 64, 16]               0
       Bottleneck-45               [-1, 64, 16]               0
      BatchNorm1d-46               [-1, 64, 16]             128
             ReLU-47               [-1, 64, 16]               0
           Linear-48                    [-1, 2]             130
================================================================
Total params: 17,386
Trainable params: 17,386
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.16
Params size (MB): 0.07
Estimated Total Size (MB): 0.22
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 8, kernel_size: 16, n_block: 8
************************************************************
************************************************************
(2000, 1, 16) Counter({1: 1000, 0: 1000})
(2000, 1, 16) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1                [-1, 8, 16]             136
   MyConv1dPadSame-2                [-1, 8, 16]               0
       BatchNorm1d-3                [-1, 8, 16]              16
              ReLU-4                [-1, 8, 16]               0
            Conv1d-5                [-1, 8, 16]             136
   MyConv1dPadSame-6                [-1, 8, 16]               0
       BatchNorm1d-7                [-1, 8, 16]              16
              ReLU-8                [-1, 8, 16]               0
           Dropout-9                [-1, 8, 16]               0
           Conv1d-10                [-1, 8, 16]             136
  MyConv1dPadSame-11                [-1, 8, 16]               0
       Bottleneck-12                [-1, 8, 16]               0
      BatchNorm1d-13                [-1, 8, 16]              16
             ReLU-14                [-1, 8, 16]               0
          Dropout-15                [-1, 8, 16]               0
           Conv1d-16                [-1, 8, 16]             136
  MyConv1dPadSame-17                [-1, 8, 16]               0
      BatchNorm1d-18                [-1, 8, 16]              16
             ReLU-19                [-1, 8, 16]               0
          Dropout-20                [-1, 8, 16]               0
           Conv1d-21                [-1, 8, 16]             136
  MyConv1dPadSame-22                [-1, 8, 16]               0
       Bottleneck-23                [-1, 8, 16]               0
      BatchNorm1d-24                [-1, 8, 16]              16
             ReLU-25                [-1, 8, 16]               0
          Dropout-26                [-1, 8, 16]               0
           Conv1d-27               [-1, 16, 16]             272
  MyConv1dPadSame-28               [-1, 16, 16]               0
      BatchNorm1d-29               [-1, 16, 16]              32
             ReLU-30               [-1, 16, 16]               0
          Dropout-31               [-1, 16, 16]               0
           Conv1d-32               [-1, 16, 16]             528
  MyConv1dPadSame-33               [-1, 16, 16]               0
       Bottleneck-34               [-1, 16, 16]               0
      BatchNorm1d-35               [-1, 16, 16]              32
             ReLU-36               [-1, 16, 16]               0
          Dropout-37               [-1, 16, 16]               0
           Conv1d-38               [-1, 16, 16]             528
  MyConv1dPadSame-39               [-1, 16, 16]               0
      BatchNorm1d-40               [-1, 16, 16]              32
             ReLU-41               [-1, 16, 16]               0
          Dropout-42               [-1, 16, 16]               0
           Conv1d-43               [-1, 16, 16]             528
  MyConv1dPadSame-44               [-1, 16, 16]               0
       Bottleneck-45               [-1, 16, 16]               0
      BatchNorm1d-46               [-1, 16, 16]              32
             ReLU-47               [-1, 16, 16]               0
          Dropout-48               [-1, 16, 16]               0
           Conv1d-49               [-1, 32, 16]           1,056
  MyConv1dPadSame-50               [-1, 32, 16]               0
      BatchNorm1d-51               [-1, 32, 16]              64
             ReLU-52               [-1, 32, 16]               0
          Dropout-53               [-1, 32, 16]               0
           Conv1d-54               [-1, 32, 16]           2,080
  MyConv1dPadSame-55               [-1, 32, 16]               0
       Bottleneck-56               [-1, 32, 16]               0
      BatchNorm1d-57               [-1, 32, 16]              64
             ReLU-58               [-1, 32, 16]               0
          Dropout-59               [-1, 32, 16]               0
           Conv1d-60               [-1, 32, 16]           2,080
  MyConv1dPadSame-61               [-1, 32, 16]               0
      BatchNorm1d-62               [-1, 32, 16]              64
             ReLU-63               [-1, 32, 16]               0
          Dropout-64               [-1, 32, 16]               0
           Conv1d-65               [-1, 32, 16]           2,080
  MyConv1dPadSame-66               [-1, 32, 16]               0
       Bottleneck-67               [-1, 32, 16]               0
      BatchNorm1d-68               [-1, 32, 16]              64
             ReLU-69               [-1, 32, 16]               0
          Dropout-70               [-1, 32, 16]               0
           Conv1d-71               [-1, 64, 16]           4,160
  MyConv1dPadSame-72               [-1, 64, 16]               0
      BatchNorm1d-73               [-1, 64, 16]             128
             ReLU-74               [-1, 64, 16]               0
          Dropout-75               [-1, 64, 16]               0
           Conv1d-76               [-1, 64, 16]           8,256
  MyConv1dPadSame-77               [-1, 64, 16]               0
       Bottleneck-78               [-1, 64, 16]               0
      BatchNorm1d-79               [-1, 64, 16]             128
             ReLU-80               [-1, 64, 16]               0
          Dropout-81               [-1, 64, 16]               0
           Conv1d-82               [-1, 64, 16]           8,256
  MyConv1dPadSame-83               [-1, 64, 16]               0
      BatchNorm1d-84               [-1, 64, 16]             128
             ReLU-85               [-1, 64, 16]               0
          Dropout-86               [-1, 64, 16]               0
           Conv1d-87               [-1, 64, 16]           8,256
  MyConv1dPadSame-88               [-1, 64, 16]               0
       Bottleneck-89               [-1, 64, 16]               0
      BatchNorm1d-90               [-1, 64, 16]             128
             ReLU-91               [-1, 64, 16]               0
           Linear-92                    [-1, 2]             130
================================================================
Total params: 39,866
Trainable params: 39,866
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.32
Params size (MB): 0.15
Estimated Total Size (MB): 0.47
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 8, kernel_size: 16, n_block: 16
************************************************************
************************************************************
(2000, 1, 16) Counter({0: 1000, 1: 1000})
(2000, 1, 16) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1                [-1, 8, 16]             136
   MyConv1dPadSame-2                [-1, 8, 16]               0
       BatchNorm1d-3                [-1, 8, 16]              16
              ReLU-4                [-1, 8, 16]               0
            Conv1d-5                [-1, 8, 16]             136
   MyConv1dPadSame-6                [-1, 8, 16]               0
       BatchNorm1d-7                [-1, 8, 16]              16
              ReLU-8                [-1, 8, 16]               0
           Dropout-9                [-1, 8, 16]               0
           Conv1d-10                [-1, 8, 16]             136
  MyConv1dPadSame-11                [-1, 8, 16]               0
       Bottleneck-12                [-1, 8, 16]               0
      BatchNorm1d-13                [-1, 8, 16]              16
             ReLU-14                [-1, 8, 16]               0
          Dropout-15                [-1, 8, 16]               0
           Conv1d-16                 [-1, 8, 8]             136
  MyConv1dPadSame-17                 [-1, 8, 8]               0
      BatchNorm1d-18                 [-1, 8, 8]              16
             ReLU-19                 [-1, 8, 8]               0
          Dropout-20                 [-1, 8, 8]               0
           Conv1d-21                 [-1, 8, 8]             136
  MyConv1dPadSame-22                 [-1, 8, 8]               0
        MaxPool1d-23                 [-1, 8, 8]               0
MyMaxPool1dPadSame-24                 [-1, 8, 8]               0
       Bottleneck-25                 [-1, 8, 8]               0
      BatchNorm1d-26                 [-1, 8, 8]              16
             ReLU-27                 [-1, 8, 8]               0
          Dropout-28                 [-1, 8, 8]               0
           Conv1d-29                 [-1, 8, 8]             136
  MyConv1dPadSame-30                 [-1, 8, 8]               0
      BatchNorm1d-31                 [-1, 8, 8]              16
             ReLU-32                 [-1, 8, 8]               0
          Dropout-33                 [-1, 8, 8]               0
           Conv1d-34                 [-1, 8, 8]             136
  MyConv1dPadSame-35                 [-1, 8, 8]               0
       Bottleneck-36                 [-1, 8, 8]               0
      BatchNorm1d-37                 [-1, 8, 8]              16
             ReLU-38                 [-1, 8, 8]               0
          Dropout-39                 [-1, 8, 8]               0
           Conv1d-40                 [-1, 8, 4]             136
  MyConv1dPadSame-41                 [-1, 8, 4]               0
      BatchNorm1d-42                 [-1, 8, 4]              16
             ReLU-43                 [-1, 8, 4]               0
          Dropout-44                 [-1, 8, 4]               0
           Conv1d-45                 [-1, 8, 4]             136
  MyConv1dPadSame-46                 [-1, 8, 4]               0
        MaxPool1d-47                 [-1, 8, 4]               0
MyMaxPool1dPadSame-48                 [-1, 8, 4]               0
       Bottleneck-49                 [-1, 8, 4]               0
      BatchNorm1d-50                 [-1, 8, 4]              16
             ReLU-51                 [-1, 8, 4]               0
          Dropout-52                 [-1, 8, 4]               0
           Conv1d-53                [-1, 16, 4]             272
  MyConv1dPadSame-54                [-1, 16, 4]               0
      BatchNorm1d-55                [-1, 16, 4]              32
             ReLU-56                [-1, 16, 4]               0
          Dropout-57                [-1, 16, 4]               0
           Conv1d-58                [-1, 16, 4]             528
  MyConv1dPadSame-59                [-1, 16, 4]               0
       Bottleneck-60                [-1, 16, 4]               0
      BatchNorm1d-61                [-1, 16, 4]              32
             ReLU-62                [-1, 16, 4]               0
          Dropout-63                [-1, 16, 4]               0
           Conv1d-64                [-1, 16, 2]             528
  MyConv1dPadSame-65                [-1, 16, 2]               0
      BatchNorm1d-66                [-1, 16, 2]              32
             ReLU-67                [-1, 16, 2]               0
          Dropout-68                [-1, 16, 2]               0
           Conv1d-69                [-1, 16, 2]             528
  MyConv1dPadSame-70                [-1, 16, 2]               0
        MaxPool1d-71                [-1, 16, 2]               0
MyMaxPool1dPadSame-72                [-1, 16, 2]               0
       Bottleneck-73                [-1, 16, 2]               0
      BatchNorm1d-74                [-1, 16, 2]              32
             ReLU-75                [-1, 16, 2]               0
          Dropout-76                [-1, 16, 2]               0
           Conv1d-77                [-1, 16, 2]             528
  MyConv1dPadSame-78                [-1, 16, 2]               0
      BatchNorm1d-79                [-1, 16, 2]              32
             ReLU-80                [-1, 16, 2]               0
          Dropout-81                [-1, 16, 2]               0
           Conv1d-82                [-1, 16, 2]             528
  MyConv1dPadSame-83                [-1, 16, 2]               0
       Bottleneck-84                [-1, 16, 2]               0
      BatchNorm1d-85                [-1, 16, 2]              32
             ReLU-86                [-1, 16, 2]               0
          Dropout-87                [-1, 16, 2]               0
           Conv1d-88                [-1, 16, 1]             528
  MyConv1dPadSame-89                [-1, 16, 1]               0
      BatchNorm1d-90                [-1, 16, 1]              32
             ReLU-91                [-1, 16, 1]               0
          Dropout-92                [-1, 16, 1]               0
           Conv1d-93                [-1, 16, 1]             528
  MyConv1dPadSame-94                [-1, 16, 1]               0
        MaxPool1d-95                [-1, 16, 1]               0
MyMaxPool1dPadSame-96                [-1, 16, 1]               0
       Bottleneck-97                [-1, 16, 1]               0
      BatchNorm1d-98                [-1, 16, 1]              32
             ReLU-99                [-1, 16, 1]               0
         Dropout-100                [-1, 16, 1]               0
          Conv1d-101                [-1, 32, 1]           1,056
 MyConv1dPadSame-102                [-1, 32, 1]               0
     BatchNorm1d-103                [-1, 32, 1]              64
            ReLU-104                [-1, 32, 1]               0
         Dropout-105                [-1, 32, 1]               0
          Conv1d-106                [-1, 32, 1]           2,080
 MyConv1dPadSame-107                [-1, 32, 1]               0
      Bottleneck-108                [-1, 32, 1]               0
     BatchNorm1d-109                [-1, 32, 1]              64
            ReLU-110                [-1, 32, 1]               0
         Dropout-111                [-1, 32, 1]               0
          Conv1d-112                [-1, 32, 1]           2,080
 MyConv1dPadSame-113                [-1, 32, 1]               0
     BatchNorm1d-114                [-1, 32, 1]              64
            ReLU-115                [-1, 32, 1]               0
         Dropout-116                [-1, 32, 1]               0
          Conv1d-117                [-1, 32, 1]           2,080
 MyConv1dPadSame-118                [-1, 32, 1]               0
       MaxPool1d-119                [-1, 32, 1]               0
MyMaxPool1dPadSame-120                [-1, 32, 1]               0
      Bottleneck-121                [-1, 32, 1]               0
     BatchNorm1d-122                [-1, 32, 1]              64
            ReLU-123                [-1, 32, 1]               0
         Dropout-124                [-1, 32, 1]               0
          Conv1d-125                [-1, 32, 1]           2,080
 MyConv1dPadSame-126                [-1, 32, 1]               0
     BatchNorm1d-127                [-1, 32, 1]              64
            ReLU-128                [-1, 32, 1]               0
         Dropout-129                [-1, 32, 1]               0
          Conv1d-130                [-1, 32, 1]           2,080
 MyConv1dPadSame-131                [-1, 32, 1]               0
      Bottleneck-132                [-1, 32, 1]               0
     BatchNorm1d-133                [-1, 32, 1]              64
            ReLU-134                [-1, 32, 1]               0
         Dropout-135                [-1, 32, 1]               0
          Conv1d-136                [-1, 32, 1]           2,080
 MyConv1dPadSame-137                [-1, 32, 1]               0
     BatchNorm1d-138                [-1, 32, 1]              64
            ReLU-139                [-1, 32, 1]               0
         Dropout-140                [-1, 32, 1]               0
          Conv1d-141                [-1, 32, 1]           2,080
 MyConv1dPadSame-142                [-1, 32, 1]               0
       MaxPool1d-143                [-1, 32, 1]               0
MyMaxPool1dPadSame-144                [-1, 32, 1]               0
      Bottleneck-145                [-1, 32, 1]               0
     BatchNorm1d-146                [-1, 32, 1]              64
            ReLU-147                [-1, 32, 1]               0
         Dropout-148                [-1, 32, 1]               0
          Conv1d-149                [-1, 64, 1]           4,160
 MyConv1dPadSame-150                [-1, 64, 1]               0
     BatchNorm1d-151                [-1, 64, 1]             128
            ReLU-152                [-1, 64, 1]               0
         Dropout-153                [-1, 64, 1]               0
          Conv1d-154                [-1, 64, 1]           8,256
 MyConv1dPadSame-155                [-1, 64, 1]               0
      Bottleneck-156                [-1, 64, 1]               0
     BatchNorm1d-157                [-1, 64, 1]             128
            ReLU-158                [-1, 64, 1]               0
         Dropout-159                [-1, 64, 1]               0
          Conv1d-160                [-1, 64, 1]           8,256
 MyConv1dPadSame-161                [-1, 64, 1]               0
     BatchNorm1d-162                [-1, 64, 1]             128
            ReLU-163                [-1, 64, 1]               0
         Dropout-164                [-1, 64, 1]               0
          Conv1d-165                [-1, 64, 1]           8,256
 MyConv1dPadSame-166                [-1, 64, 1]               0
       MaxPool1d-167                [-1, 64, 1]               0
MyMaxPool1dPadSame-168                [-1, 64, 1]               0
      Bottleneck-169                [-1, 64, 1]               0
     BatchNorm1d-170                [-1, 64, 1]             128
            ReLU-171                [-1, 64, 1]               0
         Dropout-172                [-1, 64, 1]               0
          Conv1d-173                [-1, 64, 1]           8,256
 MyConv1dPadSame-174                [-1, 64, 1]               0
     BatchNorm1d-175                [-1, 64, 1]             128
            ReLU-176                [-1, 64, 1]               0
         Dropout-177                [-1, 64, 1]               0
          Conv1d-178                [-1, 64, 1]           8,256
 MyConv1dPadSame-179                [-1, 64, 1]               0
      Bottleneck-180                [-1, 64, 1]               0
     BatchNorm1d-181                [-1, 64, 1]             128
            ReLU-182                [-1, 64, 1]               0
         Dropout-183                [-1, 64, 1]               0
          Conv1d-184                [-1, 64, 1]           8,256
 MyConv1dPadSame-185                [-1, 64, 1]               0
     BatchNorm1d-186                [-1, 64, 1]             128
            ReLU-187                [-1, 64, 1]               0
         Dropout-188                [-1, 64, 1]               0
          Conv1d-189                [-1, 64, 1]           8,256
 MyConv1dPadSame-190                [-1, 64, 1]               0
       MaxPool1d-191                [-1, 64, 1]               0
MyMaxPool1dPadSame-192                [-1, 64, 1]               0
      Bottleneck-193                [-1, 64, 1]               0
     BatchNorm1d-194                [-1, 64, 1]             128
            ReLU-195                [-1, 64, 1]               0
          Linear-196                    [-1, 2]             130
================================================================
Total params: 84,826
Trainable params: 84,826
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.08
Params size (MB): 0.32
Estimated Total Size (MB): 0.40
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 16, kernel_size: 2, n_block: 2
************************************************************
************************************************************
(2000, 1, 16) Counter({1: 1000, 0: 1000})
(2000, 1, 16) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 16, 16]              48
   MyConv1dPadSame-2               [-1, 16, 16]               0
       BatchNorm1d-3               [-1, 16, 16]              32
              ReLU-4               [-1, 16, 16]               0
            Conv1d-5               [-1, 16, 16]              48
   MyConv1dPadSame-6               [-1, 16, 16]               0
       BatchNorm1d-7               [-1, 16, 16]              32
              ReLU-8               [-1, 16, 16]               0
           Dropout-9               [-1, 16, 16]               0
           Conv1d-10               [-1, 16, 16]              48
  MyConv1dPadSame-11               [-1, 16, 16]               0
       Bottleneck-12               [-1, 16, 16]               0
      BatchNorm1d-13               [-1, 16, 16]              32
             ReLU-14               [-1, 16, 16]               0
          Dropout-15               [-1, 16, 16]               0
           Conv1d-16               [-1, 32, 16]              96
  MyConv1dPadSame-17               [-1, 32, 16]               0
      BatchNorm1d-18               [-1, 32, 16]              64
             ReLU-19               [-1, 32, 16]               0
          Dropout-20               [-1, 32, 16]               0
           Conv1d-21               [-1, 32, 16]             160
  MyConv1dPadSame-22               [-1, 32, 16]               0
       Bottleneck-23               [-1, 32, 16]               0
      BatchNorm1d-24               [-1, 32, 16]              64
             ReLU-25               [-1, 32, 16]               0
           Linear-26                    [-1, 2]              66
================================================================
Total params: 690
Trainable params: 690
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.07
Params size (MB): 0.00
Estimated Total Size (MB): 0.07
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 16, kernel_size: 2, n_block: 4
************************************************************
************************************************************
(2000, 1, 16) Counter({0: 1000, 1: 1000})
(2000, 1, 16) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 16, 16]              48
   MyConv1dPadSame-2               [-1, 16, 16]               0
       BatchNorm1d-3               [-1, 16, 16]              32
              ReLU-4               [-1, 16, 16]               0
            Conv1d-5               [-1, 16, 16]              48
   MyConv1dPadSame-6               [-1, 16, 16]               0
       BatchNorm1d-7               [-1, 16, 16]              32
              ReLU-8               [-1, 16, 16]               0
           Dropout-9               [-1, 16, 16]               0
           Conv1d-10               [-1, 16, 16]              48
  MyConv1dPadSame-11               [-1, 16, 16]               0
       Bottleneck-12               [-1, 16, 16]               0
      BatchNorm1d-13               [-1, 16, 16]              32
             ReLU-14               [-1, 16, 16]               0
          Dropout-15               [-1, 16, 16]               0
           Conv1d-16               [-1, 32, 16]              96
  MyConv1dPadSame-17               [-1, 32, 16]               0
      BatchNorm1d-18               [-1, 32, 16]              64
             ReLU-19               [-1, 32, 16]               0
          Dropout-20               [-1, 32, 16]               0
           Conv1d-21               [-1, 32, 16]             160
  MyConv1dPadSame-22               [-1, 32, 16]               0
       Bottleneck-23               [-1, 32, 16]               0
      BatchNorm1d-24               [-1, 32, 16]              64
             ReLU-25               [-1, 32, 16]               0
          Dropout-26               [-1, 32, 16]               0
           Conv1d-27               [-1, 64, 16]             320
  MyConv1dPadSame-28               [-1, 64, 16]               0
      BatchNorm1d-29               [-1, 64, 16]             128
             ReLU-30               [-1, 64, 16]               0
          Dropout-31               [-1, 64, 16]               0
           Conv1d-32               [-1, 64, 16]             576
  MyConv1dPadSame-33               [-1, 64, 16]               0
       Bottleneck-34               [-1, 64, 16]               0
      BatchNorm1d-35               [-1, 64, 16]             128
             ReLU-36               [-1, 64, 16]               0
          Dropout-37               [-1, 64, 16]               0
           Conv1d-38              [-1, 128, 16]           1,152
  MyConv1dPadSame-39              [-1, 128, 16]               0
      BatchNorm1d-40              [-1, 128, 16]             256
             ReLU-41              [-1, 128, 16]               0
          Dropout-42              [-1, 128, 16]               0
           Conv1d-43              [-1, 128, 16]           2,176
  MyConv1dPadSame-44              [-1, 128, 16]               0
       Bottleneck-45              [-1, 128, 16]               0
      BatchNorm1d-46              [-1, 128, 16]             256
             ReLU-47              [-1, 128, 16]               0
           Linear-48                    [-1, 2]             258
================================================================
Total params: 5,874
Trainable params: 5,874
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.31
Params size (MB): 0.02
Estimated Total Size (MB): 0.34
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 16, kernel_size: 2, n_block: 8
************************************************************
************************************************************
(2000, 1, 16) Counter({1: 1000, 0: 1000})
(2000, 1, 16) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 16, 16]              48
   MyConv1dPadSame-2               [-1, 16, 16]               0
       BatchNorm1d-3               [-1, 16, 16]              32
              ReLU-4               [-1, 16, 16]               0
            Conv1d-5               [-1, 16, 16]              48
   MyConv1dPadSame-6               [-1, 16, 16]               0
       BatchNorm1d-7               [-1, 16, 16]              32
              ReLU-8               [-1, 16, 16]               0
           Dropout-9               [-1, 16, 16]               0
           Conv1d-10               [-1, 16, 16]              48
  MyConv1dPadSame-11               [-1, 16, 16]               0
       Bottleneck-12               [-1, 16, 16]               0
      BatchNorm1d-13               [-1, 16, 16]              32
             ReLU-14               [-1, 16, 16]               0
          Dropout-15               [-1, 16, 16]               0
           Conv1d-16               [-1, 16, 16]              48
  MyConv1dPadSame-17               [-1, 16, 16]               0
      BatchNorm1d-18               [-1, 16, 16]              32
             ReLU-19               [-1, 16, 16]               0
          Dropout-20               [-1, 16, 16]               0
           Conv1d-21               [-1, 16, 16]              48
  MyConv1dPadSame-22               [-1, 16, 16]               0
       Bottleneck-23               [-1, 16, 16]               0
      BatchNorm1d-24               [-1, 16, 16]              32
             ReLU-25               [-1, 16, 16]               0
          Dropout-26               [-1, 16, 16]               0
           Conv1d-27               [-1, 32, 16]              96
  MyConv1dPadSame-28               [-1, 32, 16]               0
      BatchNorm1d-29               [-1, 32, 16]              64
             ReLU-30               [-1, 32, 16]               0
          Dropout-31               [-1, 32, 16]               0
           Conv1d-32               [-1, 32, 16]             160
  MyConv1dPadSame-33               [-1, 32, 16]               0
       Bottleneck-34               [-1, 32, 16]               0
      BatchNorm1d-35               [-1, 32, 16]              64
             ReLU-36               [-1, 32, 16]               0
          Dropout-37               [-1, 32, 16]               0
           Conv1d-38               [-1, 32, 16]             160
  MyConv1dPadSame-39               [-1, 32, 16]               0
      BatchNorm1d-40               [-1, 32, 16]              64
             ReLU-41               [-1, 32, 16]               0
          Dropout-42               [-1, 32, 16]               0
           Conv1d-43               [-1, 32, 16]             160
  MyConv1dPadSame-44               [-1, 32, 16]               0
       Bottleneck-45               [-1, 32, 16]               0
      BatchNorm1d-46               [-1, 32, 16]              64
             ReLU-47               [-1, 32, 16]               0
          Dropout-48               [-1, 32, 16]               0
           Conv1d-49               [-1, 64, 16]             320
  MyConv1dPadSame-50               [-1, 64, 16]               0
      BatchNorm1d-51               [-1, 64, 16]             128
             ReLU-52               [-1, 64, 16]               0
          Dropout-53               [-1, 64, 16]               0
           Conv1d-54               [-1, 64, 16]             576
  MyConv1dPadSame-55               [-1, 64, 16]               0
       Bottleneck-56               [-1, 64, 16]               0
      BatchNorm1d-57               [-1, 64, 16]             128
             ReLU-58               [-1, 64, 16]               0
          Dropout-59               [-1, 64, 16]               0
           Conv1d-60               [-1, 64, 16]             576
  MyConv1dPadSame-61               [-1, 64, 16]               0
      BatchNorm1d-62               [-1, 64, 16]             128
             ReLU-63               [-1, 64, 16]               0
          Dropout-64               [-1, 64, 16]               0
           Conv1d-65               [-1, 64, 16]             576
  MyConv1dPadSame-66               [-1, 64, 16]               0
       Bottleneck-67               [-1, 64, 16]               0
      BatchNorm1d-68               [-1, 64, 16]             128
             ReLU-69               [-1, 64, 16]               0
          Dropout-70               [-1, 64, 16]               0
           Conv1d-71              [-1, 128, 16]           1,152
  MyConv1dPadSame-72              [-1, 128, 16]               0
      BatchNorm1d-73              [-1, 128, 16]             256
             ReLU-74              [-1, 128, 16]               0
          Dropout-75              [-1, 128, 16]               0
           Conv1d-76              [-1, 128, 16]           2,176
  MyConv1dPadSame-77              [-1, 128, 16]               0
       Bottleneck-78              [-1, 128, 16]               0
      BatchNorm1d-79              [-1, 128, 16]             256
             ReLU-80              [-1, 128, 16]               0
          Dropout-81              [-1, 128, 16]               0
           Conv1d-82              [-1, 128, 16]           2,176
  MyConv1dPadSame-83              [-1, 128, 16]               0
      BatchNorm1d-84              [-1, 128, 16]             256
             ReLU-85              [-1, 128, 16]               0
          Dropout-86              [-1, 128, 16]               0
           Conv1d-87              [-1, 128, 16]           2,176
  MyConv1dPadSame-88              [-1, 128, 16]               0
       Bottleneck-89              [-1, 128, 16]               0
      BatchNorm1d-90              [-1, 128, 16]             256
             ReLU-91              [-1, 128, 16]               0
           Linear-92                    [-1, 2]             258
================================================================
Total params: 12,754
Trainable params: 12,754
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.64
Params size (MB): 0.05
Estimated Total Size (MB): 0.69
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 16, kernel_size: 2, n_block: 16
************************************************************
************************************************************
(2000, 1, 16) Counter({1: 1000, 0: 1000})
(2000, 1, 16) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 16, 16]              48
   MyConv1dPadSame-2               [-1, 16, 16]               0
       BatchNorm1d-3               [-1, 16, 16]              32
              ReLU-4               [-1, 16, 16]               0
            Conv1d-5               [-1, 16, 16]              48
   MyConv1dPadSame-6               [-1, 16, 16]               0
       BatchNorm1d-7               [-1, 16, 16]              32
              ReLU-8               [-1, 16, 16]               0
           Dropout-9               [-1, 16, 16]               0
           Conv1d-10               [-1, 16, 16]              48
  MyConv1dPadSame-11               [-1, 16, 16]               0
       Bottleneck-12               [-1, 16, 16]               0
      BatchNorm1d-13               [-1, 16, 16]              32
             ReLU-14               [-1, 16, 16]               0
          Dropout-15               [-1, 16, 16]               0
           Conv1d-16                [-1, 16, 8]              48
  MyConv1dPadSame-17                [-1, 16, 8]               0
      BatchNorm1d-18                [-1, 16, 8]              32
             ReLU-19                [-1, 16, 8]               0
          Dropout-20                [-1, 16, 8]               0
           Conv1d-21                [-1, 16, 8]              48
  MyConv1dPadSame-22                [-1, 16, 8]               0
        MaxPool1d-23                [-1, 16, 8]               0
MyMaxPool1dPadSame-24                [-1, 16, 8]               0
       Bottleneck-25                [-1, 16, 8]               0
      BatchNorm1d-26                [-1, 16, 8]              32
             ReLU-27                [-1, 16, 8]               0
          Dropout-28                [-1, 16, 8]               0
           Conv1d-29                [-1, 16, 8]              48
  MyConv1dPadSame-30                [-1, 16, 8]               0
      BatchNorm1d-31                [-1, 16, 8]              32
             ReLU-32                [-1, 16, 8]               0
          Dropout-33                [-1, 16, 8]               0
           Conv1d-34                [-1, 16, 8]              48
  MyConv1dPadSame-35                [-1, 16, 8]               0
       Bottleneck-36                [-1, 16, 8]               0
      BatchNorm1d-37                [-1, 16, 8]              32
             ReLU-38                [-1, 16, 8]               0
          Dropout-39                [-1, 16, 8]               0
           Conv1d-40                [-1, 16, 4]              48
  MyConv1dPadSame-41                [-1, 16, 4]               0
      BatchNorm1d-42                [-1, 16, 4]              32
             ReLU-43                [-1, 16, 4]               0
          Dropout-44                [-1, 16, 4]               0
           Conv1d-45                [-1, 16, 4]              48
  MyConv1dPadSame-46                [-1, 16, 4]               0
        MaxPool1d-47                [-1, 16, 4]               0
MyMaxPool1dPadSame-48                [-1, 16, 4]               0
       Bottleneck-49                [-1, 16, 4]               0
      BatchNorm1d-50                [-1, 16, 4]              32
             ReLU-51                [-1, 16, 4]               0
          Dropout-52                [-1, 16, 4]               0
           Conv1d-53                [-1, 32, 4]              96
  MyConv1dPadSame-54                [-1, 32, 4]               0
      BatchNorm1d-55                [-1, 32, 4]              64
             ReLU-56                [-1, 32, 4]               0
          Dropout-57                [-1, 32, 4]               0
           Conv1d-58                [-1, 32, 4]             160
  MyConv1dPadSame-59                [-1, 32, 4]               0
       Bottleneck-60                [-1, 32, 4]               0
      BatchNorm1d-61                [-1, 32, 4]              64
             ReLU-62                [-1, 32, 4]               0
          Dropout-63                [-1, 32, 4]               0
           Conv1d-64                [-1, 32, 2]             160
  MyConv1dPadSame-65                [-1, 32, 2]               0
      BatchNorm1d-66                [-1, 32, 2]              64
             ReLU-67                [-1, 32, 2]               0
          Dropout-68                [-1, 32, 2]               0
           Conv1d-69                [-1, 32, 2]             160
  MyConv1dPadSame-70                [-1, 32, 2]               0
        MaxPool1d-71                [-1, 32, 2]               0
MyMaxPool1dPadSame-72                [-1, 32, 2]               0
       Bottleneck-73                [-1, 32, 2]               0
      BatchNorm1d-74                [-1, 32, 2]              64
             ReLU-75                [-1, 32, 2]               0
          Dropout-76                [-1, 32, 2]               0
           Conv1d-77                [-1, 32, 2]             160
  MyConv1dPadSame-78                [-1, 32, 2]               0
      BatchNorm1d-79                [-1, 32, 2]              64
             ReLU-80                [-1, 32, 2]               0
          Dropout-81                [-1, 32, 2]               0
           Conv1d-82                [-1, 32, 2]             160
  MyConv1dPadSame-83                [-1, 32, 2]               0
       Bottleneck-84                [-1, 32, 2]               0
      BatchNorm1d-85                [-1, 32, 2]              64
             ReLU-86                [-1, 32, 2]               0
          Dropout-87                [-1, 32, 2]               0
           Conv1d-88                [-1, 32, 1]             160
  MyConv1dPadSame-89                [-1, 32, 1]               0
      BatchNorm1d-90                [-1, 32, 1]              64
             ReLU-91                [-1, 32, 1]               0
          Dropout-92                [-1, 32, 1]               0
           Conv1d-93                [-1, 32, 1]             160
  MyConv1dPadSame-94                [-1, 32, 1]               0
        MaxPool1d-95                [-1, 32, 1]               0
MyMaxPool1dPadSame-96                [-1, 32, 1]               0
       Bottleneck-97                [-1, 32, 1]               0
      BatchNorm1d-98                [-1, 32, 1]              64
             ReLU-99                [-1, 32, 1]               0
         Dropout-100                [-1, 32, 1]               0
          Conv1d-101                [-1, 64, 1]             320
 MyConv1dPadSame-102                [-1, 64, 1]               0
     BatchNorm1d-103                [-1, 64, 1]             128
            ReLU-104                [-1, 64, 1]               0
         Dropout-105                [-1, 64, 1]               0
          Conv1d-106                [-1, 64, 1]             576
 MyConv1dPadSame-107                [-1, 64, 1]               0
      Bottleneck-108                [-1, 64, 1]               0
     BatchNorm1d-109                [-1, 64, 1]             128
            ReLU-110                [-1, 64, 1]               0
         Dropout-111                [-1, 64, 1]               0
          Conv1d-112                [-1, 64, 1]             576
 MyConv1dPadSame-113                [-1, 64, 1]               0
     BatchNorm1d-114                [-1, 64, 1]             128
            ReLU-115                [-1, 64, 1]               0
         Dropout-116                [-1, 64, 1]               0
          Conv1d-117                [-1, 64, 1]             576
 MyConv1dPadSame-118                [-1, 64, 1]               0
       MaxPool1d-119                [-1, 64, 1]               0
MyMaxPool1dPadSame-120                [-1, 64, 1]               0
      Bottleneck-121                [-1, 64, 1]               0
     BatchNorm1d-122                [-1, 64, 1]             128
            ReLU-123                [-1, 64, 1]               0
         Dropout-124                [-1, 64, 1]               0
          Conv1d-125                [-1, 64, 1]             576
 MyConv1dPadSame-126                [-1, 64, 1]               0
     BatchNorm1d-127                [-1, 64, 1]             128
            ReLU-128                [-1, 64, 1]               0
         Dropout-129                [-1, 64, 1]               0
          Conv1d-130                [-1, 64, 1]             576
 MyConv1dPadSame-131                [-1, 64, 1]               0
      Bottleneck-132                [-1, 64, 1]               0
     BatchNorm1d-133                [-1, 64, 1]             128
            ReLU-134                [-1, 64, 1]               0
         Dropout-135                [-1, 64, 1]               0
          Conv1d-136                [-1, 64, 1]             576
 MyConv1dPadSame-137                [-1, 64, 1]               0
     BatchNorm1d-138                [-1, 64, 1]             128
            ReLU-139                [-1, 64, 1]               0
         Dropout-140                [-1, 64, 1]               0
          Conv1d-141                [-1, 64, 1]             576
 MyConv1dPadSame-142                [-1, 64, 1]               0
       MaxPool1d-143                [-1, 64, 1]               0
MyMaxPool1dPadSame-144                [-1, 64, 1]               0
      Bottleneck-145                [-1, 64, 1]               0
     BatchNorm1d-146                [-1, 64, 1]             128
            ReLU-147                [-1, 64, 1]               0
         Dropout-148                [-1, 64, 1]               0
          Conv1d-149               [-1, 128, 1]           1,152
 MyConv1dPadSame-150               [-1, 128, 1]               0
     BatchNorm1d-151               [-1, 128, 1]             256
            ReLU-152               [-1, 128, 1]               0
         Dropout-153               [-1, 128, 1]               0
          Conv1d-154               [-1, 128, 1]           2,176
 MyConv1dPadSame-155               [-1, 128, 1]               0
      Bottleneck-156               [-1, 128, 1]               0
     BatchNorm1d-157               [-1, 128, 1]             256
            ReLU-158               [-1, 128, 1]               0
         Dropout-159               [-1, 128, 1]               0
          Conv1d-160               [-1, 128, 1]           2,176
 MyConv1dPadSame-161               [-1, 128, 1]               0
     BatchNorm1d-162               [-1, 128, 1]             256
            ReLU-163               [-1, 128, 1]               0
         Dropout-164               [-1, 128, 1]               0
          Conv1d-165               [-1, 128, 1]           2,176
 MyConv1dPadSame-166               [-1, 128, 1]               0
       MaxPool1d-167               [-1, 128, 1]               0
MyMaxPool1dPadSame-168               [-1, 128, 1]               0
      Bottleneck-169               [-1, 128, 1]               0
     BatchNorm1d-170               [-1, 128, 1]             256
            ReLU-171               [-1, 128, 1]               0
         Dropout-172               [-1, 128, 1]               0
          Conv1d-173               [-1, 128, 1]           2,176
 MyConv1dPadSame-174               [-1, 128, 1]               0
     BatchNorm1d-175               [-1, 128, 1]             256
            ReLU-176               [-1, 128, 1]               0
         Dropout-177               [-1, 128, 1]               0
          Conv1d-178               [-1, 128, 1]           2,176
 MyConv1dPadSame-179               [-1, 128, 1]               0
      Bottleneck-180               [-1, 128, 1]               0
     BatchNorm1d-181               [-1, 128, 1]             256
            ReLU-182               [-1, 128, 1]               0
         Dropout-183               [-1, 128, 1]               0
          Conv1d-184               [-1, 128, 1]           2,176
 MyConv1dPadSame-185               [-1, 128, 1]               0
     BatchNorm1d-186               [-1, 128, 1]             256
            ReLU-187               [-1, 128, 1]               0
         Dropout-188               [-1, 128, 1]               0
          Conv1d-189               [-1, 128, 1]           2,176
 MyConv1dPadSame-190               [-1, 128, 1]               0
       MaxPool1d-191               [-1, 128, 1]               0
MyMaxPool1dPadSame-192               [-1, 128, 1]               0
      Bottleneck-193               [-1, 128, 1]               0
     BatchNorm1d-194               [-1, 128, 1]             256
            ReLU-195               [-1, 128, 1]               0
          Linear-196                    [-1, 2]             258
================================================================
Total params: 26,514
Trainable params: 26,514
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.15
Params size (MB): 0.10
Estimated Total Size (MB): 0.26
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 16, kernel_size: 4, n_block: 2
************************************************************
************************************************************
(2000, 1, 16) Counter({0: 1000, 1: 1000})
(2000, 1, 16) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 16, 16]              80
   MyConv1dPadSame-2               [-1, 16, 16]               0
       BatchNorm1d-3               [-1, 16, 16]              32
              ReLU-4               [-1, 16, 16]               0
            Conv1d-5               [-1, 16, 16]              80
   MyConv1dPadSame-6               [-1, 16, 16]               0
       BatchNorm1d-7               [-1, 16, 16]              32
              ReLU-8               [-1, 16, 16]               0
           Dropout-9               [-1, 16, 16]               0
           Conv1d-10               [-1, 16, 16]              80
  MyConv1dPadSame-11               [-1, 16, 16]               0
       Bottleneck-12               [-1, 16, 16]               0
      BatchNorm1d-13               [-1, 16, 16]              32
             ReLU-14               [-1, 16, 16]               0
          Dropout-15               [-1, 16, 16]               0
           Conv1d-16               [-1, 32, 16]             160
  MyConv1dPadSame-17               [-1, 32, 16]               0
      BatchNorm1d-18               [-1, 32, 16]              64
             ReLU-19               [-1, 32, 16]               0
          Dropout-20               [-1, 32, 16]               0
           Conv1d-21               [-1, 32, 16]             288
  MyConv1dPadSame-22               [-1, 32, 16]               0
       Bottleneck-23               [-1, 32, 16]               0
      BatchNorm1d-24               [-1, 32, 16]              64
             ReLU-25               [-1, 32, 16]               0
           Linear-26                    [-1, 2]              66
================================================================
Total params: 978
Trainable params: 978
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.07
Params size (MB): 0.00
Estimated Total Size (MB): 0.07
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 16, kernel_size: 4, n_block: 4
************************************************************
************************************************************
(2000, 1, 16) Counter({1: 1000, 0: 1000})
(2000, 1, 16) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 16, 16]              80
   MyConv1dPadSame-2               [-1, 16, 16]               0
       BatchNorm1d-3               [-1, 16, 16]              32
              ReLU-4               [-1, 16, 16]               0
            Conv1d-5               [-1, 16, 16]              80
   MyConv1dPadSame-6               [-1, 16, 16]               0
       BatchNorm1d-7               [-1, 16, 16]              32
              ReLU-8               [-1, 16, 16]               0
           Dropout-9               [-1, 16, 16]               0
           Conv1d-10               [-1, 16, 16]              80
  MyConv1dPadSame-11               [-1, 16, 16]               0
       Bottleneck-12               [-1, 16, 16]               0
      BatchNorm1d-13               [-1, 16, 16]              32
             ReLU-14               [-1, 16, 16]               0
          Dropout-15               [-1, 16, 16]               0
           Conv1d-16               [-1, 32, 16]             160
  MyConv1dPadSame-17               [-1, 32, 16]               0
      BatchNorm1d-18               [-1, 32, 16]              64
             ReLU-19               [-1, 32, 16]               0
          Dropout-20               [-1, 32, 16]               0
           Conv1d-21               [-1, 32, 16]             288
  MyConv1dPadSame-22               [-1, 32, 16]               0
       Bottleneck-23               [-1, 32, 16]               0
      BatchNorm1d-24               [-1, 32, 16]              64
             ReLU-25               [-1, 32, 16]               0
          Dropout-26               [-1, 32, 16]               0
           Conv1d-27               [-1, 64, 16]             576
  MyConv1dPadSame-28               [-1, 64, 16]               0
      BatchNorm1d-29               [-1, 64, 16]             128
             ReLU-30               [-1, 64, 16]               0
          Dropout-31               [-1, 64, 16]               0
           Conv1d-32               [-1, 64, 16]           1,088
  MyConv1dPadSame-33               [-1, 64, 16]               0
       Bottleneck-34               [-1, 64, 16]               0
      BatchNorm1d-35               [-1, 64, 16]             128
             ReLU-36               [-1, 64, 16]               0
          Dropout-37               [-1, 64, 16]               0
           Conv1d-38              [-1, 128, 16]           2,176
  MyConv1dPadSame-39              [-1, 128, 16]               0
      BatchNorm1d-40              [-1, 128, 16]             256
             ReLU-41              [-1, 128, 16]               0
          Dropout-42              [-1, 128, 16]               0
           Conv1d-43              [-1, 128, 16]           4,224
  MyConv1dPadSame-44              [-1, 128, 16]               0
       Bottleneck-45              [-1, 128, 16]               0
      BatchNorm1d-46              [-1, 128, 16]             256
             ReLU-47              [-1, 128, 16]               0
           Linear-48                    [-1, 2]             258
================================================================
Total params: 10,002
Trainable params: 10,002
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.31
Params size (MB): 0.04
Estimated Total Size (MB): 0.35
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 16, kernel_size: 4, n_block: 8
************************************************************
************************************************************
(2000, 1, 16) Counter({0: 1000, 1: 1000})
(2000, 1, 16) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 16, 16]              80
   MyConv1dPadSame-2               [-1, 16, 16]               0
       BatchNorm1d-3               [-1, 16, 16]              32
              ReLU-4               [-1, 16, 16]               0
            Conv1d-5               [-1, 16, 16]              80
   MyConv1dPadSame-6               [-1, 16, 16]               0
       BatchNorm1d-7               [-1, 16, 16]              32
              ReLU-8               [-1, 16, 16]               0
           Dropout-9               [-1, 16, 16]               0
           Conv1d-10               [-1, 16, 16]              80
  MyConv1dPadSame-11               [-1, 16, 16]               0
       Bottleneck-12               [-1, 16, 16]               0
      BatchNorm1d-13               [-1, 16, 16]              32
             ReLU-14               [-1, 16, 16]               0
          Dropout-15               [-1, 16, 16]               0
           Conv1d-16               [-1, 16, 16]              80
  MyConv1dPadSame-17               [-1, 16, 16]               0
      BatchNorm1d-18               [-1, 16, 16]              32
             ReLU-19               [-1, 16, 16]               0
          Dropout-20               [-1, 16, 16]               0
           Conv1d-21               [-1, 16, 16]              80
  MyConv1dPadSame-22               [-1, 16, 16]               0
       Bottleneck-23               [-1, 16, 16]               0
      BatchNorm1d-24               [-1, 16, 16]              32
             ReLU-25               [-1, 16, 16]               0
          Dropout-26               [-1, 16, 16]               0
           Conv1d-27               [-1, 32, 16]             160
  MyConv1dPadSame-28               [-1, 32, 16]               0
      BatchNorm1d-29               [-1, 32, 16]              64
             ReLU-30               [-1, 32, 16]               0
          Dropout-31               [-1, 32, 16]               0
           Conv1d-32               [-1, 32, 16]             288
  MyConv1dPadSame-33               [-1, 32, 16]               0
       Bottleneck-34               [-1, 32, 16]               0
      BatchNorm1d-35               [-1, 32, 16]              64
             ReLU-36               [-1, 32, 16]               0
          Dropout-37               [-1, 32, 16]               0
           Conv1d-38               [-1, 32, 16]             288
  MyConv1dPadSame-39               [-1, 32, 16]               0
      BatchNorm1d-40               [-1, 32, 16]              64
             ReLU-41               [-1, 32, 16]               0
          Dropout-42               [-1, 32, 16]               0
           Conv1d-43               [-1, 32, 16]             288
  MyConv1dPadSame-44               [-1, 32, 16]               0
       Bottleneck-45               [-1, 32, 16]               0
      BatchNorm1d-46               [-1, 32, 16]              64
             ReLU-47               [-1, 32, 16]               0
          Dropout-48               [-1, 32, 16]               0
           Conv1d-49               [-1, 64, 16]             576
  MyConv1dPadSame-50               [-1, 64, 16]               0
      BatchNorm1d-51               [-1, 64, 16]             128
             ReLU-52               [-1, 64, 16]               0
          Dropout-53               [-1, 64, 16]               0
           Conv1d-54               [-1, 64, 16]           1,088
  MyConv1dPadSame-55               [-1, 64, 16]               0
       Bottleneck-56               [-1, 64, 16]               0
      BatchNorm1d-57               [-1, 64, 16]             128
             ReLU-58               [-1, 64, 16]               0
          Dropout-59               [-1, 64, 16]               0
           Conv1d-60               [-1, 64, 16]           1,088
  MyConv1dPadSame-61               [-1, 64, 16]               0
      BatchNorm1d-62               [-1, 64, 16]             128
             ReLU-63               [-1, 64, 16]               0
          Dropout-64               [-1, 64, 16]               0
           Conv1d-65               [-1, 64, 16]           1,088
  MyConv1dPadSame-66               [-1, 64, 16]               0
       Bottleneck-67               [-1, 64, 16]               0
      BatchNorm1d-68               [-1, 64, 16]             128
             ReLU-69               [-1, 64, 16]               0
          Dropout-70               [-1, 64, 16]               0
           Conv1d-71              [-1, 128, 16]           2,176
  MyConv1dPadSame-72              [-1, 128, 16]               0
      BatchNorm1d-73              [-1, 128, 16]             256
             ReLU-74              [-1, 128, 16]               0
          Dropout-75              [-1, 128, 16]               0
           Conv1d-76              [-1, 128, 16]           4,224
  MyConv1dPadSame-77              [-1, 128, 16]               0
       Bottleneck-78              [-1, 128, 16]               0
      BatchNorm1d-79              [-1, 128, 16]             256
             ReLU-80              [-1, 128, 16]               0
          Dropout-81              [-1, 128, 16]               0
           Conv1d-82              [-1, 128, 16]           4,224
  MyConv1dPadSame-83              [-1, 128, 16]               0
      BatchNorm1d-84              [-1, 128, 16]             256
             ReLU-85              [-1, 128, 16]               0
          Dropout-86              [-1, 128, 16]               0
           Conv1d-87              [-1, 128, 16]           4,224
  MyConv1dPadSame-88              [-1, 128, 16]               0
       Bottleneck-89              [-1, 128, 16]               0
      BatchNorm1d-90              [-1, 128, 16]             256
             ReLU-91              [-1, 128, 16]               0
           Linear-92                    [-1, 2]             258
================================================================
Total params: 22,322
Trainable params: 22,322
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.64
Params size (MB): 0.09
Estimated Total Size (MB): 0.72
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 16, kernel_size: 4, n_block: 16
************************************************************
************************************************************
(2000, 1, 16) Counter({0: 1000, 1: 1000})
(2000, 1, 16) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 16, 16]              80
   MyConv1dPadSame-2               [-1, 16, 16]               0
       BatchNorm1d-3               [-1, 16, 16]              32
              ReLU-4               [-1, 16, 16]               0
            Conv1d-5               [-1, 16, 16]              80
   MyConv1dPadSame-6               [-1, 16, 16]               0
       BatchNorm1d-7               [-1, 16, 16]              32
              ReLU-8               [-1, 16, 16]               0
           Dropout-9               [-1, 16, 16]               0
           Conv1d-10               [-1, 16, 16]              80
  MyConv1dPadSame-11               [-1, 16, 16]               0
       Bottleneck-12               [-1, 16, 16]               0
      BatchNorm1d-13               [-1, 16, 16]              32
             ReLU-14               [-1, 16, 16]               0
          Dropout-15               [-1, 16, 16]               0
           Conv1d-16                [-1, 16, 8]              80
  MyConv1dPadSame-17                [-1, 16, 8]               0
      BatchNorm1d-18                [-1, 16, 8]              32
             ReLU-19                [-1, 16, 8]               0
          Dropout-20                [-1, 16, 8]               0
           Conv1d-21                [-1, 16, 8]              80
  MyConv1dPadSame-22                [-1, 16, 8]               0
        MaxPool1d-23                [-1, 16, 8]               0
MyMaxPool1dPadSame-24                [-1, 16, 8]               0
       Bottleneck-25                [-1, 16, 8]               0
      BatchNorm1d-26                [-1, 16, 8]              32
             ReLU-27                [-1, 16, 8]               0
          Dropout-28                [-1, 16, 8]               0
           Conv1d-29                [-1, 16, 8]              80
  MyConv1dPadSame-30                [-1, 16, 8]               0
      BatchNorm1d-31                [-1, 16, 8]              32
             ReLU-32                [-1, 16, 8]               0
          Dropout-33                [-1, 16, 8]               0
           Conv1d-34                [-1, 16, 8]              80
  MyConv1dPadSame-35                [-1, 16, 8]               0
       Bottleneck-36                [-1, 16, 8]               0
      BatchNorm1d-37                [-1, 16, 8]              32
             ReLU-38                [-1, 16, 8]               0
          Dropout-39                [-1, 16, 8]               0
           Conv1d-40                [-1, 16, 4]              80
  MyConv1dPadSame-41                [-1, 16, 4]               0
      BatchNorm1d-42                [-1, 16, 4]              32
             ReLU-43                [-1, 16, 4]               0
          Dropout-44                [-1, 16, 4]               0
           Conv1d-45                [-1, 16, 4]              80
  MyConv1dPadSame-46                [-1, 16, 4]               0
        MaxPool1d-47                [-1, 16, 4]               0
MyMaxPool1dPadSame-48                [-1, 16, 4]               0
       Bottleneck-49                [-1, 16, 4]               0
      BatchNorm1d-50                [-1, 16, 4]              32
             ReLU-51                [-1, 16, 4]               0
          Dropout-52                [-1, 16, 4]               0
           Conv1d-53                [-1, 32, 4]             160
  MyConv1dPadSame-54                [-1, 32, 4]               0
      BatchNorm1d-55                [-1, 32, 4]              64
             ReLU-56                [-1, 32, 4]               0
          Dropout-57                [-1, 32, 4]               0
           Conv1d-58                [-1, 32, 4]             288
  MyConv1dPadSame-59                [-1, 32, 4]               0
       Bottleneck-60                [-1, 32, 4]               0
      BatchNorm1d-61                [-1, 32, 4]              64
             ReLU-62                [-1, 32, 4]               0
          Dropout-63                [-1, 32, 4]               0
           Conv1d-64                [-1, 32, 2]             288
  MyConv1dPadSame-65                [-1, 32, 2]               0
      BatchNorm1d-66                [-1, 32, 2]              64
             ReLU-67                [-1, 32, 2]               0
          Dropout-68                [-1, 32, 2]               0
           Conv1d-69                [-1, 32, 2]             288
  MyConv1dPadSame-70                [-1, 32, 2]               0
        MaxPool1d-71                [-1, 32, 2]               0
MyMaxPool1dPadSame-72                [-1, 32, 2]               0
       Bottleneck-73                [-1, 32, 2]               0
      BatchNorm1d-74                [-1, 32, 2]              64
             ReLU-75                [-1, 32, 2]               0
          Dropout-76                [-1, 32, 2]               0
           Conv1d-77                [-1, 32, 2]             288
  MyConv1dPadSame-78                [-1, 32, 2]               0
      BatchNorm1d-79                [-1, 32, 2]              64
             ReLU-80                [-1, 32, 2]               0
          Dropout-81                [-1, 32, 2]               0
           Conv1d-82                [-1, 32, 2]             288
  MyConv1dPadSame-83                [-1, 32, 2]               0
       Bottleneck-84                [-1, 32, 2]               0
      BatchNorm1d-85                [-1, 32, 2]              64
             ReLU-86                [-1, 32, 2]               0
          Dropout-87                [-1, 32, 2]               0
           Conv1d-88                [-1, 32, 1]             288
  MyConv1dPadSame-89                [-1, 32, 1]               0
      BatchNorm1d-90                [-1, 32, 1]              64
             ReLU-91                [-1, 32, 1]               0
          Dropout-92                [-1, 32, 1]               0
           Conv1d-93                [-1, 32, 1]             288
  MyConv1dPadSame-94                [-1, 32, 1]               0
        MaxPool1d-95                [-1, 32, 1]               0
MyMaxPool1dPadSame-96                [-1, 32, 1]               0
       Bottleneck-97                [-1, 32, 1]               0
      BatchNorm1d-98                [-1, 32, 1]              64
             ReLU-99                [-1, 32, 1]               0
         Dropout-100                [-1, 32, 1]               0
          Conv1d-101                [-1, 64, 1]             576
 MyConv1dPadSame-102                [-1, 64, 1]               0
     BatchNorm1d-103                [-1, 64, 1]             128
            ReLU-104                [-1, 64, 1]               0
         Dropout-105                [-1, 64, 1]               0
          Conv1d-106                [-1, 64, 1]           1,088
 MyConv1dPadSame-107                [-1, 64, 1]               0
      Bottleneck-108                [-1, 64, 1]               0
     BatchNorm1d-109                [-1, 64, 1]             128
            ReLU-110                [-1, 64, 1]               0
         Dropout-111                [-1, 64, 1]               0
          Conv1d-112                [-1, 64, 1]           1,088
 MyConv1dPadSame-113                [-1, 64, 1]               0
     BatchNorm1d-114                [-1, 64, 1]             128
            ReLU-115                [-1, 64, 1]               0
         Dropout-116                [-1, 64, 1]               0
          Conv1d-117                [-1, 64, 1]           1,088
 MyConv1dPadSame-118                [-1, 64, 1]               0
       MaxPool1d-119                [-1, 64, 1]               0
MyMaxPool1dPadSame-120                [-1, 64, 1]               0
      Bottleneck-121                [-1, 64, 1]               0
     BatchNorm1d-122                [-1, 64, 1]             128
            ReLU-123                [-1, 64, 1]               0
         Dropout-124                [-1, 64, 1]               0
          Conv1d-125                [-1, 64, 1]           1,088
 MyConv1dPadSame-126                [-1, 64, 1]               0
     BatchNorm1d-127                [-1, 64, 1]             128
            ReLU-128                [-1, 64, 1]               0
         Dropout-129                [-1, 64, 1]               0
          Conv1d-130                [-1, 64, 1]           1,088
 MyConv1dPadSame-131                [-1, 64, 1]               0
      Bottleneck-132                [-1, 64, 1]               0
     BatchNorm1d-133                [-1, 64, 1]             128
            ReLU-134                [-1, 64, 1]               0
         Dropout-135                [-1, 64, 1]               0
          Conv1d-136                [-1, 64, 1]           1,088
 MyConv1dPadSame-137                [-1, 64, 1]               0
     BatchNorm1d-138                [-1, 64, 1]             128
            ReLU-139                [-1, 64, 1]               0
         Dropout-140                [-1, 64, 1]               0
          Conv1d-141                [-1, 64, 1]           1,088
 MyConv1dPadSame-142                [-1, 64, 1]               0
       MaxPool1d-143                [-1, 64, 1]               0
MyMaxPool1dPadSame-144                [-1, 64, 1]               0
      Bottleneck-145                [-1, 64, 1]               0
     BatchNorm1d-146                [-1, 64, 1]             128
            ReLU-147                [-1, 64, 1]               0
         Dropout-148                [-1, 64, 1]               0
          Conv1d-149               [-1, 128, 1]           2,176
 MyConv1dPadSame-150               [-1, 128, 1]               0
     BatchNorm1d-151               [-1, 128, 1]             256
            ReLU-152               [-1, 128, 1]               0
         Dropout-153               [-1, 128, 1]               0
          Conv1d-154               [-1, 128, 1]           4,224
 MyConv1dPadSame-155               [-1, 128, 1]               0
      Bottleneck-156               [-1, 128, 1]               0
     BatchNorm1d-157               [-1, 128, 1]             256
            ReLU-158               [-1, 128, 1]               0
         Dropout-159               [-1, 128, 1]               0
          Conv1d-160               [-1, 128, 1]           4,224
 MyConv1dPadSame-161               [-1, 128, 1]               0
     BatchNorm1d-162               [-1, 128, 1]             256
            ReLU-163               [-1, 128, 1]               0
         Dropout-164               [-1, 128, 1]               0
          Conv1d-165               [-1, 128, 1]           4,224
 MyConv1dPadSame-166               [-1, 128, 1]               0
       MaxPool1d-167               [-1, 128, 1]               0
MyMaxPool1dPadSame-168               [-1, 128, 1]               0
      Bottleneck-169               [-1, 128, 1]               0
     BatchNorm1d-170               [-1, 128, 1]             256
            ReLU-171               [-1, 128, 1]               0
         Dropout-172               [-1, 128, 1]               0
          Conv1d-173               [-1, 128, 1]           4,224
 MyConv1dPadSame-174               [-1, 128, 1]               0
     BatchNorm1d-175               [-1, 128, 1]             256
            ReLU-176               [-1, 128, 1]               0
         Dropout-177               [-1, 128, 1]               0
          Conv1d-178               [-1, 128, 1]           4,224
 MyConv1dPadSame-179               [-1, 128, 1]               0
      Bottleneck-180               [-1, 128, 1]               0
     BatchNorm1d-181               [-1, 128, 1]             256
            ReLU-182               [-1, 128, 1]               0
         Dropout-183               [-1, 128, 1]               0
          Conv1d-184               [-1, 128, 1]           4,224
 MyConv1dPadSame-185               [-1, 128, 1]               0
     BatchNorm1d-186               [-1, 128, 1]             256
            ReLU-187               [-1, 128, 1]               0
         Dropout-188               [-1, 128, 1]               0
          Conv1d-189               [-1, 128, 1]           4,224
 MyConv1dPadSame-190               [-1, 128, 1]               0
       MaxPool1d-191               [-1, 128, 1]               0
MyMaxPool1dPadSame-192               [-1, 128, 1]               0
      Bottleneck-193               [-1, 128, 1]               0
     BatchNorm1d-194               [-1, 128, 1]             256
            ReLU-195               [-1, 128, 1]               0
          Linear-196                    [-1, 2]             258
================================================================
Total params: 46,962
Trainable params: 46,962
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.15
Params size (MB): 0.18
Estimated Total Size (MB): 0.33
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 16, kernel_size: 8, n_block: 2
************************************************************
************************************************************
(2000, 1, 16) Counter({1: 1000, 0: 1000})
(2000, 1, 16) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 16, 16]             144
   MyConv1dPadSame-2               [-1, 16, 16]               0
       BatchNorm1d-3               [-1, 16, 16]              32
              ReLU-4               [-1, 16, 16]               0
            Conv1d-5               [-1, 16, 16]             144
   MyConv1dPadSame-6               [-1, 16, 16]               0
       BatchNorm1d-7               [-1, 16, 16]              32
              ReLU-8               [-1, 16, 16]               0
           Dropout-9               [-1, 16, 16]               0
           Conv1d-10               [-1, 16, 16]             144
  MyConv1dPadSame-11               [-1, 16, 16]               0
       Bottleneck-12               [-1, 16, 16]               0
      BatchNorm1d-13               [-1, 16, 16]              32
             ReLU-14               [-1, 16, 16]               0
          Dropout-15               [-1, 16, 16]               0
           Conv1d-16               [-1, 32, 16]             288
  MyConv1dPadSame-17               [-1, 32, 16]               0
      BatchNorm1d-18               [-1, 32, 16]              64
             ReLU-19               [-1, 32, 16]               0
          Dropout-20               [-1, 32, 16]               0
           Conv1d-21               [-1, 32, 16]             544
  MyConv1dPadSame-22               [-1, 32, 16]               0
       Bottleneck-23               [-1, 32, 16]               0
      BatchNorm1d-24               [-1, 32, 16]              64
             ReLU-25               [-1, 32, 16]               0
           Linear-26                    [-1, 2]              66
================================================================
Total params: 1,554
Trainable params: 1,554
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.07
Params size (MB): 0.01
Estimated Total Size (MB): 0.07
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 16, kernel_size: 8, n_block: 4
************************************************************
************************************************************
(2000, 1, 16) Counter({1: 1000, 0: 1000})
(2000, 1, 16) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 16, 16]             144
   MyConv1dPadSame-2               [-1, 16, 16]               0
       BatchNorm1d-3               [-1, 16, 16]              32
              ReLU-4               [-1, 16, 16]               0
            Conv1d-5               [-1, 16, 16]             144
   MyConv1dPadSame-6               [-1, 16, 16]               0
       BatchNorm1d-7               [-1, 16, 16]              32
              ReLU-8               [-1, 16, 16]               0
           Dropout-9               [-1, 16, 16]               0
           Conv1d-10               [-1, 16, 16]             144
  MyConv1dPadSame-11               [-1, 16, 16]               0
       Bottleneck-12               [-1, 16, 16]               0
      BatchNorm1d-13               [-1, 16, 16]              32
             ReLU-14               [-1, 16, 16]               0
          Dropout-15               [-1, 16, 16]               0
           Conv1d-16               [-1, 32, 16]             288
  MyConv1dPadSame-17               [-1, 32, 16]               0
      BatchNorm1d-18               [-1, 32, 16]              64
             ReLU-19               [-1, 32, 16]               0
          Dropout-20               [-1, 32, 16]               0
           Conv1d-21               [-1, 32, 16]             544
  MyConv1dPadSame-22               [-1, 32, 16]               0
       Bottleneck-23               [-1, 32, 16]               0
      BatchNorm1d-24               [-1, 32, 16]              64
             ReLU-25               [-1, 32, 16]               0
          Dropout-26               [-1, 32, 16]               0
           Conv1d-27               [-1, 64, 16]           1,088
  MyConv1dPadSame-28               [-1, 64, 16]               0
      BatchNorm1d-29               [-1, 64, 16]             128
             ReLU-30               [-1, 64, 16]               0
          Dropout-31               [-1, 64, 16]               0
           Conv1d-32               [-1, 64, 16]           2,112
  MyConv1dPadSame-33               [-1, 64, 16]               0
       Bottleneck-34               [-1, 64, 16]               0
      BatchNorm1d-35               [-1, 64, 16]             128
             ReLU-36               [-1, 64, 16]               0
          Dropout-37               [-1, 64, 16]               0
           Conv1d-38              [-1, 128, 16]           4,224
  MyConv1dPadSame-39              [-1, 128, 16]               0
      BatchNorm1d-40              [-1, 128, 16]             256
             ReLU-41              [-1, 128, 16]               0
          Dropout-42              [-1, 128, 16]               0
           Conv1d-43              [-1, 128, 16]           8,320
  MyConv1dPadSame-44              [-1, 128, 16]               0
       Bottleneck-45              [-1, 128, 16]               0
      BatchNorm1d-46              [-1, 128, 16]             256
             ReLU-47              [-1, 128, 16]               0
           Linear-48                    [-1, 2]             258
================================================================
Total params: 18,258
Trainable params: 18,258
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.31
Params size (MB): 0.07
Estimated Total Size (MB): 0.38
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 16, kernel_size: 8, n_block: 8
************************************************************
************************************************************
(2000, 1, 16) Counter({1: 1000, 0: 1000})
(2000, 1, 16) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 16, 16]             144
   MyConv1dPadSame-2               [-1, 16, 16]               0
       BatchNorm1d-3               [-1, 16, 16]              32
              ReLU-4               [-1, 16, 16]               0
            Conv1d-5               [-1, 16, 16]             144
   MyConv1dPadSame-6               [-1, 16, 16]               0
       BatchNorm1d-7               [-1, 16, 16]              32
              ReLU-8               [-1, 16, 16]               0
           Dropout-9               [-1, 16, 16]               0
           Conv1d-10               [-1, 16, 16]             144
  MyConv1dPadSame-11               [-1, 16, 16]               0
       Bottleneck-12               [-1, 16, 16]               0
      BatchNorm1d-13               [-1, 16, 16]              32
             ReLU-14               [-1, 16, 16]               0
          Dropout-15               [-1, 16, 16]               0
           Conv1d-16               [-1, 16, 16]             144
  MyConv1dPadSame-17               [-1, 16, 16]               0
      BatchNorm1d-18               [-1, 16, 16]              32
             ReLU-19               [-1, 16, 16]               0
          Dropout-20               [-1, 16, 16]               0
           Conv1d-21               [-1, 16, 16]             144
  MyConv1dPadSame-22               [-1, 16, 16]               0
       Bottleneck-23               [-1, 16, 16]               0
      BatchNorm1d-24               [-1, 16, 16]              32
             ReLU-25               [-1, 16, 16]               0
          Dropout-26               [-1, 16, 16]               0
           Conv1d-27               [-1, 32, 16]             288
  MyConv1dPadSame-28               [-1, 32, 16]               0
      BatchNorm1d-29               [-1, 32, 16]              64
             ReLU-30               [-1, 32, 16]               0
          Dropout-31               [-1, 32, 16]               0
           Conv1d-32               [-1, 32, 16]             544
  MyConv1dPadSame-33               [-1, 32, 16]               0
       Bottleneck-34               [-1, 32, 16]               0
      BatchNorm1d-35               [-1, 32, 16]              64
             ReLU-36               [-1, 32, 16]               0
          Dropout-37               [-1, 32, 16]               0
           Conv1d-38               [-1, 32, 16]             544
  MyConv1dPadSame-39               [-1, 32, 16]               0
      BatchNorm1d-40               [-1, 32, 16]              64
             ReLU-41               [-1, 32, 16]               0
          Dropout-42               [-1, 32, 16]               0
           Conv1d-43               [-1, 32, 16]             544
  MyConv1dPadSame-44               [-1, 32, 16]               0
       Bottleneck-45               [-1, 32, 16]               0
      BatchNorm1d-46               [-1, 32, 16]              64
             ReLU-47               [-1, 32, 16]               0
          Dropout-48               [-1, 32, 16]               0
           Conv1d-49               [-1, 64, 16]           1,088
  MyConv1dPadSame-50               [-1, 64, 16]               0
      BatchNorm1d-51               [-1, 64, 16]             128
             ReLU-52               [-1, 64, 16]               0
          Dropout-53               [-1, 64, 16]               0
           Conv1d-54               [-1, 64, 16]           2,112
  MyConv1dPadSame-55               [-1, 64, 16]               0
       Bottleneck-56               [-1, 64, 16]               0
      BatchNorm1d-57               [-1, 64, 16]             128
             ReLU-58               [-1, 64, 16]               0
          Dropout-59               [-1, 64, 16]               0
           Conv1d-60               [-1, 64, 16]           2,112
  MyConv1dPadSame-61               [-1, 64, 16]               0
      BatchNorm1d-62               [-1, 64, 16]             128
             ReLU-63               [-1, 64, 16]               0
          Dropout-64               [-1, 64, 16]               0
           Conv1d-65               [-1, 64, 16]           2,112
  MyConv1dPadSame-66               [-1, 64, 16]               0
       Bottleneck-67               [-1, 64, 16]               0
      BatchNorm1d-68               [-1, 64, 16]             128
             ReLU-69               [-1, 64, 16]               0
          Dropout-70               [-1, 64, 16]               0
           Conv1d-71              [-1, 128, 16]           4,224
  MyConv1dPadSame-72              [-1, 128, 16]               0
      BatchNorm1d-73              [-1, 128, 16]             256
             ReLU-74              [-1, 128, 16]               0
          Dropout-75              [-1, 128, 16]               0
           Conv1d-76              [-1, 128, 16]           8,320
  MyConv1dPadSame-77              [-1, 128, 16]               0
       Bottleneck-78              [-1, 128, 16]               0
      BatchNorm1d-79              [-1, 128, 16]             256
             ReLU-80              [-1, 128, 16]               0
          Dropout-81              [-1, 128, 16]               0
           Conv1d-82              [-1, 128, 16]           8,320
  MyConv1dPadSame-83              [-1, 128, 16]               0
      BatchNorm1d-84              [-1, 128, 16]             256
             ReLU-85              [-1, 128, 16]               0
          Dropout-86              [-1, 128, 16]               0
           Conv1d-87              [-1, 128, 16]           8,320
  MyConv1dPadSame-88              [-1, 128, 16]               0
       Bottleneck-89              [-1, 128, 16]               0
      BatchNorm1d-90              [-1, 128, 16]             256
             ReLU-91              [-1, 128, 16]               0
           Linear-92                    [-1, 2]             258
================================================================
Total params: 41,458
Trainable params: 41,458
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.64
Params size (MB): 0.16
Estimated Total Size (MB): 0.79
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 16, kernel_size: 8, n_block: 16
************************************************************
************************************************************
(2000, 1, 16) Counter({1: 1000, 0: 1000})
(2000, 1, 16) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 16, 16]             144
   MyConv1dPadSame-2               [-1, 16, 16]               0
       BatchNorm1d-3               [-1, 16, 16]              32
              ReLU-4               [-1, 16, 16]               0
            Conv1d-5               [-1, 16, 16]             144
   MyConv1dPadSame-6               [-1, 16, 16]               0
       BatchNorm1d-7               [-1, 16, 16]              32
              ReLU-8               [-1, 16, 16]               0
           Dropout-9               [-1, 16, 16]               0
           Conv1d-10               [-1, 16, 16]             144
  MyConv1dPadSame-11               [-1, 16, 16]               0
       Bottleneck-12               [-1, 16, 16]               0
      BatchNorm1d-13               [-1, 16, 16]              32
             ReLU-14               [-1, 16, 16]               0
          Dropout-15               [-1, 16, 16]               0
           Conv1d-16                [-1, 16, 8]             144
  MyConv1dPadSame-17                [-1, 16, 8]               0
      BatchNorm1d-18                [-1, 16, 8]              32
             ReLU-19                [-1, 16, 8]               0
          Dropout-20                [-1, 16, 8]               0
           Conv1d-21                [-1, 16, 8]             144
  MyConv1dPadSame-22                [-1, 16, 8]               0
        MaxPool1d-23                [-1, 16, 8]               0
MyMaxPool1dPadSame-24                [-1, 16, 8]               0
       Bottleneck-25                [-1, 16, 8]               0
      BatchNorm1d-26                [-1, 16, 8]              32
             ReLU-27                [-1, 16, 8]               0
          Dropout-28                [-1, 16, 8]               0
           Conv1d-29                [-1, 16, 8]             144
  MyConv1dPadSame-30                [-1, 16, 8]               0
      BatchNorm1d-31                [-1, 16, 8]              32
             ReLU-32                [-1, 16, 8]               0
          Dropout-33                [-1, 16, 8]               0
           Conv1d-34                [-1, 16, 8]             144
  MyConv1dPadSame-35                [-1, 16, 8]               0
       Bottleneck-36                [-1, 16, 8]               0
      BatchNorm1d-37                [-1, 16, 8]              32
             ReLU-38                [-1, 16, 8]               0
          Dropout-39                [-1, 16, 8]               0
           Conv1d-40                [-1, 16, 4]             144
  MyConv1dPadSame-41                [-1, 16, 4]               0
      BatchNorm1d-42                [-1, 16, 4]              32
             ReLU-43                [-1, 16, 4]               0
          Dropout-44                [-1, 16, 4]               0
           Conv1d-45                [-1, 16, 4]             144
  MyConv1dPadSame-46                [-1, 16, 4]               0
        MaxPool1d-47                [-1, 16, 4]               0
MyMaxPool1dPadSame-48                [-1, 16, 4]               0
       Bottleneck-49                [-1, 16, 4]               0
      BatchNorm1d-50                [-1, 16, 4]              32
             ReLU-51                [-1, 16, 4]               0
          Dropout-52                [-1, 16, 4]               0
           Conv1d-53                [-1, 32, 4]             288
  MyConv1dPadSame-54                [-1, 32, 4]               0
      BatchNorm1d-55                [-1, 32, 4]              64
             ReLU-56                [-1, 32, 4]               0
          Dropout-57                [-1, 32, 4]               0
           Conv1d-58                [-1, 32, 4]             544
  MyConv1dPadSame-59                [-1, 32, 4]               0
       Bottleneck-60                [-1, 32, 4]               0
      BatchNorm1d-61                [-1, 32, 4]              64
             ReLU-62                [-1, 32, 4]               0
          Dropout-63                [-1, 32, 4]               0
           Conv1d-64                [-1, 32, 2]             544
  MyConv1dPadSame-65                [-1, 32, 2]               0
      BatchNorm1d-66                [-1, 32, 2]              64
             ReLU-67                [-1, 32, 2]               0
          Dropout-68                [-1, 32, 2]               0
           Conv1d-69                [-1, 32, 2]             544
  MyConv1dPadSame-70                [-1, 32, 2]               0
        MaxPool1d-71                [-1, 32, 2]               0
MyMaxPool1dPadSame-72                [-1, 32, 2]               0
       Bottleneck-73                [-1, 32, 2]               0
      BatchNorm1d-74                [-1, 32, 2]              64
             ReLU-75                [-1, 32, 2]               0
          Dropout-76                [-1, 32, 2]               0
           Conv1d-77                [-1, 32, 2]             544
  MyConv1dPadSame-78                [-1, 32, 2]               0
      BatchNorm1d-79                [-1, 32, 2]              64
             ReLU-80                [-1, 32, 2]               0
          Dropout-81                [-1, 32, 2]               0
           Conv1d-82                [-1, 32, 2]             544
  MyConv1dPadSame-83                [-1, 32, 2]               0
       Bottleneck-84                [-1, 32, 2]               0
      BatchNorm1d-85                [-1, 32, 2]              64
             ReLU-86                [-1, 32, 2]               0
          Dropout-87                [-1, 32, 2]               0
           Conv1d-88                [-1, 32, 1]             544
  MyConv1dPadSame-89                [-1, 32, 1]               0
      BatchNorm1d-90                [-1, 32, 1]              64
             ReLU-91                [-1, 32, 1]               0
          Dropout-92                [-1, 32, 1]               0
           Conv1d-93                [-1, 32, 1]             544
  MyConv1dPadSame-94                [-1, 32, 1]               0
        MaxPool1d-95                [-1, 32, 1]               0
MyMaxPool1dPadSame-96                [-1, 32, 1]               0
       Bottleneck-97                [-1, 32, 1]               0
      BatchNorm1d-98                [-1, 32, 1]              64
             ReLU-99                [-1, 32, 1]               0
         Dropout-100                [-1, 32, 1]               0
          Conv1d-101                [-1, 64, 1]           1,088
 MyConv1dPadSame-102                [-1, 64, 1]               0
     BatchNorm1d-103                [-1, 64, 1]             128
            ReLU-104                [-1, 64, 1]               0
         Dropout-105                [-1, 64, 1]               0
          Conv1d-106                [-1, 64, 1]           2,112
 MyConv1dPadSame-107                [-1, 64, 1]               0
      Bottleneck-108                [-1, 64, 1]               0
     BatchNorm1d-109                [-1, 64, 1]             128
            ReLU-110                [-1, 64, 1]               0
         Dropout-111                [-1, 64, 1]               0
          Conv1d-112                [-1, 64, 1]           2,112
 MyConv1dPadSame-113                [-1, 64, 1]               0
     BatchNorm1d-114                [-1, 64, 1]             128
            ReLU-115                [-1, 64, 1]               0
         Dropout-116                [-1, 64, 1]               0
          Conv1d-117                [-1, 64, 1]           2,112
 MyConv1dPadSame-118                [-1, 64, 1]               0
       MaxPool1d-119                [-1, 64, 1]               0
MyMaxPool1dPadSame-120                [-1, 64, 1]               0
      Bottleneck-121                [-1, 64, 1]               0
     BatchNorm1d-122                [-1, 64, 1]             128
            ReLU-123                [-1, 64, 1]               0
         Dropout-124                [-1, 64, 1]               0
          Conv1d-125                [-1, 64, 1]           2,112
 MyConv1dPadSame-126                [-1, 64, 1]               0
     BatchNorm1d-127                [-1, 64, 1]             128
            ReLU-128                [-1, 64, 1]               0
         Dropout-129                [-1, 64, 1]               0
          Conv1d-130                [-1, 64, 1]           2,112
 MyConv1dPadSame-131                [-1, 64, 1]               0
      Bottleneck-132                [-1, 64, 1]               0
     BatchNorm1d-133                [-1, 64, 1]             128
            ReLU-134                [-1, 64, 1]               0
         Dropout-135                [-1, 64, 1]               0
          Conv1d-136                [-1, 64, 1]           2,112
 MyConv1dPadSame-137                [-1, 64, 1]               0
     BatchNorm1d-138                [-1, 64, 1]             128
            ReLU-139                [-1, 64, 1]               0
         Dropout-140                [-1, 64, 1]               0
          Conv1d-141                [-1, 64, 1]           2,112
 MyConv1dPadSame-142                [-1, 64, 1]               0
       MaxPool1d-143                [-1, 64, 1]               0
MyMaxPool1dPadSame-144                [-1, 64, 1]               0
      Bottleneck-145                [-1, 64, 1]               0
     BatchNorm1d-146                [-1, 64, 1]             128
            ReLU-147                [-1, 64, 1]               0
         Dropout-148                [-1, 64, 1]               0
          Conv1d-149               [-1, 128, 1]           4,224
 MyConv1dPadSame-150               [-1, 128, 1]               0
     BatchNorm1d-151               [-1, 128, 1]             256
            ReLU-152               [-1, 128, 1]               0
         Dropout-153               [-1, 128, 1]               0
          Conv1d-154               [-1, 128, 1]           8,320
 MyConv1dPadSame-155               [-1, 128, 1]               0
      Bottleneck-156               [-1, 128, 1]               0
     BatchNorm1d-157               [-1, 128, 1]             256
            ReLU-158               [-1, 128, 1]               0
         Dropout-159               [-1, 128, 1]               0
          Conv1d-160               [-1, 128, 1]           8,320
 MyConv1dPadSame-161               [-1, 128, 1]               0
     BatchNorm1d-162               [-1, 128, 1]             256
            ReLU-163               [-1, 128, 1]               0
         Dropout-164               [-1, 128, 1]               0
          Conv1d-165               [-1, 128, 1]           8,320
 MyConv1dPadSame-166               [-1, 128, 1]               0
       MaxPool1d-167               [-1, 128, 1]               0
MyMaxPool1dPadSame-168               [-1, 128, 1]               0
      Bottleneck-169               [-1, 128, 1]               0
     BatchNorm1d-170               [-1, 128, 1]             256
            ReLU-171               [-1, 128, 1]               0
         Dropout-172               [-1, 128, 1]               0
          Conv1d-173               [-1, 128, 1]           8,320
 MyConv1dPadSame-174               [-1, 128, 1]               0
     BatchNorm1d-175               [-1, 128, 1]             256
            ReLU-176               [-1, 128, 1]               0
         Dropout-177               [-1, 128, 1]               0
          Conv1d-178               [-1, 128, 1]           8,320
 MyConv1dPadSame-179               [-1, 128, 1]               0
      Bottleneck-180               [-1, 128, 1]               0
     BatchNorm1d-181               [-1, 128, 1]             256
            ReLU-182               [-1, 128, 1]               0
         Dropout-183               [-1, 128, 1]               0
          Conv1d-184               [-1, 128, 1]           8,320
 MyConv1dPadSame-185               [-1, 128, 1]               0
     BatchNorm1d-186               [-1, 128, 1]             256
            ReLU-187               [-1, 128, 1]               0
         Dropout-188               [-1, 128, 1]               0
          Conv1d-189               [-1, 128, 1]           8,320
 MyConv1dPadSame-190               [-1, 128, 1]               0
       MaxPool1d-191               [-1, 128, 1]               0
MyMaxPool1dPadSame-192               [-1, 128, 1]               0
      Bottleneck-193               [-1, 128, 1]               0
     BatchNorm1d-194               [-1, 128, 1]             256
            ReLU-195               [-1, 128, 1]               0
          Linear-196                    [-1, 2]             258
================================================================
Total params: 87,858
Trainable params: 87,858
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.15
Params size (MB): 0.34
Estimated Total Size (MB): 0.49
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 16, kernel_size: 16, n_block: 2
************************************************************
************************************************************
(2000, 1, 16) Counter({1: 1000, 0: 1000})
(2000, 1, 16) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 16, 16]             272
   MyConv1dPadSame-2               [-1, 16, 16]               0
       BatchNorm1d-3               [-1, 16, 16]              32
              ReLU-4               [-1, 16, 16]               0
            Conv1d-5               [-1, 16, 16]             272
   MyConv1dPadSame-6               [-1, 16, 16]               0
       BatchNorm1d-7               [-1, 16, 16]              32
              ReLU-8               [-1, 16, 16]               0
           Dropout-9               [-1, 16, 16]               0
           Conv1d-10               [-1, 16, 16]             272
  MyConv1dPadSame-11               [-1, 16, 16]               0
       Bottleneck-12               [-1, 16, 16]               0
      BatchNorm1d-13               [-1, 16, 16]              32
             ReLU-14               [-1, 16, 16]               0
          Dropout-15               [-1, 16, 16]               0
           Conv1d-16               [-1, 32, 16]             544
  MyConv1dPadSame-17               [-1, 32, 16]               0
      BatchNorm1d-18               [-1, 32, 16]              64
             ReLU-19               [-1, 32, 16]               0
          Dropout-20               [-1, 32, 16]               0
           Conv1d-21               [-1, 32, 16]           1,056
  MyConv1dPadSame-22               [-1, 32, 16]               0
       Bottleneck-23               [-1, 32, 16]               0
      BatchNorm1d-24               [-1, 32, 16]              64
             ReLU-25               [-1, 32, 16]               0
           Linear-26                    [-1, 2]              66
================================================================
Total params: 2,706
Trainable params: 2,706
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.07
Params size (MB): 0.01
Estimated Total Size (MB): 0.08
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 16, kernel_size: 16, n_block: 4
************************************************************
************************************************************
(2000, 1, 16) Counter({1: 1000, 0: 1000})
(2000, 1, 16) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 16, 16]             272
   MyConv1dPadSame-2               [-1, 16, 16]               0
       BatchNorm1d-3               [-1, 16, 16]              32
              ReLU-4               [-1, 16, 16]               0
            Conv1d-5               [-1, 16, 16]             272
   MyConv1dPadSame-6               [-1, 16, 16]               0
       BatchNorm1d-7               [-1, 16, 16]              32
              ReLU-8               [-1, 16, 16]               0
           Dropout-9               [-1, 16, 16]               0
           Conv1d-10               [-1, 16, 16]             272
  MyConv1dPadSame-11               [-1, 16, 16]               0
       Bottleneck-12               [-1, 16, 16]               0
      BatchNorm1d-13               [-1, 16, 16]              32
             ReLU-14               [-1, 16, 16]               0
          Dropout-15               [-1, 16, 16]               0
           Conv1d-16               [-1, 32, 16]             544
  MyConv1dPadSame-17               [-1, 32, 16]               0
      BatchNorm1d-18               [-1, 32, 16]              64
             ReLU-19               [-1, 32, 16]               0
          Dropout-20               [-1, 32, 16]               0
           Conv1d-21               [-1, 32, 16]           1,056
  MyConv1dPadSame-22               [-1, 32, 16]               0
       Bottleneck-23               [-1, 32, 16]               0
      BatchNorm1d-24               [-1, 32, 16]              64
             ReLU-25               [-1, 32, 16]               0
          Dropout-26               [-1, 32, 16]               0
           Conv1d-27               [-1, 64, 16]           2,112
  MyConv1dPadSame-28               [-1, 64, 16]               0
      BatchNorm1d-29               [-1, 64, 16]             128
             ReLU-30               [-1, 64, 16]               0
          Dropout-31               [-1, 64, 16]               0
           Conv1d-32               [-1, 64, 16]           4,160
  MyConv1dPadSame-33               [-1, 64, 16]               0
       Bottleneck-34               [-1, 64, 16]               0
      BatchNorm1d-35               [-1, 64, 16]             128
             ReLU-36               [-1, 64, 16]               0
          Dropout-37               [-1, 64, 16]               0
           Conv1d-38              [-1, 128, 16]           8,320
  MyConv1dPadSame-39              [-1, 128, 16]               0
      BatchNorm1d-40              [-1, 128, 16]             256
             ReLU-41              [-1, 128, 16]               0
          Dropout-42              [-1, 128, 16]               0
           Conv1d-43              [-1, 128, 16]          16,512
  MyConv1dPadSame-44              [-1, 128, 16]               0
       Bottleneck-45              [-1, 128, 16]               0
      BatchNorm1d-46              [-1, 128, 16]             256
             ReLU-47              [-1, 128, 16]               0
           Linear-48                    [-1, 2]             258
================================================================
Total params: 34,770
Trainable params: 34,770
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.31
Params size (MB): 0.13
Estimated Total Size (MB): 0.45
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 16, kernel_size: 16, n_block: 8
************************************************************
************************************************************
(2000, 1, 16) Counter({0: 1000, 1: 1000})
(2000, 1, 16) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 16, 16]             272
   MyConv1dPadSame-2               [-1, 16, 16]               0
       BatchNorm1d-3               [-1, 16, 16]              32
              ReLU-4               [-1, 16, 16]               0
            Conv1d-5               [-1, 16, 16]             272
   MyConv1dPadSame-6               [-1, 16, 16]               0
       BatchNorm1d-7               [-1, 16, 16]              32
              ReLU-8               [-1, 16, 16]               0
           Dropout-9               [-1, 16, 16]               0
           Conv1d-10               [-1, 16, 16]             272
  MyConv1dPadSame-11               [-1, 16, 16]               0
       Bottleneck-12               [-1, 16, 16]               0
      BatchNorm1d-13               [-1, 16, 16]              32
             ReLU-14               [-1, 16, 16]               0
          Dropout-15               [-1, 16, 16]               0
           Conv1d-16               [-1, 16, 16]             272
  MyConv1dPadSame-17               [-1, 16, 16]               0
      BatchNorm1d-18               [-1, 16, 16]              32
             ReLU-19               [-1, 16, 16]               0
          Dropout-20               [-1, 16, 16]               0
           Conv1d-21               [-1, 16, 16]             272
  MyConv1dPadSame-22               [-1, 16, 16]               0
       Bottleneck-23               [-1, 16, 16]               0
      BatchNorm1d-24               [-1, 16, 16]              32
             ReLU-25               [-1, 16, 16]               0
          Dropout-26               [-1, 16, 16]               0
           Conv1d-27               [-1, 32, 16]             544
  MyConv1dPadSame-28               [-1, 32, 16]               0
      BatchNorm1d-29               [-1, 32, 16]              64
             ReLU-30               [-1, 32, 16]               0
          Dropout-31               [-1, 32, 16]               0
           Conv1d-32               [-1, 32, 16]           1,056
  MyConv1dPadSame-33               [-1, 32, 16]               0
       Bottleneck-34               [-1, 32, 16]               0
      BatchNorm1d-35               [-1, 32, 16]              64
             ReLU-36               [-1, 32, 16]               0
          Dropout-37               [-1, 32, 16]               0
           Conv1d-38               [-1, 32, 16]           1,056
  MyConv1dPadSame-39               [-1, 32, 16]               0
      BatchNorm1d-40               [-1, 32, 16]              64
             ReLU-41               [-1, 32, 16]               0
          Dropout-42               [-1, 32, 16]               0
           Conv1d-43               [-1, 32, 16]           1,056
  MyConv1dPadSame-44               [-1, 32, 16]               0
       Bottleneck-45               [-1, 32, 16]               0
      BatchNorm1d-46               [-1, 32, 16]              64
             ReLU-47               [-1, 32, 16]               0
          Dropout-48               [-1, 32, 16]               0
           Conv1d-49               [-1, 64, 16]           2,112
  MyConv1dPadSame-50               [-1, 64, 16]               0
      BatchNorm1d-51               [-1, 64, 16]             128
             ReLU-52               [-1, 64, 16]               0
          Dropout-53               [-1, 64, 16]               0
           Conv1d-54               [-1, 64, 16]           4,160
  MyConv1dPadSame-55               [-1, 64, 16]               0
       Bottleneck-56               [-1, 64, 16]               0
      BatchNorm1d-57               [-1, 64, 16]             128
             ReLU-58               [-1, 64, 16]               0
          Dropout-59               [-1, 64, 16]               0
           Conv1d-60               [-1, 64, 16]           4,160
  MyConv1dPadSame-61               [-1, 64, 16]               0
      BatchNorm1d-62               [-1, 64, 16]             128
             ReLU-63               [-1, 64, 16]               0
          Dropout-64               [-1, 64, 16]               0
           Conv1d-65               [-1, 64, 16]           4,160
  MyConv1dPadSame-66               [-1, 64, 16]               0
       Bottleneck-67               [-1, 64, 16]               0
      BatchNorm1d-68               [-1, 64, 16]             128
             ReLU-69               [-1, 64, 16]               0
          Dropout-70               [-1, 64, 16]               0
           Conv1d-71              [-1, 128, 16]           8,320
  MyConv1dPadSame-72              [-1, 128, 16]               0
      BatchNorm1d-73              [-1, 128, 16]             256
             ReLU-74              [-1, 128, 16]               0
          Dropout-75              [-1, 128, 16]               0
           Conv1d-76              [-1, 128, 16]          16,512
  MyConv1dPadSame-77              [-1, 128, 16]               0
       Bottleneck-78              [-1, 128, 16]               0
      BatchNorm1d-79              [-1, 128, 16]             256
             ReLU-80              [-1, 128, 16]               0
          Dropout-81              [-1, 128, 16]               0
           Conv1d-82              [-1, 128, 16]          16,512
  MyConv1dPadSame-83              [-1, 128, 16]               0
      BatchNorm1d-84              [-1, 128, 16]             256
             ReLU-85              [-1, 128, 16]               0
          Dropout-86              [-1, 128, 16]               0
           Conv1d-87              [-1, 128, 16]          16,512
  MyConv1dPadSame-88              [-1, 128, 16]               0
       Bottleneck-89              [-1, 128, 16]               0
      BatchNorm1d-90              [-1, 128, 16]             256
             ReLU-91              [-1, 128, 16]               0
           Linear-92                    [-1, 2]             258
================================================================
Total params: 79,730
Trainable params: 79,730
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.64
Params size (MB): 0.30
Estimated Total Size (MB): 0.94
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 16, kernel_size: 16, n_block: 16
************************************************************
************************************************************
(2000, 1, 16) Counter({0: 1000, 1: 1000})
(2000, 1, 16) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 16, 16]             272
   MyConv1dPadSame-2               [-1, 16, 16]               0
       BatchNorm1d-3               [-1, 16, 16]              32
              ReLU-4               [-1, 16, 16]               0
            Conv1d-5               [-1, 16, 16]             272
   MyConv1dPadSame-6               [-1, 16, 16]               0
       BatchNorm1d-7               [-1, 16, 16]              32
              ReLU-8               [-1, 16, 16]               0
           Dropout-9               [-1, 16, 16]               0
           Conv1d-10               [-1, 16, 16]             272
  MyConv1dPadSame-11               [-1, 16, 16]               0
       Bottleneck-12               [-1, 16, 16]               0
      BatchNorm1d-13               [-1, 16, 16]              32
             ReLU-14               [-1, 16, 16]               0
          Dropout-15               [-1, 16, 16]               0
           Conv1d-16                [-1, 16, 8]             272
  MyConv1dPadSame-17                [-1, 16, 8]               0
      BatchNorm1d-18                [-1, 16, 8]              32
             ReLU-19                [-1, 16, 8]               0
          Dropout-20                [-1, 16, 8]               0
           Conv1d-21                [-1, 16, 8]             272
  MyConv1dPadSame-22                [-1, 16, 8]               0
        MaxPool1d-23                [-1, 16, 8]               0
MyMaxPool1dPadSame-24                [-1, 16, 8]               0
       Bottleneck-25                [-1, 16, 8]               0
      BatchNorm1d-26                [-1, 16, 8]              32
             ReLU-27                [-1, 16, 8]               0
          Dropout-28                [-1, 16, 8]               0
           Conv1d-29                [-1, 16, 8]             272
  MyConv1dPadSame-30                [-1, 16, 8]               0
      BatchNorm1d-31                [-1, 16, 8]              32
             ReLU-32                [-1, 16, 8]               0
          Dropout-33                [-1, 16, 8]               0
           Conv1d-34                [-1, 16, 8]             272
  MyConv1dPadSame-35                [-1, 16, 8]               0
       Bottleneck-36                [-1, 16, 8]               0
      BatchNorm1d-37                [-1, 16, 8]              32
             ReLU-38                [-1, 16, 8]               0
          Dropout-39                [-1, 16, 8]               0
           Conv1d-40                [-1, 16, 4]             272
  MyConv1dPadSame-41                [-1, 16, 4]               0
      BatchNorm1d-42                [-1, 16, 4]              32
             ReLU-43                [-1, 16, 4]               0
          Dropout-44                [-1, 16, 4]               0
           Conv1d-45                [-1, 16, 4]             272
  MyConv1dPadSame-46                [-1, 16, 4]               0
        MaxPool1d-47                [-1, 16, 4]               0
MyMaxPool1dPadSame-48                [-1, 16, 4]               0
       Bottleneck-49                [-1, 16, 4]               0
      BatchNorm1d-50                [-1, 16, 4]              32
             ReLU-51                [-1, 16, 4]               0
          Dropout-52                [-1, 16, 4]               0
           Conv1d-53                [-1, 32, 4]             544
  MyConv1dPadSame-54                [-1, 32, 4]               0
      BatchNorm1d-55                [-1, 32, 4]              64
             ReLU-56                [-1, 32, 4]               0
          Dropout-57                [-1, 32, 4]               0
           Conv1d-58                [-1, 32, 4]           1,056
  MyConv1dPadSame-59                [-1, 32, 4]               0
       Bottleneck-60                [-1, 32, 4]               0
      BatchNorm1d-61                [-1, 32, 4]              64
             ReLU-62                [-1, 32, 4]               0
          Dropout-63                [-1, 32, 4]               0
           Conv1d-64                [-1, 32, 2]           1,056
  MyConv1dPadSame-65                [-1, 32, 2]               0
      BatchNorm1d-66                [-1, 32, 2]              64
             ReLU-67                [-1, 32, 2]               0
          Dropout-68                [-1, 32, 2]               0
           Conv1d-69                [-1, 32, 2]           1,056
  MyConv1dPadSame-70                [-1, 32, 2]               0
        MaxPool1d-71                [-1, 32, 2]               0
MyMaxPool1dPadSame-72                [-1, 32, 2]               0
       Bottleneck-73                [-1, 32, 2]               0
      BatchNorm1d-74                [-1, 32, 2]              64
             ReLU-75                [-1, 32, 2]               0
          Dropout-76                [-1, 32, 2]               0
           Conv1d-77                [-1, 32, 2]           1,056
  MyConv1dPadSame-78                [-1, 32, 2]               0
      BatchNorm1d-79                [-1, 32, 2]              64
             ReLU-80                [-1, 32, 2]               0
          Dropout-81                [-1, 32, 2]               0
           Conv1d-82                [-1, 32, 2]           1,056
  MyConv1dPadSame-83                [-1, 32, 2]               0
       Bottleneck-84                [-1, 32, 2]               0
      BatchNorm1d-85                [-1, 32, 2]              64
             ReLU-86                [-1, 32, 2]               0
          Dropout-87                [-1, 32, 2]               0
           Conv1d-88                [-1, 32, 1]           1,056
  MyConv1dPadSame-89                [-1, 32, 1]               0
      BatchNorm1d-90                [-1, 32, 1]              64
             ReLU-91                [-1, 32, 1]               0
          Dropout-92                [-1, 32, 1]               0
           Conv1d-93                [-1, 32, 1]           1,056
  MyConv1dPadSame-94                [-1, 32, 1]               0
        MaxPool1d-95                [-1, 32, 1]               0
MyMaxPool1dPadSame-96                [-1, 32, 1]               0
       Bottleneck-97                [-1, 32, 1]               0
      BatchNorm1d-98                [-1, 32, 1]              64
             ReLU-99                [-1, 32, 1]               0
         Dropout-100                [-1, 32, 1]               0
          Conv1d-101                [-1, 64, 1]           2,112
 MyConv1dPadSame-102                [-1, 64, 1]               0
     BatchNorm1d-103                [-1, 64, 1]             128
            ReLU-104                [-1, 64, 1]               0
         Dropout-105                [-1, 64, 1]               0
          Conv1d-106                [-1, 64, 1]           4,160
 MyConv1dPadSame-107                [-1, 64, 1]               0
      Bottleneck-108                [-1, 64, 1]               0
     BatchNorm1d-109                [-1, 64, 1]             128
            ReLU-110                [-1, 64, 1]               0
         Dropout-111                [-1, 64, 1]               0
          Conv1d-112                [-1, 64, 1]           4,160
 MyConv1dPadSame-113                [-1, 64, 1]               0
     BatchNorm1d-114                [-1, 64, 1]             128
            ReLU-115                [-1, 64, 1]               0
         Dropout-116                [-1, 64, 1]               0
          Conv1d-117                [-1, 64, 1]           4,160
 MyConv1dPadSame-118                [-1, 64, 1]               0
       MaxPool1d-119                [-1, 64, 1]               0
MyMaxPool1dPadSame-120                [-1, 64, 1]               0
      Bottleneck-121                [-1, 64, 1]               0
     BatchNorm1d-122                [-1, 64, 1]             128
            ReLU-123                [-1, 64, 1]               0
         Dropout-124                [-1, 64, 1]               0
          Conv1d-125                [-1, 64, 1]           4,160
 MyConv1dPadSame-126                [-1, 64, 1]               0
     BatchNorm1d-127                [-1, 64, 1]             128
            ReLU-128                [-1, 64, 1]               0
         Dropout-129                [-1, 64, 1]               0
          Conv1d-130                [-1, 64, 1]           4,160
 MyConv1dPadSame-131                [-1, 64, 1]               0
      Bottleneck-132                [-1, 64, 1]               0
     BatchNorm1d-133                [-1, 64, 1]             128
            ReLU-134                [-1, 64, 1]               0
         Dropout-135                [-1, 64, 1]               0
          Conv1d-136                [-1, 64, 1]           4,160
 MyConv1dPadSame-137                [-1, 64, 1]               0
     BatchNorm1d-138                [-1, 64, 1]             128
            ReLU-139                [-1, 64, 1]               0
         Dropout-140                [-1, 64, 1]               0
          Conv1d-141                [-1, 64, 1]           4,160
 MyConv1dPadSame-142                [-1, 64, 1]               0
       MaxPool1d-143                [-1, 64, 1]               0
MyMaxPool1dPadSame-144                [-1, 64, 1]               0
      Bottleneck-145                [-1, 64, 1]               0
     BatchNorm1d-146                [-1, 64, 1]             128
            ReLU-147                [-1, 64, 1]               0
         Dropout-148                [-1, 64, 1]               0
          Conv1d-149               [-1, 128, 1]           8,320
 MyConv1dPadSame-150               [-1, 128, 1]               0
     BatchNorm1d-151               [-1, 128, 1]             256
            ReLU-152               [-1, 128, 1]               0
         Dropout-153               [-1, 128, 1]               0
          Conv1d-154               [-1, 128, 1]          16,512
 MyConv1dPadSame-155               [-1, 128, 1]               0
      Bottleneck-156               [-1, 128, 1]               0
     BatchNorm1d-157               [-1, 128, 1]             256
            ReLU-158               [-1, 128, 1]               0
         Dropout-159               [-1, 128, 1]               0
          Conv1d-160               [-1, 128, 1]          16,512
 MyConv1dPadSame-161               [-1, 128, 1]               0
     BatchNorm1d-162               [-1, 128, 1]             256
            ReLU-163               [-1, 128, 1]               0
         Dropout-164               [-1, 128, 1]               0
          Conv1d-165               [-1, 128, 1]          16,512
 MyConv1dPadSame-166               [-1, 128, 1]               0
       MaxPool1d-167               [-1, 128, 1]               0
MyMaxPool1dPadSame-168               [-1, 128, 1]               0
      Bottleneck-169               [-1, 128, 1]               0
     BatchNorm1d-170               [-1, 128, 1]             256
            ReLU-171               [-1, 128, 1]               0
         Dropout-172               [-1, 128, 1]               0
          Conv1d-173               [-1, 128, 1]          16,512
 MyConv1dPadSame-174               [-1, 128, 1]               0
     BatchNorm1d-175               [-1, 128, 1]             256
            ReLU-176               [-1, 128, 1]               0
         Dropout-177               [-1, 128, 1]               0
          Conv1d-178               [-1, 128, 1]          16,512
 MyConv1dPadSame-179               [-1, 128, 1]               0
      Bottleneck-180               [-1, 128, 1]               0
     BatchNorm1d-181               [-1, 128, 1]             256
            ReLU-182               [-1, 128, 1]               0
         Dropout-183               [-1, 128, 1]               0
          Conv1d-184               [-1, 128, 1]          16,512
 MyConv1dPadSame-185               [-1, 128, 1]               0
     BatchNorm1d-186               [-1, 128, 1]             256
            ReLU-187               [-1, 128, 1]               0
         Dropout-188               [-1, 128, 1]               0
          Conv1d-189               [-1, 128, 1]          16,512
 MyConv1dPadSame-190               [-1, 128, 1]               0
       MaxPool1d-191               [-1, 128, 1]               0
MyMaxPool1dPadSame-192               [-1, 128, 1]               0
      Bottleneck-193               [-1, 128, 1]               0
     BatchNorm1d-194               [-1, 128, 1]             256
            ReLU-195               [-1, 128, 1]               0
          Linear-196                    [-1, 2]             258
================================================================
Total params: 169,650
Trainable params: 169,650
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.15
Params size (MB): 0.65
Estimated Total Size (MB): 0.80
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 32, kernel_size: 2, n_block: 2
************************************************************
************************************************************
(2000, 1, 16) Counter({1: 1000, 0: 1000})
(2000, 1, 16) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 32, 16]              96
   MyConv1dPadSame-2               [-1, 32, 16]               0
       BatchNorm1d-3               [-1, 32, 16]              64
              ReLU-4               [-1, 32, 16]               0
            Conv1d-5               [-1, 32, 16]              96
   MyConv1dPadSame-6               [-1, 32, 16]               0
       BatchNorm1d-7               [-1, 32, 16]              64
              ReLU-8               [-1, 32, 16]               0
           Dropout-9               [-1, 32, 16]               0
           Conv1d-10               [-1, 32, 16]              96
  MyConv1dPadSame-11               [-1, 32, 16]               0
       Bottleneck-12               [-1, 32, 16]               0
      BatchNorm1d-13               [-1, 32, 16]              64
             ReLU-14               [-1, 32, 16]               0
          Dropout-15               [-1, 32, 16]               0
           Conv1d-16               [-1, 64, 16]             192
  MyConv1dPadSame-17               [-1, 64, 16]               0
      BatchNorm1d-18               [-1, 64, 16]             128
             ReLU-19               [-1, 64, 16]               0
          Dropout-20               [-1, 64, 16]               0
           Conv1d-21               [-1, 64, 16]             320
  MyConv1dPadSame-22               [-1, 64, 16]               0
       Bottleneck-23               [-1, 64, 16]               0
      BatchNorm1d-24               [-1, 64, 16]             128
             ReLU-25               [-1, 64, 16]               0
           Linear-26                    [-1, 2]             130
================================================================
Total params: 1,378
Trainable params: 1,378
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.14
Params size (MB): 0.01
Estimated Total Size (MB): 0.14
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 32, kernel_size: 2, n_block: 4
************************************************************
************************************************************
(2000, 1, 16) Counter({0: 1000, 1: 1000})
(2000, 1, 16) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 32, 16]              96
   MyConv1dPadSame-2               [-1, 32, 16]               0
       BatchNorm1d-3               [-1, 32, 16]              64
              ReLU-4               [-1, 32, 16]               0
            Conv1d-5               [-1, 32, 16]              96
   MyConv1dPadSame-6               [-1, 32, 16]               0
       BatchNorm1d-7               [-1, 32, 16]              64
              ReLU-8               [-1, 32, 16]               0
           Dropout-9               [-1, 32, 16]               0
           Conv1d-10               [-1, 32, 16]              96
  MyConv1dPadSame-11               [-1, 32, 16]               0
       Bottleneck-12               [-1, 32, 16]               0
      BatchNorm1d-13               [-1, 32, 16]              64
             ReLU-14               [-1, 32, 16]               0
          Dropout-15               [-1, 32, 16]               0
           Conv1d-16               [-1, 64, 16]             192
  MyConv1dPadSame-17               [-1, 64, 16]               0
      BatchNorm1d-18               [-1, 64, 16]             128
             ReLU-19               [-1, 64, 16]               0
          Dropout-20               [-1, 64, 16]               0
           Conv1d-21               [-1, 64, 16]             320
  MyConv1dPadSame-22               [-1, 64, 16]               0
       Bottleneck-23               [-1, 64, 16]               0
      BatchNorm1d-24               [-1, 64, 16]             128
             ReLU-25               [-1, 64, 16]               0
          Dropout-26               [-1, 64, 16]               0
           Conv1d-27              [-1, 128, 16]             640
  MyConv1dPadSame-28              [-1, 128, 16]               0
      BatchNorm1d-29              [-1, 128, 16]             256
             ReLU-30              [-1, 128, 16]               0
          Dropout-31              [-1, 128, 16]               0
           Conv1d-32              [-1, 128, 16]           1,152
  MyConv1dPadSame-33              [-1, 128, 16]               0
       Bottleneck-34              [-1, 128, 16]               0
      BatchNorm1d-35              [-1, 128, 16]             256
             ReLU-36              [-1, 128, 16]               0
          Dropout-37              [-1, 128, 16]               0
           Conv1d-38              [-1, 256, 16]           2,304
  MyConv1dPadSame-39              [-1, 256, 16]               0
      BatchNorm1d-40              [-1, 256, 16]             512
             ReLU-41              [-1, 256, 16]               0
          Dropout-42              [-1, 256, 16]               0
           Conv1d-43              [-1, 256, 16]           4,352
  MyConv1dPadSame-44              [-1, 256, 16]               0
       Bottleneck-45              [-1, 256, 16]               0
      BatchNorm1d-46              [-1, 256, 16]             512
             ReLU-47              [-1, 256, 16]               0
           Linear-48                    [-1, 2]             514
================================================================
Total params: 11,746
Trainable params: 11,746
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.63
Params size (MB): 0.04
Estimated Total Size (MB): 0.67
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 32, kernel_size: 2, n_block: 8
************************************************************
************************************************************
(2000, 1, 16) Counter({1: 1000, 0: 1000})
(2000, 1, 16) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 32, 16]              96
   MyConv1dPadSame-2               [-1, 32, 16]               0
       BatchNorm1d-3               [-1, 32, 16]              64
              ReLU-4               [-1, 32, 16]               0
            Conv1d-5               [-1, 32, 16]              96
   MyConv1dPadSame-6               [-1, 32, 16]               0
       BatchNorm1d-7               [-1, 32, 16]              64
              ReLU-8               [-1, 32, 16]               0
           Dropout-9               [-1, 32, 16]               0
           Conv1d-10               [-1, 32, 16]              96
  MyConv1dPadSame-11               [-1, 32, 16]               0
       Bottleneck-12               [-1, 32, 16]               0
      BatchNorm1d-13               [-1, 32, 16]              64
             ReLU-14               [-1, 32, 16]               0
          Dropout-15               [-1, 32, 16]               0
           Conv1d-16               [-1, 32, 16]              96
  MyConv1dPadSame-17               [-1, 32, 16]               0
      BatchNorm1d-18               [-1, 32, 16]              64
             ReLU-19               [-1, 32, 16]               0
          Dropout-20               [-1, 32, 16]               0
           Conv1d-21               [-1, 32, 16]              96
  MyConv1dPadSame-22               [-1, 32, 16]               0
       Bottleneck-23               [-1, 32, 16]               0
      BatchNorm1d-24               [-1, 32, 16]              64
             ReLU-25               [-1, 32, 16]               0
          Dropout-26               [-1, 32, 16]               0
           Conv1d-27               [-1, 64, 16]             192
  MyConv1dPadSame-28               [-1, 64, 16]               0
      BatchNorm1d-29               [-1, 64, 16]             128
             ReLU-30               [-1, 64, 16]               0
          Dropout-31               [-1, 64, 16]               0
           Conv1d-32               [-1, 64, 16]             320
  MyConv1dPadSame-33               [-1, 64, 16]               0
       Bottleneck-34               [-1, 64, 16]               0
      BatchNorm1d-35               [-1, 64, 16]             128
             ReLU-36               [-1, 64, 16]               0
          Dropout-37               [-1, 64, 16]               0
           Conv1d-38               [-1, 64, 16]             320
  MyConv1dPadSame-39               [-1, 64, 16]               0
      BatchNorm1d-40               [-1, 64, 16]             128
             ReLU-41               [-1, 64, 16]               0
          Dropout-42               [-1, 64, 16]               0
           Conv1d-43               [-1, 64, 16]             320
  MyConv1dPadSame-44               [-1, 64, 16]               0
       Bottleneck-45               [-1, 64, 16]               0
      BatchNorm1d-46               [-1, 64, 16]             128
             ReLU-47               [-1, 64, 16]               0
          Dropout-48               [-1, 64, 16]               0
           Conv1d-49              [-1, 128, 16]             640
  MyConv1dPadSame-50              [-1, 128, 16]               0
      BatchNorm1d-51              [-1, 128, 16]             256
             ReLU-52              [-1, 128, 16]               0
          Dropout-53              [-1, 128, 16]               0
           Conv1d-54              [-1, 128, 16]           1,152
  MyConv1dPadSame-55              [-1, 128, 16]               0
       Bottleneck-56              [-1, 128, 16]               0
      BatchNorm1d-57              [-1, 128, 16]             256
             ReLU-58              [-1, 128, 16]               0
          Dropout-59              [-1, 128, 16]               0
           Conv1d-60              [-1, 128, 16]           1,152
  MyConv1dPadSame-61              [-1, 128, 16]               0
      BatchNorm1d-62              [-1, 128, 16]             256
             ReLU-63              [-1, 128, 16]               0
          Dropout-64              [-1, 128, 16]               0
           Conv1d-65              [-1, 128, 16]           1,152
  MyConv1dPadSame-66              [-1, 128, 16]               0
       Bottleneck-67              [-1, 128, 16]               0
      BatchNorm1d-68              [-1, 128, 16]             256
             ReLU-69              [-1, 128, 16]               0
          Dropout-70              [-1, 128, 16]               0
           Conv1d-71              [-1, 256, 16]           2,304
  MyConv1dPadSame-72              [-1, 256, 16]               0
      BatchNorm1d-73              [-1, 256, 16]             512
             ReLU-74              [-1, 256, 16]               0
          Dropout-75              [-1, 256, 16]               0
           Conv1d-76              [-1, 256, 16]           4,352
  MyConv1dPadSame-77              [-1, 256, 16]               0
       Bottleneck-78              [-1, 256, 16]               0
      BatchNorm1d-79              [-1, 256, 16]             512
             ReLU-80              [-1, 256, 16]               0
          Dropout-81              [-1, 256, 16]               0
           Conv1d-82              [-1, 256, 16]           4,352
  MyConv1dPadSame-83              [-1, 256, 16]               0
      BatchNorm1d-84              [-1, 256, 16]             512
             ReLU-85              [-1, 256, 16]               0
          Dropout-86              [-1, 256, 16]               0
           Conv1d-87              [-1, 256, 16]           4,352
  MyConv1dPadSame-88              [-1, 256, 16]               0
       Bottleneck-89              [-1, 256, 16]               0
      BatchNorm1d-90              [-1, 256, 16]             512
             ReLU-91              [-1, 256, 16]               0
           Linear-92                    [-1, 2]             514
================================================================
Total params: 25,506
Trainable params: 25,506
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 1.27
Params size (MB): 0.10
Estimated Total Size (MB): 1.37
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 32, kernel_size: 2, n_block: 16
************************************************************
************************************************************
(2000, 1, 16) Counter({0: 1000, 1: 1000})
(2000, 1, 16) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 32, 16]              96
   MyConv1dPadSame-2               [-1, 32, 16]               0
       BatchNorm1d-3               [-1, 32, 16]              64
              ReLU-4               [-1, 32, 16]               0
            Conv1d-5               [-1, 32, 16]              96
   MyConv1dPadSame-6               [-1, 32, 16]               0
       BatchNorm1d-7               [-1, 32, 16]              64
              ReLU-8               [-1, 32, 16]               0
           Dropout-9               [-1, 32, 16]               0
           Conv1d-10               [-1, 32, 16]              96
  MyConv1dPadSame-11               [-1, 32, 16]               0
       Bottleneck-12               [-1, 32, 16]               0
      BatchNorm1d-13               [-1, 32, 16]              64
             ReLU-14               [-1, 32, 16]               0
          Dropout-15               [-1, 32, 16]               0
           Conv1d-16                [-1, 32, 8]              96
  MyConv1dPadSame-17                [-1, 32, 8]               0
      BatchNorm1d-18                [-1, 32, 8]              64
             ReLU-19                [-1, 32, 8]               0
          Dropout-20                [-1, 32, 8]               0
           Conv1d-21                [-1, 32, 8]              96
  MyConv1dPadSame-22                [-1, 32, 8]               0
        MaxPool1d-23                [-1, 32, 8]               0
MyMaxPool1dPadSame-24                [-1, 32, 8]               0
       Bottleneck-25                [-1, 32, 8]               0
      BatchNorm1d-26                [-1, 32, 8]              64
             ReLU-27                [-1, 32, 8]               0
          Dropout-28                [-1, 32, 8]               0
           Conv1d-29                [-1, 32, 8]              96
  MyConv1dPadSame-30                [-1, 32, 8]               0
      BatchNorm1d-31                [-1, 32, 8]              64
             ReLU-32                [-1, 32, 8]               0
          Dropout-33                [-1, 32, 8]               0
           Conv1d-34                [-1, 32, 8]              96
  MyConv1dPadSame-35                [-1, 32, 8]               0
       Bottleneck-36                [-1, 32, 8]               0
      BatchNorm1d-37                [-1, 32, 8]              64
             ReLU-38                [-1, 32, 8]               0
          Dropout-39                [-1, 32, 8]               0
           Conv1d-40                [-1, 32, 4]              96
  MyConv1dPadSame-41                [-1, 32, 4]               0
      BatchNorm1d-42                [-1, 32, 4]              64
             ReLU-43                [-1, 32, 4]               0
          Dropout-44                [-1, 32, 4]               0
           Conv1d-45                [-1, 32, 4]              96
  MyConv1dPadSame-46                [-1, 32, 4]               0
        MaxPool1d-47                [-1, 32, 4]               0
MyMaxPool1dPadSame-48                [-1, 32, 4]               0
       Bottleneck-49                [-1, 32, 4]               0
      BatchNorm1d-50                [-1, 32, 4]              64
             ReLU-51                [-1, 32, 4]               0
          Dropout-52                [-1, 32, 4]               0
           Conv1d-53                [-1, 64, 4]             192
  MyConv1dPadSame-54                [-1, 64, 4]               0
      BatchNorm1d-55                [-1, 64, 4]             128
             ReLU-56                [-1, 64, 4]               0
          Dropout-57                [-1, 64, 4]               0
           Conv1d-58                [-1, 64, 4]             320
  MyConv1dPadSame-59                [-1, 64, 4]               0
       Bottleneck-60                [-1, 64, 4]               0
      BatchNorm1d-61                [-1, 64, 4]             128
             ReLU-62                [-1, 64, 4]               0
          Dropout-63                [-1, 64, 4]               0
           Conv1d-64                [-1, 64, 2]             320
  MyConv1dPadSame-65                [-1, 64, 2]               0
      BatchNorm1d-66                [-1, 64, 2]             128
             ReLU-67                [-1, 64, 2]               0
          Dropout-68                [-1, 64, 2]               0
           Conv1d-69                [-1, 64, 2]             320
  MyConv1dPadSame-70                [-1, 64, 2]               0
        MaxPool1d-71                [-1, 64, 2]               0
MyMaxPool1dPadSame-72                [-1, 64, 2]               0
       Bottleneck-73                [-1, 64, 2]               0
      BatchNorm1d-74                [-1, 64, 2]             128
             ReLU-75                [-1, 64, 2]               0
          Dropout-76                [-1, 64, 2]               0
           Conv1d-77                [-1, 64, 2]             320
  MyConv1dPadSame-78                [-1, 64, 2]               0
      BatchNorm1d-79                [-1, 64, 2]             128
             ReLU-80                [-1, 64, 2]               0
          Dropout-81                [-1, 64, 2]               0
           Conv1d-82                [-1, 64, 2]             320
  MyConv1dPadSame-83                [-1, 64, 2]               0
       Bottleneck-84                [-1, 64, 2]               0
      BatchNorm1d-85                [-1, 64, 2]             128
             ReLU-86                [-1, 64, 2]               0
          Dropout-87                [-1, 64, 2]               0
           Conv1d-88                [-1, 64, 1]             320
  MyConv1dPadSame-89                [-1, 64, 1]               0
      BatchNorm1d-90                [-1, 64, 1]             128
             ReLU-91                [-1, 64, 1]               0
          Dropout-92                [-1, 64, 1]               0
           Conv1d-93                [-1, 64, 1]             320
  MyConv1dPadSame-94                [-1, 64, 1]               0
        MaxPool1d-95                [-1, 64, 1]               0
MyMaxPool1dPadSame-96                [-1, 64, 1]               0
       Bottleneck-97                [-1, 64, 1]               0
      BatchNorm1d-98                [-1, 64, 1]             128
             ReLU-99                [-1, 64, 1]               0
         Dropout-100                [-1, 64, 1]               0
          Conv1d-101               [-1, 128, 1]             640
 MyConv1dPadSame-102               [-1, 128, 1]               0
     BatchNorm1d-103               [-1, 128, 1]             256
            ReLU-104               [-1, 128, 1]               0
         Dropout-105               [-1, 128, 1]               0
          Conv1d-106               [-1, 128, 1]           1,152
 MyConv1dPadSame-107               [-1, 128, 1]               0
      Bottleneck-108               [-1, 128, 1]               0
     BatchNorm1d-109               [-1, 128, 1]             256
            ReLU-110               [-1, 128, 1]               0
         Dropout-111               [-1, 128, 1]               0
          Conv1d-112               [-1, 128, 1]           1,152
 MyConv1dPadSame-113               [-1, 128, 1]               0
     BatchNorm1d-114               [-1, 128, 1]             256
            ReLU-115               [-1, 128, 1]               0
         Dropout-116               [-1, 128, 1]               0
          Conv1d-117               [-1, 128, 1]           1,152
 MyConv1dPadSame-118               [-1, 128, 1]               0
       MaxPool1d-119               [-1, 128, 1]               0
MyMaxPool1dPadSame-120               [-1, 128, 1]               0
      Bottleneck-121               [-1, 128, 1]               0
     BatchNorm1d-122               [-1, 128, 1]             256
            ReLU-123               [-1, 128, 1]               0
         Dropout-124               [-1, 128, 1]               0
          Conv1d-125               [-1, 128, 1]           1,152
 MyConv1dPadSame-126               [-1, 128, 1]               0
     BatchNorm1d-127               [-1, 128, 1]             256
            ReLU-128               [-1, 128, 1]               0
         Dropout-129               [-1, 128, 1]               0
          Conv1d-130               [-1, 128, 1]           1,152
 MyConv1dPadSame-131               [-1, 128, 1]               0
      Bottleneck-132               [-1, 128, 1]               0
     BatchNorm1d-133               [-1, 128, 1]             256
            ReLU-134               [-1, 128, 1]               0
         Dropout-135               [-1, 128, 1]               0
          Conv1d-136               [-1, 128, 1]           1,152
 MyConv1dPadSame-137               [-1, 128, 1]               0
     BatchNorm1d-138               [-1, 128, 1]             256
            ReLU-139               [-1, 128, 1]               0
         Dropout-140               [-1, 128, 1]               0
          Conv1d-141               [-1, 128, 1]           1,152
 MyConv1dPadSame-142               [-1, 128, 1]               0
       MaxPool1d-143               [-1, 128, 1]               0
MyMaxPool1dPadSame-144               [-1, 128, 1]               0
      Bottleneck-145               [-1, 128, 1]               0
     BatchNorm1d-146               [-1, 128, 1]             256
            ReLU-147               [-1, 128, 1]               0
         Dropout-148               [-1, 128, 1]               0
          Conv1d-149               [-1, 256, 1]           2,304
 MyConv1dPadSame-150               [-1, 256, 1]               0
     BatchNorm1d-151               [-1, 256, 1]             512
            ReLU-152               [-1, 256, 1]               0
         Dropout-153               [-1, 256, 1]               0
          Conv1d-154               [-1, 256, 1]           4,352
 MyConv1dPadSame-155               [-1, 256, 1]               0
      Bottleneck-156               [-1, 256, 1]               0
     BatchNorm1d-157               [-1, 256, 1]             512
            ReLU-158               [-1, 256, 1]               0
         Dropout-159               [-1, 256, 1]               0
          Conv1d-160               [-1, 256, 1]           4,352
 MyConv1dPadSame-161               [-1, 256, 1]               0
     BatchNorm1d-162               [-1, 256, 1]             512
            ReLU-163               [-1, 256, 1]               0
         Dropout-164               [-1, 256, 1]               0
          Conv1d-165               [-1, 256, 1]           4,352
 MyConv1dPadSame-166               [-1, 256, 1]               0
       MaxPool1d-167               [-1, 256, 1]               0
MyMaxPool1dPadSame-168               [-1, 256, 1]               0
      Bottleneck-169               [-1, 256, 1]               0
     BatchNorm1d-170               [-1, 256, 1]             512
            ReLU-171               [-1, 256, 1]               0
         Dropout-172               [-1, 256, 1]               0
          Conv1d-173               [-1, 256, 1]           4,352
 MyConv1dPadSame-174               [-1, 256, 1]               0
     BatchNorm1d-175               [-1, 256, 1]             512
            ReLU-176               [-1, 256, 1]               0
         Dropout-177               [-1, 256, 1]               0
          Conv1d-178               [-1, 256, 1]           4,352
 MyConv1dPadSame-179               [-1, 256, 1]               0
      Bottleneck-180               [-1, 256, 1]               0
     BatchNorm1d-181               [-1, 256, 1]             512
            ReLU-182               [-1, 256, 1]               0
         Dropout-183               [-1, 256, 1]               0
          Conv1d-184               [-1, 256, 1]           4,352
 MyConv1dPadSame-185               [-1, 256, 1]               0
     BatchNorm1d-186               [-1, 256, 1]             512
            ReLU-187               [-1, 256, 1]               0
         Dropout-188               [-1, 256, 1]               0
          Conv1d-189               [-1, 256, 1]           4,352
 MyConv1dPadSame-190               [-1, 256, 1]               0
       MaxPool1d-191               [-1, 256, 1]               0
MyMaxPool1dPadSame-192               [-1, 256, 1]               0
      Bottleneck-193               [-1, 256, 1]               0
     BatchNorm1d-194               [-1, 256, 1]             512
            ReLU-195               [-1, 256, 1]               0
          Linear-196                    [-1, 2]             514
================================================================
Total params: 53,026
Trainable params: 53,026
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.31
Params size (MB): 0.20
Estimated Total Size (MB): 0.51
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 32, kernel_size: 4, n_block: 2
************************************************************
************************************************************
(2000, 1, 16) Counter({0: 1000, 1: 1000})
(2000, 1, 16) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 32, 16]             160
   MyConv1dPadSame-2               [-1, 32, 16]               0
       BatchNorm1d-3               [-1, 32, 16]              64
              ReLU-4               [-1, 32, 16]               0
            Conv1d-5               [-1, 32, 16]             160
   MyConv1dPadSame-6               [-1, 32, 16]               0
       BatchNorm1d-7               [-1, 32, 16]              64
              ReLU-8               [-1, 32, 16]               0
           Dropout-9               [-1, 32, 16]               0
           Conv1d-10               [-1, 32, 16]             160
  MyConv1dPadSame-11               [-1, 32, 16]               0
       Bottleneck-12               [-1, 32, 16]               0
      BatchNorm1d-13               [-1, 32, 16]              64
             ReLU-14               [-1, 32, 16]               0
          Dropout-15               [-1, 32, 16]               0
           Conv1d-16               [-1, 64, 16]             320
  MyConv1dPadSame-17               [-1, 64, 16]               0
      BatchNorm1d-18               [-1, 64, 16]             128
             ReLU-19               [-1, 64, 16]               0
          Dropout-20               [-1, 64, 16]               0
           Conv1d-21               [-1, 64, 16]             576
  MyConv1dPadSame-22               [-1, 64, 16]               0
       Bottleneck-23               [-1, 64, 16]               0
      BatchNorm1d-24               [-1, 64, 16]             128
             ReLU-25               [-1, 64, 16]               0
           Linear-26                    [-1, 2]             130
================================================================
Total params: 1,954
Trainable params: 1,954
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.14
Params size (MB): 0.01
Estimated Total Size (MB): 0.14
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 32, kernel_size: 4, n_block: 4
************************************************************
************************************************************
(2000, 1, 16) Counter({1: 1000, 0: 1000})
(2000, 1, 16) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 32, 16]             160
   MyConv1dPadSame-2               [-1, 32, 16]               0
       BatchNorm1d-3               [-1, 32, 16]              64
              ReLU-4               [-1, 32, 16]               0
            Conv1d-5               [-1, 32, 16]             160
   MyConv1dPadSame-6               [-1, 32, 16]               0
       BatchNorm1d-7               [-1, 32, 16]              64
              ReLU-8               [-1, 32, 16]               0
           Dropout-9               [-1, 32, 16]               0
           Conv1d-10               [-1, 32, 16]             160
  MyConv1dPadSame-11               [-1, 32, 16]               0
       Bottleneck-12               [-1, 32, 16]               0
      BatchNorm1d-13               [-1, 32, 16]              64
             ReLU-14               [-1, 32, 16]               0
          Dropout-15               [-1, 32, 16]               0
           Conv1d-16               [-1, 64, 16]             320
  MyConv1dPadSame-17               [-1, 64, 16]               0
      BatchNorm1d-18               [-1, 64, 16]             128
             ReLU-19               [-1, 64, 16]               0
          Dropout-20               [-1, 64, 16]               0
           Conv1d-21               [-1, 64, 16]             576
  MyConv1dPadSame-22               [-1, 64, 16]               0
       Bottleneck-23               [-1, 64, 16]               0
      BatchNorm1d-24               [-1, 64, 16]             128
             ReLU-25               [-1, 64, 16]               0
          Dropout-26               [-1, 64, 16]               0
           Conv1d-27              [-1, 128, 16]           1,152
  MyConv1dPadSame-28              [-1, 128, 16]               0
      BatchNorm1d-29              [-1, 128, 16]             256
             ReLU-30              [-1, 128, 16]               0
          Dropout-31              [-1, 128, 16]               0
           Conv1d-32              [-1, 128, 16]           2,176
  MyConv1dPadSame-33              [-1, 128, 16]               0
       Bottleneck-34              [-1, 128, 16]               0
      BatchNorm1d-35              [-1, 128, 16]             256
             ReLU-36              [-1, 128, 16]               0
          Dropout-37              [-1, 128, 16]               0
           Conv1d-38              [-1, 256, 16]           4,352
  MyConv1dPadSame-39              [-1, 256, 16]               0
      BatchNorm1d-40              [-1, 256, 16]             512
             ReLU-41              [-1, 256, 16]               0
          Dropout-42              [-1, 256, 16]               0
           Conv1d-43              [-1, 256, 16]           8,448
  MyConv1dPadSame-44              [-1, 256, 16]               0
       Bottleneck-45              [-1, 256, 16]               0
      BatchNorm1d-46              [-1, 256, 16]             512
             ReLU-47              [-1, 256, 16]               0
           Linear-48                    [-1, 2]             514
================================================================
Total params: 20,002
Trainable params: 20,002
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.63
Params size (MB): 0.08
Estimated Total Size (MB): 0.71
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 32, kernel_size: 4, n_block: 8
************************************************************
************************************************************
(2000, 1, 16) Counter({0: 1000, 1: 1000})
(2000, 1, 16) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 32, 16]             160
   MyConv1dPadSame-2               [-1, 32, 16]               0
       BatchNorm1d-3               [-1, 32, 16]              64
              ReLU-4               [-1, 32, 16]               0
            Conv1d-5               [-1, 32, 16]             160
   MyConv1dPadSame-6               [-1, 32, 16]               0
       BatchNorm1d-7               [-1, 32, 16]              64
              ReLU-8               [-1, 32, 16]               0
           Dropout-9               [-1, 32, 16]               0
           Conv1d-10               [-1, 32, 16]             160
  MyConv1dPadSame-11               [-1, 32, 16]               0
       Bottleneck-12               [-1, 32, 16]               0
      BatchNorm1d-13               [-1, 32, 16]              64
             ReLU-14               [-1, 32, 16]               0
          Dropout-15               [-1, 32, 16]               0
           Conv1d-16               [-1, 32, 16]             160
  MyConv1dPadSame-17               [-1, 32, 16]               0
      BatchNorm1d-18               [-1, 32, 16]              64
             ReLU-19               [-1, 32, 16]               0
          Dropout-20               [-1, 32, 16]               0
           Conv1d-21               [-1, 32, 16]             160
  MyConv1dPadSame-22               [-1, 32, 16]               0
       Bottleneck-23               [-1, 32, 16]               0
      BatchNorm1d-24               [-1, 32, 16]              64
             ReLU-25               [-1, 32, 16]               0
          Dropout-26               [-1, 32, 16]               0
           Conv1d-27               [-1, 64, 16]             320
  MyConv1dPadSame-28               [-1, 64, 16]               0
      BatchNorm1d-29               [-1, 64, 16]             128
             ReLU-30               [-1, 64, 16]               0
          Dropout-31               [-1, 64, 16]               0
           Conv1d-32               [-1, 64, 16]             576
  MyConv1dPadSame-33               [-1, 64, 16]               0
       Bottleneck-34               [-1, 64, 16]               0
      BatchNorm1d-35               [-1, 64, 16]             128
             ReLU-36               [-1, 64, 16]               0
          Dropout-37               [-1, 64, 16]               0
           Conv1d-38               [-1, 64, 16]             576
  MyConv1dPadSame-39               [-1, 64, 16]               0
      BatchNorm1d-40               [-1, 64, 16]             128
             ReLU-41               [-1, 64, 16]               0
          Dropout-42               [-1, 64, 16]               0
           Conv1d-43               [-1, 64, 16]             576
  MyConv1dPadSame-44               [-1, 64, 16]               0
       Bottleneck-45               [-1, 64, 16]               0
      BatchNorm1d-46               [-1, 64, 16]             128
             ReLU-47               [-1, 64, 16]               0
          Dropout-48               [-1, 64, 16]               0
           Conv1d-49              [-1, 128, 16]           1,152
  MyConv1dPadSame-50              [-1, 128, 16]               0
      BatchNorm1d-51              [-1, 128, 16]             256
             ReLU-52              [-1, 128, 16]               0
          Dropout-53              [-1, 128, 16]               0
           Conv1d-54              [-1, 128, 16]           2,176
  MyConv1dPadSame-55              [-1, 128, 16]               0
       Bottleneck-56              [-1, 128, 16]               0
      BatchNorm1d-57              [-1, 128, 16]             256
             ReLU-58              [-1, 128, 16]               0
          Dropout-59              [-1, 128, 16]               0
           Conv1d-60              [-1, 128, 16]           2,176
  MyConv1dPadSame-61              [-1, 128, 16]               0
      BatchNorm1d-62              [-1, 128, 16]             256
             ReLU-63              [-1, 128, 16]               0
          Dropout-64              [-1, 128, 16]               0
           Conv1d-65              [-1, 128, 16]           2,176
  MyConv1dPadSame-66              [-1, 128, 16]               0
       Bottleneck-67              [-1, 128, 16]               0
      BatchNorm1d-68              [-1, 128, 16]             256
             ReLU-69              [-1, 128, 16]               0
          Dropout-70              [-1, 128, 16]               0
           Conv1d-71              [-1, 256, 16]           4,352
  MyConv1dPadSame-72              [-1, 256, 16]               0
      BatchNorm1d-73              [-1, 256, 16]             512
             ReLU-74              [-1, 256, 16]               0
          Dropout-75              [-1, 256, 16]               0
           Conv1d-76              [-1, 256, 16]           8,448
  MyConv1dPadSame-77              [-1, 256, 16]               0
       Bottleneck-78              [-1, 256, 16]               0
      BatchNorm1d-79              [-1, 256, 16]             512
             ReLU-80              [-1, 256, 16]               0
          Dropout-81              [-1, 256, 16]               0
           Conv1d-82              [-1, 256, 16]           8,448
  MyConv1dPadSame-83              [-1, 256, 16]               0
      BatchNorm1d-84              [-1, 256, 16]             512
             ReLU-85              [-1, 256, 16]               0
          Dropout-86              [-1, 256, 16]               0
           Conv1d-87              [-1, 256, 16]           8,448
  MyConv1dPadSame-88              [-1, 256, 16]               0
       Bottleneck-89              [-1, 256, 16]               0
      BatchNorm1d-90              [-1, 256, 16]             512
             ReLU-91              [-1, 256, 16]               0
           Linear-92                    [-1, 2]             514
================================================================
Total params: 44,642
Trainable params: 44,642
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 1.27
Params size (MB): 0.17
Estimated Total Size (MB): 1.44
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 32, kernel_size: 4, n_block: 16
************************************************************
************************************************************
(2000, 1, 16) Counter({1: 1000, 0: 1000})
(2000, 1, 16) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 32, 16]             160
   MyConv1dPadSame-2               [-1, 32, 16]               0
       BatchNorm1d-3               [-1, 32, 16]              64
              ReLU-4               [-1, 32, 16]               0
            Conv1d-5               [-1, 32, 16]             160
   MyConv1dPadSame-6               [-1, 32, 16]               0
       BatchNorm1d-7               [-1, 32, 16]              64
              ReLU-8               [-1, 32, 16]               0
           Dropout-9               [-1, 32, 16]               0
           Conv1d-10               [-1, 32, 16]             160
  MyConv1dPadSame-11               [-1, 32, 16]               0
       Bottleneck-12               [-1, 32, 16]               0
      BatchNorm1d-13               [-1, 32, 16]              64
             ReLU-14               [-1, 32, 16]               0
          Dropout-15               [-1, 32, 16]               0
           Conv1d-16                [-1, 32, 8]             160
  MyConv1dPadSame-17                [-1, 32, 8]               0
      BatchNorm1d-18                [-1, 32, 8]              64
             ReLU-19                [-1, 32, 8]               0
          Dropout-20                [-1, 32, 8]               0
           Conv1d-21                [-1, 32, 8]             160
  MyConv1dPadSame-22                [-1, 32, 8]               0
        MaxPool1d-23                [-1, 32, 8]               0
MyMaxPool1dPadSame-24                [-1, 32, 8]               0
       Bottleneck-25                [-1, 32, 8]               0
      BatchNorm1d-26                [-1, 32, 8]              64
             ReLU-27                [-1, 32, 8]               0
          Dropout-28                [-1, 32, 8]               0
           Conv1d-29                [-1, 32, 8]             160
  MyConv1dPadSame-30                [-1, 32, 8]               0
      BatchNorm1d-31                [-1, 32, 8]              64
             ReLU-32                [-1, 32, 8]               0
          Dropout-33                [-1, 32, 8]               0
           Conv1d-34                [-1, 32, 8]             160
  MyConv1dPadSame-35                [-1, 32, 8]               0
       Bottleneck-36                [-1, 32, 8]               0
      BatchNorm1d-37                [-1, 32, 8]              64
             ReLU-38                [-1, 32, 8]               0
          Dropout-39                [-1, 32, 8]               0
           Conv1d-40                [-1, 32, 4]             160
  MyConv1dPadSame-41                [-1, 32, 4]               0
      BatchNorm1d-42                [-1, 32, 4]              64
             ReLU-43                [-1, 32, 4]               0
          Dropout-44                [-1, 32, 4]               0
           Conv1d-45                [-1, 32, 4]             160
  MyConv1dPadSame-46                [-1, 32, 4]               0
        MaxPool1d-47                [-1, 32, 4]               0
MyMaxPool1dPadSame-48                [-1, 32, 4]               0
       Bottleneck-49                [-1, 32, 4]               0
      BatchNorm1d-50                [-1, 32, 4]              64
             ReLU-51                [-1, 32, 4]               0
          Dropout-52                [-1, 32, 4]               0
           Conv1d-53                [-1, 64, 4]             320
  MyConv1dPadSame-54                [-1, 64, 4]               0
      BatchNorm1d-55                [-1, 64, 4]             128
             ReLU-56                [-1, 64, 4]               0
          Dropout-57                [-1, 64, 4]               0
           Conv1d-58                [-1, 64, 4]             576
  MyConv1dPadSame-59                [-1, 64, 4]               0
       Bottleneck-60                [-1, 64, 4]               0
      BatchNorm1d-61                [-1, 64, 4]             128
             ReLU-62                [-1, 64, 4]               0
          Dropout-63                [-1, 64, 4]               0
           Conv1d-64                [-1, 64, 2]             576
  MyConv1dPadSame-65                [-1, 64, 2]               0
      BatchNorm1d-66                [-1, 64, 2]             128
             ReLU-67                [-1, 64, 2]               0
          Dropout-68                [-1, 64, 2]               0
           Conv1d-69                [-1, 64, 2]             576
  MyConv1dPadSame-70                [-1, 64, 2]               0
        MaxPool1d-71                [-1, 64, 2]               0
MyMaxPool1dPadSame-72                [-1, 64, 2]               0
       Bottleneck-73                [-1, 64, 2]               0
      BatchNorm1d-74                [-1, 64, 2]             128
             ReLU-75                [-1, 64, 2]               0
          Dropout-76                [-1, 64, 2]               0
           Conv1d-77                [-1, 64, 2]             576
  MyConv1dPadSame-78                [-1, 64, 2]               0
      BatchNorm1d-79                [-1, 64, 2]             128
             ReLU-80                [-1, 64, 2]               0
          Dropout-81                [-1, 64, 2]               0
           Conv1d-82                [-1, 64, 2]             576
  MyConv1dPadSame-83                [-1, 64, 2]               0
       Bottleneck-84                [-1, 64, 2]               0
      BatchNorm1d-85                [-1, 64, 2]             128
             ReLU-86                [-1, 64, 2]               0
          Dropout-87                [-1, 64, 2]               0
           Conv1d-88                [-1, 64, 1]             576
  MyConv1dPadSame-89                [-1, 64, 1]               0
      BatchNorm1d-90                [-1, 64, 1]             128
             ReLU-91                [-1, 64, 1]               0
          Dropout-92                [-1, 64, 1]               0
           Conv1d-93                [-1, 64, 1]             576
  MyConv1dPadSame-94                [-1, 64, 1]               0
        MaxPool1d-95                [-1, 64, 1]               0
MyMaxPool1dPadSame-96                [-1, 64, 1]               0
       Bottleneck-97                [-1, 64, 1]               0
      BatchNorm1d-98                [-1, 64, 1]             128
             ReLU-99                [-1, 64, 1]               0
         Dropout-100                [-1, 64, 1]               0
          Conv1d-101               [-1, 128, 1]           1,152
 MyConv1dPadSame-102               [-1, 128, 1]               0
     BatchNorm1d-103               [-1, 128, 1]             256
            ReLU-104               [-1, 128, 1]               0
         Dropout-105               [-1, 128, 1]               0
          Conv1d-106               [-1, 128, 1]           2,176
 MyConv1dPadSame-107               [-1, 128, 1]               0
      Bottleneck-108               [-1, 128, 1]               0
     BatchNorm1d-109               [-1, 128, 1]             256
            ReLU-110               [-1, 128, 1]               0
         Dropout-111               [-1, 128, 1]               0
          Conv1d-112               [-1, 128, 1]           2,176
 MyConv1dPadSame-113               [-1, 128, 1]               0
     BatchNorm1d-114               [-1, 128, 1]             256
            ReLU-115               [-1, 128, 1]               0
         Dropout-116               [-1, 128, 1]               0
          Conv1d-117               [-1, 128, 1]           2,176
 MyConv1dPadSame-118               [-1, 128, 1]               0
       MaxPool1d-119               [-1, 128, 1]               0
MyMaxPool1dPadSame-120               [-1, 128, 1]               0
      Bottleneck-121               [-1, 128, 1]               0
     BatchNorm1d-122               [-1, 128, 1]             256
            ReLU-123               [-1, 128, 1]               0
         Dropout-124               [-1, 128, 1]               0
          Conv1d-125               [-1, 128, 1]           2,176
 MyConv1dPadSame-126               [-1, 128, 1]               0
     BatchNorm1d-127               [-1, 128, 1]             256
            ReLU-128               [-1, 128, 1]               0
         Dropout-129               [-1, 128, 1]               0
          Conv1d-130               [-1, 128, 1]           2,176
 MyConv1dPadSame-131               [-1, 128, 1]               0
      Bottleneck-132               [-1, 128, 1]               0
     BatchNorm1d-133               [-1, 128, 1]             256
            ReLU-134               [-1, 128, 1]               0
         Dropout-135               [-1, 128, 1]               0
          Conv1d-136               [-1, 128, 1]           2,176
 MyConv1dPadSame-137               [-1, 128, 1]               0
     BatchNorm1d-138               [-1, 128, 1]             256
            ReLU-139               [-1, 128, 1]               0
         Dropout-140               [-1, 128, 1]               0
          Conv1d-141               [-1, 128, 1]           2,176
 MyConv1dPadSame-142               [-1, 128, 1]               0
       MaxPool1d-143               [-1, 128, 1]               0
MyMaxPool1dPadSame-144               [-1, 128, 1]               0
      Bottleneck-145               [-1, 128, 1]               0
     BatchNorm1d-146               [-1, 128, 1]             256
            ReLU-147               [-1, 128, 1]               0
         Dropout-148               [-1, 128, 1]               0
          Conv1d-149               [-1, 256, 1]           4,352
 MyConv1dPadSame-150               [-1, 256, 1]               0
     BatchNorm1d-151               [-1, 256, 1]             512
            ReLU-152               [-1, 256, 1]               0
         Dropout-153               [-1, 256, 1]               0
          Conv1d-154               [-1, 256, 1]           8,448
 MyConv1dPadSame-155               [-1, 256, 1]               0
      Bottleneck-156               [-1, 256, 1]               0
     BatchNorm1d-157               [-1, 256, 1]             512
            ReLU-158               [-1, 256, 1]               0
         Dropout-159               [-1, 256, 1]               0
          Conv1d-160               [-1, 256, 1]           8,448
 MyConv1dPadSame-161               [-1, 256, 1]               0
     BatchNorm1d-162               [-1, 256, 1]             512
            ReLU-163               [-1, 256, 1]               0
         Dropout-164               [-1, 256, 1]               0
          Conv1d-165               [-1, 256, 1]           8,448
 MyConv1dPadSame-166               [-1, 256, 1]               0
       MaxPool1d-167               [-1, 256, 1]               0
MyMaxPool1dPadSame-168               [-1, 256, 1]               0
      Bottleneck-169               [-1, 256, 1]               0
     BatchNorm1d-170               [-1, 256, 1]             512
            ReLU-171               [-1, 256, 1]               0
         Dropout-172               [-1, 256, 1]               0
          Conv1d-173               [-1, 256, 1]           8,448
 MyConv1dPadSame-174               [-1, 256, 1]               0
     BatchNorm1d-175               [-1, 256, 1]             512
            ReLU-176               [-1, 256, 1]               0
         Dropout-177               [-1, 256, 1]               0
          Conv1d-178               [-1, 256, 1]           8,448
 MyConv1dPadSame-179               [-1, 256, 1]               0
      Bottleneck-180               [-1, 256, 1]               0
     BatchNorm1d-181               [-1, 256, 1]             512
            ReLU-182               [-1, 256, 1]               0
         Dropout-183               [-1, 256, 1]               0
          Conv1d-184               [-1, 256, 1]           8,448
 MyConv1dPadSame-185               [-1, 256, 1]               0
     BatchNorm1d-186               [-1, 256, 1]             512
            ReLU-187               [-1, 256, 1]               0
         Dropout-188               [-1, 256, 1]               0
          Conv1d-189               [-1, 256, 1]           8,448
 MyConv1dPadSame-190               [-1, 256, 1]               0
       MaxPool1d-191               [-1, 256, 1]               0
MyMaxPool1dPadSame-192               [-1, 256, 1]               0
      Bottleneck-193               [-1, 256, 1]               0
     BatchNorm1d-194               [-1, 256, 1]             512
            ReLU-195               [-1, 256, 1]               0
          Linear-196                    [-1, 2]             514
================================================================
Total params: 93,922
Trainable params: 93,922
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.31
Params size (MB): 0.36
Estimated Total Size (MB): 0.67
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 32, kernel_size: 8, n_block: 2
************************************************************
************************************************************
(2000, 1, 16) Counter({0: 1000, 1: 1000})
(2000, 1, 16) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 32, 16]             288
   MyConv1dPadSame-2               [-1, 32, 16]               0
       BatchNorm1d-3               [-1, 32, 16]              64
              ReLU-4               [-1, 32, 16]               0
            Conv1d-5               [-1, 32, 16]             288
   MyConv1dPadSame-6               [-1, 32, 16]               0
       BatchNorm1d-7               [-1, 32, 16]              64
              ReLU-8               [-1, 32, 16]               0
           Dropout-9               [-1, 32, 16]               0
           Conv1d-10               [-1, 32, 16]             288
  MyConv1dPadSame-11               [-1, 32, 16]               0
       Bottleneck-12               [-1, 32, 16]               0
      BatchNorm1d-13               [-1, 32, 16]              64
             ReLU-14               [-1, 32, 16]               0
          Dropout-15               [-1, 32, 16]               0
           Conv1d-16               [-1, 64, 16]             576
  MyConv1dPadSame-17               [-1, 64, 16]               0
      BatchNorm1d-18               [-1, 64, 16]             128
             ReLU-19               [-1, 64, 16]               0
          Dropout-20               [-1, 64, 16]               0
           Conv1d-21               [-1, 64, 16]           1,088
  MyConv1dPadSame-22               [-1, 64, 16]               0
       Bottleneck-23               [-1, 64, 16]               0
      BatchNorm1d-24               [-1, 64, 16]             128
             ReLU-25               [-1, 64, 16]               0
           Linear-26                    [-1, 2]             130
================================================================
Total params: 3,106
Trainable params: 3,106
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.14
Params size (MB): 0.01
Estimated Total Size (MB): 0.15
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 32, kernel_size: 8, n_block: 4
************************************************************
************************************************************
(2000, 1, 16) Counter({0: 1000, 1: 1000})
(2000, 1, 16) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 32, 16]             288
   MyConv1dPadSame-2               [-1, 32, 16]               0
       BatchNorm1d-3               [-1, 32, 16]              64
              ReLU-4               [-1, 32, 16]               0
            Conv1d-5               [-1, 32, 16]             288
   MyConv1dPadSame-6               [-1, 32, 16]               0
       BatchNorm1d-7               [-1, 32, 16]              64
              ReLU-8               [-1, 32, 16]               0
           Dropout-9               [-1, 32, 16]               0
           Conv1d-10               [-1, 32, 16]             288
  MyConv1dPadSame-11               [-1, 32, 16]               0
       Bottleneck-12               [-1, 32, 16]               0
      BatchNorm1d-13               [-1, 32, 16]              64
             ReLU-14               [-1, 32, 16]               0
          Dropout-15               [-1, 32, 16]               0
           Conv1d-16               [-1, 64, 16]             576
  MyConv1dPadSame-17               [-1, 64, 16]               0
      BatchNorm1d-18               [-1, 64, 16]             128
             ReLU-19               [-1, 64, 16]               0
          Dropout-20               [-1, 64, 16]               0
           Conv1d-21               [-1, 64, 16]           1,088
  MyConv1dPadSame-22               [-1, 64, 16]               0
       Bottleneck-23               [-1, 64, 16]               0
      BatchNorm1d-24               [-1, 64, 16]             128
             ReLU-25               [-1, 64, 16]               0
          Dropout-26               [-1, 64, 16]               0
           Conv1d-27              [-1, 128, 16]           2,176
  MyConv1dPadSame-28              [-1, 128, 16]               0
      BatchNorm1d-29              [-1, 128, 16]             256
             ReLU-30              [-1, 128, 16]               0
          Dropout-31              [-1, 128, 16]               0
           Conv1d-32              [-1, 128, 16]           4,224
  MyConv1dPadSame-33              [-1, 128, 16]               0
       Bottleneck-34              [-1, 128, 16]               0
      BatchNorm1d-35              [-1, 128, 16]             256
             ReLU-36              [-1, 128, 16]               0
          Dropout-37              [-1, 128, 16]               0
           Conv1d-38              [-1, 256, 16]           8,448
  MyConv1dPadSame-39              [-1, 256, 16]               0
      BatchNorm1d-40              [-1, 256, 16]             512
             ReLU-41              [-1, 256, 16]               0
          Dropout-42              [-1, 256, 16]               0
           Conv1d-43              [-1, 256, 16]          16,640
  MyConv1dPadSame-44              [-1, 256, 16]               0
       Bottleneck-45              [-1, 256, 16]               0
      BatchNorm1d-46              [-1, 256, 16]             512
             ReLU-47              [-1, 256, 16]               0
           Linear-48                    [-1, 2]             514
================================================================
Total params: 36,514
Trainable params: 36,514
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.63
Params size (MB): 0.14
Estimated Total Size (MB): 0.77
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 32, kernel_size: 8, n_block: 8
************************************************************
************************************************************
(2000, 1, 16) Counter({1: 1000, 0: 1000})
(2000, 1, 16) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 32, 16]             288
   MyConv1dPadSame-2               [-1, 32, 16]               0
       BatchNorm1d-3               [-1, 32, 16]              64
              ReLU-4               [-1, 32, 16]               0
            Conv1d-5               [-1, 32, 16]             288
   MyConv1dPadSame-6               [-1, 32, 16]               0
       BatchNorm1d-7               [-1, 32, 16]              64
              ReLU-8               [-1, 32, 16]               0
           Dropout-9               [-1, 32, 16]               0
           Conv1d-10               [-1, 32, 16]             288
  MyConv1dPadSame-11               [-1, 32, 16]               0
       Bottleneck-12               [-1, 32, 16]               0
      BatchNorm1d-13               [-1, 32, 16]              64
             ReLU-14               [-1, 32, 16]               0
          Dropout-15               [-1, 32, 16]               0
           Conv1d-16               [-1, 32, 16]             288
  MyConv1dPadSame-17               [-1, 32, 16]               0
      BatchNorm1d-18               [-1, 32, 16]              64
             ReLU-19               [-1, 32, 16]               0
          Dropout-20               [-1, 32, 16]               0
           Conv1d-21               [-1, 32, 16]             288
  MyConv1dPadSame-22               [-1, 32, 16]               0
       Bottleneck-23               [-1, 32, 16]               0
      BatchNorm1d-24               [-1, 32, 16]              64
             ReLU-25               [-1, 32, 16]               0
          Dropout-26               [-1, 32, 16]               0
           Conv1d-27               [-1, 64, 16]             576
  MyConv1dPadSame-28               [-1, 64, 16]               0
      BatchNorm1d-29               [-1, 64, 16]             128
             ReLU-30               [-1, 64, 16]               0
          Dropout-31               [-1, 64, 16]               0
           Conv1d-32               [-1, 64, 16]           1,088
  MyConv1dPadSame-33               [-1, 64, 16]               0
       Bottleneck-34               [-1, 64, 16]               0
      BatchNorm1d-35               [-1, 64, 16]             128
             ReLU-36               [-1, 64, 16]               0
          Dropout-37               [-1, 64, 16]               0
           Conv1d-38               [-1, 64, 16]           1,088
  MyConv1dPadSame-39               [-1, 64, 16]               0
      BatchNorm1d-40               [-1, 64, 16]             128
             ReLU-41               [-1, 64, 16]               0
          Dropout-42               [-1, 64, 16]               0
           Conv1d-43               [-1, 64, 16]           1,088
  MyConv1dPadSame-44               [-1, 64, 16]               0
       Bottleneck-45               [-1, 64, 16]               0
      BatchNorm1d-46               [-1, 64, 16]             128
             ReLU-47               [-1, 64, 16]               0
          Dropout-48               [-1, 64, 16]               0
           Conv1d-49              [-1, 128, 16]           2,176
  MyConv1dPadSame-50              [-1, 128, 16]               0
      BatchNorm1d-51              [-1, 128, 16]             256
             ReLU-52              [-1, 128, 16]               0
          Dropout-53              [-1, 128, 16]               0
           Conv1d-54              [-1, 128, 16]           4,224
  MyConv1dPadSame-55              [-1, 128, 16]               0
       Bottleneck-56              [-1, 128, 16]               0
      BatchNorm1d-57              [-1, 128, 16]             256
             ReLU-58              [-1, 128, 16]               0
          Dropout-59              [-1, 128, 16]               0
           Conv1d-60              [-1, 128, 16]           4,224
  MyConv1dPadSame-61              [-1, 128, 16]               0
      BatchNorm1d-62              [-1, 128, 16]             256
             ReLU-63              [-1, 128, 16]               0
          Dropout-64              [-1, 128, 16]               0
           Conv1d-65              [-1, 128, 16]           4,224
  MyConv1dPadSame-66              [-1, 128, 16]               0
       Bottleneck-67              [-1, 128, 16]               0
      BatchNorm1d-68              [-1, 128, 16]             256
             ReLU-69              [-1, 128, 16]               0
          Dropout-70              [-1, 128, 16]               0
           Conv1d-71              [-1, 256, 16]           8,448
  MyConv1dPadSame-72              [-1, 256, 16]               0
      BatchNorm1d-73              [-1, 256, 16]             512
             ReLU-74              [-1, 256, 16]               0
          Dropout-75              [-1, 256, 16]               0
           Conv1d-76              [-1, 256, 16]          16,640
  MyConv1dPadSame-77              [-1, 256, 16]               0
       Bottleneck-78              [-1, 256, 16]               0
      BatchNorm1d-79              [-1, 256, 16]             512
             ReLU-80              [-1, 256, 16]               0
          Dropout-81              [-1, 256, 16]               0
           Conv1d-82              [-1, 256, 16]          16,640
  MyConv1dPadSame-83              [-1, 256, 16]               0
      BatchNorm1d-84              [-1, 256, 16]             512
             ReLU-85              [-1, 256, 16]               0
          Dropout-86              [-1, 256, 16]               0
           Conv1d-87              [-1, 256, 16]          16,640
  MyConv1dPadSame-88              [-1, 256, 16]               0
       Bottleneck-89              [-1, 256, 16]               0
      BatchNorm1d-90              [-1, 256, 16]             512
             ReLU-91              [-1, 256, 16]               0
           Linear-92                    [-1, 2]             514
================================================================
Total params: 82,914
Trainable params: 82,914
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 1.27
Params size (MB): 0.32
Estimated Total Size (MB): 1.59
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 32, kernel_size: 8, n_block: 16
************************************************************
************************************************************
(2000, 1, 16) Counter({0: 1000, 1: 1000})
(2000, 1, 16) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 32, 16]             288
   MyConv1dPadSame-2               [-1, 32, 16]               0
       BatchNorm1d-3               [-1, 32, 16]              64
              ReLU-4               [-1, 32, 16]               0
            Conv1d-5               [-1, 32, 16]             288
   MyConv1dPadSame-6               [-1, 32, 16]               0
       BatchNorm1d-7               [-1, 32, 16]              64
              ReLU-8               [-1, 32, 16]               0
           Dropout-9               [-1, 32, 16]               0
           Conv1d-10               [-1, 32, 16]             288
  MyConv1dPadSame-11               [-1, 32, 16]               0
       Bottleneck-12               [-1, 32, 16]               0
      BatchNorm1d-13               [-1, 32, 16]              64
             ReLU-14               [-1, 32, 16]               0
          Dropout-15               [-1, 32, 16]               0
           Conv1d-16                [-1, 32, 8]             288
  MyConv1dPadSame-17                [-1, 32, 8]               0
      BatchNorm1d-18                [-1, 32, 8]              64
             ReLU-19                [-1, 32, 8]               0
          Dropout-20                [-1, 32, 8]               0
           Conv1d-21                [-1, 32, 8]             288
  MyConv1dPadSame-22                [-1, 32, 8]               0
        MaxPool1d-23                [-1, 32, 8]               0
MyMaxPool1dPadSame-24                [-1, 32, 8]               0
       Bottleneck-25                [-1, 32, 8]               0
      BatchNorm1d-26                [-1, 32, 8]              64
             ReLU-27                [-1, 32, 8]               0
          Dropout-28                [-1, 32, 8]               0
           Conv1d-29                [-1, 32, 8]             288
  MyConv1dPadSame-30                [-1, 32, 8]               0
      BatchNorm1d-31                [-1, 32, 8]              64
             ReLU-32                [-1, 32, 8]               0
          Dropout-33                [-1, 32, 8]               0
           Conv1d-34                [-1, 32, 8]             288
  MyConv1dPadSame-35                [-1, 32, 8]               0
       Bottleneck-36                [-1, 32, 8]               0
      BatchNorm1d-37                [-1, 32, 8]              64
             ReLU-38                [-1, 32, 8]               0
          Dropout-39                [-1, 32, 8]               0
           Conv1d-40                [-1, 32, 4]             288
  MyConv1dPadSame-41                [-1, 32, 4]               0
      BatchNorm1d-42                [-1, 32, 4]              64
             ReLU-43                [-1, 32, 4]               0
          Dropout-44                [-1, 32, 4]               0
           Conv1d-45                [-1, 32, 4]             288
  MyConv1dPadSame-46                [-1, 32, 4]               0
        MaxPool1d-47                [-1, 32, 4]               0
MyMaxPool1dPadSame-48                [-1, 32, 4]               0
       Bottleneck-49                [-1, 32, 4]               0
      BatchNorm1d-50                [-1, 32, 4]              64
             ReLU-51                [-1, 32, 4]               0
          Dropout-52                [-1, 32, 4]               0
           Conv1d-53                [-1, 64, 4]             576
  MyConv1dPadSame-54                [-1, 64, 4]               0
      BatchNorm1d-55                [-1, 64, 4]             128
             ReLU-56                [-1, 64, 4]               0
          Dropout-57                [-1, 64, 4]               0
           Conv1d-58                [-1, 64, 4]           1,088
  MyConv1dPadSame-59                [-1, 64, 4]               0
       Bottleneck-60                [-1, 64, 4]               0
      BatchNorm1d-61                [-1, 64, 4]             128
             ReLU-62                [-1, 64, 4]               0
          Dropout-63                [-1, 64, 4]               0
           Conv1d-64                [-1, 64, 2]           1,088
  MyConv1dPadSame-65                [-1, 64, 2]               0
      BatchNorm1d-66                [-1, 64, 2]             128
             ReLU-67                [-1, 64, 2]               0
          Dropout-68                [-1, 64, 2]               0
           Conv1d-69                [-1, 64, 2]           1,088
  MyConv1dPadSame-70                [-1, 64, 2]               0
        MaxPool1d-71                [-1, 64, 2]               0
MyMaxPool1dPadSame-72                [-1, 64, 2]               0
       Bottleneck-73                [-1, 64, 2]               0
      BatchNorm1d-74                [-1, 64, 2]             128
             ReLU-75                [-1, 64, 2]               0
          Dropout-76                [-1, 64, 2]               0
           Conv1d-77                [-1, 64, 2]           1,088
  MyConv1dPadSame-78                [-1, 64, 2]               0
      BatchNorm1d-79                [-1, 64, 2]             128
             ReLU-80                [-1, 64, 2]               0
          Dropout-81                [-1, 64, 2]               0
           Conv1d-82                [-1, 64, 2]           1,088
  MyConv1dPadSame-83                [-1, 64, 2]               0
       Bottleneck-84                [-1, 64, 2]               0
      BatchNorm1d-85                [-1, 64, 2]             128
             ReLU-86                [-1, 64, 2]               0
          Dropout-87                [-1, 64, 2]               0
           Conv1d-88                [-1, 64, 1]           1,088
  MyConv1dPadSame-89                [-1, 64, 1]               0
      BatchNorm1d-90                [-1, 64, 1]             128
             ReLU-91                [-1, 64, 1]               0
          Dropout-92                [-1, 64, 1]               0
           Conv1d-93                [-1, 64, 1]           1,088
  MyConv1dPadSame-94                [-1, 64, 1]               0
        MaxPool1d-95                [-1, 64, 1]               0
MyMaxPool1dPadSame-96                [-1, 64, 1]               0
       Bottleneck-97                [-1, 64, 1]               0
      BatchNorm1d-98                [-1, 64, 1]             128
             ReLU-99                [-1, 64, 1]               0
         Dropout-100                [-1, 64, 1]               0
          Conv1d-101               [-1, 128, 1]           2,176
 MyConv1dPadSame-102               [-1, 128, 1]               0
     BatchNorm1d-103               [-1, 128, 1]             256
            ReLU-104               [-1, 128, 1]               0
         Dropout-105               [-1, 128, 1]               0
          Conv1d-106               [-1, 128, 1]           4,224
 MyConv1dPadSame-107               [-1, 128, 1]               0
      Bottleneck-108               [-1, 128, 1]               0
     BatchNorm1d-109               [-1, 128, 1]             256
            ReLU-110               [-1, 128, 1]               0
         Dropout-111               [-1, 128, 1]               0
          Conv1d-112               [-1, 128, 1]           4,224
 MyConv1dPadSame-113               [-1, 128, 1]               0
     BatchNorm1d-114               [-1, 128, 1]             256
            ReLU-115               [-1, 128, 1]               0
         Dropout-116               [-1, 128, 1]               0
          Conv1d-117               [-1, 128, 1]           4,224
 MyConv1dPadSame-118               [-1, 128, 1]               0
       MaxPool1d-119               [-1, 128, 1]               0
MyMaxPool1dPadSame-120               [-1, 128, 1]               0
      Bottleneck-121               [-1, 128, 1]               0
     BatchNorm1d-122               [-1, 128, 1]             256
            ReLU-123               [-1, 128, 1]               0
         Dropout-124               [-1, 128, 1]               0
          Conv1d-125               [-1, 128, 1]           4,224
 MyConv1dPadSame-126               [-1, 128, 1]               0
     BatchNorm1d-127               [-1, 128, 1]             256
            ReLU-128               [-1, 128, 1]               0
         Dropout-129               [-1, 128, 1]               0
          Conv1d-130               [-1, 128, 1]           4,224
 MyConv1dPadSame-131               [-1, 128, 1]               0
      Bottleneck-132               [-1, 128, 1]               0
     BatchNorm1d-133               [-1, 128, 1]             256
            ReLU-134               [-1, 128, 1]               0
         Dropout-135               [-1, 128, 1]               0
          Conv1d-136               [-1, 128, 1]           4,224
 MyConv1dPadSame-137               [-1, 128, 1]               0
     BatchNorm1d-138               [-1, 128, 1]             256
            ReLU-139               [-1, 128, 1]               0
         Dropout-140               [-1, 128, 1]               0
          Conv1d-141               [-1, 128, 1]           4,224
 MyConv1dPadSame-142               [-1, 128, 1]               0
       MaxPool1d-143               [-1, 128, 1]               0
MyMaxPool1dPadSame-144               [-1, 128, 1]               0
      Bottleneck-145               [-1, 128, 1]               0
     BatchNorm1d-146               [-1, 128, 1]             256
            ReLU-147               [-1, 128, 1]               0
         Dropout-148               [-1, 128, 1]               0
          Conv1d-149               [-1, 256, 1]           8,448
 MyConv1dPadSame-150               [-1, 256, 1]               0
     BatchNorm1d-151               [-1, 256, 1]             512
            ReLU-152               [-1, 256, 1]               0
         Dropout-153               [-1, 256, 1]               0
          Conv1d-154               [-1, 256, 1]          16,640
 MyConv1dPadSame-155               [-1, 256, 1]               0
      Bottleneck-156               [-1, 256, 1]               0
     BatchNorm1d-157               [-1, 256, 1]             512
            ReLU-158               [-1, 256, 1]               0
         Dropout-159               [-1, 256, 1]               0
          Conv1d-160               [-1, 256, 1]          16,640
 MyConv1dPadSame-161               [-1, 256, 1]               0
     BatchNorm1d-162               [-1, 256, 1]             512
            ReLU-163               [-1, 256, 1]               0
         Dropout-164               [-1, 256, 1]               0
          Conv1d-165               [-1, 256, 1]          16,640
 MyConv1dPadSame-166               [-1, 256, 1]               0
       MaxPool1d-167               [-1, 256, 1]               0
MyMaxPool1dPadSame-168               [-1, 256, 1]               0
      Bottleneck-169               [-1, 256, 1]               0
     BatchNorm1d-170               [-1, 256, 1]             512
            ReLU-171               [-1, 256, 1]               0
         Dropout-172               [-1, 256, 1]               0
          Conv1d-173               [-1, 256, 1]          16,640
 MyConv1dPadSame-174               [-1, 256, 1]               0
     BatchNorm1d-175               [-1, 256, 1]             512
            ReLU-176               [-1, 256, 1]               0
         Dropout-177               [-1, 256, 1]               0
          Conv1d-178               [-1, 256, 1]          16,640
 MyConv1dPadSame-179               [-1, 256, 1]               0
      Bottleneck-180               [-1, 256, 1]               0
     BatchNorm1d-181               [-1, 256, 1]             512
            ReLU-182               [-1, 256, 1]               0
         Dropout-183               [-1, 256, 1]               0
          Conv1d-184               [-1, 256, 1]          16,640
 MyConv1dPadSame-185               [-1, 256, 1]               0
     BatchNorm1d-186               [-1, 256, 1]             512
            ReLU-187               [-1, 256, 1]               0
         Dropout-188               [-1, 256, 1]               0
          Conv1d-189               [-1, 256, 1]          16,640
 MyConv1dPadSame-190               [-1, 256, 1]               0
       MaxPool1d-191               [-1, 256, 1]               0
MyMaxPool1dPadSame-192               [-1, 256, 1]               0
      Bottleneck-193               [-1, 256, 1]               0
     BatchNorm1d-194               [-1, 256, 1]             512
            ReLU-195               [-1, 256, 1]               0
          Linear-196                    [-1, 2]             514
================================================================
Total params: 175,714
Trainable params: 175,714
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.31
Params size (MB): 0.67
Estimated Total Size (MB): 0.98
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 32, kernel_size: 16, n_block: 2
************************************************************
************************************************************
(2000, 1, 16) Counter({1: 1000, 0: 1000})
(2000, 1, 16) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 32, 16]             544
   MyConv1dPadSame-2               [-1, 32, 16]               0
       BatchNorm1d-3               [-1, 32, 16]              64
              ReLU-4               [-1, 32, 16]               0
            Conv1d-5               [-1, 32, 16]             544
   MyConv1dPadSame-6               [-1, 32, 16]               0
       BatchNorm1d-7               [-1, 32, 16]              64
              ReLU-8               [-1, 32, 16]               0
           Dropout-9               [-1, 32, 16]               0
           Conv1d-10               [-1, 32, 16]             544
  MyConv1dPadSame-11               [-1, 32, 16]               0
       Bottleneck-12               [-1, 32, 16]               0
      BatchNorm1d-13               [-1, 32, 16]              64
             ReLU-14               [-1, 32, 16]               0
          Dropout-15               [-1, 32, 16]               0
           Conv1d-16               [-1, 64, 16]           1,088
  MyConv1dPadSame-17               [-1, 64, 16]               0
      BatchNorm1d-18               [-1, 64, 16]             128
             ReLU-19               [-1, 64, 16]               0
          Dropout-20               [-1, 64, 16]               0
           Conv1d-21               [-1, 64, 16]           2,112
  MyConv1dPadSame-22               [-1, 64, 16]               0
       Bottleneck-23               [-1, 64, 16]               0
      BatchNorm1d-24               [-1, 64, 16]             128
             ReLU-25               [-1, 64, 16]               0
           Linear-26                    [-1, 2]             130
================================================================
Total params: 5,410
Trainable params: 5,410
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.14
Params size (MB): 0.02
Estimated Total Size (MB): 0.16
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 32, kernel_size: 16, n_block: 4
************************************************************
************************************************************
(2000, 1, 16) Counter({0: 1000, 1: 1000})
(2000, 1, 16) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 32, 16]             544
   MyConv1dPadSame-2               [-1, 32, 16]               0
       BatchNorm1d-3               [-1, 32, 16]              64
              ReLU-4               [-1, 32, 16]               0
            Conv1d-5               [-1, 32, 16]             544
   MyConv1dPadSame-6               [-1, 32, 16]               0
       BatchNorm1d-7               [-1, 32, 16]              64
              ReLU-8               [-1, 32, 16]               0
           Dropout-9               [-1, 32, 16]               0
           Conv1d-10               [-1, 32, 16]             544
  MyConv1dPadSame-11               [-1, 32, 16]               0
       Bottleneck-12               [-1, 32, 16]               0
      BatchNorm1d-13               [-1, 32, 16]              64
             ReLU-14               [-1, 32, 16]               0
          Dropout-15               [-1, 32, 16]               0
           Conv1d-16               [-1, 64, 16]           1,088
  MyConv1dPadSame-17               [-1, 64, 16]               0
      BatchNorm1d-18               [-1, 64, 16]             128
             ReLU-19               [-1, 64, 16]               0
          Dropout-20               [-1, 64, 16]               0
           Conv1d-21               [-1, 64, 16]           2,112
  MyConv1dPadSame-22               [-1, 64, 16]               0
       Bottleneck-23               [-1, 64, 16]               0
      BatchNorm1d-24               [-1, 64, 16]             128
             ReLU-25               [-1, 64, 16]               0
          Dropout-26               [-1, 64, 16]               0
           Conv1d-27              [-1, 128, 16]           4,224
  MyConv1dPadSame-28              [-1, 128, 16]               0
      BatchNorm1d-29              [-1, 128, 16]             256
             ReLU-30              [-1, 128, 16]               0
          Dropout-31              [-1, 128, 16]               0
           Conv1d-32              [-1, 128, 16]           8,320
  MyConv1dPadSame-33              [-1, 128, 16]               0
       Bottleneck-34              [-1, 128, 16]               0
      BatchNorm1d-35              [-1, 128, 16]             256
             ReLU-36              [-1, 128, 16]               0
          Dropout-37              [-1, 128, 16]               0
           Conv1d-38              [-1, 256, 16]          16,640
  MyConv1dPadSame-39              [-1, 256, 16]               0
      BatchNorm1d-40              [-1, 256, 16]             512
             ReLU-41              [-1, 256, 16]               0
          Dropout-42              [-1, 256, 16]               0
           Conv1d-43              [-1, 256, 16]          33,024
  MyConv1dPadSame-44              [-1, 256, 16]               0
       Bottleneck-45              [-1, 256, 16]               0
      BatchNorm1d-46              [-1, 256, 16]             512
             ReLU-47              [-1, 256, 16]               0
           Linear-48                    [-1, 2]             514
================================================================
Total params: 69,538
Trainable params: 69,538
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.63
Params size (MB): 0.27
Estimated Total Size (MB): 0.89
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 32, kernel_size: 16, n_block: 8
************************************************************
************************************************************
(2000, 1, 16) Counter({1: 1000, 0: 1000})
(2000, 1, 16) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 32, 16]             544
   MyConv1dPadSame-2               [-1, 32, 16]               0
       BatchNorm1d-3               [-1, 32, 16]              64
              ReLU-4               [-1, 32, 16]               0
            Conv1d-5               [-1, 32, 16]             544
   MyConv1dPadSame-6               [-1, 32, 16]               0
       BatchNorm1d-7               [-1, 32, 16]              64
              ReLU-8               [-1, 32, 16]               0
           Dropout-9               [-1, 32, 16]               0
           Conv1d-10               [-1, 32, 16]             544
  MyConv1dPadSame-11               [-1, 32, 16]               0
       Bottleneck-12               [-1, 32, 16]               0
      BatchNorm1d-13               [-1, 32, 16]              64
             ReLU-14               [-1, 32, 16]               0
          Dropout-15               [-1, 32, 16]               0
           Conv1d-16               [-1, 32, 16]             544
  MyConv1dPadSame-17               [-1, 32, 16]               0
      BatchNorm1d-18               [-1, 32, 16]              64
             ReLU-19               [-1, 32, 16]               0
          Dropout-20               [-1, 32, 16]               0
           Conv1d-21               [-1, 32, 16]             544
  MyConv1dPadSame-22               [-1, 32, 16]               0
       Bottleneck-23               [-1, 32, 16]               0
      BatchNorm1d-24               [-1, 32, 16]              64
             ReLU-25               [-1, 32, 16]               0
          Dropout-26               [-1, 32, 16]               0
           Conv1d-27               [-1, 64, 16]           1,088
  MyConv1dPadSame-28               [-1, 64, 16]               0
      BatchNorm1d-29               [-1, 64, 16]             128
             ReLU-30               [-1, 64, 16]               0
          Dropout-31               [-1, 64, 16]               0
           Conv1d-32               [-1, 64, 16]           2,112
  MyConv1dPadSame-33               [-1, 64, 16]               0
       Bottleneck-34               [-1, 64, 16]               0
      BatchNorm1d-35               [-1, 64, 16]             128
             ReLU-36               [-1, 64, 16]               0
          Dropout-37               [-1, 64, 16]               0
           Conv1d-38               [-1, 64, 16]           2,112
  MyConv1dPadSame-39               [-1, 64, 16]               0
      BatchNorm1d-40               [-1, 64, 16]             128
             ReLU-41               [-1, 64, 16]               0
          Dropout-42               [-1, 64, 16]               0
           Conv1d-43               [-1, 64, 16]           2,112
  MyConv1dPadSame-44               [-1, 64, 16]               0
       Bottleneck-45               [-1, 64, 16]               0
      BatchNorm1d-46               [-1, 64, 16]             128
             ReLU-47               [-1, 64, 16]               0
          Dropout-48               [-1, 64, 16]               0
           Conv1d-49              [-1, 128, 16]           4,224
  MyConv1dPadSame-50              [-1, 128, 16]               0
      BatchNorm1d-51              [-1, 128, 16]             256
             ReLU-52              [-1, 128, 16]               0
          Dropout-53              [-1, 128, 16]               0
           Conv1d-54              [-1, 128, 16]           8,320
  MyConv1dPadSame-55              [-1, 128, 16]               0
       Bottleneck-56              [-1, 128, 16]               0
      BatchNorm1d-57              [-1, 128, 16]             256
             ReLU-58              [-1, 128, 16]               0
          Dropout-59              [-1, 128, 16]               0
           Conv1d-60              [-1, 128, 16]           8,320
  MyConv1dPadSame-61              [-1, 128, 16]               0
      BatchNorm1d-62              [-1, 128, 16]             256
             ReLU-63              [-1, 128, 16]               0
          Dropout-64              [-1, 128, 16]               0
           Conv1d-65              [-1, 128, 16]           8,320
  MyConv1dPadSame-66              [-1, 128, 16]               0
       Bottleneck-67              [-1, 128, 16]               0
      BatchNorm1d-68              [-1, 128, 16]             256
             ReLU-69              [-1, 128, 16]               0
          Dropout-70              [-1, 128, 16]               0
           Conv1d-71              [-1, 256, 16]          16,640
  MyConv1dPadSame-72              [-1, 256, 16]               0
      BatchNorm1d-73              [-1, 256, 16]             512
             ReLU-74              [-1, 256, 16]               0
          Dropout-75              [-1, 256, 16]               0
           Conv1d-76              [-1, 256, 16]          33,024
  MyConv1dPadSame-77              [-1, 256, 16]               0
       Bottleneck-78              [-1, 256, 16]               0
      BatchNorm1d-79              [-1, 256, 16]             512
             ReLU-80              [-1, 256, 16]               0
          Dropout-81              [-1, 256, 16]               0
           Conv1d-82              [-1, 256, 16]          33,024
  MyConv1dPadSame-83              [-1, 256, 16]               0
      BatchNorm1d-84              [-1, 256, 16]             512
             ReLU-85              [-1, 256, 16]               0
          Dropout-86              [-1, 256, 16]               0
           Conv1d-87              [-1, 256, 16]          33,024
  MyConv1dPadSame-88              [-1, 256, 16]               0
       Bottleneck-89              [-1, 256, 16]               0
      BatchNorm1d-90              [-1, 256, 16]             512
             ReLU-91              [-1, 256, 16]               0
           Linear-92                    [-1, 2]             514
================================================================
Total params: 159,458
Trainable params: 159,458
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 1.27
Params size (MB): 0.61
Estimated Total Size (MB): 1.88
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 32, kernel_size: 16, n_block: 16
************************************************************
************************************************************
(2000, 1, 16) Counter({1: 1000, 0: 1000})
(2000, 1, 16) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 32, 16]             544
   MyConv1dPadSame-2               [-1, 32, 16]               0
       BatchNorm1d-3               [-1, 32, 16]              64
              ReLU-4               [-1, 32, 16]               0
            Conv1d-5               [-1, 32, 16]             544
   MyConv1dPadSame-6               [-1, 32, 16]               0
       BatchNorm1d-7               [-1, 32, 16]              64
              ReLU-8               [-1, 32, 16]               0
           Dropout-9               [-1, 32, 16]               0
           Conv1d-10               [-1, 32, 16]             544
  MyConv1dPadSame-11               [-1, 32, 16]               0
       Bottleneck-12               [-1, 32, 16]               0
      BatchNorm1d-13               [-1, 32, 16]              64
             ReLU-14               [-1, 32, 16]               0
          Dropout-15               [-1, 32, 16]               0
           Conv1d-16                [-1, 32, 8]             544
  MyConv1dPadSame-17                [-1, 32, 8]               0
      BatchNorm1d-18                [-1, 32, 8]              64
             ReLU-19                [-1, 32, 8]               0
          Dropout-20                [-1, 32, 8]               0
           Conv1d-21                [-1, 32, 8]             544
  MyConv1dPadSame-22                [-1, 32, 8]               0
        MaxPool1d-23                [-1, 32, 8]               0
MyMaxPool1dPadSame-24                [-1, 32, 8]               0
       Bottleneck-25                [-1, 32, 8]               0
      BatchNorm1d-26                [-1, 32, 8]              64
             ReLU-27                [-1, 32, 8]               0
          Dropout-28                [-1, 32, 8]               0
           Conv1d-29                [-1, 32, 8]             544
  MyConv1dPadSame-30                [-1, 32, 8]               0
      BatchNorm1d-31                [-1, 32, 8]              64
             ReLU-32                [-1, 32, 8]               0
          Dropout-33                [-1, 32, 8]               0
           Conv1d-34                [-1, 32, 8]             544
  MyConv1dPadSame-35                [-1, 32, 8]               0
       Bottleneck-36                [-1, 32, 8]               0
      BatchNorm1d-37                [-1, 32, 8]              64
             ReLU-38                [-1, 32, 8]               0
          Dropout-39                [-1, 32, 8]               0
           Conv1d-40                [-1, 32, 4]             544
  MyConv1dPadSame-41                [-1, 32, 4]               0
      BatchNorm1d-42                [-1, 32, 4]              64
             ReLU-43                [-1, 32, 4]               0
          Dropout-44                [-1, 32, 4]               0
           Conv1d-45                [-1, 32, 4]             544
  MyConv1dPadSame-46                [-1, 32, 4]               0
        MaxPool1d-47                [-1, 32, 4]               0
MyMaxPool1dPadSame-48                [-1, 32, 4]               0
       Bottleneck-49                [-1, 32, 4]               0
      BatchNorm1d-50                [-1, 32, 4]              64
             ReLU-51                [-1, 32, 4]               0
          Dropout-52                [-1, 32, 4]               0
           Conv1d-53                [-1, 64, 4]           1,088
  MyConv1dPadSame-54                [-1, 64, 4]               0
      BatchNorm1d-55                [-1, 64, 4]             128
             ReLU-56                [-1, 64, 4]               0
          Dropout-57                [-1, 64, 4]               0
           Conv1d-58                [-1, 64, 4]           2,112
  MyConv1dPadSame-59                [-1, 64, 4]               0
       Bottleneck-60                [-1, 64, 4]               0
      BatchNorm1d-61                [-1, 64, 4]             128
             ReLU-62                [-1, 64, 4]               0
          Dropout-63                [-1, 64, 4]               0
           Conv1d-64                [-1, 64, 2]           2,112
  MyConv1dPadSame-65                [-1, 64, 2]               0
      BatchNorm1d-66                [-1, 64, 2]             128
             ReLU-67                [-1, 64, 2]               0
          Dropout-68                [-1, 64, 2]               0
           Conv1d-69                [-1, 64, 2]           2,112
  MyConv1dPadSame-70                [-1, 64, 2]               0
        MaxPool1d-71                [-1, 64, 2]               0
MyMaxPool1dPadSame-72                [-1, 64, 2]               0
       Bottleneck-73                [-1, 64, 2]               0
      BatchNorm1d-74                [-1, 64, 2]             128
             ReLU-75                [-1, 64, 2]               0
          Dropout-76                [-1, 64, 2]               0
           Conv1d-77                [-1, 64, 2]           2,112
  MyConv1dPadSame-78                [-1, 64, 2]               0
      BatchNorm1d-79                [-1, 64, 2]             128
             ReLU-80                [-1, 64, 2]               0
          Dropout-81                [-1, 64, 2]               0
           Conv1d-82                [-1, 64, 2]           2,112
  MyConv1dPadSame-83                [-1, 64, 2]               0
       Bottleneck-84                [-1, 64, 2]               0
      BatchNorm1d-85                [-1, 64, 2]             128
             ReLU-86                [-1, 64, 2]               0
          Dropout-87                [-1, 64, 2]               0
           Conv1d-88                [-1, 64, 1]           2,112
  MyConv1dPadSame-89                [-1, 64, 1]               0
      BatchNorm1d-90                [-1, 64, 1]             128
             ReLU-91                [-1, 64, 1]               0
          Dropout-92                [-1, 64, 1]               0
           Conv1d-93                [-1, 64, 1]           2,112
  MyConv1dPadSame-94                [-1, 64, 1]               0
        MaxPool1d-95                [-1, 64, 1]               0
MyMaxPool1dPadSame-96                [-1, 64, 1]               0
       Bottleneck-97                [-1, 64, 1]               0
      BatchNorm1d-98                [-1, 64, 1]             128
             ReLU-99                [-1, 64, 1]               0
         Dropout-100                [-1, 64, 1]               0
          Conv1d-101               [-1, 128, 1]           4,224
 MyConv1dPadSame-102               [-1, 128, 1]               0
     BatchNorm1d-103               [-1, 128, 1]             256
            ReLU-104               [-1, 128, 1]               0
         Dropout-105               [-1, 128, 1]               0
          Conv1d-106               [-1, 128, 1]           8,320
 MyConv1dPadSame-107               [-1, 128, 1]               0
      Bottleneck-108               [-1, 128, 1]               0
     BatchNorm1d-109               [-1, 128, 1]             256
            ReLU-110               [-1, 128, 1]               0
         Dropout-111               [-1, 128, 1]               0
          Conv1d-112               [-1, 128, 1]           8,320
 MyConv1dPadSame-113               [-1, 128, 1]               0
     BatchNorm1d-114               [-1, 128, 1]             256
            ReLU-115               [-1, 128, 1]               0
         Dropout-116               [-1, 128, 1]               0
          Conv1d-117               [-1, 128, 1]           8,320
 MyConv1dPadSame-118               [-1, 128, 1]               0
       MaxPool1d-119               [-1, 128, 1]               0
MyMaxPool1dPadSame-120               [-1, 128, 1]               0
      Bottleneck-121               [-1, 128, 1]               0
     BatchNorm1d-122               [-1, 128, 1]             256
            ReLU-123               [-1, 128, 1]               0
         Dropout-124               [-1, 128, 1]               0
          Conv1d-125               [-1, 128, 1]           8,320
 MyConv1dPadSame-126               [-1, 128, 1]               0
     BatchNorm1d-127               [-1, 128, 1]             256
            ReLU-128               [-1, 128, 1]               0
         Dropout-129               [-1, 128, 1]               0
          Conv1d-130               [-1, 128, 1]           8,320
 MyConv1dPadSame-131               [-1, 128, 1]               0
      Bottleneck-132               [-1, 128, 1]               0
     BatchNorm1d-133               [-1, 128, 1]             256
            ReLU-134               [-1, 128, 1]               0
         Dropout-135               [-1, 128, 1]               0
          Conv1d-136               [-1, 128, 1]           8,320
 MyConv1dPadSame-137               [-1, 128, 1]               0
     BatchNorm1d-138               [-1, 128, 1]             256
            ReLU-139               [-1, 128, 1]               0
         Dropout-140               [-1, 128, 1]               0
          Conv1d-141               [-1, 128, 1]           8,320
 MyConv1dPadSame-142               [-1, 128, 1]               0
       MaxPool1d-143               [-1, 128, 1]               0
MyMaxPool1dPadSame-144               [-1, 128, 1]               0
      Bottleneck-145               [-1, 128, 1]               0
     BatchNorm1d-146               [-1, 128, 1]             256
            ReLU-147               [-1, 128, 1]               0
         Dropout-148               [-1, 128, 1]               0
          Conv1d-149               [-1, 256, 1]          16,640
 MyConv1dPadSame-150               [-1, 256, 1]               0
     BatchNorm1d-151               [-1, 256, 1]             512
            ReLU-152               [-1, 256, 1]               0
         Dropout-153               [-1, 256, 1]               0
          Conv1d-154               [-1, 256, 1]          33,024
 MyConv1dPadSame-155               [-1, 256, 1]               0
      Bottleneck-156               [-1, 256, 1]               0
     BatchNorm1d-157               [-1, 256, 1]             512
            ReLU-158               [-1, 256, 1]               0
         Dropout-159               [-1, 256, 1]               0
          Conv1d-160               [-1, 256, 1]          33,024
 MyConv1dPadSame-161               [-1, 256, 1]               0
     BatchNorm1d-162               [-1, 256, 1]             512
            ReLU-163               [-1, 256, 1]               0
         Dropout-164               [-1, 256, 1]               0
          Conv1d-165               [-1, 256, 1]          33,024
 MyConv1dPadSame-166               [-1, 256, 1]               0
       MaxPool1d-167               [-1, 256, 1]               0
MyMaxPool1dPadSame-168               [-1, 256, 1]               0
      Bottleneck-169               [-1, 256, 1]               0
     BatchNorm1d-170               [-1, 256, 1]             512
            ReLU-171               [-1, 256, 1]               0
         Dropout-172               [-1, 256, 1]               0
          Conv1d-173               [-1, 256, 1]          33,024
 MyConv1dPadSame-174               [-1, 256, 1]               0
     BatchNorm1d-175               [-1, 256, 1]             512
            ReLU-176               [-1, 256, 1]               0
         Dropout-177               [-1, 256, 1]               0
          Conv1d-178               [-1, 256, 1]          33,024
 MyConv1dPadSame-179               [-1, 256, 1]               0
      Bottleneck-180               [-1, 256, 1]               0
     BatchNorm1d-181               [-1, 256, 1]             512
            ReLU-182               [-1, 256, 1]               0
         Dropout-183               [-1, 256, 1]               0
          Conv1d-184               [-1, 256, 1]          33,024
 MyConv1dPadSame-185               [-1, 256, 1]               0
     BatchNorm1d-186               [-1, 256, 1]             512
            ReLU-187               [-1, 256, 1]               0
         Dropout-188               [-1, 256, 1]               0
          Conv1d-189               [-1, 256, 1]          33,024
 MyConv1dPadSame-190               [-1, 256, 1]               0
       MaxPool1d-191               [-1, 256, 1]               0
MyMaxPool1dPadSame-192               [-1, 256, 1]               0
      Bottleneck-193               [-1, 256, 1]               0
     BatchNorm1d-194               [-1, 256, 1]             512
            ReLU-195               [-1, 256, 1]               0
          Linear-196                    [-1, 2]             514
================================================================
Total params: 339,298
Trainable params: 339,298
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.31
Params size (MB): 1.29
Estimated Total Size (MB): 1.60
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 64, kernel_size: 2, n_block: 2
************************************************************
************************************************************
(2000, 1, 16) Counter({1: 1000, 0: 1000})
(2000, 1, 16) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 64, 16]             192
   MyConv1dPadSame-2               [-1, 64, 16]               0
       BatchNorm1d-3               [-1, 64, 16]             128
              ReLU-4               [-1, 64, 16]               0
            Conv1d-5               [-1, 64, 16]             192
   MyConv1dPadSame-6               [-1, 64, 16]               0
       BatchNorm1d-7               [-1, 64, 16]             128
              ReLU-8               [-1, 64, 16]               0
           Dropout-9               [-1, 64, 16]               0
           Conv1d-10               [-1, 64, 16]             192
  MyConv1dPadSame-11               [-1, 64, 16]               0
       Bottleneck-12               [-1, 64, 16]               0
      BatchNorm1d-13               [-1, 64, 16]             128
             ReLU-14               [-1, 64, 16]               0
          Dropout-15               [-1, 64, 16]               0
           Conv1d-16              [-1, 128, 16]             384
  MyConv1dPadSame-17              [-1, 128, 16]               0
      BatchNorm1d-18              [-1, 128, 16]             256
             ReLU-19              [-1, 128, 16]               0
          Dropout-20              [-1, 128, 16]               0
           Conv1d-21              [-1, 128, 16]             640
  MyConv1dPadSame-22              [-1, 128, 16]               0
       Bottleneck-23              [-1, 128, 16]               0
      BatchNorm1d-24              [-1, 128, 16]             256
             ReLU-25              [-1, 128, 16]               0
           Linear-26                    [-1, 2]             258
================================================================
Total params: 2,754
Trainable params: 2,754
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.27
Params size (MB): 0.01
Estimated Total Size (MB): 0.28
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 64, kernel_size: 2, n_block: 4
************************************************************
************************************************************
(2000, 1, 16) Counter({0: 1000, 1: 1000})
(2000, 1, 16) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 64, 16]             192
   MyConv1dPadSame-2               [-1, 64, 16]               0
       BatchNorm1d-3               [-1, 64, 16]             128
              ReLU-4               [-1, 64, 16]               0
            Conv1d-5               [-1, 64, 16]             192
   MyConv1dPadSame-6               [-1, 64, 16]               0
       BatchNorm1d-7               [-1, 64, 16]             128
              ReLU-8               [-1, 64, 16]               0
           Dropout-9               [-1, 64, 16]               0
           Conv1d-10               [-1, 64, 16]             192
  MyConv1dPadSame-11               [-1, 64, 16]               0
       Bottleneck-12               [-1, 64, 16]               0
      BatchNorm1d-13               [-1, 64, 16]             128
             ReLU-14               [-1, 64, 16]               0
          Dropout-15               [-1, 64, 16]               0
           Conv1d-16              [-1, 128, 16]             384
  MyConv1dPadSame-17              [-1, 128, 16]               0
      BatchNorm1d-18              [-1, 128, 16]             256
             ReLU-19              [-1, 128, 16]               0
          Dropout-20              [-1, 128, 16]               0
           Conv1d-21              [-1, 128, 16]             640
  MyConv1dPadSame-22              [-1, 128, 16]               0
       Bottleneck-23              [-1, 128, 16]               0
      BatchNorm1d-24              [-1, 128, 16]             256
             ReLU-25              [-1, 128, 16]               0
          Dropout-26              [-1, 128, 16]               0
           Conv1d-27              [-1, 256, 16]           1,280
  MyConv1dPadSame-28              [-1, 256, 16]               0
      BatchNorm1d-29              [-1, 256, 16]             512
             ReLU-30              [-1, 256, 16]               0
          Dropout-31              [-1, 256, 16]               0
           Conv1d-32              [-1, 256, 16]           2,304
  MyConv1dPadSame-33              [-1, 256, 16]               0
       Bottleneck-34              [-1, 256, 16]               0
      BatchNorm1d-35              [-1, 256, 16]             512
             ReLU-36              [-1, 256, 16]               0
          Dropout-37              [-1, 256, 16]               0
           Conv1d-38              [-1, 512, 16]           4,608
  MyConv1dPadSame-39              [-1, 512, 16]               0
      BatchNorm1d-40              [-1, 512, 16]           1,024
             ReLU-41              [-1, 512, 16]               0
          Dropout-42              [-1, 512, 16]               0
           Conv1d-43              [-1, 512, 16]           8,704
  MyConv1dPadSame-44              [-1, 512, 16]               0
       Bottleneck-45              [-1, 512, 16]               0
      BatchNorm1d-46              [-1, 512, 16]           1,024
             ReLU-47              [-1, 512, 16]               0
           Linear-48                    [-1, 2]           1,026
================================================================
Total params: 23,490
Trainable params: 23,490
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 1.26
Params size (MB): 0.09
Estimated Total Size (MB): 1.35
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 64, kernel_size: 2, n_block: 8
************************************************************
************************************************************
(2000, 1, 16) Counter({1: 1000, 0: 1000})
(2000, 1, 16) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 64, 16]             192
   MyConv1dPadSame-2               [-1, 64, 16]               0
       BatchNorm1d-3               [-1, 64, 16]             128
              ReLU-4               [-1, 64, 16]               0
            Conv1d-5               [-1, 64, 16]             192
   MyConv1dPadSame-6               [-1, 64, 16]               0
       BatchNorm1d-7               [-1, 64, 16]             128
              ReLU-8               [-1, 64, 16]               0
           Dropout-9               [-1, 64, 16]               0
           Conv1d-10               [-1, 64, 16]             192
  MyConv1dPadSame-11               [-1, 64, 16]               0
       Bottleneck-12               [-1, 64, 16]               0
      BatchNorm1d-13               [-1, 64, 16]             128
             ReLU-14               [-1, 64, 16]               0
          Dropout-15               [-1, 64, 16]               0
           Conv1d-16               [-1, 64, 16]             192
  MyConv1dPadSame-17               [-1, 64, 16]               0
      BatchNorm1d-18               [-1, 64, 16]             128
             ReLU-19               [-1, 64, 16]               0
          Dropout-20               [-1, 64, 16]               0
           Conv1d-21               [-1, 64, 16]             192
  MyConv1dPadSame-22               [-1, 64, 16]               0
       Bottleneck-23               [-1, 64, 16]               0
      BatchNorm1d-24               [-1, 64, 16]             128
             ReLU-25               [-1, 64, 16]               0
          Dropout-26               [-1, 64, 16]               0
           Conv1d-27              [-1, 128, 16]             384
  MyConv1dPadSame-28              [-1, 128, 16]               0
      BatchNorm1d-29              [-1, 128, 16]             256
             ReLU-30              [-1, 128, 16]               0
          Dropout-31              [-1, 128, 16]               0
           Conv1d-32              [-1, 128, 16]             640
  MyConv1dPadSame-33              [-1, 128, 16]               0
       Bottleneck-34              [-1, 128, 16]               0
      BatchNorm1d-35              [-1, 128, 16]             256
             ReLU-36              [-1, 128, 16]               0
          Dropout-37              [-1, 128, 16]               0
           Conv1d-38              [-1, 128, 16]             640
  MyConv1dPadSame-39              [-1, 128, 16]               0
      BatchNorm1d-40              [-1, 128, 16]             256
             ReLU-41              [-1, 128, 16]               0
          Dropout-42              [-1, 128, 16]               0
           Conv1d-43              [-1, 128, 16]             640
  MyConv1dPadSame-44              [-1, 128, 16]               0
       Bottleneck-45              [-1, 128, 16]               0
      BatchNorm1d-46              [-1, 128, 16]             256
             ReLU-47              [-1, 128, 16]               0
          Dropout-48              [-1, 128, 16]               0
           Conv1d-49              [-1, 256, 16]           1,280
  MyConv1dPadSame-50              [-1, 256, 16]               0
      BatchNorm1d-51              [-1, 256, 16]             512
             ReLU-52              [-1, 256, 16]               0
          Dropout-53              [-1, 256, 16]               0
           Conv1d-54              [-1, 256, 16]           2,304
  MyConv1dPadSame-55              [-1, 256, 16]               0
       Bottleneck-56              [-1, 256, 16]               0
      BatchNorm1d-57              [-1, 256, 16]             512
             ReLU-58              [-1, 256, 16]               0
          Dropout-59              [-1, 256, 16]               0
           Conv1d-60              [-1, 256, 16]           2,304
  MyConv1dPadSame-61              [-1, 256, 16]               0
      BatchNorm1d-62              [-1, 256, 16]             512
             ReLU-63              [-1, 256, 16]               0
          Dropout-64              [-1, 256, 16]               0
           Conv1d-65              [-1, 256, 16]           2,304
  MyConv1dPadSame-66              [-1, 256, 16]               0
       Bottleneck-67              [-1, 256, 16]               0
      BatchNorm1d-68              [-1, 256, 16]             512
             ReLU-69              [-1, 256, 16]               0
          Dropout-70              [-1, 256, 16]               0
           Conv1d-71              [-1, 512, 16]           4,608
  MyConv1dPadSame-72              [-1, 512, 16]               0
      BatchNorm1d-73              [-1, 512, 16]           1,024
             ReLU-74              [-1, 512, 16]               0
          Dropout-75              [-1, 512, 16]               0
           Conv1d-76              [-1, 512, 16]           8,704
  MyConv1dPadSame-77              [-1, 512, 16]               0
       Bottleneck-78              [-1, 512, 16]               0
      BatchNorm1d-79              [-1, 512, 16]           1,024
             ReLU-80              [-1, 512, 16]               0
          Dropout-81              [-1, 512, 16]               0
           Conv1d-82              [-1, 512, 16]           8,704
  MyConv1dPadSame-83              [-1, 512, 16]               0
      BatchNorm1d-84              [-1, 512, 16]           1,024
             ReLU-85              [-1, 512, 16]               0
          Dropout-86              [-1, 512, 16]               0
           Conv1d-87              [-1, 512, 16]           8,704
  MyConv1dPadSame-88              [-1, 512, 16]               0
       Bottleneck-89              [-1, 512, 16]               0
      BatchNorm1d-90              [-1, 512, 16]           1,024
             ReLU-91              [-1, 512, 16]               0
           Linear-92                    [-1, 2]           1,026
================================================================
Total params: 51,010
Trainable params: 51,010
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 2.55
Params size (MB): 0.19
Estimated Total Size (MB): 2.74
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 64, kernel_size: 2, n_block: 16
************************************************************
************************************************************
(2000, 1, 16) Counter({1: 1000, 0: 1000})
(2000, 1, 16) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 64, 16]             192
   MyConv1dPadSame-2               [-1, 64, 16]               0
       BatchNorm1d-3               [-1, 64, 16]             128
              ReLU-4               [-1, 64, 16]               0
            Conv1d-5               [-1, 64, 16]             192
   MyConv1dPadSame-6               [-1, 64, 16]               0
       BatchNorm1d-7               [-1, 64, 16]             128
              ReLU-8               [-1, 64, 16]               0
           Dropout-9               [-1, 64, 16]               0
           Conv1d-10               [-1, 64, 16]             192
  MyConv1dPadSame-11               [-1, 64, 16]               0
       Bottleneck-12               [-1, 64, 16]               0
      BatchNorm1d-13               [-1, 64, 16]             128
             ReLU-14               [-1, 64, 16]               0
          Dropout-15               [-1, 64, 16]               0
           Conv1d-16                [-1, 64, 8]             192
  MyConv1dPadSame-17                [-1, 64, 8]               0
      BatchNorm1d-18                [-1, 64, 8]             128
             ReLU-19                [-1, 64, 8]               0
          Dropout-20                [-1, 64, 8]               0
           Conv1d-21                [-1, 64, 8]             192
  MyConv1dPadSame-22                [-1, 64, 8]               0
        MaxPool1d-23                [-1, 64, 8]               0
MyMaxPool1dPadSame-24                [-1, 64, 8]               0
       Bottleneck-25                [-1, 64, 8]               0
      BatchNorm1d-26                [-1, 64, 8]             128
             ReLU-27                [-1, 64, 8]               0
          Dropout-28                [-1, 64, 8]               0
           Conv1d-29                [-1, 64, 8]             192
  MyConv1dPadSame-30                [-1, 64, 8]               0
      BatchNorm1d-31                [-1, 64, 8]             128
             ReLU-32                [-1, 64, 8]               0
          Dropout-33                [-1, 64, 8]               0
           Conv1d-34                [-1, 64, 8]             192
  MyConv1dPadSame-35                [-1, 64, 8]               0
       Bottleneck-36                [-1, 64, 8]               0
      BatchNorm1d-37                [-1, 64, 8]             128
             ReLU-38                [-1, 64, 8]               0
          Dropout-39                [-1, 64, 8]               0
           Conv1d-40                [-1, 64, 4]             192
  MyConv1dPadSame-41                [-1, 64, 4]               0
      BatchNorm1d-42                [-1, 64, 4]             128
             ReLU-43                [-1, 64, 4]               0
          Dropout-44                [-1, 64, 4]               0
           Conv1d-45                [-1, 64, 4]             192
  MyConv1dPadSame-46                [-1, 64, 4]               0
        MaxPool1d-47                [-1, 64, 4]               0
MyMaxPool1dPadSame-48                [-1, 64, 4]               0
       Bottleneck-49                [-1, 64, 4]               0
      BatchNorm1d-50                [-1, 64, 4]             128
             ReLU-51                [-1, 64, 4]               0
          Dropout-52                [-1, 64, 4]               0
           Conv1d-53               [-1, 128, 4]             384
  MyConv1dPadSame-54               [-1, 128, 4]               0
      BatchNorm1d-55               [-1, 128, 4]             256
             ReLU-56               [-1, 128, 4]               0
          Dropout-57               [-1, 128, 4]               0
           Conv1d-58               [-1, 128, 4]             640
  MyConv1dPadSame-59               [-1, 128, 4]               0
       Bottleneck-60               [-1, 128, 4]               0
      BatchNorm1d-61               [-1, 128, 4]             256
             ReLU-62               [-1, 128, 4]               0
          Dropout-63               [-1, 128, 4]               0
           Conv1d-64               [-1, 128, 2]             640
  MyConv1dPadSame-65               [-1, 128, 2]               0
      BatchNorm1d-66               [-1, 128, 2]             256
             ReLU-67               [-1, 128, 2]               0
          Dropout-68               [-1, 128, 2]               0
           Conv1d-69               [-1, 128, 2]             640
  MyConv1dPadSame-70               [-1, 128, 2]               0
        MaxPool1d-71               [-1, 128, 2]               0
MyMaxPool1dPadSame-72               [-1, 128, 2]               0
       Bottleneck-73               [-1, 128, 2]               0
      BatchNorm1d-74               [-1, 128, 2]             256
             ReLU-75               [-1, 128, 2]               0
          Dropout-76               [-1, 128, 2]               0
           Conv1d-77               [-1, 128, 2]             640
  MyConv1dPadSame-78               [-1, 128, 2]               0
      BatchNorm1d-79               [-1, 128, 2]             256
             ReLU-80               [-1, 128, 2]               0
          Dropout-81               [-1, 128, 2]               0
           Conv1d-82               [-1, 128, 2]             640
  MyConv1dPadSame-83               [-1, 128, 2]               0
       Bottleneck-84               [-1, 128, 2]               0
      BatchNorm1d-85               [-1, 128, 2]             256
             ReLU-86               [-1, 128, 2]               0
          Dropout-87               [-1, 128, 2]               0
           Conv1d-88               [-1, 128, 1]             640
  MyConv1dPadSame-89               [-1, 128, 1]               0
      BatchNorm1d-90               [-1, 128, 1]             256
             ReLU-91               [-1, 128, 1]               0
          Dropout-92               [-1, 128, 1]               0
           Conv1d-93               [-1, 128, 1]             640
  MyConv1dPadSame-94               [-1, 128, 1]               0
        MaxPool1d-95               [-1, 128, 1]               0
MyMaxPool1dPadSame-96               [-1, 128, 1]               0
       Bottleneck-97               [-1, 128, 1]               0
      BatchNorm1d-98               [-1, 128, 1]             256
             ReLU-99               [-1, 128, 1]               0
         Dropout-100               [-1, 128, 1]               0
          Conv1d-101               [-1, 256, 1]           1,280
 MyConv1dPadSame-102               [-1, 256, 1]               0
     BatchNorm1d-103               [-1, 256, 1]             512
            ReLU-104               [-1, 256, 1]               0
         Dropout-105               [-1, 256, 1]               0
          Conv1d-106               [-1, 256, 1]           2,304
 MyConv1dPadSame-107               [-1, 256, 1]               0
      Bottleneck-108               [-1, 256, 1]               0
     BatchNorm1d-109               [-1, 256, 1]             512
            ReLU-110               [-1, 256, 1]               0
         Dropout-111               [-1, 256, 1]               0
          Conv1d-112               [-1, 256, 1]           2,304
 MyConv1dPadSame-113               [-1, 256, 1]               0
     BatchNorm1d-114               [-1, 256, 1]             512
            ReLU-115               [-1, 256, 1]               0
         Dropout-116               [-1, 256, 1]               0
          Conv1d-117               [-1, 256, 1]           2,304
 MyConv1dPadSame-118               [-1, 256, 1]               0
       MaxPool1d-119               [-1, 256, 1]               0
MyMaxPool1dPadSame-120               [-1, 256, 1]               0
      Bottleneck-121               [-1, 256, 1]               0
     BatchNorm1d-122               [-1, 256, 1]             512
            ReLU-123               [-1, 256, 1]               0
         Dropout-124               [-1, 256, 1]               0
          Conv1d-125               [-1, 256, 1]           2,304
 MyConv1dPadSame-126               [-1, 256, 1]               0
     BatchNorm1d-127               [-1, 256, 1]             512
            ReLU-128               [-1, 256, 1]               0
         Dropout-129               [-1, 256, 1]               0
          Conv1d-130               [-1, 256, 1]           2,304
 MyConv1dPadSame-131               [-1, 256, 1]               0
      Bottleneck-132               [-1, 256, 1]               0
     BatchNorm1d-133               [-1, 256, 1]             512
            ReLU-134               [-1, 256, 1]               0
         Dropout-135               [-1, 256, 1]               0
          Conv1d-136               [-1, 256, 1]           2,304
 MyConv1dPadSame-137               [-1, 256, 1]               0
     BatchNorm1d-138               [-1, 256, 1]             512
            ReLU-139               [-1, 256, 1]               0
         Dropout-140               [-1, 256, 1]               0
          Conv1d-141               [-1, 256, 1]           2,304
 MyConv1dPadSame-142               [-1, 256, 1]               0
       MaxPool1d-143               [-1, 256, 1]               0
MyMaxPool1dPadSame-144               [-1, 256, 1]               0
      Bottleneck-145               [-1, 256, 1]               0
     BatchNorm1d-146               [-1, 256, 1]             512
            ReLU-147               [-1, 256, 1]               0
         Dropout-148               [-1, 256, 1]               0
          Conv1d-149               [-1, 512, 1]           4,608
 MyConv1dPadSame-150               [-1, 512, 1]               0
     BatchNorm1d-151               [-1, 512, 1]           1,024
            ReLU-152               [-1, 512, 1]               0
         Dropout-153               [-1, 512, 1]               0
          Conv1d-154               [-1, 512, 1]           8,704
 MyConv1dPadSame-155               [-1, 512, 1]               0
      Bottleneck-156               [-1, 512, 1]               0
     BatchNorm1d-157               [-1, 512, 1]           1,024
            ReLU-158               [-1, 512, 1]               0
         Dropout-159               [-1, 512, 1]               0
          Conv1d-160               [-1, 512, 1]           8,704
 MyConv1dPadSame-161               [-1, 512, 1]               0
     BatchNorm1d-162               [-1, 512, 1]           1,024
            ReLU-163               [-1, 512, 1]               0
         Dropout-164               [-1, 512, 1]               0
          Conv1d-165               [-1, 512, 1]           8,704
 MyConv1dPadSame-166               [-1, 512, 1]               0
       MaxPool1d-167               [-1, 512, 1]               0
MyMaxPool1dPadSame-168               [-1, 512, 1]               0
      Bottleneck-169               [-1, 512, 1]               0
     BatchNorm1d-170               [-1, 512, 1]           1,024
            ReLU-171               [-1, 512, 1]               0
         Dropout-172               [-1, 512, 1]               0
          Conv1d-173               [-1, 512, 1]           8,704
 MyConv1dPadSame-174               [-1, 512, 1]               0
     BatchNorm1d-175               [-1, 512, 1]           1,024
            ReLU-176               [-1, 512, 1]               0
         Dropout-177               [-1, 512, 1]               0
          Conv1d-178               [-1, 512, 1]           8,704
 MyConv1dPadSame-179               [-1, 512, 1]               0
      Bottleneck-180               [-1, 512, 1]               0
     BatchNorm1d-181               [-1, 512, 1]           1,024
            ReLU-182               [-1, 512, 1]               0
         Dropout-183               [-1, 512, 1]               0
          Conv1d-184               [-1, 512, 1]           8,704
 MyConv1dPadSame-185               [-1, 512, 1]               0
     BatchNorm1d-186               [-1, 512, 1]           1,024
            ReLU-187               [-1, 512, 1]               0
         Dropout-188               [-1, 512, 1]               0
          Conv1d-189               [-1, 512, 1]           8,704
 MyConv1dPadSame-190               [-1, 512, 1]               0
       MaxPool1d-191               [-1, 512, 1]               0
MyMaxPool1dPadSame-192               [-1, 512, 1]               0
      Bottleneck-193               [-1, 512, 1]               0
     BatchNorm1d-194               [-1, 512, 1]           1,024
            ReLU-195               [-1, 512, 1]               0
          Linear-196                    [-1, 2]           1,026
================================================================
Total params: 106,050
Trainable params: 106,050
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.62
Params size (MB): 0.40
Estimated Total Size (MB): 1.02
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 64, kernel_size: 4, n_block: 2
************************************************************
************************************************************
(2000, 1, 16) Counter({0: 1000, 1: 1000})
(2000, 1, 16) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 64, 16]             320
   MyConv1dPadSame-2               [-1, 64, 16]               0
       BatchNorm1d-3               [-1, 64, 16]             128
              ReLU-4               [-1, 64, 16]               0
            Conv1d-5               [-1, 64, 16]             320
   MyConv1dPadSame-6               [-1, 64, 16]               0
       BatchNorm1d-7               [-1, 64, 16]             128
              ReLU-8               [-1, 64, 16]               0
           Dropout-9               [-1, 64, 16]               0
           Conv1d-10               [-1, 64, 16]             320
  MyConv1dPadSame-11               [-1, 64, 16]               0
       Bottleneck-12               [-1, 64, 16]               0
      BatchNorm1d-13               [-1, 64, 16]             128
             ReLU-14               [-1, 64, 16]               0
          Dropout-15               [-1, 64, 16]               0
           Conv1d-16              [-1, 128, 16]             640
  MyConv1dPadSame-17              [-1, 128, 16]               0
      BatchNorm1d-18              [-1, 128, 16]             256
             ReLU-19              [-1, 128, 16]               0
          Dropout-20              [-1, 128, 16]               0
           Conv1d-21              [-1, 128, 16]           1,152
  MyConv1dPadSame-22              [-1, 128, 16]               0
       Bottleneck-23              [-1, 128, 16]               0
      BatchNorm1d-24              [-1, 128, 16]             256
             ReLU-25              [-1, 128, 16]               0
           Linear-26                    [-1, 2]             258
================================================================
Total params: 3,906
Trainable params: 3,906
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.27
Params size (MB): 0.01
Estimated Total Size (MB): 0.29
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 64, kernel_size: 4, n_block: 4
************************************************************
************************************************************
(2000, 1, 16) Counter({1: 1000, 0: 1000})
(2000, 1, 16) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 64, 16]             320
   MyConv1dPadSame-2               [-1, 64, 16]               0
       BatchNorm1d-3               [-1, 64, 16]             128
              ReLU-4               [-1, 64, 16]               0
            Conv1d-5               [-1, 64, 16]             320
   MyConv1dPadSame-6               [-1, 64, 16]               0
       BatchNorm1d-7               [-1, 64, 16]             128
              ReLU-8               [-1, 64, 16]               0
           Dropout-9               [-1, 64, 16]               0
           Conv1d-10               [-1, 64, 16]             320
  MyConv1dPadSame-11               [-1, 64, 16]               0
       Bottleneck-12               [-1, 64, 16]               0
      BatchNorm1d-13               [-1, 64, 16]             128
             ReLU-14               [-1, 64, 16]               0
          Dropout-15               [-1, 64, 16]               0
           Conv1d-16              [-1, 128, 16]             640
  MyConv1dPadSame-17              [-1, 128, 16]               0
      BatchNorm1d-18              [-1, 128, 16]             256
             ReLU-19              [-1, 128, 16]               0
          Dropout-20              [-1, 128, 16]               0
           Conv1d-21              [-1, 128, 16]           1,152
  MyConv1dPadSame-22              [-1, 128, 16]               0
       Bottleneck-23              [-1, 128, 16]               0
      BatchNorm1d-24              [-1, 128, 16]             256
             ReLU-25              [-1, 128, 16]               0
          Dropout-26              [-1, 128, 16]               0
           Conv1d-27              [-1, 256, 16]           2,304
  MyConv1dPadSame-28              [-1, 256, 16]               0
      BatchNorm1d-29              [-1, 256, 16]             512
             ReLU-30              [-1, 256, 16]               0
          Dropout-31              [-1, 256, 16]               0
           Conv1d-32              [-1, 256, 16]           4,352
  MyConv1dPadSame-33              [-1, 256, 16]               0
       Bottleneck-34              [-1, 256, 16]               0
      BatchNorm1d-35              [-1, 256, 16]             512
             ReLU-36              [-1, 256, 16]               0
          Dropout-37              [-1, 256, 16]               0
           Conv1d-38              [-1, 512, 16]           8,704
  MyConv1dPadSame-39              [-1, 512, 16]               0
      BatchNorm1d-40              [-1, 512, 16]           1,024
             ReLU-41              [-1, 512, 16]               0
          Dropout-42              [-1, 512, 16]               0
           Conv1d-43              [-1, 512, 16]          16,896
  MyConv1dPadSame-44              [-1, 512, 16]               0
       Bottleneck-45              [-1, 512, 16]               0
      BatchNorm1d-46              [-1, 512, 16]           1,024
             ReLU-47              [-1, 512, 16]               0
           Linear-48                    [-1, 2]           1,026
================================================================
Total params: 40,002
Trainable params: 40,002
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 1.26
Params size (MB): 0.15
Estimated Total Size (MB): 1.41
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 64, kernel_size: 4, n_block: 8
************************************************************
************************************************************
(2000, 1, 16) Counter({1: 1000, 0: 1000})
(2000, 1, 16) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 64, 16]             320
   MyConv1dPadSame-2               [-1, 64, 16]               0
       BatchNorm1d-3               [-1, 64, 16]             128
              ReLU-4               [-1, 64, 16]               0
            Conv1d-5               [-1, 64, 16]             320
   MyConv1dPadSame-6               [-1, 64, 16]               0
       BatchNorm1d-7               [-1, 64, 16]             128
              ReLU-8               [-1, 64, 16]               0
           Dropout-9               [-1, 64, 16]               0
           Conv1d-10               [-1, 64, 16]             320
  MyConv1dPadSame-11               [-1, 64, 16]               0
       Bottleneck-12               [-1, 64, 16]               0
      BatchNorm1d-13               [-1, 64, 16]             128
             ReLU-14               [-1, 64, 16]               0
          Dropout-15               [-1, 64, 16]               0
           Conv1d-16               [-1, 64, 16]             320
  MyConv1dPadSame-17               [-1, 64, 16]               0
      BatchNorm1d-18               [-1, 64, 16]             128
             ReLU-19               [-1, 64, 16]               0
          Dropout-20               [-1, 64, 16]               0
           Conv1d-21               [-1, 64, 16]             320
  MyConv1dPadSame-22               [-1, 64, 16]               0
       Bottleneck-23               [-1, 64, 16]               0
      BatchNorm1d-24               [-1, 64, 16]             128
             ReLU-25               [-1, 64, 16]               0
          Dropout-26               [-1, 64, 16]               0
           Conv1d-27              [-1, 128, 16]             640
  MyConv1dPadSame-28              [-1, 128, 16]               0
      BatchNorm1d-29              [-1, 128, 16]             256
             ReLU-30              [-1, 128, 16]               0
          Dropout-31              [-1, 128, 16]               0
           Conv1d-32              [-1, 128, 16]           1,152
  MyConv1dPadSame-33              [-1, 128, 16]               0
       Bottleneck-34              [-1, 128, 16]               0
      BatchNorm1d-35              [-1, 128, 16]             256
             ReLU-36              [-1, 128, 16]               0
          Dropout-37              [-1, 128, 16]               0
           Conv1d-38              [-1, 128, 16]           1,152
  MyConv1dPadSame-39              [-1, 128, 16]               0
      BatchNorm1d-40              [-1, 128, 16]             256
             ReLU-41              [-1, 128, 16]               0
          Dropout-42              [-1, 128, 16]               0
           Conv1d-43              [-1, 128, 16]           1,152
  MyConv1dPadSame-44              [-1, 128, 16]               0
       Bottleneck-45              [-1, 128, 16]               0
      BatchNorm1d-46              [-1, 128, 16]             256
             ReLU-47              [-1, 128, 16]               0
          Dropout-48              [-1, 128, 16]               0
           Conv1d-49              [-1, 256, 16]           2,304
  MyConv1dPadSame-50              [-1, 256, 16]               0
      BatchNorm1d-51              [-1, 256, 16]             512
             ReLU-52              [-1, 256, 16]               0
          Dropout-53              [-1, 256, 16]               0
           Conv1d-54              [-1, 256, 16]           4,352
  MyConv1dPadSame-55              [-1, 256, 16]               0
       Bottleneck-56              [-1, 256, 16]               0
      BatchNorm1d-57              [-1, 256, 16]             512
             ReLU-58              [-1, 256, 16]               0
          Dropout-59              [-1, 256, 16]               0
           Conv1d-60              [-1, 256, 16]           4,352
  MyConv1dPadSame-61              [-1, 256, 16]               0
      BatchNorm1d-62              [-1, 256, 16]             512
             ReLU-63              [-1, 256, 16]               0
          Dropout-64              [-1, 256, 16]               0
           Conv1d-65              [-1, 256, 16]           4,352
  MyConv1dPadSame-66              [-1, 256, 16]               0
       Bottleneck-67              [-1, 256, 16]               0
      BatchNorm1d-68              [-1, 256, 16]             512
             ReLU-69              [-1, 256, 16]               0
          Dropout-70              [-1, 256, 16]               0
           Conv1d-71              [-1, 512, 16]           8,704
  MyConv1dPadSame-72              [-1, 512, 16]               0
      BatchNorm1d-73              [-1, 512, 16]           1,024
             ReLU-74              [-1, 512, 16]               0
          Dropout-75              [-1, 512, 16]               0
           Conv1d-76              [-1, 512, 16]          16,896
  MyConv1dPadSame-77              [-1, 512, 16]               0
       Bottleneck-78              [-1, 512, 16]               0
      BatchNorm1d-79              [-1, 512, 16]           1,024
             ReLU-80              [-1, 512, 16]               0
          Dropout-81              [-1, 512, 16]               0
           Conv1d-82              [-1, 512, 16]          16,896
  MyConv1dPadSame-83              [-1, 512, 16]               0
      BatchNorm1d-84              [-1, 512, 16]           1,024
             ReLU-85              [-1, 512, 16]               0
          Dropout-86              [-1, 512, 16]               0
           Conv1d-87              [-1, 512, 16]          16,896
  MyConv1dPadSame-88              [-1, 512, 16]               0
       Bottleneck-89              [-1, 512, 16]               0
      BatchNorm1d-90              [-1, 512, 16]           1,024
             ReLU-91              [-1, 512, 16]               0
           Linear-92                    [-1, 2]           1,026
================================================================
Total params: 89,282
Trainable params: 89,282
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 2.55
Params size (MB): 0.34
Estimated Total Size (MB): 2.89
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 64, kernel_size: 4, n_block: 16
************************************************************
************************************************************
(2000, 1, 16) Counter({1: 1000, 0: 1000})
(2000, 1, 16) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 64, 16]             320
   MyConv1dPadSame-2               [-1, 64, 16]               0
       BatchNorm1d-3               [-1, 64, 16]             128
              ReLU-4               [-1, 64, 16]               0
            Conv1d-5               [-1, 64, 16]             320
   MyConv1dPadSame-6               [-1, 64, 16]               0
       BatchNorm1d-7               [-1, 64, 16]             128
              ReLU-8               [-1, 64, 16]               0
           Dropout-9               [-1, 64, 16]               0
           Conv1d-10               [-1, 64, 16]             320
  MyConv1dPadSame-11               [-1, 64, 16]               0
       Bottleneck-12               [-1, 64, 16]               0
      BatchNorm1d-13               [-1, 64, 16]             128
             ReLU-14               [-1, 64, 16]               0
          Dropout-15               [-1, 64, 16]               0
           Conv1d-16                [-1, 64, 8]             320
  MyConv1dPadSame-17                [-1, 64, 8]               0
      BatchNorm1d-18                [-1, 64, 8]             128
             ReLU-19                [-1, 64, 8]               0
          Dropout-20                [-1, 64, 8]               0
           Conv1d-21                [-1, 64, 8]             320
  MyConv1dPadSame-22                [-1, 64, 8]               0
        MaxPool1d-23                [-1, 64, 8]               0
MyMaxPool1dPadSame-24                [-1, 64, 8]               0
       Bottleneck-25                [-1, 64, 8]               0
      BatchNorm1d-26                [-1, 64, 8]             128
             ReLU-27                [-1, 64, 8]               0
          Dropout-28                [-1, 64, 8]               0
           Conv1d-29                [-1, 64, 8]             320
  MyConv1dPadSame-30                [-1, 64, 8]               0
      BatchNorm1d-31                [-1, 64, 8]             128
             ReLU-32                [-1, 64, 8]               0
          Dropout-33                [-1, 64, 8]               0
           Conv1d-34                [-1, 64, 8]             320
  MyConv1dPadSame-35                [-1, 64, 8]               0
       Bottleneck-36                [-1, 64, 8]               0
      BatchNorm1d-37                [-1, 64, 8]             128
             ReLU-38                [-1, 64, 8]               0
          Dropout-39                [-1, 64, 8]               0
           Conv1d-40                [-1, 64, 4]             320
  MyConv1dPadSame-41                [-1, 64, 4]               0
      BatchNorm1d-42                [-1, 64, 4]             128
             ReLU-43                [-1, 64, 4]               0
          Dropout-44                [-1, 64, 4]               0
           Conv1d-45                [-1, 64, 4]             320
  MyConv1dPadSame-46                [-1, 64, 4]               0
        MaxPool1d-47                [-1, 64, 4]               0
MyMaxPool1dPadSame-48                [-1, 64, 4]               0
       Bottleneck-49                [-1, 64, 4]               0
      BatchNorm1d-50                [-1, 64, 4]             128
             ReLU-51                [-1, 64, 4]               0
          Dropout-52                [-1, 64, 4]               0
           Conv1d-53               [-1, 128, 4]             640
  MyConv1dPadSame-54               [-1, 128, 4]               0
      BatchNorm1d-55               [-1, 128, 4]             256
             ReLU-56               [-1, 128, 4]               0
          Dropout-57               [-1, 128, 4]               0
           Conv1d-58               [-1, 128, 4]           1,152
  MyConv1dPadSame-59               [-1, 128, 4]               0
       Bottleneck-60               [-1, 128, 4]               0
      BatchNorm1d-61               [-1, 128, 4]             256
             ReLU-62               [-1, 128, 4]               0
          Dropout-63               [-1, 128, 4]               0
           Conv1d-64               [-1, 128, 2]           1,152
  MyConv1dPadSame-65               [-1, 128, 2]               0
      BatchNorm1d-66               [-1, 128, 2]             256
             ReLU-67               [-1, 128, 2]               0
          Dropout-68               [-1, 128, 2]               0
           Conv1d-69               [-1, 128, 2]           1,152
  MyConv1dPadSame-70               [-1, 128, 2]               0
        MaxPool1d-71               [-1, 128, 2]               0
MyMaxPool1dPadSame-72               [-1, 128, 2]               0
       Bottleneck-73               [-1, 128, 2]               0
      BatchNorm1d-74               [-1, 128, 2]             256
             ReLU-75               [-1, 128, 2]               0
          Dropout-76               [-1, 128, 2]               0
           Conv1d-77               [-1, 128, 2]           1,152
  MyConv1dPadSame-78               [-1, 128, 2]               0
      BatchNorm1d-79               [-1, 128, 2]             256
             ReLU-80               [-1, 128, 2]               0
          Dropout-81               [-1, 128, 2]               0
           Conv1d-82               [-1, 128, 2]           1,152
  MyConv1dPadSame-83               [-1, 128, 2]               0
       Bottleneck-84               [-1, 128, 2]               0
      BatchNorm1d-85               [-1, 128, 2]             256
             ReLU-86               [-1, 128, 2]               0
          Dropout-87               [-1, 128, 2]               0
           Conv1d-88               [-1, 128, 1]           1,152
  MyConv1dPadSame-89               [-1, 128, 1]               0
      BatchNorm1d-90               [-1, 128, 1]             256
             ReLU-91               [-1, 128, 1]               0
          Dropout-92               [-1, 128, 1]               0
           Conv1d-93               [-1, 128, 1]           1,152
  MyConv1dPadSame-94               [-1, 128, 1]               0
        MaxPool1d-95               [-1, 128, 1]               0
MyMaxPool1dPadSame-96               [-1, 128, 1]               0
       Bottleneck-97               [-1, 128, 1]               0
      BatchNorm1d-98               [-1, 128, 1]             256
             ReLU-99               [-1, 128, 1]               0
         Dropout-100               [-1, 128, 1]               0
          Conv1d-101               [-1, 256, 1]           2,304
 MyConv1dPadSame-102               [-1, 256, 1]               0
     BatchNorm1d-103               [-1, 256, 1]             512
            ReLU-104               [-1, 256, 1]               0
         Dropout-105               [-1, 256, 1]               0
          Conv1d-106               [-1, 256, 1]           4,352
 MyConv1dPadSame-107               [-1, 256, 1]               0
      Bottleneck-108               [-1, 256, 1]               0
     BatchNorm1d-109               [-1, 256, 1]             512
            ReLU-110               [-1, 256, 1]               0
         Dropout-111               [-1, 256, 1]               0
          Conv1d-112               [-1, 256, 1]           4,352
 MyConv1dPadSame-113               [-1, 256, 1]               0
     BatchNorm1d-114               [-1, 256, 1]             512
            ReLU-115               [-1, 256, 1]               0
         Dropout-116               [-1, 256, 1]               0
          Conv1d-117               [-1, 256, 1]           4,352
 MyConv1dPadSame-118               [-1, 256, 1]               0
       MaxPool1d-119               [-1, 256, 1]               0
MyMaxPool1dPadSame-120               [-1, 256, 1]               0
      Bottleneck-121               [-1, 256, 1]               0
     BatchNorm1d-122               [-1, 256, 1]             512
            ReLU-123               [-1, 256, 1]               0
         Dropout-124               [-1, 256, 1]               0
          Conv1d-125               [-1, 256, 1]           4,352
 MyConv1dPadSame-126               [-1, 256, 1]               0
     BatchNorm1d-127               [-1, 256, 1]             512
            ReLU-128               [-1, 256, 1]               0
         Dropout-129               [-1, 256, 1]               0
          Conv1d-130               [-1, 256, 1]           4,352
 MyConv1dPadSame-131               [-1, 256, 1]               0
      Bottleneck-132               [-1, 256, 1]               0
     BatchNorm1d-133               [-1, 256, 1]             512
            ReLU-134               [-1, 256, 1]               0
         Dropout-135               [-1, 256, 1]               0
          Conv1d-136               [-1, 256, 1]           4,352
 MyConv1dPadSame-137               [-1, 256, 1]               0
     BatchNorm1d-138               [-1, 256, 1]             512
            ReLU-139               [-1, 256, 1]               0
         Dropout-140               [-1, 256, 1]               0
          Conv1d-141               [-1, 256, 1]           4,352
 MyConv1dPadSame-142               [-1, 256, 1]               0
       MaxPool1d-143               [-1, 256, 1]               0
MyMaxPool1dPadSame-144               [-1, 256, 1]               0
      Bottleneck-145               [-1, 256, 1]               0
     BatchNorm1d-146               [-1, 256, 1]             512
            ReLU-147               [-1, 256, 1]               0
         Dropout-148               [-1, 256, 1]               0
          Conv1d-149               [-1, 512, 1]           8,704
 MyConv1dPadSame-150               [-1, 512, 1]               0
     BatchNorm1d-151               [-1, 512, 1]           1,024
            ReLU-152               [-1, 512, 1]               0
         Dropout-153               [-1, 512, 1]               0
          Conv1d-154               [-1, 512, 1]          16,896
 MyConv1dPadSame-155               [-1, 512, 1]               0
      Bottleneck-156               [-1, 512, 1]               0
     BatchNorm1d-157               [-1, 512, 1]           1,024
            ReLU-158               [-1, 512, 1]               0
         Dropout-159               [-1, 512, 1]               0
          Conv1d-160               [-1, 512, 1]          16,896
 MyConv1dPadSame-161               [-1, 512, 1]               0
     BatchNorm1d-162               [-1, 512, 1]           1,024
            ReLU-163               [-1, 512, 1]               0
         Dropout-164               [-1, 512, 1]               0
          Conv1d-165               [-1, 512, 1]          16,896
 MyConv1dPadSame-166               [-1, 512, 1]               0
       MaxPool1d-167               [-1, 512, 1]               0
MyMaxPool1dPadSame-168               [-1, 512, 1]               0
      Bottleneck-169               [-1, 512, 1]               0
     BatchNorm1d-170               [-1, 512, 1]           1,024
            ReLU-171               [-1, 512, 1]               0
         Dropout-172               [-1, 512, 1]               0
          Conv1d-173               [-1, 512, 1]          16,896
 MyConv1dPadSame-174               [-1, 512, 1]               0
     BatchNorm1d-175               [-1, 512, 1]           1,024
            ReLU-176               [-1, 512, 1]               0
         Dropout-177               [-1, 512, 1]               0
          Conv1d-178               [-1, 512, 1]          16,896
 MyConv1dPadSame-179               [-1, 512, 1]               0
      Bottleneck-180               [-1, 512, 1]               0
     BatchNorm1d-181               [-1, 512, 1]           1,024
            ReLU-182               [-1, 512, 1]               0
         Dropout-183               [-1, 512, 1]               0
          Conv1d-184               [-1, 512, 1]          16,896
 MyConv1dPadSame-185               [-1, 512, 1]               0
     BatchNorm1d-186               [-1, 512, 1]           1,024
            ReLU-187               [-1, 512, 1]               0
         Dropout-188               [-1, 512, 1]               0
          Conv1d-189               [-1, 512, 1]          16,896
 MyConv1dPadSame-190               [-1, 512, 1]               0
       MaxPool1d-191               [-1, 512, 1]               0
MyMaxPool1dPadSame-192               [-1, 512, 1]               0
      Bottleneck-193               [-1, 512, 1]               0
     BatchNorm1d-194               [-1, 512, 1]           1,024
            ReLU-195               [-1, 512, 1]               0
          Linear-196                    [-1, 2]           1,026
================================================================
Total params: 187,842
Trainable params: 187,842
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.62
Params size (MB): 0.72
Estimated Total Size (MB): 1.33
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 64, kernel_size: 8, n_block: 2
************************************************************
************************************************************
(2000, 1, 16) Counter({1: 1000, 0: 1000})
(2000, 1, 16) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 64, 16]             576
   MyConv1dPadSame-2               [-1, 64, 16]               0
       BatchNorm1d-3               [-1, 64, 16]             128
              ReLU-4               [-1, 64, 16]               0
            Conv1d-5               [-1, 64, 16]             576
   MyConv1dPadSame-6               [-1, 64, 16]               0
       BatchNorm1d-7               [-1, 64, 16]             128
              ReLU-8               [-1, 64, 16]               0
           Dropout-9               [-1, 64, 16]               0
           Conv1d-10               [-1, 64, 16]             576
  MyConv1dPadSame-11               [-1, 64, 16]               0
       Bottleneck-12               [-1, 64, 16]               0
      BatchNorm1d-13               [-1, 64, 16]             128
             ReLU-14               [-1, 64, 16]               0
          Dropout-15               [-1, 64, 16]               0
           Conv1d-16              [-1, 128, 16]           1,152
  MyConv1dPadSame-17              [-1, 128, 16]               0
      BatchNorm1d-18              [-1, 128, 16]             256
             ReLU-19              [-1, 128, 16]               0
          Dropout-20              [-1, 128, 16]               0
           Conv1d-21              [-1, 128, 16]           2,176
  MyConv1dPadSame-22              [-1, 128, 16]               0
       Bottleneck-23              [-1, 128, 16]               0
      BatchNorm1d-24              [-1, 128, 16]             256
             ReLU-25              [-1, 128, 16]               0
           Linear-26                    [-1, 2]             258
================================================================
Total params: 6,210
Trainable params: 6,210
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.27
Params size (MB): 0.02
Estimated Total Size (MB): 0.30
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 64, kernel_size: 8, n_block: 4
************************************************************
************************************************************
(2000, 1, 16) Counter({1: 1000, 0: 1000})
(2000, 1, 16) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 64, 16]             576
   MyConv1dPadSame-2               [-1, 64, 16]               0
       BatchNorm1d-3               [-1, 64, 16]             128
              ReLU-4               [-1, 64, 16]               0
            Conv1d-5               [-1, 64, 16]             576
   MyConv1dPadSame-6               [-1, 64, 16]               0
       BatchNorm1d-7               [-1, 64, 16]             128
              ReLU-8               [-1, 64, 16]               0
           Dropout-9               [-1, 64, 16]               0
           Conv1d-10               [-1, 64, 16]             576
  MyConv1dPadSame-11               [-1, 64, 16]               0
       Bottleneck-12               [-1, 64, 16]               0
      BatchNorm1d-13               [-1, 64, 16]             128
             ReLU-14               [-1, 64, 16]               0
          Dropout-15               [-1, 64, 16]               0
           Conv1d-16              [-1, 128, 16]           1,152
  MyConv1dPadSame-17              [-1, 128, 16]               0
      BatchNorm1d-18              [-1, 128, 16]             256
             ReLU-19              [-1, 128, 16]               0
          Dropout-20              [-1, 128, 16]               0
           Conv1d-21              [-1, 128, 16]           2,176
  MyConv1dPadSame-22              [-1, 128, 16]               0
       Bottleneck-23              [-1, 128, 16]               0
      BatchNorm1d-24              [-1, 128, 16]             256
             ReLU-25              [-1, 128, 16]               0
          Dropout-26              [-1, 128, 16]               0
           Conv1d-27              [-1, 256, 16]           4,352
  MyConv1dPadSame-28              [-1, 256, 16]               0
      BatchNorm1d-29              [-1, 256, 16]             512
             ReLU-30              [-1, 256, 16]               0
          Dropout-31              [-1, 256, 16]               0
           Conv1d-32              [-1, 256, 16]           8,448
  MyConv1dPadSame-33              [-1, 256, 16]               0
       Bottleneck-34              [-1, 256, 16]               0
      BatchNorm1d-35              [-1, 256, 16]             512
             ReLU-36              [-1, 256, 16]               0
          Dropout-37              [-1, 256, 16]               0
           Conv1d-38              [-1, 512, 16]          16,896
  MyConv1dPadSame-39              [-1, 512, 16]               0
      BatchNorm1d-40              [-1, 512, 16]           1,024
             ReLU-41              [-1, 512, 16]               0
          Dropout-42              [-1, 512, 16]               0
           Conv1d-43              [-1, 512, 16]          33,280
  MyConv1dPadSame-44              [-1, 512, 16]               0
       Bottleneck-45              [-1, 512, 16]               0
      BatchNorm1d-46              [-1, 512, 16]           1,024
             ReLU-47              [-1, 512, 16]               0
           Linear-48                    [-1, 2]           1,026
================================================================
Total params: 73,026
Trainable params: 73,026
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 1.26
Params size (MB): 0.28
Estimated Total Size (MB): 1.54
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 64, kernel_size: 8, n_block: 8
************************************************************
************************************************************
(2000, 1, 16) Counter({1: 1000, 0: 1000})
(2000, 1, 16) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 64, 16]             576
   MyConv1dPadSame-2               [-1, 64, 16]               0
       BatchNorm1d-3               [-1, 64, 16]             128
              ReLU-4               [-1, 64, 16]               0
            Conv1d-5               [-1, 64, 16]             576
   MyConv1dPadSame-6               [-1, 64, 16]               0
       BatchNorm1d-7               [-1, 64, 16]             128
              ReLU-8               [-1, 64, 16]               0
           Dropout-9               [-1, 64, 16]               0
           Conv1d-10               [-1, 64, 16]             576
  MyConv1dPadSame-11               [-1, 64, 16]               0
       Bottleneck-12               [-1, 64, 16]               0
      BatchNorm1d-13               [-1, 64, 16]             128
             ReLU-14               [-1, 64, 16]               0
          Dropout-15               [-1, 64, 16]               0
           Conv1d-16               [-1, 64, 16]             576
  MyConv1dPadSame-17               [-1, 64, 16]               0
      BatchNorm1d-18               [-1, 64, 16]             128
             ReLU-19               [-1, 64, 16]               0
          Dropout-20               [-1, 64, 16]               0
           Conv1d-21               [-1, 64, 16]             576
  MyConv1dPadSame-22               [-1, 64, 16]               0
       Bottleneck-23               [-1, 64, 16]               0
      BatchNorm1d-24               [-1, 64, 16]             128
             ReLU-25               [-1, 64, 16]               0
          Dropout-26               [-1, 64, 16]               0
           Conv1d-27              [-1, 128, 16]           1,152
  MyConv1dPadSame-28              [-1, 128, 16]               0
      BatchNorm1d-29              [-1, 128, 16]             256
             ReLU-30              [-1, 128, 16]               0
          Dropout-31              [-1, 128, 16]               0
           Conv1d-32              [-1, 128, 16]           2,176
  MyConv1dPadSame-33              [-1, 128, 16]               0
       Bottleneck-34              [-1, 128, 16]               0
      BatchNorm1d-35              [-1, 128, 16]             256
             ReLU-36              [-1, 128, 16]               0
          Dropout-37              [-1, 128, 16]               0
           Conv1d-38              [-1, 128, 16]           2,176
  MyConv1dPadSame-39              [-1, 128, 16]               0
      BatchNorm1d-40              [-1, 128, 16]             256
             ReLU-41              [-1, 128, 16]               0
          Dropout-42              [-1, 128, 16]               0
           Conv1d-43              [-1, 128, 16]           2,176
  MyConv1dPadSame-44              [-1, 128, 16]               0
       Bottleneck-45              [-1, 128, 16]               0
      BatchNorm1d-46              [-1, 128, 16]             256
             ReLU-47              [-1, 128, 16]               0
          Dropout-48              [-1, 128, 16]               0
           Conv1d-49              [-1, 256, 16]           4,352
  MyConv1dPadSame-50              [-1, 256, 16]               0
      BatchNorm1d-51              [-1, 256, 16]             512
             ReLU-52              [-1, 256, 16]               0
          Dropout-53              [-1, 256, 16]               0
           Conv1d-54              [-1, 256, 16]           8,448
  MyConv1dPadSame-55              [-1, 256, 16]               0
       Bottleneck-56              [-1, 256, 16]               0
      BatchNorm1d-57              [-1, 256, 16]             512
             ReLU-58              [-1, 256, 16]               0
          Dropout-59              [-1, 256, 16]               0
           Conv1d-60              [-1, 256, 16]           8,448
  MyConv1dPadSame-61              [-1, 256, 16]               0
      BatchNorm1d-62              [-1, 256, 16]             512
             ReLU-63              [-1, 256, 16]               0
          Dropout-64              [-1, 256, 16]               0
           Conv1d-65              [-1, 256, 16]           8,448
  MyConv1dPadSame-66              [-1, 256, 16]               0
       Bottleneck-67              [-1, 256, 16]               0
      BatchNorm1d-68              [-1, 256, 16]             512
             ReLU-69              [-1, 256, 16]               0
          Dropout-70              [-1, 256, 16]               0
           Conv1d-71              [-1, 512, 16]          16,896
  MyConv1dPadSame-72              [-1, 512, 16]               0
      BatchNorm1d-73              [-1, 512, 16]           1,024
             ReLU-74              [-1, 512, 16]               0
          Dropout-75              [-1, 512, 16]               0
           Conv1d-76              [-1, 512, 16]          33,280
  MyConv1dPadSame-77              [-1, 512, 16]               0
       Bottleneck-78              [-1, 512, 16]               0
      BatchNorm1d-79              [-1, 512, 16]           1,024
             ReLU-80              [-1, 512, 16]               0
          Dropout-81              [-1, 512, 16]               0
           Conv1d-82              [-1, 512, 16]          33,280
  MyConv1dPadSame-83              [-1, 512, 16]               0
      BatchNorm1d-84              [-1, 512, 16]           1,024
             ReLU-85              [-1, 512, 16]               0
          Dropout-86              [-1, 512, 16]               0
           Conv1d-87              [-1, 512, 16]          33,280
  MyConv1dPadSame-88              [-1, 512, 16]               0
       Bottleneck-89              [-1, 512, 16]               0
      BatchNorm1d-90              [-1, 512, 16]           1,024
             ReLU-91              [-1, 512, 16]               0
           Linear-92                    [-1, 2]           1,026
================================================================
Total params: 165,826
Trainable params: 165,826
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 2.55
Params size (MB): 0.63
Estimated Total Size (MB): 3.18
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 64, kernel_size: 8, n_block: 16
************************************************************
************************************************************
(2000, 1, 16) Counter({1: 1000, 0: 1000})
(2000, 1, 16) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 64, 16]             576
   MyConv1dPadSame-2               [-1, 64, 16]               0
       BatchNorm1d-3               [-1, 64, 16]             128
              ReLU-4               [-1, 64, 16]               0
            Conv1d-5               [-1, 64, 16]             576
   MyConv1dPadSame-6               [-1, 64, 16]               0
       BatchNorm1d-7               [-1, 64, 16]             128
              ReLU-8               [-1, 64, 16]               0
           Dropout-9               [-1, 64, 16]               0
           Conv1d-10               [-1, 64, 16]             576
  MyConv1dPadSame-11               [-1, 64, 16]               0
       Bottleneck-12               [-1, 64, 16]               0
      BatchNorm1d-13               [-1, 64, 16]             128
             ReLU-14               [-1, 64, 16]               0
          Dropout-15               [-1, 64, 16]               0
           Conv1d-16                [-1, 64, 8]             576
  MyConv1dPadSame-17                [-1, 64, 8]               0
      BatchNorm1d-18                [-1, 64, 8]             128
             ReLU-19                [-1, 64, 8]               0
          Dropout-20                [-1, 64, 8]               0
           Conv1d-21                [-1, 64, 8]             576
  MyConv1dPadSame-22                [-1, 64, 8]               0
        MaxPool1d-23                [-1, 64, 8]               0
MyMaxPool1dPadSame-24                [-1, 64, 8]               0
       Bottleneck-25                [-1, 64, 8]               0
      BatchNorm1d-26                [-1, 64, 8]             128
             ReLU-27                [-1, 64, 8]               0
          Dropout-28                [-1, 64, 8]               0
           Conv1d-29                [-1, 64, 8]             576
  MyConv1dPadSame-30                [-1, 64, 8]               0
      BatchNorm1d-31                [-1, 64, 8]             128
             ReLU-32                [-1, 64, 8]               0
          Dropout-33                [-1, 64, 8]               0
           Conv1d-34                [-1, 64, 8]             576
  MyConv1dPadSame-35                [-1, 64, 8]               0
       Bottleneck-36                [-1, 64, 8]               0
      BatchNorm1d-37                [-1, 64, 8]             128
             ReLU-38                [-1, 64, 8]               0
          Dropout-39                [-1, 64, 8]               0
           Conv1d-40                [-1, 64, 4]             576
  MyConv1dPadSame-41                [-1, 64, 4]               0
      BatchNorm1d-42                [-1, 64, 4]             128
             ReLU-43                [-1, 64, 4]               0
          Dropout-44                [-1, 64, 4]               0
           Conv1d-45                [-1, 64, 4]             576
  MyConv1dPadSame-46                [-1, 64, 4]               0
        MaxPool1d-47                [-1, 64, 4]               0
MyMaxPool1dPadSame-48                [-1, 64, 4]               0
       Bottleneck-49                [-1, 64, 4]               0
      BatchNorm1d-50                [-1, 64, 4]             128
             ReLU-51                [-1, 64, 4]               0
          Dropout-52                [-1, 64, 4]               0
           Conv1d-53               [-1, 128, 4]           1,152
  MyConv1dPadSame-54               [-1, 128, 4]               0
      BatchNorm1d-55               [-1, 128, 4]             256
             ReLU-56               [-1, 128, 4]               0
          Dropout-57               [-1, 128, 4]               0
           Conv1d-58               [-1, 128, 4]           2,176
  MyConv1dPadSame-59               [-1, 128, 4]               0
       Bottleneck-60               [-1, 128, 4]               0
      BatchNorm1d-61               [-1, 128, 4]             256
             ReLU-62               [-1, 128, 4]               0
          Dropout-63               [-1, 128, 4]               0
           Conv1d-64               [-1, 128, 2]           2,176
  MyConv1dPadSame-65               [-1, 128, 2]               0
      BatchNorm1d-66               [-1, 128, 2]             256
             ReLU-67               [-1, 128, 2]               0
          Dropout-68               [-1, 128, 2]               0
           Conv1d-69               [-1, 128, 2]           2,176
  MyConv1dPadSame-70               [-1, 128, 2]               0
        MaxPool1d-71               [-1, 128, 2]               0
MyMaxPool1dPadSame-72               [-1, 128, 2]               0
       Bottleneck-73               [-1, 128, 2]               0
      BatchNorm1d-74               [-1, 128, 2]             256
             ReLU-75               [-1, 128, 2]               0
          Dropout-76               [-1, 128, 2]               0
           Conv1d-77               [-1, 128, 2]           2,176
  MyConv1dPadSame-78               [-1, 128, 2]               0
      BatchNorm1d-79               [-1, 128, 2]             256
             ReLU-80               [-1, 128, 2]               0
          Dropout-81               [-1, 128, 2]               0
           Conv1d-82               [-1, 128, 2]           2,176
  MyConv1dPadSame-83               [-1, 128, 2]               0
       Bottleneck-84               [-1, 128, 2]               0
      BatchNorm1d-85               [-1, 128, 2]             256
             ReLU-86               [-1, 128, 2]               0
          Dropout-87               [-1, 128, 2]               0
           Conv1d-88               [-1, 128, 1]           2,176
  MyConv1dPadSame-89               [-1, 128, 1]               0
      BatchNorm1d-90               [-1, 128, 1]             256
             ReLU-91               [-1, 128, 1]               0
          Dropout-92               [-1, 128, 1]               0
           Conv1d-93               [-1, 128, 1]           2,176
  MyConv1dPadSame-94               [-1, 128, 1]               0
        MaxPool1d-95               [-1, 128, 1]               0
MyMaxPool1dPadSame-96               [-1, 128, 1]               0
       Bottleneck-97               [-1, 128, 1]               0
      BatchNorm1d-98               [-1, 128, 1]             256
             ReLU-99               [-1, 128, 1]               0
         Dropout-100               [-1, 128, 1]               0
          Conv1d-101               [-1, 256, 1]           4,352
 MyConv1dPadSame-102               [-1, 256, 1]               0
     BatchNorm1d-103               [-1, 256, 1]             512
            ReLU-104               [-1, 256, 1]               0
         Dropout-105               [-1, 256, 1]               0
          Conv1d-106               [-1, 256, 1]           8,448
 MyConv1dPadSame-107               [-1, 256, 1]               0
      Bottleneck-108               [-1, 256, 1]               0
     BatchNorm1d-109               [-1, 256, 1]             512
            ReLU-110               [-1, 256, 1]               0
         Dropout-111               [-1, 256, 1]               0
          Conv1d-112               [-1, 256, 1]           8,448
 MyConv1dPadSame-113               [-1, 256, 1]               0
     BatchNorm1d-114               [-1, 256, 1]             512
            ReLU-115               [-1, 256, 1]               0
         Dropout-116               [-1, 256, 1]               0
          Conv1d-117               [-1, 256, 1]           8,448
 MyConv1dPadSame-118               [-1, 256, 1]               0
       MaxPool1d-119               [-1, 256, 1]               0
MyMaxPool1dPadSame-120               [-1, 256, 1]               0
      Bottleneck-121               [-1, 256, 1]               0
     BatchNorm1d-122               [-1, 256, 1]             512
            ReLU-123               [-1, 256, 1]               0
         Dropout-124               [-1, 256, 1]               0
          Conv1d-125               [-1, 256, 1]           8,448
 MyConv1dPadSame-126               [-1, 256, 1]               0
     BatchNorm1d-127               [-1, 256, 1]             512
            ReLU-128               [-1, 256, 1]               0
         Dropout-129               [-1, 256, 1]               0
          Conv1d-130               [-1, 256, 1]           8,448
 MyConv1dPadSame-131               [-1, 256, 1]               0
      Bottleneck-132               [-1, 256, 1]               0
     BatchNorm1d-133               [-1, 256, 1]             512
            ReLU-134               [-1, 256, 1]               0
         Dropout-135               [-1, 256, 1]               0
          Conv1d-136               [-1, 256, 1]           8,448
 MyConv1dPadSame-137               [-1, 256, 1]               0
     BatchNorm1d-138               [-1, 256, 1]             512
            ReLU-139               [-1, 256, 1]               0
         Dropout-140               [-1, 256, 1]               0
          Conv1d-141               [-1, 256, 1]           8,448
 MyConv1dPadSame-142               [-1, 256, 1]               0
       MaxPool1d-143               [-1, 256, 1]               0
MyMaxPool1dPadSame-144               [-1, 256, 1]               0
      Bottleneck-145               [-1, 256, 1]               0
     BatchNorm1d-146               [-1, 256, 1]             512
            ReLU-147               [-1, 256, 1]               0
         Dropout-148               [-1, 256, 1]               0
          Conv1d-149               [-1, 512, 1]          16,896
 MyConv1dPadSame-150               [-1, 512, 1]               0
     BatchNorm1d-151               [-1, 512, 1]           1,024
            ReLU-152               [-1, 512, 1]               0
         Dropout-153               [-1, 512, 1]               0
          Conv1d-154               [-1, 512, 1]          33,280
 MyConv1dPadSame-155               [-1, 512, 1]               0
      Bottleneck-156               [-1, 512, 1]               0
     BatchNorm1d-157               [-1, 512, 1]           1,024
            ReLU-158               [-1, 512, 1]               0
         Dropout-159               [-1, 512, 1]               0
          Conv1d-160               [-1, 512, 1]          33,280
 MyConv1dPadSame-161               [-1, 512, 1]               0
     BatchNorm1d-162               [-1, 512, 1]           1,024
            ReLU-163               [-1, 512, 1]               0
         Dropout-164               [-1, 512, 1]               0
          Conv1d-165               [-1, 512, 1]          33,280
 MyConv1dPadSame-166               [-1, 512, 1]               0
       MaxPool1d-167               [-1, 512, 1]               0
MyMaxPool1dPadSame-168               [-1, 512, 1]               0
      Bottleneck-169               [-1, 512, 1]               0
     BatchNorm1d-170               [-1, 512, 1]           1,024
            ReLU-171               [-1, 512, 1]               0
         Dropout-172               [-1, 512, 1]               0
          Conv1d-173               [-1, 512, 1]          33,280
 MyConv1dPadSame-174               [-1, 512, 1]               0
     BatchNorm1d-175               [-1, 512, 1]           1,024
            ReLU-176               [-1, 512, 1]               0
         Dropout-177               [-1, 512, 1]               0
          Conv1d-178               [-1, 512, 1]          33,280
 MyConv1dPadSame-179               [-1, 512, 1]               0
      Bottleneck-180               [-1, 512, 1]               0
     BatchNorm1d-181               [-1, 512, 1]           1,024
            ReLU-182               [-1, 512, 1]               0
         Dropout-183               [-1, 512, 1]               0
          Conv1d-184               [-1, 512, 1]          33,280
 MyConv1dPadSame-185               [-1, 512, 1]               0
     BatchNorm1d-186               [-1, 512, 1]           1,024
            ReLU-187               [-1, 512, 1]               0
         Dropout-188               [-1, 512, 1]               0
          Conv1d-189               [-1, 512, 1]          33,280
 MyConv1dPadSame-190               [-1, 512, 1]               0
       MaxPool1d-191               [-1, 512, 1]               0
MyMaxPool1dPadSame-192               [-1, 512, 1]               0
      Bottleneck-193               [-1, 512, 1]               0
     BatchNorm1d-194               [-1, 512, 1]           1,024
            ReLU-195               [-1, 512, 1]               0
          Linear-196                    [-1, 2]           1,026
================================================================
Total params: 351,426
Trainable params: 351,426
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.62
Params size (MB): 1.34
Estimated Total Size (MB): 1.96
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 64, kernel_size: 16, n_block: 2
************************************************************
************************************************************
(2000, 1, 16) Counter({0: 1000, 1: 1000})
(2000, 1, 16) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 64, 16]           1,088
   MyConv1dPadSame-2               [-1, 64, 16]               0
       BatchNorm1d-3               [-1, 64, 16]             128
              ReLU-4               [-1, 64, 16]               0
            Conv1d-5               [-1, 64, 16]           1,088
   MyConv1dPadSame-6               [-1, 64, 16]               0
       BatchNorm1d-7               [-1, 64, 16]             128
              ReLU-8               [-1, 64, 16]               0
           Dropout-9               [-1, 64, 16]               0
           Conv1d-10               [-1, 64, 16]           1,088
  MyConv1dPadSame-11               [-1, 64, 16]               0
       Bottleneck-12               [-1, 64, 16]               0
      BatchNorm1d-13               [-1, 64, 16]             128
             ReLU-14               [-1, 64, 16]               0
          Dropout-15               [-1, 64, 16]               0
           Conv1d-16              [-1, 128, 16]           2,176
  MyConv1dPadSame-17              [-1, 128, 16]               0
      BatchNorm1d-18              [-1, 128, 16]             256
             ReLU-19              [-1, 128, 16]               0
          Dropout-20              [-1, 128, 16]               0
           Conv1d-21              [-1, 128, 16]           4,224
  MyConv1dPadSame-22              [-1, 128, 16]               0
       Bottleneck-23              [-1, 128, 16]               0
      BatchNorm1d-24              [-1, 128, 16]             256
             ReLU-25              [-1, 128, 16]               0
           Linear-26                    [-1, 2]             258
================================================================
Total params: 10,818
Trainable params: 10,818
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.27
Params size (MB): 0.04
Estimated Total Size (MB): 0.31
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 64, kernel_size: 16, n_block: 4
************************************************************
************************************************************
(2000, 1, 16) Counter({1: 1000, 0: 1000})
(2000, 1, 16) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 64, 16]           1,088
   MyConv1dPadSame-2               [-1, 64, 16]               0
       BatchNorm1d-3               [-1, 64, 16]             128
              ReLU-4               [-1, 64, 16]               0
            Conv1d-5               [-1, 64, 16]           1,088
   MyConv1dPadSame-6               [-1, 64, 16]               0
       BatchNorm1d-7               [-1, 64, 16]             128
              ReLU-8               [-1, 64, 16]               0
           Dropout-9               [-1, 64, 16]               0
           Conv1d-10               [-1, 64, 16]           1,088
  MyConv1dPadSame-11               [-1, 64, 16]               0
       Bottleneck-12               [-1, 64, 16]               0
      BatchNorm1d-13               [-1, 64, 16]             128
             ReLU-14               [-1, 64, 16]               0
          Dropout-15               [-1, 64, 16]               0
           Conv1d-16              [-1, 128, 16]           2,176
  MyConv1dPadSame-17              [-1, 128, 16]               0
      BatchNorm1d-18              [-1, 128, 16]             256
             ReLU-19              [-1, 128, 16]               0
          Dropout-20              [-1, 128, 16]               0
           Conv1d-21              [-1, 128, 16]           4,224
  MyConv1dPadSame-22              [-1, 128, 16]               0
       Bottleneck-23              [-1, 128, 16]               0
      BatchNorm1d-24              [-1, 128, 16]             256
             ReLU-25              [-1, 128, 16]               0
          Dropout-26              [-1, 128, 16]               0
           Conv1d-27              [-1, 256, 16]           8,448
  MyConv1dPadSame-28              [-1, 256, 16]               0
      BatchNorm1d-29              [-1, 256, 16]             512
             ReLU-30              [-1, 256, 16]               0
          Dropout-31              [-1, 256, 16]               0
           Conv1d-32              [-1, 256, 16]          16,640
  MyConv1dPadSame-33              [-1, 256, 16]               0
       Bottleneck-34              [-1, 256, 16]               0
      BatchNorm1d-35              [-1, 256, 16]             512
             ReLU-36              [-1, 256, 16]               0
          Dropout-37              [-1, 256, 16]               0
           Conv1d-38              [-1, 512, 16]          33,280
  MyConv1dPadSame-39              [-1, 512, 16]               0
      BatchNorm1d-40              [-1, 512, 16]           1,024
             ReLU-41              [-1, 512, 16]               0
          Dropout-42              [-1, 512, 16]               0
           Conv1d-43              [-1, 512, 16]          66,048
  MyConv1dPadSame-44              [-1, 512, 16]               0
       Bottleneck-45              [-1, 512, 16]               0
      BatchNorm1d-46              [-1, 512, 16]           1,024
             ReLU-47              [-1, 512, 16]               0
           Linear-48                    [-1, 2]           1,026
================================================================
Total params: 139,074
Trainable params: 139,074
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 1.26
Params size (MB): 0.53
Estimated Total Size (MB): 1.79
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 64, kernel_size: 16, n_block: 8
************************************************************
************************************************************
(2000, 1, 16) Counter({1: 1000, 0: 1000})
(2000, 1, 16) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 64, 16]           1,088
   MyConv1dPadSame-2               [-1, 64, 16]               0
       BatchNorm1d-3               [-1, 64, 16]             128
              ReLU-4               [-1, 64, 16]               0
            Conv1d-5               [-1, 64, 16]           1,088
   MyConv1dPadSame-6               [-1, 64, 16]               0
       BatchNorm1d-7               [-1, 64, 16]             128
              ReLU-8               [-1, 64, 16]               0
           Dropout-9               [-1, 64, 16]               0
           Conv1d-10               [-1, 64, 16]           1,088
  MyConv1dPadSame-11               [-1, 64, 16]               0
       Bottleneck-12               [-1, 64, 16]               0
      BatchNorm1d-13               [-1, 64, 16]             128
             ReLU-14               [-1, 64, 16]               0
          Dropout-15               [-1, 64, 16]               0
           Conv1d-16               [-1, 64, 16]           1,088
  MyConv1dPadSame-17               [-1, 64, 16]               0
      BatchNorm1d-18               [-1, 64, 16]             128
             ReLU-19               [-1, 64, 16]               0
          Dropout-20               [-1, 64, 16]               0
           Conv1d-21               [-1, 64, 16]           1,088
  MyConv1dPadSame-22               [-1, 64, 16]               0
       Bottleneck-23               [-1, 64, 16]               0
      BatchNorm1d-24               [-1, 64, 16]             128
             ReLU-25               [-1, 64, 16]               0
          Dropout-26               [-1, 64, 16]               0
           Conv1d-27              [-1, 128, 16]           2,176
  MyConv1dPadSame-28              [-1, 128, 16]               0
      BatchNorm1d-29              [-1, 128, 16]             256
             ReLU-30              [-1, 128, 16]               0
          Dropout-31              [-1, 128, 16]               0
           Conv1d-32              [-1, 128, 16]           4,224
  MyConv1dPadSame-33              [-1, 128, 16]               0
       Bottleneck-34              [-1, 128, 16]               0
      BatchNorm1d-35              [-1, 128, 16]             256
             ReLU-36              [-1, 128, 16]               0
          Dropout-37              [-1, 128, 16]               0
           Conv1d-38              [-1, 128, 16]           4,224
  MyConv1dPadSame-39              [-1, 128, 16]               0
      BatchNorm1d-40              [-1, 128, 16]             256
             ReLU-41              [-1, 128, 16]               0
          Dropout-42              [-1, 128, 16]               0
           Conv1d-43              [-1, 128, 16]           4,224
  MyConv1dPadSame-44              [-1, 128, 16]               0
       Bottleneck-45              [-1, 128, 16]               0
      BatchNorm1d-46              [-1, 128, 16]             256
             ReLU-47              [-1, 128, 16]               0
          Dropout-48              [-1, 128, 16]               0
           Conv1d-49              [-1, 256, 16]           8,448
  MyConv1dPadSame-50              [-1, 256, 16]               0
      BatchNorm1d-51              [-1, 256, 16]             512
             ReLU-52              [-1, 256, 16]               0
          Dropout-53              [-1, 256, 16]               0
           Conv1d-54              [-1, 256, 16]          16,640
  MyConv1dPadSame-55              [-1, 256, 16]               0
       Bottleneck-56              [-1, 256, 16]               0
      BatchNorm1d-57              [-1, 256, 16]             512
             ReLU-58              [-1, 256, 16]               0
          Dropout-59              [-1, 256, 16]               0
           Conv1d-60              [-1, 256, 16]          16,640
  MyConv1dPadSame-61              [-1, 256, 16]               0
      BatchNorm1d-62              [-1, 256, 16]             512
             ReLU-63              [-1, 256, 16]               0
          Dropout-64              [-1, 256, 16]               0
           Conv1d-65              [-1, 256, 16]          16,640
  MyConv1dPadSame-66              [-1, 256, 16]               0
       Bottleneck-67              [-1, 256, 16]               0
      BatchNorm1d-68              [-1, 256, 16]             512
             ReLU-69              [-1, 256, 16]               0
          Dropout-70              [-1, 256, 16]               0
           Conv1d-71              [-1, 512, 16]          33,280
  MyConv1dPadSame-72              [-1, 512, 16]               0
      BatchNorm1d-73              [-1, 512, 16]           1,024
             ReLU-74              [-1, 512, 16]               0
          Dropout-75              [-1, 512, 16]               0
           Conv1d-76              [-1, 512, 16]          66,048
  MyConv1dPadSame-77              [-1, 512, 16]               0
       Bottleneck-78              [-1, 512, 16]               0
      BatchNorm1d-79              [-1, 512, 16]           1,024
             ReLU-80              [-1, 512, 16]               0
          Dropout-81              [-1, 512, 16]               0
           Conv1d-82              [-1, 512, 16]          66,048
  MyConv1dPadSame-83              [-1, 512, 16]               0
      BatchNorm1d-84              [-1, 512, 16]           1,024
             ReLU-85              [-1, 512, 16]               0
          Dropout-86              [-1, 512, 16]               0
           Conv1d-87              [-1, 512, 16]          66,048
  MyConv1dPadSame-88              [-1, 512, 16]               0
       Bottleneck-89              [-1, 512, 16]               0
      BatchNorm1d-90              [-1, 512, 16]           1,024
             ReLU-91              [-1, 512, 16]               0
           Linear-92                    [-1, 2]           1,026
================================================================
Total params: 318,914
Trainable params: 318,914
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 2.55
Params size (MB): 1.22
Estimated Total Size (MB): 3.76
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 64, kernel_size: 16, n_block: 16
************************************************************
************************************************************
(2000, 1, 16) Counter({0: 1000, 1: 1000})
(2000, 1, 16) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 64, 16]           1,088
   MyConv1dPadSame-2               [-1, 64, 16]               0
       BatchNorm1d-3               [-1, 64, 16]             128
              ReLU-4               [-1, 64, 16]               0
            Conv1d-5               [-1, 64, 16]           1,088
   MyConv1dPadSame-6               [-1, 64, 16]               0
       BatchNorm1d-7               [-1, 64, 16]             128
              ReLU-8               [-1, 64, 16]               0
           Dropout-9               [-1, 64, 16]               0
           Conv1d-10               [-1, 64, 16]           1,088
  MyConv1dPadSame-11               [-1, 64, 16]               0
       Bottleneck-12               [-1, 64, 16]               0
      BatchNorm1d-13               [-1, 64, 16]             128
             ReLU-14               [-1, 64, 16]               0
          Dropout-15               [-1, 64, 16]               0
           Conv1d-16                [-1, 64, 8]           1,088
  MyConv1dPadSame-17                [-1, 64, 8]               0
      BatchNorm1d-18                [-1, 64, 8]             128
             ReLU-19                [-1, 64, 8]               0
          Dropout-20                [-1, 64, 8]               0
           Conv1d-21                [-1, 64, 8]           1,088
  MyConv1dPadSame-22                [-1, 64, 8]               0
        MaxPool1d-23                [-1, 64, 8]               0
MyMaxPool1dPadSame-24                [-1, 64, 8]               0
       Bottleneck-25                [-1, 64, 8]               0
      BatchNorm1d-26                [-1, 64, 8]             128
             ReLU-27                [-1, 64, 8]               0
          Dropout-28                [-1, 64, 8]               0
           Conv1d-29                [-1, 64, 8]           1,088
  MyConv1dPadSame-30                [-1, 64, 8]               0
      BatchNorm1d-31                [-1, 64, 8]             128
             ReLU-32                [-1, 64, 8]               0
          Dropout-33                [-1, 64, 8]               0
           Conv1d-34                [-1, 64, 8]           1,088
  MyConv1dPadSame-35                [-1, 64, 8]               0
       Bottleneck-36                [-1, 64, 8]               0
      BatchNorm1d-37                [-1, 64, 8]             128
             ReLU-38                [-1, 64, 8]               0
          Dropout-39                [-1, 64, 8]               0
           Conv1d-40                [-1, 64, 4]           1,088
  MyConv1dPadSame-41                [-1, 64, 4]               0
      BatchNorm1d-42                [-1, 64, 4]             128
             ReLU-43                [-1, 64, 4]               0
          Dropout-44                [-1, 64, 4]               0
           Conv1d-45                [-1, 64, 4]           1,088
  MyConv1dPadSame-46                [-1, 64, 4]               0
        MaxPool1d-47                [-1, 64, 4]               0
MyMaxPool1dPadSame-48                [-1, 64, 4]               0
       Bottleneck-49                [-1, 64, 4]               0
      BatchNorm1d-50                [-1, 64, 4]             128
             ReLU-51                [-1, 64, 4]               0
          Dropout-52                [-1, 64, 4]               0
           Conv1d-53               [-1, 128, 4]           2,176
  MyConv1dPadSame-54               [-1, 128, 4]               0
      BatchNorm1d-55               [-1, 128, 4]             256
             ReLU-56               [-1, 128, 4]               0
          Dropout-57               [-1, 128, 4]               0
           Conv1d-58               [-1, 128, 4]           4,224
  MyConv1dPadSame-59               [-1, 128, 4]               0
       Bottleneck-60               [-1, 128, 4]               0
      BatchNorm1d-61               [-1, 128, 4]             256
             ReLU-62               [-1, 128, 4]               0
          Dropout-63               [-1, 128, 4]               0
           Conv1d-64               [-1, 128, 2]           4,224
  MyConv1dPadSame-65               [-1, 128, 2]               0
      BatchNorm1d-66               [-1, 128, 2]             256
             ReLU-67               [-1, 128, 2]               0
          Dropout-68               [-1, 128, 2]               0
           Conv1d-69               [-1, 128, 2]           4,224
  MyConv1dPadSame-70               [-1, 128, 2]               0
        MaxPool1d-71               [-1, 128, 2]               0
MyMaxPool1dPadSame-72               [-1, 128, 2]               0
       Bottleneck-73               [-1, 128, 2]               0
      BatchNorm1d-74               [-1, 128, 2]             256
             ReLU-75               [-1, 128, 2]               0
          Dropout-76               [-1, 128, 2]               0
           Conv1d-77               [-1, 128, 2]           4,224
  MyConv1dPadSame-78               [-1, 128, 2]               0
      BatchNorm1d-79               [-1, 128, 2]             256
             ReLU-80               [-1, 128, 2]               0
          Dropout-81               [-1, 128, 2]               0
           Conv1d-82               [-1, 128, 2]           4,224
  MyConv1dPadSame-83               [-1, 128, 2]               0
       Bottleneck-84               [-1, 128, 2]               0
      BatchNorm1d-85               [-1, 128, 2]             256
             ReLU-86               [-1, 128, 2]               0
          Dropout-87               [-1, 128, 2]               0
           Conv1d-88               [-1, 128, 1]           4,224
  MyConv1dPadSame-89               [-1, 128, 1]               0
      BatchNorm1d-90               [-1, 128, 1]             256
             ReLU-91               [-1, 128, 1]               0
          Dropout-92               [-1, 128, 1]               0
           Conv1d-93               [-1, 128, 1]           4,224
  MyConv1dPadSame-94               [-1, 128, 1]               0
        MaxPool1d-95               [-1, 128, 1]               0
MyMaxPool1dPadSame-96               [-1, 128, 1]               0
       Bottleneck-97               [-1, 128, 1]               0
      BatchNorm1d-98               [-1, 128, 1]             256
             ReLU-99               [-1, 128, 1]               0
         Dropout-100               [-1, 128, 1]               0
          Conv1d-101               [-1, 256, 1]           8,448
 MyConv1dPadSame-102               [-1, 256, 1]               0
     BatchNorm1d-103               [-1, 256, 1]             512
            ReLU-104               [-1, 256, 1]               0
         Dropout-105               [-1, 256, 1]               0
          Conv1d-106               [-1, 256, 1]          16,640
 MyConv1dPadSame-107               [-1, 256, 1]               0
      Bottleneck-108               [-1, 256, 1]               0
     BatchNorm1d-109               [-1, 256, 1]             512
            ReLU-110               [-1, 256, 1]               0
         Dropout-111               [-1, 256, 1]               0
          Conv1d-112               [-1, 256, 1]          16,640
 MyConv1dPadSame-113               [-1, 256, 1]               0
     BatchNorm1d-114               [-1, 256, 1]             512
            ReLU-115               [-1, 256, 1]               0
         Dropout-116               [-1, 256, 1]               0
          Conv1d-117               [-1, 256, 1]          16,640
 MyConv1dPadSame-118               [-1, 256, 1]               0
       MaxPool1d-119               [-1, 256, 1]               0
MyMaxPool1dPadSame-120               [-1, 256, 1]               0
      Bottleneck-121               [-1, 256, 1]               0
     BatchNorm1d-122               [-1, 256, 1]             512
            ReLU-123               [-1, 256, 1]               0
         Dropout-124               [-1, 256, 1]               0
          Conv1d-125               [-1, 256, 1]          16,640
 MyConv1dPadSame-126               [-1, 256, 1]               0
     BatchNorm1d-127               [-1, 256, 1]             512
            ReLU-128               [-1, 256, 1]               0
         Dropout-129               [-1, 256, 1]               0
          Conv1d-130               [-1, 256, 1]          16,640
 MyConv1dPadSame-131               [-1, 256, 1]               0
      Bottleneck-132               [-1, 256, 1]               0
     BatchNorm1d-133               [-1, 256, 1]             512
            ReLU-134               [-1, 256, 1]               0
         Dropout-135               [-1, 256, 1]               0
          Conv1d-136               [-1, 256, 1]          16,640
 MyConv1dPadSame-137               [-1, 256, 1]               0
     BatchNorm1d-138               [-1, 256, 1]             512
            ReLU-139               [-1, 256, 1]               0
         Dropout-140               [-1, 256, 1]               0
          Conv1d-141               [-1, 256, 1]          16,640
 MyConv1dPadSame-142               [-1, 256, 1]               0
       MaxPool1d-143               [-1, 256, 1]               0
MyMaxPool1dPadSame-144               [-1, 256, 1]               0
      Bottleneck-145               [-1, 256, 1]               0
     BatchNorm1d-146               [-1, 256, 1]             512
            ReLU-147               [-1, 256, 1]               0
         Dropout-148               [-1, 256, 1]               0
          Conv1d-149               [-1, 512, 1]          33,280
 MyConv1dPadSame-150               [-1, 512, 1]               0
     BatchNorm1d-151               [-1, 512, 1]           1,024
            ReLU-152               [-1, 512, 1]               0
         Dropout-153               [-1, 512, 1]               0
          Conv1d-154               [-1, 512, 1]          66,048
 MyConv1dPadSame-155               [-1, 512, 1]               0
      Bottleneck-156               [-1, 512, 1]               0
     BatchNorm1d-157               [-1, 512, 1]           1,024
            ReLU-158               [-1, 512, 1]               0
         Dropout-159               [-1, 512, 1]               0
          Conv1d-160               [-1, 512, 1]          66,048
 MyConv1dPadSame-161               [-1, 512, 1]               0
     BatchNorm1d-162               [-1, 512, 1]           1,024
            ReLU-163               [-1, 512, 1]               0
         Dropout-164               [-1, 512, 1]               0
          Conv1d-165               [-1, 512, 1]          66,048
 MyConv1dPadSame-166               [-1, 512, 1]               0
       MaxPool1d-167               [-1, 512, 1]               0
MyMaxPool1dPadSame-168               [-1, 512, 1]               0
      Bottleneck-169               [-1, 512, 1]               0
     BatchNorm1d-170               [-1, 512, 1]           1,024
            ReLU-171               [-1, 512, 1]               0
         Dropout-172               [-1, 512, 1]               0
          Conv1d-173               [-1, 512, 1]          66,048
 MyConv1dPadSame-174               [-1, 512, 1]               0
     BatchNorm1d-175               [-1, 512, 1]           1,024
            ReLU-176               [-1, 512, 1]               0
         Dropout-177               [-1, 512, 1]               0
          Conv1d-178               [-1, 512, 1]          66,048
 MyConv1dPadSame-179               [-1, 512, 1]               0
      Bottleneck-180               [-1, 512, 1]               0
     BatchNorm1d-181               [-1, 512, 1]           1,024
            ReLU-182               [-1, 512, 1]               0
         Dropout-183               [-1, 512, 1]               0
          Conv1d-184               [-1, 512, 1]          66,048
 MyConv1dPadSame-185               [-1, 512, 1]               0
     BatchNorm1d-186               [-1, 512, 1]           1,024
            ReLU-187               [-1, 512, 1]               0
         Dropout-188               [-1, 512, 1]               0
          Conv1d-189               [-1, 512, 1]          66,048
 MyConv1dPadSame-190               [-1, 512, 1]               0
       MaxPool1d-191               [-1, 512, 1]               0
MyMaxPool1dPadSame-192               [-1, 512, 1]               0
      Bottleneck-193               [-1, 512, 1]               0
     BatchNorm1d-194               [-1, 512, 1]           1,024
            ReLU-195               [-1, 512, 1]               0
          Linear-196                    [-1, 2]           1,026
================================================================
Total params: 678,594
Trainable params: 678,594
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.62
Params size (MB): 2.59
Estimated Total Size (MB): 3.20
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 128, kernel_size: 2, n_block: 2
************************************************************
************************************************************
(2000, 1, 16) Counter({1: 1000, 0: 1000})
(2000, 1, 16) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 128, 16]             384
   MyConv1dPadSame-2              [-1, 128, 16]               0
       BatchNorm1d-3              [-1, 128, 16]             256
              ReLU-4              [-1, 128, 16]               0
            Conv1d-5              [-1, 128, 16]             384
   MyConv1dPadSame-6              [-1, 128, 16]               0
       BatchNorm1d-7              [-1, 128, 16]             256
              ReLU-8              [-1, 128, 16]               0
           Dropout-9              [-1, 128, 16]               0
           Conv1d-10              [-1, 128, 16]             384
  MyConv1dPadSame-11              [-1, 128, 16]               0
       Bottleneck-12              [-1, 128, 16]               0
      BatchNorm1d-13              [-1, 128, 16]             256
             ReLU-14              [-1, 128, 16]               0
          Dropout-15              [-1, 128, 16]               0
           Conv1d-16              [-1, 256, 16]             768
  MyConv1dPadSame-17              [-1, 256, 16]               0
      BatchNorm1d-18              [-1, 256, 16]             512
             ReLU-19              [-1, 256, 16]               0
          Dropout-20              [-1, 256, 16]               0
           Conv1d-21              [-1, 256, 16]           1,280
  MyConv1dPadSame-22              [-1, 256, 16]               0
       Bottleneck-23              [-1, 256, 16]               0
      BatchNorm1d-24              [-1, 256, 16]             512
             ReLU-25              [-1, 256, 16]               0
           Linear-26                    [-1, 2]             514
================================================================
Total params: 5,506
Trainable params: 5,506
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.55
Params size (MB): 0.02
Estimated Total Size (MB): 0.57
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 128, kernel_size: 2, n_block: 4
************************************************************
************************************************************
(2000, 1, 16) Counter({0: 1000, 1: 1000})
(2000, 1, 16) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 128, 16]             384
   MyConv1dPadSame-2              [-1, 128, 16]               0
       BatchNorm1d-3              [-1, 128, 16]             256
              ReLU-4              [-1, 128, 16]               0
            Conv1d-5              [-1, 128, 16]             384
   MyConv1dPadSame-6              [-1, 128, 16]               0
       BatchNorm1d-7              [-1, 128, 16]             256
              ReLU-8              [-1, 128, 16]               0
           Dropout-9              [-1, 128, 16]               0
           Conv1d-10              [-1, 128, 16]             384
  MyConv1dPadSame-11              [-1, 128, 16]               0
       Bottleneck-12              [-1, 128, 16]               0
      BatchNorm1d-13              [-1, 128, 16]             256
             ReLU-14              [-1, 128, 16]               0
          Dropout-15              [-1, 128, 16]               0
           Conv1d-16              [-1, 256, 16]             768
  MyConv1dPadSame-17              [-1, 256, 16]               0
      BatchNorm1d-18              [-1, 256, 16]             512
             ReLU-19              [-1, 256, 16]               0
          Dropout-20              [-1, 256, 16]               0
           Conv1d-21              [-1, 256, 16]           1,280
  MyConv1dPadSame-22              [-1, 256, 16]               0
       Bottleneck-23              [-1, 256, 16]               0
      BatchNorm1d-24              [-1, 256, 16]             512
             ReLU-25              [-1, 256, 16]               0
          Dropout-26              [-1, 256, 16]               0
           Conv1d-27              [-1, 512, 16]           2,560
  MyConv1dPadSame-28              [-1, 512, 16]               0
      BatchNorm1d-29              [-1, 512, 16]           1,024
             ReLU-30              [-1, 512, 16]               0
          Dropout-31              [-1, 512, 16]               0
           Conv1d-32              [-1, 512, 16]           4,608
  MyConv1dPadSame-33              [-1, 512, 16]               0
       Bottleneck-34              [-1, 512, 16]               0
      BatchNorm1d-35              [-1, 512, 16]           1,024
             ReLU-36              [-1, 512, 16]               0
          Dropout-37              [-1, 512, 16]               0
           Conv1d-38             [-1, 1024, 16]           9,216
  MyConv1dPadSame-39             [-1, 1024, 16]               0
      BatchNorm1d-40             [-1, 1024, 16]           2,048
             ReLU-41             [-1, 1024, 16]               0
          Dropout-42             [-1, 1024, 16]               0
           Conv1d-43             [-1, 1024, 16]          17,408
  MyConv1dPadSame-44             [-1, 1024, 16]               0
       Bottleneck-45             [-1, 1024, 16]               0
      BatchNorm1d-46             [-1, 1024, 16]           2,048
             ReLU-47             [-1, 1024, 16]               0
           Linear-48                    [-1, 2]           2,050
================================================================
Total params: 46,978
Trainable params: 46,978
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 2.52
Params size (MB): 0.18
Estimated Total Size (MB): 2.69
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 128, kernel_size: 2, n_block: 8
************************************************************
************************************************************
(2000, 1, 16) Counter({1: 1000, 0: 1000})
(2000, 1, 16) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 128, 16]             384
   MyConv1dPadSame-2              [-1, 128, 16]               0
       BatchNorm1d-3              [-1, 128, 16]             256
              ReLU-4              [-1, 128, 16]               0
            Conv1d-5              [-1, 128, 16]             384
   MyConv1dPadSame-6              [-1, 128, 16]               0
       BatchNorm1d-7              [-1, 128, 16]             256
              ReLU-8              [-1, 128, 16]               0
           Dropout-9              [-1, 128, 16]               0
           Conv1d-10              [-1, 128, 16]             384
  MyConv1dPadSame-11              [-1, 128, 16]               0
       Bottleneck-12              [-1, 128, 16]               0
      BatchNorm1d-13              [-1, 128, 16]             256
             ReLU-14              [-1, 128, 16]               0
          Dropout-15              [-1, 128, 16]               0
           Conv1d-16              [-1, 128, 16]             384
  MyConv1dPadSame-17              [-1, 128, 16]               0
      BatchNorm1d-18              [-1, 128, 16]             256
             ReLU-19              [-1, 128, 16]               0
          Dropout-20              [-1, 128, 16]               0
           Conv1d-21              [-1, 128, 16]             384
  MyConv1dPadSame-22              [-1, 128, 16]               0
       Bottleneck-23              [-1, 128, 16]               0
      BatchNorm1d-24              [-1, 128, 16]             256
             ReLU-25              [-1, 128, 16]               0
          Dropout-26              [-1, 128, 16]               0
           Conv1d-27              [-1, 256, 16]             768
  MyConv1dPadSame-28              [-1, 256, 16]               0
      BatchNorm1d-29              [-1, 256, 16]             512
             ReLU-30              [-1, 256, 16]               0
          Dropout-31              [-1, 256, 16]               0
           Conv1d-32              [-1, 256, 16]           1,280
  MyConv1dPadSame-33              [-1, 256, 16]               0
       Bottleneck-34              [-1, 256, 16]               0
      BatchNorm1d-35              [-1, 256, 16]             512
             ReLU-36              [-1, 256, 16]               0
          Dropout-37              [-1, 256, 16]               0
           Conv1d-38              [-1, 256, 16]           1,280
  MyConv1dPadSame-39              [-1, 256, 16]               0
      BatchNorm1d-40              [-1, 256, 16]             512
             ReLU-41              [-1, 256, 16]               0
          Dropout-42              [-1, 256, 16]               0
           Conv1d-43              [-1, 256, 16]           1,280
  MyConv1dPadSame-44              [-1, 256, 16]               0
       Bottleneck-45              [-1, 256, 16]               0
      BatchNorm1d-46              [-1, 256, 16]             512
             ReLU-47              [-1, 256, 16]               0
          Dropout-48              [-1, 256, 16]               0
           Conv1d-49              [-1, 512, 16]           2,560
  MyConv1dPadSame-50              [-1, 512, 16]               0
      BatchNorm1d-51              [-1, 512, 16]           1,024
             ReLU-52              [-1, 512, 16]               0
          Dropout-53              [-1, 512, 16]               0
           Conv1d-54              [-1, 512, 16]           4,608
  MyConv1dPadSame-55              [-1, 512, 16]               0
       Bottleneck-56              [-1, 512, 16]               0
      BatchNorm1d-57              [-1, 512, 16]           1,024
             ReLU-58              [-1, 512, 16]               0
          Dropout-59              [-1, 512, 16]               0
           Conv1d-60              [-1, 512, 16]           4,608
  MyConv1dPadSame-61              [-1, 512, 16]               0
      BatchNorm1d-62              [-1, 512, 16]           1,024
             ReLU-63              [-1, 512, 16]               0
          Dropout-64              [-1, 512, 16]               0
           Conv1d-65              [-1, 512, 16]           4,608
  MyConv1dPadSame-66              [-1, 512, 16]               0
       Bottleneck-67              [-1, 512, 16]               0
      BatchNorm1d-68              [-1, 512, 16]           1,024
             ReLU-69              [-1, 512, 16]               0
          Dropout-70              [-1, 512, 16]               0
           Conv1d-71             [-1, 1024, 16]           9,216
  MyConv1dPadSame-72             [-1, 1024, 16]               0
      BatchNorm1d-73             [-1, 1024, 16]           2,048
             ReLU-74             [-1, 1024, 16]               0
          Dropout-75             [-1, 1024, 16]               0
           Conv1d-76             [-1, 1024, 16]          17,408
  MyConv1dPadSame-77             [-1, 1024, 16]               0
       Bottleneck-78             [-1, 1024, 16]               0
      BatchNorm1d-79             [-1, 1024, 16]           2,048
             ReLU-80             [-1, 1024, 16]               0
          Dropout-81             [-1, 1024, 16]               0
           Conv1d-82             [-1, 1024, 16]          17,408
  MyConv1dPadSame-83             [-1, 1024, 16]               0
      BatchNorm1d-84             [-1, 1024, 16]           2,048
             ReLU-85             [-1, 1024, 16]               0
          Dropout-86             [-1, 1024, 16]               0
           Conv1d-87             [-1, 1024, 16]          17,408
  MyConv1dPadSame-88             [-1, 1024, 16]               0
       Bottleneck-89             [-1, 1024, 16]               0
      BatchNorm1d-90             [-1, 1024, 16]           2,048
             ReLU-91             [-1, 1024, 16]               0
           Linear-92                    [-1, 2]           2,050
================================================================
Total params: 102,018
Trainable params: 102,018
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 5.09
Params size (MB): 0.39
Estimated Total Size (MB): 5.48
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 128, kernel_size: 2, n_block: 16
************************************************************
************************************************************
(2000, 1, 16) Counter({0: 1000, 1: 1000})
(2000, 1, 16) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 128, 16]             384
   MyConv1dPadSame-2              [-1, 128, 16]               0
       BatchNorm1d-3              [-1, 128, 16]             256
              ReLU-4              [-1, 128, 16]               0
            Conv1d-5              [-1, 128, 16]             384
   MyConv1dPadSame-6              [-1, 128, 16]               0
       BatchNorm1d-7              [-1, 128, 16]             256
              ReLU-8              [-1, 128, 16]               0
           Dropout-9              [-1, 128, 16]               0
           Conv1d-10              [-1, 128, 16]             384
  MyConv1dPadSame-11              [-1, 128, 16]               0
       Bottleneck-12              [-1, 128, 16]               0
      BatchNorm1d-13              [-1, 128, 16]             256
             ReLU-14              [-1, 128, 16]               0
          Dropout-15              [-1, 128, 16]               0
           Conv1d-16               [-1, 128, 8]             384
  MyConv1dPadSame-17               [-1, 128, 8]               0
      BatchNorm1d-18               [-1, 128, 8]             256
             ReLU-19               [-1, 128, 8]               0
          Dropout-20               [-1, 128, 8]               0
           Conv1d-21               [-1, 128, 8]             384
  MyConv1dPadSame-22               [-1, 128, 8]               0
        MaxPool1d-23               [-1, 128, 8]               0
MyMaxPool1dPadSame-24               [-1, 128, 8]               0
       Bottleneck-25               [-1, 128, 8]               0
      BatchNorm1d-26               [-1, 128, 8]             256
             ReLU-27               [-1, 128, 8]               0
          Dropout-28               [-1, 128, 8]               0
           Conv1d-29               [-1, 128, 8]             384
  MyConv1dPadSame-30               [-1, 128, 8]               0
      BatchNorm1d-31               [-1, 128, 8]             256
             ReLU-32               [-1, 128, 8]               0
          Dropout-33               [-1, 128, 8]               0
           Conv1d-34               [-1, 128, 8]             384
  MyConv1dPadSame-35               [-1, 128, 8]               0
       Bottleneck-36               [-1, 128, 8]               0
      BatchNorm1d-37               [-1, 128, 8]             256
             ReLU-38               [-1, 128, 8]               0
          Dropout-39               [-1, 128, 8]               0
           Conv1d-40               [-1, 128, 4]             384
  MyConv1dPadSame-41               [-1, 128, 4]               0
      BatchNorm1d-42               [-1, 128, 4]             256
             ReLU-43               [-1, 128, 4]               0
          Dropout-44               [-1, 128, 4]               0
           Conv1d-45               [-1, 128, 4]             384
  MyConv1dPadSame-46               [-1, 128, 4]               0
        MaxPool1d-47               [-1, 128, 4]               0
MyMaxPool1dPadSame-48               [-1, 128, 4]               0
       Bottleneck-49               [-1, 128, 4]               0
      BatchNorm1d-50               [-1, 128, 4]             256
             ReLU-51               [-1, 128, 4]               0
          Dropout-52               [-1, 128, 4]               0
           Conv1d-53               [-1, 256, 4]             768
  MyConv1dPadSame-54               [-1, 256, 4]               0
      BatchNorm1d-55               [-1, 256, 4]             512
             ReLU-56               [-1, 256, 4]               0
          Dropout-57               [-1, 256, 4]               0
           Conv1d-58               [-1, 256, 4]           1,280
  MyConv1dPadSame-59               [-1, 256, 4]               0
       Bottleneck-60               [-1, 256, 4]               0
      BatchNorm1d-61               [-1, 256, 4]             512
             ReLU-62               [-1, 256, 4]               0
          Dropout-63               [-1, 256, 4]               0
           Conv1d-64               [-1, 256, 2]           1,280
  MyConv1dPadSame-65               [-1, 256, 2]               0
      BatchNorm1d-66               [-1, 256, 2]             512
             ReLU-67               [-1, 256, 2]               0
          Dropout-68               [-1, 256, 2]               0
           Conv1d-69               [-1, 256, 2]           1,280
  MyConv1dPadSame-70               [-1, 256, 2]               0
        MaxPool1d-71               [-1, 256, 2]               0
MyMaxPool1dPadSame-72               [-1, 256, 2]               0
       Bottleneck-73               [-1, 256, 2]               0
      BatchNorm1d-74               [-1, 256, 2]             512
             ReLU-75               [-1, 256, 2]               0
          Dropout-76               [-1, 256, 2]               0
           Conv1d-77               [-1, 256, 2]           1,280
  MyConv1dPadSame-78               [-1, 256, 2]               0
      BatchNorm1d-79               [-1, 256, 2]             512
             ReLU-80               [-1, 256, 2]               0
          Dropout-81               [-1, 256, 2]               0
           Conv1d-82               [-1, 256, 2]           1,280
  MyConv1dPadSame-83               [-1, 256, 2]               0
       Bottleneck-84               [-1, 256, 2]               0
      BatchNorm1d-85               [-1, 256, 2]             512
             ReLU-86               [-1, 256, 2]               0
          Dropout-87               [-1, 256, 2]               0
           Conv1d-88               [-1, 256, 1]           1,280
  MyConv1dPadSame-89               [-1, 256, 1]               0
      BatchNorm1d-90               [-1, 256, 1]             512
             ReLU-91               [-1, 256, 1]               0
          Dropout-92               [-1, 256, 1]               0
           Conv1d-93               [-1, 256, 1]           1,280
  MyConv1dPadSame-94               [-1, 256, 1]               0
        MaxPool1d-95               [-1, 256, 1]               0
MyMaxPool1dPadSame-96               [-1, 256, 1]               0
       Bottleneck-97               [-1, 256, 1]               0
      BatchNorm1d-98               [-1, 256, 1]             512
             ReLU-99               [-1, 256, 1]               0
         Dropout-100               [-1, 256, 1]               0
          Conv1d-101               [-1, 512, 1]           2,560
 MyConv1dPadSame-102               [-1, 512, 1]               0
     BatchNorm1d-103               [-1, 512, 1]           1,024
            ReLU-104               [-1, 512, 1]               0
         Dropout-105               [-1, 512, 1]               0
          Conv1d-106               [-1, 512, 1]           4,608
 MyConv1dPadSame-107               [-1, 512, 1]               0
      Bottleneck-108               [-1, 512, 1]               0
     BatchNorm1d-109               [-1, 512, 1]           1,024
            ReLU-110               [-1, 512, 1]               0
         Dropout-111               [-1, 512, 1]               0
          Conv1d-112               [-1, 512, 1]           4,608
 MyConv1dPadSame-113               [-1, 512, 1]               0
     BatchNorm1d-114               [-1, 512, 1]           1,024
            ReLU-115               [-1, 512, 1]               0
         Dropout-116               [-1, 512, 1]               0
          Conv1d-117               [-1, 512, 1]           4,608
 MyConv1dPadSame-118               [-1, 512, 1]               0
       MaxPool1d-119               [-1, 512, 1]               0
MyMaxPool1dPadSame-120               [-1, 512, 1]               0
      Bottleneck-121               [-1, 512, 1]               0
     BatchNorm1d-122               [-1, 512, 1]           1,024
            ReLU-123               [-1, 512, 1]               0
         Dropout-124               [-1, 512, 1]               0
          Conv1d-125               [-1, 512, 1]           4,608
 MyConv1dPadSame-126               [-1, 512, 1]               0
     BatchNorm1d-127               [-1, 512, 1]           1,024
            ReLU-128               [-1, 512, 1]               0
         Dropout-129               [-1, 512, 1]               0
          Conv1d-130               [-1, 512, 1]           4,608
 MyConv1dPadSame-131               [-1, 512, 1]               0
      Bottleneck-132               [-1, 512, 1]               0
     BatchNorm1d-133               [-1, 512, 1]           1,024
            ReLU-134               [-1, 512, 1]               0
         Dropout-135               [-1, 512, 1]               0
          Conv1d-136               [-1, 512, 1]           4,608
 MyConv1dPadSame-137               [-1, 512, 1]               0
     BatchNorm1d-138               [-1, 512, 1]           1,024
            ReLU-139               [-1, 512, 1]               0
         Dropout-140               [-1, 512, 1]               0
          Conv1d-141               [-1, 512, 1]           4,608
 MyConv1dPadSame-142               [-1, 512, 1]               0
       MaxPool1d-143               [-1, 512, 1]               0
MyMaxPool1dPadSame-144               [-1, 512, 1]               0
      Bottleneck-145               [-1, 512, 1]               0
     BatchNorm1d-146               [-1, 512, 1]           1,024
            ReLU-147               [-1, 512, 1]               0
         Dropout-148               [-1, 512, 1]               0
          Conv1d-149              [-1, 1024, 1]           9,216
 MyConv1dPadSame-150              [-1, 1024, 1]               0
     BatchNorm1d-151              [-1, 1024, 1]           2,048
            ReLU-152              [-1, 1024, 1]               0
         Dropout-153              [-1, 1024, 1]               0
          Conv1d-154              [-1, 1024, 1]          17,408
 MyConv1dPadSame-155              [-1, 1024, 1]               0
      Bottleneck-156              [-1, 1024, 1]               0
     BatchNorm1d-157              [-1, 1024, 1]           2,048
            ReLU-158              [-1, 1024, 1]               0
         Dropout-159              [-1, 1024, 1]               0
          Conv1d-160              [-1, 1024, 1]          17,408
 MyConv1dPadSame-161              [-1, 1024, 1]               0
     BatchNorm1d-162              [-1, 1024, 1]           2,048
            ReLU-163              [-1, 1024, 1]               0
         Dropout-164              [-1, 1024, 1]               0
          Conv1d-165              [-1, 1024, 1]          17,408
 MyConv1dPadSame-166              [-1, 1024, 1]               0
       MaxPool1d-167              [-1, 1024, 1]               0
MyMaxPool1dPadSame-168              [-1, 1024, 1]               0
      Bottleneck-169              [-1, 1024, 1]               0
     BatchNorm1d-170              [-1, 1024, 1]           2,048
            ReLU-171              [-1, 1024, 1]               0
         Dropout-172              [-1, 1024, 1]               0
          Conv1d-173              [-1, 1024, 1]          17,408
 MyConv1dPadSame-174              [-1, 1024, 1]               0
     BatchNorm1d-175              [-1, 1024, 1]           2,048
            ReLU-176              [-1, 1024, 1]               0
         Dropout-177              [-1, 1024, 1]               0
          Conv1d-178              [-1, 1024, 1]          17,408
 MyConv1dPadSame-179              [-1, 1024, 1]               0
      Bottleneck-180              [-1, 1024, 1]               0
     BatchNorm1d-181              [-1, 1024, 1]           2,048
            ReLU-182              [-1, 1024, 1]               0
         Dropout-183              [-1, 1024, 1]               0
          Conv1d-184              [-1, 1024, 1]          17,408
 MyConv1dPadSame-185              [-1, 1024, 1]               0
     BatchNorm1d-186              [-1, 1024, 1]           2,048
            ReLU-187              [-1, 1024, 1]               0
         Dropout-188              [-1, 1024, 1]               0
          Conv1d-189              [-1, 1024, 1]          17,408
 MyConv1dPadSame-190              [-1, 1024, 1]               0
       MaxPool1d-191              [-1, 1024, 1]               0
MyMaxPool1dPadSame-192              [-1, 1024, 1]               0
      Bottleneck-193              [-1, 1024, 1]               0
     BatchNorm1d-194              [-1, 1024, 1]           2,048
            ReLU-195              [-1, 1024, 1]               0
          Linear-196                    [-1, 2]           2,050
================================================================
Total params: 212,098
Trainable params: 212,098
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 1.23
Params size (MB): 0.81
Estimated Total Size (MB): 2.04
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 128, kernel_size: 4, n_block: 2
************************************************************
************************************************************
(2000, 1, 16) Counter({0: 1000, 1: 1000})
(2000, 1, 16) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 128, 16]             640
   MyConv1dPadSame-2              [-1, 128, 16]               0
       BatchNorm1d-3              [-1, 128, 16]             256
              ReLU-4              [-1, 128, 16]               0
            Conv1d-5              [-1, 128, 16]             640
   MyConv1dPadSame-6              [-1, 128, 16]               0
       BatchNorm1d-7              [-1, 128, 16]             256
              ReLU-8              [-1, 128, 16]               0
           Dropout-9              [-1, 128, 16]               0
           Conv1d-10              [-1, 128, 16]             640
  MyConv1dPadSame-11              [-1, 128, 16]               0
       Bottleneck-12              [-1, 128, 16]               0
      BatchNorm1d-13              [-1, 128, 16]             256
             ReLU-14              [-1, 128, 16]               0
          Dropout-15              [-1, 128, 16]               0
           Conv1d-16              [-1, 256, 16]           1,280
  MyConv1dPadSame-17              [-1, 256, 16]               0
      BatchNorm1d-18              [-1, 256, 16]             512
             ReLU-19              [-1, 256, 16]               0
          Dropout-20              [-1, 256, 16]               0
           Conv1d-21              [-1, 256, 16]           2,304
  MyConv1dPadSame-22              [-1, 256, 16]               0
       Bottleneck-23              [-1, 256, 16]               0
      BatchNorm1d-24              [-1, 256, 16]             512
             ReLU-25              [-1, 256, 16]               0
           Linear-26                    [-1, 2]             514
================================================================
Total params: 7,810
Trainable params: 7,810
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.55
Params size (MB): 0.03
Estimated Total Size (MB): 0.58
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 128, kernel_size: 4, n_block: 4
************************************************************
************************************************************
(2000, 1, 16) Counter({1: 1000, 0: 1000})
(2000, 1, 16) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 128, 16]             640
   MyConv1dPadSame-2              [-1, 128, 16]               0
       BatchNorm1d-3              [-1, 128, 16]             256
              ReLU-4              [-1, 128, 16]               0
            Conv1d-5              [-1, 128, 16]             640
   MyConv1dPadSame-6              [-1, 128, 16]               0
       BatchNorm1d-7              [-1, 128, 16]             256
              ReLU-8              [-1, 128, 16]               0
           Dropout-9              [-1, 128, 16]               0
           Conv1d-10              [-1, 128, 16]             640
  MyConv1dPadSame-11              [-1, 128, 16]               0
       Bottleneck-12              [-1, 128, 16]               0
      BatchNorm1d-13              [-1, 128, 16]             256
             ReLU-14              [-1, 128, 16]               0
          Dropout-15              [-1, 128, 16]               0
           Conv1d-16              [-1, 256, 16]           1,280
  MyConv1dPadSame-17              [-1, 256, 16]               0
      BatchNorm1d-18              [-1, 256, 16]             512
             ReLU-19              [-1, 256, 16]               0
          Dropout-20              [-1, 256, 16]               0
           Conv1d-21              [-1, 256, 16]           2,304
  MyConv1dPadSame-22              [-1, 256, 16]               0
       Bottleneck-23              [-1, 256, 16]               0
      BatchNorm1d-24              [-1, 256, 16]             512
             ReLU-25              [-1, 256, 16]               0
          Dropout-26              [-1, 256, 16]               0
           Conv1d-27              [-1, 512, 16]           4,608
  MyConv1dPadSame-28              [-1, 512, 16]               0
      BatchNorm1d-29              [-1, 512, 16]           1,024
             ReLU-30              [-1, 512, 16]               0
          Dropout-31              [-1, 512, 16]               0
           Conv1d-32              [-1, 512, 16]           8,704
  MyConv1dPadSame-33              [-1, 512, 16]               0
       Bottleneck-34              [-1, 512, 16]               0
      BatchNorm1d-35              [-1, 512, 16]           1,024
             ReLU-36              [-1, 512, 16]               0
          Dropout-37              [-1, 512, 16]               0
           Conv1d-38             [-1, 1024, 16]          17,408
  MyConv1dPadSame-39             [-1, 1024, 16]               0
      BatchNorm1d-40             [-1, 1024, 16]           2,048
             ReLU-41             [-1, 1024, 16]               0
          Dropout-42             [-1, 1024, 16]               0
           Conv1d-43             [-1, 1024, 16]          33,792
  MyConv1dPadSame-44             [-1, 1024, 16]               0
       Bottleneck-45             [-1, 1024, 16]               0
      BatchNorm1d-46             [-1, 1024, 16]           2,048
             ReLU-47             [-1, 1024, 16]               0
           Linear-48                    [-1, 2]           2,050
================================================================
Total params: 80,002
Trainable params: 80,002
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 2.52
Params size (MB): 0.31
Estimated Total Size (MB): 2.82
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 128, kernel_size: 4, n_block: 8
************************************************************
************************************************************
(2000, 1, 16) Counter({0: 1000, 1: 1000})
(2000, 1, 16) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 128, 16]             640
   MyConv1dPadSame-2              [-1, 128, 16]               0
       BatchNorm1d-3              [-1, 128, 16]             256
              ReLU-4              [-1, 128, 16]               0
            Conv1d-5              [-1, 128, 16]             640
   MyConv1dPadSame-6              [-1, 128, 16]               0
       BatchNorm1d-7              [-1, 128, 16]             256
              ReLU-8              [-1, 128, 16]               0
           Dropout-9              [-1, 128, 16]               0
           Conv1d-10              [-1, 128, 16]             640
  MyConv1dPadSame-11              [-1, 128, 16]               0
       Bottleneck-12              [-1, 128, 16]               0
      BatchNorm1d-13              [-1, 128, 16]             256
             ReLU-14              [-1, 128, 16]               0
          Dropout-15              [-1, 128, 16]               0
           Conv1d-16              [-1, 128, 16]             640
  MyConv1dPadSame-17              [-1, 128, 16]               0
      BatchNorm1d-18              [-1, 128, 16]             256
             ReLU-19              [-1, 128, 16]               0
          Dropout-20              [-1, 128, 16]               0
           Conv1d-21              [-1, 128, 16]             640
  MyConv1dPadSame-22              [-1, 128, 16]               0
       Bottleneck-23              [-1, 128, 16]               0
      BatchNorm1d-24              [-1, 128, 16]             256
             ReLU-25              [-1, 128, 16]               0
          Dropout-26              [-1, 128, 16]               0
           Conv1d-27              [-1, 256, 16]           1,280
  MyConv1dPadSame-28              [-1, 256, 16]               0
      BatchNorm1d-29              [-1, 256, 16]             512
             ReLU-30              [-1, 256, 16]               0
          Dropout-31              [-1, 256, 16]               0
           Conv1d-32              [-1, 256, 16]           2,304
  MyConv1dPadSame-33              [-1, 256, 16]               0
       Bottleneck-34              [-1, 256, 16]               0
      BatchNorm1d-35              [-1, 256, 16]             512
             ReLU-36              [-1, 256, 16]               0
          Dropout-37              [-1, 256, 16]               0
           Conv1d-38              [-1, 256, 16]           2,304
  MyConv1dPadSame-39              [-1, 256, 16]               0
      BatchNorm1d-40              [-1, 256, 16]             512
             ReLU-41              [-1, 256, 16]               0
          Dropout-42              [-1, 256, 16]               0
           Conv1d-43              [-1, 256, 16]           2,304
  MyConv1dPadSame-44              [-1, 256, 16]               0
       Bottleneck-45              [-1, 256, 16]               0
      BatchNorm1d-46              [-1, 256, 16]             512
             ReLU-47              [-1, 256, 16]               0
          Dropout-48              [-1, 256, 16]               0
           Conv1d-49              [-1, 512, 16]           4,608
  MyConv1dPadSame-50              [-1, 512, 16]               0
      BatchNorm1d-51              [-1, 512, 16]           1,024
             ReLU-52              [-1, 512, 16]               0
          Dropout-53              [-1, 512, 16]               0
           Conv1d-54              [-1, 512, 16]           8,704
  MyConv1dPadSame-55              [-1, 512, 16]               0
       Bottleneck-56              [-1, 512, 16]               0
      BatchNorm1d-57              [-1, 512, 16]           1,024
             ReLU-58              [-1, 512, 16]               0
          Dropout-59              [-1, 512, 16]               0
           Conv1d-60              [-1, 512, 16]           8,704
  MyConv1dPadSame-61              [-1, 512, 16]               0
      BatchNorm1d-62              [-1, 512, 16]           1,024
             ReLU-63              [-1, 512, 16]               0
          Dropout-64              [-1, 512, 16]               0
           Conv1d-65              [-1, 512, 16]           8,704
  MyConv1dPadSame-66              [-1, 512, 16]               0
       Bottleneck-67              [-1, 512, 16]               0
      BatchNorm1d-68              [-1, 512, 16]           1,024
             ReLU-69              [-1, 512, 16]               0
          Dropout-70              [-1, 512, 16]               0
           Conv1d-71             [-1, 1024, 16]          17,408
  MyConv1dPadSame-72             [-1, 1024, 16]               0
      BatchNorm1d-73             [-1, 1024, 16]           2,048
             ReLU-74             [-1, 1024, 16]               0
          Dropout-75             [-1, 1024, 16]               0
           Conv1d-76             [-1, 1024, 16]          33,792
  MyConv1dPadSame-77             [-1, 1024, 16]               0
       Bottleneck-78             [-1, 1024, 16]               0
      BatchNorm1d-79             [-1, 1024, 16]           2,048
             ReLU-80             [-1, 1024, 16]               0
          Dropout-81             [-1, 1024, 16]               0
           Conv1d-82             [-1, 1024, 16]          33,792
  MyConv1dPadSame-83             [-1, 1024, 16]               0
      BatchNorm1d-84             [-1, 1024, 16]           2,048
             ReLU-85             [-1, 1024, 16]               0
          Dropout-86             [-1, 1024, 16]               0
           Conv1d-87             [-1, 1024, 16]          33,792
  MyConv1dPadSame-88             [-1, 1024, 16]               0
       Bottleneck-89             [-1, 1024, 16]               0
      BatchNorm1d-90             [-1, 1024, 16]           2,048
             ReLU-91             [-1, 1024, 16]               0
           Linear-92                    [-1, 2]           2,050
================================================================
Total params: 178,562
Trainable params: 178,562
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 5.09
Params size (MB): 0.68
Estimated Total Size (MB): 5.77
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 128, kernel_size: 4, n_block: 16
************************************************************
************************************************************
(2000, 1, 16) Counter({1: 1000, 0: 1000})
(2000, 1, 16) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 128, 16]             640
   MyConv1dPadSame-2              [-1, 128, 16]               0
       BatchNorm1d-3              [-1, 128, 16]             256
              ReLU-4              [-1, 128, 16]               0
            Conv1d-5              [-1, 128, 16]             640
   MyConv1dPadSame-6              [-1, 128, 16]               0
       BatchNorm1d-7              [-1, 128, 16]             256
              ReLU-8              [-1, 128, 16]               0
           Dropout-9              [-1, 128, 16]               0
           Conv1d-10              [-1, 128, 16]             640
  MyConv1dPadSame-11              [-1, 128, 16]               0
       Bottleneck-12              [-1, 128, 16]               0
      BatchNorm1d-13              [-1, 128, 16]             256
             ReLU-14              [-1, 128, 16]               0
          Dropout-15              [-1, 128, 16]               0
           Conv1d-16               [-1, 128, 8]             640
  MyConv1dPadSame-17               [-1, 128, 8]               0
      BatchNorm1d-18               [-1, 128, 8]             256
             ReLU-19               [-1, 128, 8]               0
          Dropout-20               [-1, 128, 8]               0
           Conv1d-21               [-1, 128, 8]             640
  MyConv1dPadSame-22               [-1, 128, 8]               0
        MaxPool1d-23               [-1, 128, 8]               0
MyMaxPool1dPadSame-24               [-1, 128, 8]               0
       Bottleneck-25               [-1, 128, 8]               0
      BatchNorm1d-26               [-1, 128, 8]             256
             ReLU-27               [-1, 128, 8]               0
          Dropout-28               [-1, 128, 8]               0
           Conv1d-29               [-1, 128, 8]             640
  MyConv1dPadSame-30               [-1, 128, 8]               0
      BatchNorm1d-31               [-1, 128, 8]             256
             ReLU-32               [-1, 128, 8]               0
          Dropout-33               [-1, 128, 8]               0
           Conv1d-34               [-1, 128, 8]             640
  MyConv1dPadSame-35               [-1, 128, 8]               0
       Bottleneck-36               [-1, 128, 8]               0
      BatchNorm1d-37               [-1, 128, 8]             256
             ReLU-38               [-1, 128, 8]               0
          Dropout-39               [-1, 128, 8]               0
           Conv1d-40               [-1, 128, 4]             640
  MyConv1dPadSame-41               [-1, 128, 4]               0
      BatchNorm1d-42               [-1, 128, 4]             256
             ReLU-43               [-1, 128, 4]               0
          Dropout-44               [-1, 128, 4]               0
           Conv1d-45               [-1, 128, 4]             640
  MyConv1dPadSame-46               [-1, 128, 4]               0
        MaxPool1d-47               [-1, 128, 4]               0
MyMaxPool1dPadSame-48               [-1, 128, 4]               0
       Bottleneck-49               [-1, 128, 4]               0
      BatchNorm1d-50               [-1, 128, 4]             256
             ReLU-51               [-1, 128, 4]               0
          Dropout-52               [-1, 128, 4]               0
           Conv1d-53               [-1, 256, 4]           1,280
  MyConv1dPadSame-54               [-1, 256, 4]               0
      BatchNorm1d-55               [-1, 256, 4]             512
             ReLU-56               [-1, 256, 4]               0
          Dropout-57               [-1, 256, 4]               0
           Conv1d-58               [-1, 256, 4]           2,304
  MyConv1dPadSame-59               [-1, 256, 4]               0
       Bottleneck-60               [-1, 256, 4]               0
      BatchNorm1d-61               [-1, 256, 4]             512
             ReLU-62               [-1, 256, 4]               0
          Dropout-63               [-1, 256, 4]               0
           Conv1d-64               [-1, 256, 2]           2,304
  MyConv1dPadSame-65               [-1, 256, 2]               0
      BatchNorm1d-66               [-1, 256, 2]             512
             ReLU-67               [-1, 256, 2]               0
          Dropout-68               [-1, 256, 2]               0
           Conv1d-69               [-1, 256, 2]           2,304
  MyConv1dPadSame-70               [-1, 256, 2]               0
        MaxPool1d-71               [-1, 256, 2]               0
MyMaxPool1dPadSame-72               [-1, 256, 2]               0
       Bottleneck-73               [-1, 256, 2]               0
      BatchNorm1d-74               [-1, 256, 2]             512
             ReLU-75               [-1, 256, 2]               0
          Dropout-76               [-1, 256, 2]               0
           Conv1d-77               [-1, 256, 2]           2,304
  MyConv1dPadSame-78               [-1, 256, 2]               0
      BatchNorm1d-79               [-1, 256, 2]             512
             ReLU-80               [-1, 256, 2]               0
          Dropout-81               [-1, 256, 2]               0
           Conv1d-82               [-1, 256, 2]           2,304
  MyConv1dPadSame-83               [-1, 256, 2]               0
       Bottleneck-84               [-1, 256, 2]               0
      BatchNorm1d-85               [-1, 256, 2]             512
             ReLU-86               [-1, 256, 2]               0
          Dropout-87               [-1, 256, 2]               0
           Conv1d-88               [-1, 256, 1]           2,304
  MyConv1dPadSame-89               [-1, 256, 1]               0
      BatchNorm1d-90               [-1, 256, 1]             512
             ReLU-91               [-1, 256, 1]               0
          Dropout-92               [-1, 256, 1]               0
           Conv1d-93               [-1, 256, 1]           2,304
  MyConv1dPadSame-94               [-1, 256, 1]               0
        MaxPool1d-95               [-1, 256, 1]               0
MyMaxPool1dPadSame-96               [-1, 256, 1]               0
       Bottleneck-97               [-1, 256, 1]               0
      BatchNorm1d-98               [-1, 256, 1]             512
             ReLU-99               [-1, 256, 1]               0
         Dropout-100               [-1, 256, 1]               0
          Conv1d-101               [-1, 512, 1]           4,608
 MyConv1dPadSame-102               [-1, 512, 1]               0
     BatchNorm1d-103               [-1, 512, 1]           1,024
            ReLU-104               [-1, 512, 1]               0
         Dropout-105               [-1, 512, 1]               0
          Conv1d-106               [-1, 512, 1]           8,704
 MyConv1dPadSame-107               [-1, 512, 1]               0
      Bottleneck-108               [-1, 512, 1]               0
     BatchNorm1d-109               [-1, 512, 1]           1,024
            ReLU-110               [-1, 512, 1]               0
         Dropout-111               [-1, 512, 1]               0
          Conv1d-112               [-1, 512, 1]           8,704
 MyConv1dPadSame-113               [-1, 512, 1]               0
     BatchNorm1d-114               [-1, 512, 1]           1,024
            ReLU-115               [-1, 512, 1]               0
         Dropout-116               [-1, 512, 1]               0
          Conv1d-117               [-1, 512, 1]           8,704
 MyConv1dPadSame-118               [-1, 512, 1]               0
       MaxPool1d-119               [-1, 512, 1]               0
MyMaxPool1dPadSame-120               [-1, 512, 1]               0
      Bottleneck-121               [-1, 512, 1]               0
     BatchNorm1d-122               [-1, 512, 1]           1,024
            ReLU-123               [-1, 512, 1]               0
         Dropout-124               [-1, 512, 1]               0
          Conv1d-125               [-1, 512, 1]           8,704
 MyConv1dPadSame-126               [-1, 512, 1]               0
     BatchNorm1d-127               [-1, 512, 1]           1,024
            ReLU-128               [-1, 512, 1]               0
         Dropout-129               [-1, 512, 1]               0
          Conv1d-130               [-1, 512, 1]           8,704
 MyConv1dPadSame-131               [-1, 512, 1]               0
      Bottleneck-132               [-1, 512, 1]               0
     BatchNorm1d-133               [-1, 512, 1]           1,024
            ReLU-134               [-1, 512, 1]               0
         Dropout-135               [-1, 512, 1]               0
          Conv1d-136               [-1, 512, 1]           8,704
 MyConv1dPadSame-137               [-1, 512, 1]               0
     BatchNorm1d-138               [-1, 512, 1]           1,024
            ReLU-139               [-1, 512, 1]               0
         Dropout-140               [-1, 512, 1]               0
          Conv1d-141               [-1, 512, 1]           8,704
 MyConv1dPadSame-142               [-1, 512, 1]               0
       MaxPool1d-143               [-1, 512, 1]               0
MyMaxPool1dPadSame-144               [-1, 512, 1]               0
      Bottleneck-145               [-1, 512, 1]               0
     BatchNorm1d-146               [-1, 512, 1]           1,024
            ReLU-147               [-1, 512, 1]               0
         Dropout-148               [-1, 512, 1]               0
          Conv1d-149              [-1, 1024, 1]          17,408
 MyConv1dPadSame-150              [-1, 1024, 1]               0
     BatchNorm1d-151              [-1, 1024, 1]           2,048
            ReLU-152              [-1, 1024, 1]               0
         Dropout-153              [-1, 1024, 1]               0
          Conv1d-154              [-1, 1024, 1]          33,792
 MyConv1dPadSame-155              [-1, 1024, 1]               0
      Bottleneck-156              [-1, 1024, 1]               0
     BatchNorm1d-157              [-1, 1024, 1]           2,048
            ReLU-158              [-1, 1024, 1]               0
         Dropout-159              [-1, 1024, 1]               0
          Conv1d-160              [-1, 1024, 1]          33,792
 MyConv1dPadSame-161              [-1, 1024, 1]               0
     BatchNorm1d-162              [-1, 1024, 1]           2,048
            ReLU-163              [-1, 1024, 1]               0
         Dropout-164              [-1, 1024, 1]               0
          Conv1d-165              [-1, 1024, 1]          33,792
 MyConv1dPadSame-166              [-1, 1024, 1]               0
       MaxPool1d-167              [-1, 1024, 1]               0
MyMaxPool1dPadSame-168              [-1, 1024, 1]               0
      Bottleneck-169              [-1, 1024, 1]               0
     BatchNorm1d-170              [-1, 1024, 1]           2,048
            ReLU-171              [-1, 1024, 1]               0
         Dropout-172              [-1, 1024, 1]               0
          Conv1d-173              [-1, 1024, 1]          33,792
 MyConv1dPadSame-174              [-1, 1024, 1]               0
     BatchNorm1d-175              [-1, 1024, 1]           2,048
            ReLU-176              [-1, 1024, 1]               0
         Dropout-177              [-1, 1024, 1]               0
          Conv1d-178              [-1, 1024, 1]          33,792
 MyConv1dPadSame-179              [-1, 1024, 1]               0
      Bottleneck-180              [-1, 1024, 1]               0
     BatchNorm1d-181              [-1, 1024, 1]           2,048
            ReLU-182              [-1, 1024, 1]               0
         Dropout-183              [-1, 1024, 1]               0
          Conv1d-184              [-1, 1024, 1]          33,792
 MyConv1dPadSame-185              [-1, 1024, 1]               0
     BatchNorm1d-186              [-1, 1024, 1]           2,048
            ReLU-187              [-1, 1024, 1]               0
         Dropout-188              [-1, 1024, 1]               0
          Conv1d-189              [-1, 1024, 1]          33,792
 MyConv1dPadSame-190              [-1, 1024, 1]               0
       MaxPool1d-191              [-1, 1024, 1]               0
MyMaxPool1dPadSame-192              [-1, 1024, 1]               0
      Bottleneck-193              [-1, 1024, 1]               0
     BatchNorm1d-194              [-1, 1024, 1]           2,048
            ReLU-195              [-1, 1024, 1]               0
          Linear-196                    [-1, 2]           2,050
================================================================
Total params: 375,682
Trainable params: 375,682
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 1.23
Params size (MB): 1.43
Estimated Total Size (MB): 2.67
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 128, kernel_size: 8, n_block: 2
************************************************************
************************************************************
(2000, 1, 16) Counter({1: 1000, 0: 1000})
(2000, 1, 16) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 128, 16]           1,152
   MyConv1dPadSame-2              [-1, 128, 16]               0
       BatchNorm1d-3              [-1, 128, 16]             256
              ReLU-4              [-1, 128, 16]               0
            Conv1d-5              [-1, 128, 16]           1,152
   MyConv1dPadSame-6              [-1, 128, 16]               0
       BatchNorm1d-7              [-1, 128, 16]             256
              ReLU-8              [-1, 128, 16]               0
           Dropout-9              [-1, 128, 16]               0
           Conv1d-10              [-1, 128, 16]           1,152
  MyConv1dPadSame-11              [-1, 128, 16]               0
       Bottleneck-12              [-1, 128, 16]               0
      BatchNorm1d-13              [-1, 128, 16]             256
             ReLU-14              [-1, 128, 16]               0
          Dropout-15              [-1, 128, 16]               0
           Conv1d-16              [-1, 256, 16]           2,304
  MyConv1dPadSame-17              [-1, 256, 16]               0
      BatchNorm1d-18              [-1, 256, 16]             512
             ReLU-19              [-1, 256, 16]               0
          Dropout-20              [-1, 256, 16]               0
           Conv1d-21              [-1, 256, 16]           4,352
  MyConv1dPadSame-22              [-1, 256, 16]               0
       Bottleneck-23              [-1, 256, 16]               0
      BatchNorm1d-24              [-1, 256, 16]             512
             ReLU-25              [-1, 256, 16]               0
           Linear-26                    [-1, 2]             514
================================================================
Total params: 12,418
Trainable params: 12,418
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.55
Params size (MB): 0.05
Estimated Total Size (MB): 0.59
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 128, kernel_size: 8, n_block: 4
************************************************************
************************************************************
(2000, 1, 16) Counter({0: 1000, 1: 1000})
(2000, 1, 16) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 128, 16]           1,152
   MyConv1dPadSame-2              [-1, 128, 16]               0
       BatchNorm1d-3              [-1, 128, 16]             256
              ReLU-4              [-1, 128, 16]               0
            Conv1d-5              [-1, 128, 16]           1,152
   MyConv1dPadSame-6              [-1, 128, 16]               0
       BatchNorm1d-7              [-1, 128, 16]             256
              ReLU-8              [-1, 128, 16]               0
           Dropout-9              [-1, 128, 16]               0
           Conv1d-10              [-1, 128, 16]           1,152
  MyConv1dPadSame-11              [-1, 128, 16]               0
       Bottleneck-12              [-1, 128, 16]               0
      BatchNorm1d-13              [-1, 128, 16]             256
             ReLU-14              [-1, 128, 16]               0
          Dropout-15              [-1, 128, 16]               0
           Conv1d-16              [-1, 256, 16]           2,304
  MyConv1dPadSame-17              [-1, 256, 16]               0
      BatchNorm1d-18              [-1, 256, 16]             512
             ReLU-19              [-1, 256, 16]               0
          Dropout-20              [-1, 256, 16]               0
           Conv1d-21              [-1, 256, 16]           4,352
  MyConv1dPadSame-22              [-1, 256, 16]               0
       Bottleneck-23              [-1, 256, 16]               0
      BatchNorm1d-24              [-1, 256, 16]             512
             ReLU-25              [-1, 256, 16]               0
          Dropout-26              [-1, 256, 16]               0
           Conv1d-27              [-1, 512, 16]           8,704
  MyConv1dPadSame-28              [-1, 512, 16]               0
      BatchNorm1d-29              [-1, 512, 16]           1,024
             ReLU-30              [-1, 512, 16]               0
          Dropout-31              [-1, 512, 16]               0
           Conv1d-32              [-1, 512, 16]          16,896
  MyConv1dPadSame-33              [-1, 512, 16]               0
       Bottleneck-34              [-1, 512, 16]               0
      BatchNorm1d-35              [-1, 512, 16]           1,024
             ReLU-36              [-1, 512, 16]               0
          Dropout-37              [-1, 512, 16]               0
           Conv1d-38             [-1, 1024, 16]          33,792
  MyConv1dPadSame-39             [-1, 1024, 16]               0
      BatchNorm1d-40             [-1, 1024, 16]           2,048
             ReLU-41             [-1, 1024, 16]               0
          Dropout-42             [-1, 1024, 16]               0
           Conv1d-43             [-1, 1024, 16]          66,560
  MyConv1dPadSame-44             [-1, 1024, 16]               0
       Bottleneck-45             [-1, 1024, 16]               0
      BatchNorm1d-46             [-1, 1024, 16]           2,048
             ReLU-47             [-1, 1024, 16]               0
           Linear-48                    [-1, 2]           2,050
================================================================
Total params: 146,050
Trainable params: 146,050
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 2.52
Params size (MB): 0.56
Estimated Total Size (MB): 3.07
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 128, kernel_size: 8, n_block: 8
************************************************************
************************************************************
(2000, 1, 16) Counter({0: 1000, 1: 1000})
(2000, 1, 16) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 128, 16]           1,152
   MyConv1dPadSame-2              [-1, 128, 16]               0
       BatchNorm1d-3              [-1, 128, 16]             256
              ReLU-4              [-1, 128, 16]               0
            Conv1d-5              [-1, 128, 16]           1,152
   MyConv1dPadSame-6              [-1, 128, 16]               0
       BatchNorm1d-7              [-1, 128, 16]             256
              ReLU-8              [-1, 128, 16]               0
           Dropout-9              [-1, 128, 16]               0
           Conv1d-10              [-1, 128, 16]           1,152
  MyConv1dPadSame-11              [-1, 128, 16]               0
       Bottleneck-12              [-1, 128, 16]               0
      BatchNorm1d-13              [-1, 128, 16]             256
             ReLU-14              [-1, 128, 16]               0
          Dropout-15              [-1, 128, 16]               0
           Conv1d-16              [-1, 128, 16]           1,152
  MyConv1dPadSame-17              [-1, 128, 16]               0
      BatchNorm1d-18              [-1, 128, 16]             256
             ReLU-19              [-1, 128, 16]               0
          Dropout-20              [-1, 128, 16]               0
           Conv1d-21              [-1, 128, 16]           1,152
  MyConv1dPadSame-22              [-1, 128, 16]               0
       Bottleneck-23              [-1, 128, 16]               0
      BatchNorm1d-24              [-1, 128, 16]             256
             ReLU-25              [-1, 128, 16]               0
          Dropout-26              [-1, 128, 16]               0
           Conv1d-27              [-1, 256, 16]           2,304
  MyConv1dPadSame-28              [-1, 256, 16]               0
      BatchNorm1d-29              [-1, 256, 16]             512
             ReLU-30              [-1, 256, 16]               0
          Dropout-31              [-1, 256, 16]               0
           Conv1d-32              [-1, 256, 16]           4,352
  MyConv1dPadSame-33              [-1, 256, 16]               0
       Bottleneck-34              [-1, 256, 16]               0
      BatchNorm1d-35              [-1, 256, 16]             512
             ReLU-36              [-1, 256, 16]               0
          Dropout-37              [-1, 256, 16]               0
           Conv1d-38              [-1, 256, 16]           4,352
  MyConv1dPadSame-39              [-1, 256, 16]               0
      BatchNorm1d-40              [-1, 256, 16]             512
             ReLU-41              [-1, 256, 16]               0
          Dropout-42              [-1, 256, 16]               0
           Conv1d-43              [-1, 256, 16]           4,352
  MyConv1dPadSame-44              [-1, 256, 16]               0
       Bottleneck-45              [-1, 256, 16]               0
      BatchNorm1d-46              [-1, 256, 16]             512
             ReLU-47              [-1, 256, 16]               0
          Dropout-48              [-1, 256, 16]               0
           Conv1d-49              [-1, 512, 16]           8,704
  MyConv1dPadSame-50              [-1, 512, 16]               0
      BatchNorm1d-51              [-1, 512, 16]           1,024
             ReLU-52              [-1, 512, 16]               0
          Dropout-53              [-1, 512, 16]               0
           Conv1d-54              [-1, 512, 16]          16,896
  MyConv1dPadSame-55              [-1, 512, 16]               0
       Bottleneck-56              [-1, 512, 16]               0
      BatchNorm1d-57              [-1, 512, 16]           1,024
             ReLU-58              [-1, 512, 16]               0
          Dropout-59              [-1, 512, 16]               0
           Conv1d-60              [-1, 512, 16]          16,896
  MyConv1dPadSame-61              [-1, 512, 16]               0
      BatchNorm1d-62              [-1, 512, 16]           1,024
             ReLU-63              [-1, 512, 16]               0
          Dropout-64              [-1, 512, 16]               0
           Conv1d-65              [-1, 512, 16]          16,896
  MyConv1dPadSame-66              [-1, 512, 16]               0
       Bottleneck-67              [-1, 512, 16]               0
      BatchNorm1d-68              [-1, 512, 16]           1,024
             ReLU-69              [-1, 512, 16]               0
          Dropout-70              [-1, 512, 16]               0
           Conv1d-71             [-1, 1024, 16]          33,792
  MyConv1dPadSame-72             [-1, 1024, 16]               0
      BatchNorm1d-73             [-1, 1024, 16]           2,048
             ReLU-74             [-1, 1024, 16]               0
          Dropout-75             [-1, 1024, 16]               0
           Conv1d-76             [-1, 1024, 16]          66,560
  MyConv1dPadSame-77             [-1, 1024, 16]               0
       Bottleneck-78             [-1, 1024, 16]               0
      BatchNorm1d-79             [-1, 1024, 16]           2,048
             ReLU-80             [-1, 1024, 16]               0
          Dropout-81             [-1, 1024, 16]               0
           Conv1d-82             [-1, 1024, 16]          66,560
  MyConv1dPadSame-83             [-1, 1024, 16]               0
      BatchNorm1d-84             [-1, 1024, 16]           2,048
             ReLU-85             [-1, 1024, 16]               0
          Dropout-86             [-1, 1024, 16]               0
           Conv1d-87             [-1, 1024, 16]          66,560
  MyConv1dPadSame-88             [-1, 1024, 16]               0
       Bottleneck-89             [-1, 1024, 16]               0
      BatchNorm1d-90             [-1, 1024, 16]           2,048
             ReLU-91             [-1, 1024, 16]               0
           Linear-92                    [-1, 2]           2,050
================================================================
Total params: 331,650
Trainable params: 331,650
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 5.09
Params size (MB): 1.27
Estimated Total Size (MB): 6.36
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 128, kernel_size: 8, n_block: 16
************************************************************
************************************************************
(2000, 1, 16) Counter({1: 1000, 0: 1000})
(2000, 1, 16) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 128, 16]           1,152
   MyConv1dPadSame-2              [-1, 128, 16]               0
       BatchNorm1d-3              [-1, 128, 16]             256
              ReLU-4              [-1, 128, 16]               0
            Conv1d-5              [-1, 128, 16]           1,152
   MyConv1dPadSame-6              [-1, 128, 16]               0
       BatchNorm1d-7              [-1, 128, 16]             256
              ReLU-8              [-1, 128, 16]               0
           Dropout-9              [-1, 128, 16]               0
           Conv1d-10              [-1, 128, 16]           1,152
  MyConv1dPadSame-11              [-1, 128, 16]               0
       Bottleneck-12              [-1, 128, 16]               0
      BatchNorm1d-13              [-1, 128, 16]             256
             ReLU-14              [-1, 128, 16]               0
          Dropout-15              [-1, 128, 16]               0
           Conv1d-16               [-1, 128, 8]           1,152
  MyConv1dPadSame-17               [-1, 128, 8]               0
      BatchNorm1d-18               [-1, 128, 8]             256
             ReLU-19               [-1, 128, 8]               0
          Dropout-20               [-1, 128, 8]               0
           Conv1d-21               [-1, 128, 8]           1,152
  MyConv1dPadSame-22               [-1, 128, 8]               0
        MaxPool1d-23               [-1, 128, 8]               0
MyMaxPool1dPadSame-24               [-1, 128, 8]               0
       Bottleneck-25               [-1, 128, 8]               0
      BatchNorm1d-26               [-1, 128, 8]             256
             ReLU-27               [-1, 128, 8]               0
          Dropout-28               [-1, 128, 8]               0
           Conv1d-29               [-1, 128, 8]           1,152
  MyConv1dPadSame-30               [-1, 128, 8]               0
      BatchNorm1d-31               [-1, 128, 8]             256
             ReLU-32               [-1, 128, 8]               0
          Dropout-33               [-1, 128, 8]               0
           Conv1d-34               [-1, 128, 8]           1,152
  MyConv1dPadSame-35               [-1, 128, 8]               0
       Bottleneck-36               [-1, 128, 8]               0
      BatchNorm1d-37               [-1, 128, 8]             256
             ReLU-38               [-1, 128, 8]               0
          Dropout-39               [-1, 128, 8]               0
           Conv1d-40               [-1, 128, 4]           1,152
  MyConv1dPadSame-41               [-1, 128, 4]               0
      BatchNorm1d-42               [-1, 128, 4]             256
             ReLU-43               [-1, 128, 4]               0
          Dropout-44               [-1, 128, 4]               0
           Conv1d-45               [-1, 128, 4]           1,152
  MyConv1dPadSame-46               [-1, 128, 4]               0
        MaxPool1d-47               [-1, 128, 4]               0
MyMaxPool1dPadSame-48               [-1, 128, 4]               0
       Bottleneck-49               [-1, 128, 4]               0
      BatchNorm1d-50               [-1, 128, 4]             256
             ReLU-51               [-1, 128, 4]               0
          Dropout-52               [-1, 128, 4]               0
           Conv1d-53               [-1, 256, 4]           2,304
  MyConv1dPadSame-54               [-1, 256, 4]               0
      BatchNorm1d-55               [-1, 256, 4]             512
             ReLU-56               [-1, 256, 4]               0
          Dropout-57               [-1, 256, 4]               0
           Conv1d-58               [-1, 256, 4]           4,352
  MyConv1dPadSame-59               [-1, 256, 4]               0
       Bottleneck-60               [-1, 256, 4]               0
      BatchNorm1d-61               [-1, 256, 4]             512
             ReLU-62               [-1, 256, 4]               0
          Dropout-63               [-1, 256, 4]               0
           Conv1d-64               [-1, 256, 2]           4,352
  MyConv1dPadSame-65               [-1, 256, 2]               0
      BatchNorm1d-66               [-1, 256, 2]             512
             ReLU-67               [-1, 256, 2]               0
          Dropout-68               [-1, 256, 2]               0
           Conv1d-69               [-1, 256, 2]           4,352
  MyConv1dPadSame-70               [-1, 256, 2]               0
        MaxPool1d-71               [-1, 256, 2]               0
MyMaxPool1dPadSame-72               [-1, 256, 2]               0
       Bottleneck-73               [-1, 256, 2]               0
      BatchNorm1d-74               [-1, 256, 2]             512
             ReLU-75               [-1, 256, 2]               0
          Dropout-76               [-1, 256, 2]               0
           Conv1d-77               [-1, 256, 2]           4,352
  MyConv1dPadSame-78               [-1, 256, 2]               0
      BatchNorm1d-79               [-1, 256, 2]             512
             ReLU-80               [-1, 256, 2]               0
          Dropout-81               [-1, 256, 2]               0
           Conv1d-82               [-1, 256, 2]           4,352
  MyConv1dPadSame-83               [-1, 256, 2]               0
       Bottleneck-84               [-1, 256, 2]               0
      BatchNorm1d-85               [-1, 256, 2]             512
             ReLU-86               [-1, 256, 2]               0
          Dropout-87               [-1, 256, 2]               0
           Conv1d-88               [-1, 256, 1]           4,352
  MyConv1dPadSame-89               [-1, 256, 1]               0
      BatchNorm1d-90               [-1, 256, 1]             512
             ReLU-91               [-1, 256, 1]               0
          Dropout-92               [-1, 256, 1]               0
           Conv1d-93               [-1, 256, 1]           4,352
  MyConv1dPadSame-94               [-1, 256, 1]               0
        MaxPool1d-95               [-1, 256, 1]               0
MyMaxPool1dPadSame-96               [-1, 256, 1]               0
       Bottleneck-97               [-1, 256, 1]               0
      BatchNorm1d-98               [-1, 256, 1]             512
             ReLU-99               [-1, 256, 1]               0
         Dropout-100               [-1, 256, 1]               0
          Conv1d-101               [-1, 512, 1]           8,704
 MyConv1dPadSame-102               [-1, 512, 1]               0
     BatchNorm1d-103               [-1, 512, 1]           1,024
            ReLU-104               [-1, 512, 1]               0
         Dropout-105               [-1, 512, 1]               0
          Conv1d-106               [-1, 512, 1]          16,896
 MyConv1dPadSame-107               [-1, 512, 1]               0
      Bottleneck-108               [-1, 512, 1]               0
     BatchNorm1d-109               [-1, 512, 1]           1,024
            ReLU-110               [-1, 512, 1]               0
         Dropout-111               [-1, 512, 1]               0
          Conv1d-112               [-1, 512, 1]          16,896
 MyConv1dPadSame-113               [-1, 512, 1]               0
     BatchNorm1d-114               [-1, 512, 1]           1,024
            ReLU-115               [-1, 512, 1]               0
         Dropout-116               [-1, 512, 1]               0
          Conv1d-117               [-1, 512, 1]          16,896
 MyConv1dPadSame-118               [-1, 512, 1]               0
       MaxPool1d-119               [-1, 512, 1]               0
MyMaxPool1dPadSame-120               [-1, 512, 1]               0
      Bottleneck-121               [-1, 512, 1]               0
     BatchNorm1d-122               [-1, 512, 1]           1,024
            ReLU-123               [-1, 512, 1]               0
         Dropout-124               [-1, 512, 1]               0
          Conv1d-125               [-1, 512, 1]          16,896
 MyConv1dPadSame-126               [-1, 512, 1]               0
     BatchNorm1d-127               [-1, 512, 1]           1,024
            ReLU-128               [-1, 512, 1]               0
         Dropout-129               [-1, 512, 1]               0
          Conv1d-130               [-1, 512, 1]          16,896
 MyConv1dPadSame-131               [-1, 512, 1]               0
      Bottleneck-132               [-1, 512, 1]               0
     BatchNorm1d-133               [-1, 512, 1]           1,024
            ReLU-134               [-1, 512, 1]               0
         Dropout-135               [-1, 512, 1]               0
          Conv1d-136               [-1, 512, 1]          16,896
 MyConv1dPadSame-137               [-1, 512, 1]               0
     BatchNorm1d-138               [-1, 512, 1]           1,024
            ReLU-139               [-1, 512, 1]               0
         Dropout-140               [-1, 512, 1]               0
          Conv1d-141               [-1, 512, 1]          16,896
 MyConv1dPadSame-142               [-1, 512, 1]               0
       MaxPool1d-143               [-1, 512, 1]               0
MyMaxPool1dPadSame-144               [-1, 512, 1]               0
      Bottleneck-145               [-1, 512, 1]               0
     BatchNorm1d-146               [-1, 512, 1]           1,024
            ReLU-147               [-1, 512, 1]               0
         Dropout-148               [-1, 512, 1]               0
          Conv1d-149              [-1, 1024, 1]          33,792
 MyConv1dPadSame-150              [-1, 1024, 1]               0
     BatchNorm1d-151              [-1, 1024, 1]           2,048
            ReLU-152              [-1, 1024, 1]               0
         Dropout-153              [-1, 1024, 1]               0
          Conv1d-154              [-1, 1024, 1]          66,560
 MyConv1dPadSame-155              [-1, 1024, 1]               0
      Bottleneck-156              [-1, 1024, 1]               0
     BatchNorm1d-157              [-1, 1024, 1]           2,048
            ReLU-158              [-1, 1024, 1]               0
         Dropout-159              [-1, 1024, 1]               0
          Conv1d-160              [-1, 1024, 1]          66,560
 MyConv1dPadSame-161              [-1, 1024, 1]               0
     BatchNorm1d-162              [-1, 1024, 1]           2,048
            ReLU-163              [-1, 1024, 1]               0
         Dropout-164              [-1, 1024, 1]               0
          Conv1d-165              [-1, 1024, 1]          66,560
 MyConv1dPadSame-166              [-1, 1024, 1]               0
       MaxPool1d-167              [-1, 1024, 1]               0
MyMaxPool1dPadSame-168              [-1, 1024, 1]               0
      Bottleneck-169              [-1, 1024, 1]               0
     BatchNorm1d-170              [-1, 1024, 1]           2,048
            ReLU-171              [-1, 1024, 1]               0
         Dropout-172              [-1, 1024, 1]               0
          Conv1d-173              [-1, 1024, 1]          66,560
 MyConv1dPadSame-174              [-1, 1024, 1]               0
     BatchNorm1d-175              [-1, 1024, 1]           2,048
            ReLU-176              [-1, 1024, 1]               0
         Dropout-177              [-1, 1024, 1]               0
          Conv1d-178              [-1, 1024, 1]          66,560
 MyConv1dPadSame-179              [-1, 1024, 1]               0
      Bottleneck-180              [-1, 1024, 1]               0
     BatchNorm1d-181              [-1, 1024, 1]           2,048
            ReLU-182              [-1, 1024, 1]               0
         Dropout-183              [-1, 1024, 1]               0
          Conv1d-184              [-1, 1024, 1]          66,560
 MyConv1dPadSame-185              [-1, 1024, 1]               0
     BatchNorm1d-186              [-1, 1024, 1]           2,048
            ReLU-187              [-1, 1024, 1]               0
         Dropout-188              [-1, 1024, 1]               0
          Conv1d-189              [-1, 1024, 1]          66,560
 MyConv1dPadSame-190              [-1, 1024, 1]               0
       MaxPool1d-191              [-1, 1024, 1]               0
MyMaxPool1dPadSame-192              [-1, 1024, 1]               0
      Bottleneck-193              [-1, 1024, 1]               0
     BatchNorm1d-194              [-1, 1024, 1]           2,048
            ReLU-195              [-1, 1024, 1]               0
          Linear-196                    [-1, 2]           2,050
================================================================
Total params: 702,850
Trainable params: 702,850
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 1.23
Params size (MB): 2.68
Estimated Total Size (MB): 3.91
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 128, kernel_size: 16, n_block: 2
************************************************************
************************************************************
(2000, 1, 16) Counter({0: 1000, 1: 1000})
(2000, 1, 16) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 128, 16]           2,176
   MyConv1dPadSame-2              [-1, 128, 16]               0
       BatchNorm1d-3              [-1, 128, 16]             256
              ReLU-4              [-1, 128, 16]               0
            Conv1d-5              [-1, 128, 16]           2,176
   MyConv1dPadSame-6              [-1, 128, 16]               0
       BatchNorm1d-7              [-1, 128, 16]             256
              ReLU-8              [-1, 128, 16]               0
           Dropout-9              [-1, 128, 16]               0
           Conv1d-10              [-1, 128, 16]           2,176
  MyConv1dPadSame-11              [-1, 128, 16]               0
       Bottleneck-12              [-1, 128, 16]               0
      BatchNorm1d-13              [-1, 128, 16]             256
             ReLU-14              [-1, 128, 16]               0
          Dropout-15              [-1, 128, 16]               0
           Conv1d-16              [-1, 256, 16]           4,352
  MyConv1dPadSame-17              [-1, 256, 16]               0
      BatchNorm1d-18              [-1, 256, 16]             512
             ReLU-19              [-1, 256, 16]               0
          Dropout-20              [-1, 256, 16]               0
           Conv1d-21              [-1, 256, 16]           8,448
  MyConv1dPadSame-22              [-1, 256, 16]               0
       Bottleneck-23              [-1, 256, 16]               0
      BatchNorm1d-24              [-1, 256, 16]             512
             ReLU-25              [-1, 256, 16]               0
           Linear-26                    [-1, 2]             514
================================================================
Total params: 21,634
Trainable params: 21,634
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.55
Params size (MB): 0.08
Estimated Total Size (MB): 0.63
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 128, kernel_size: 16, n_block: 4
************************************************************
************************************************************
(2000, 1, 16) Counter({1: 1000, 0: 1000})
(2000, 1, 16) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 128, 16]           2,176
   MyConv1dPadSame-2              [-1, 128, 16]               0
       BatchNorm1d-3              [-1, 128, 16]             256
              ReLU-4              [-1, 128, 16]               0
            Conv1d-5              [-1, 128, 16]           2,176
   MyConv1dPadSame-6              [-1, 128, 16]               0
       BatchNorm1d-7              [-1, 128, 16]             256
              ReLU-8              [-1, 128, 16]               0
           Dropout-9              [-1, 128, 16]               0
           Conv1d-10              [-1, 128, 16]           2,176
  MyConv1dPadSame-11              [-1, 128, 16]               0
       Bottleneck-12              [-1, 128, 16]               0
      BatchNorm1d-13              [-1, 128, 16]             256
             ReLU-14              [-1, 128, 16]               0
          Dropout-15              [-1, 128, 16]               0
           Conv1d-16              [-1, 256, 16]           4,352
  MyConv1dPadSame-17              [-1, 256, 16]               0
      BatchNorm1d-18              [-1, 256, 16]             512
             ReLU-19              [-1, 256, 16]               0
          Dropout-20              [-1, 256, 16]               0
           Conv1d-21              [-1, 256, 16]           8,448
  MyConv1dPadSame-22              [-1, 256, 16]               0
       Bottleneck-23              [-1, 256, 16]               0
      BatchNorm1d-24              [-1, 256, 16]             512
             ReLU-25              [-1, 256, 16]               0
          Dropout-26              [-1, 256, 16]               0
           Conv1d-27              [-1, 512, 16]          16,896
  MyConv1dPadSame-28              [-1, 512, 16]               0
      BatchNorm1d-29              [-1, 512, 16]           1,024
             ReLU-30              [-1, 512, 16]               0
          Dropout-31              [-1, 512, 16]               0
           Conv1d-32              [-1, 512, 16]          33,280
  MyConv1dPadSame-33              [-1, 512, 16]               0
       Bottleneck-34              [-1, 512, 16]               0
      BatchNorm1d-35              [-1, 512, 16]           1,024
             ReLU-36              [-1, 512, 16]               0
          Dropout-37              [-1, 512, 16]               0
           Conv1d-38             [-1, 1024, 16]          66,560
  MyConv1dPadSame-39             [-1, 1024, 16]               0
      BatchNorm1d-40             [-1, 1024, 16]           2,048
             ReLU-41             [-1, 1024, 16]               0
          Dropout-42             [-1, 1024, 16]               0
           Conv1d-43             [-1, 1024, 16]         132,096
  MyConv1dPadSame-44             [-1, 1024, 16]               0
       Bottleneck-45             [-1, 1024, 16]               0
      BatchNorm1d-46             [-1, 1024, 16]           2,048
             ReLU-47             [-1, 1024, 16]               0
           Linear-48                    [-1, 2]           2,050
================================================================
Total params: 278,146
Trainable params: 278,146
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 2.52
Params size (MB): 1.06
Estimated Total Size (MB): 3.58
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 128, kernel_size: 16, n_block: 8
************************************************************
************************************************************
(2000, 1, 16) Counter({1: 1000, 0: 1000})
(2000, 1, 16) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 128, 16]           2,176
   MyConv1dPadSame-2              [-1, 128, 16]               0
       BatchNorm1d-3              [-1, 128, 16]             256
              ReLU-4              [-1, 128, 16]               0
            Conv1d-5              [-1, 128, 16]           2,176
   MyConv1dPadSame-6              [-1, 128, 16]               0
       BatchNorm1d-7              [-1, 128, 16]             256
              ReLU-8              [-1, 128, 16]               0
           Dropout-9              [-1, 128, 16]               0
           Conv1d-10              [-1, 128, 16]           2,176
  MyConv1dPadSame-11              [-1, 128, 16]               0
       Bottleneck-12              [-1, 128, 16]               0
      BatchNorm1d-13              [-1, 128, 16]             256
             ReLU-14              [-1, 128, 16]               0
          Dropout-15              [-1, 128, 16]               0
           Conv1d-16              [-1, 128, 16]           2,176
  MyConv1dPadSame-17              [-1, 128, 16]               0
      BatchNorm1d-18              [-1, 128, 16]             256
             ReLU-19              [-1, 128, 16]               0
          Dropout-20              [-1, 128, 16]               0
           Conv1d-21              [-1, 128, 16]           2,176
  MyConv1dPadSame-22              [-1, 128, 16]               0
       Bottleneck-23              [-1, 128, 16]               0
      BatchNorm1d-24              [-1, 128, 16]             256
             ReLU-25              [-1, 128, 16]               0
          Dropout-26              [-1, 128, 16]               0
           Conv1d-27              [-1, 256, 16]           4,352
  MyConv1dPadSame-28              [-1, 256, 16]               0
      BatchNorm1d-29              [-1, 256, 16]             512
             ReLU-30              [-1, 256, 16]               0
          Dropout-31              [-1, 256, 16]               0
           Conv1d-32              [-1, 256, 16]           8,448
  MyConv1dPadSame-33              [-1, 256, 16]               0
       Bottleneck-34              [-1, 256, 16]               0
      BatchNorm1d-35              [-1, 256, 16]             512
             ReLU-36              [-1, 256, 16]               0
          Dropout-37              [-1, 256, 16]               0
           Conv1d-38              [-1, 256, 16]           8,448
  MyConv1dPadSame-39              [-1, 256, 16]               0
      BatchNorm1d-40              [-1, 256, 16]             512
             ReLU-41              [-1, 256, 16]               0
          Dropout-42              [-1, 256, 16]               0
           Conv1d-43              [-1, 256, 16]           8,448
  MyConv1dPadSame-44              [-1, 256, 16]               0
       Bottleneck-45              [-1, 256, 16]               0
      BatchNorm1d-46              [-1, 256, 16]             512
             ReLU-47              [-1, 256, 16]               0
          Dropout-48              [-1, 256, 16]               0
           Conv1d-49              [-1, 512, 16]          16,896
  MyConv1dPadSame-50              [-1, 512, 16]               0
      BatchNorm1d-51              [-1, 512, 16]           1,024
             ReLU-52              [-1, 512, 16]               0
          Dropout-53              [-1, 512, 16]               0
           Conv1d-54              [-1, 512, 16]          33,280
  MyConv1dPadSame-55              [-1, 512, 16]               0
       Bottleneck-56              [-1, 512, 16]               0
      BatchNorm1d-57              [-1, 512, 16]           1,024
             ReLU-58              [-1, 512, 16]               0
          Dropout-59              [-1, 512, 16]               0
           Conv1d-60              [-1, 512, 16]          33,280
  MyConv1dPadSame-61              [-1, 512, 16]               0
      BatchNorm1d-62              [-1, 512, 16]           1,024
             ReLU-63              [-1, 512, 16]               0
          Dropout-64              [-1, 512, 16]               0
           Conv1d-65              [-1, 512, 16]          33,280
  MyConv1dPadSame-66              [-1, 512, 16]               0
       Bottleneck-67              [-1, 512, 16]               0
      BatchNorm1d-68              [-1, 512, 16]           1,024
             ReLU-69              [-1, 512, 16]               0
          Dropout-70              [-1, 512, 16]               0
           Conv1d-71             [-1, 1024, 16]          66,560
  MyConv1dPadSame-72             [-1, 1024, 16]               0
      BatchNorm1d-73             [-1, 1024, 16]           2,048
             ReLU-74             [-1, 1024, 16]               0
          Dropout-75             [-1, 1024, 16]               0
           Conv1d-76             [-1, 1024, 16]         132,096
  MyConv1dPadSame-77             [-1, 1024, 16]               0
       Bottleneck-78             [-1, 1024, 16]               0
      BatchNorm1d-79             [-1, 1024, 16]           2,048
             ReLU-80             [-1, 1024, 16]               0
          Dropout-81             [-1, 1024, 16]               0
           Conv1d-82             [-1, 1024, 16]         132,096
  MyConv1dPadSame-83             [-1, 1024, 16]               0
      BatchNorm1d-84             [-1, 1024, 16]           2,048
             ReLU-85             [-1, 1024, 16]               0
          Dropout-86             [-1, 1024, 16]               0
           Conv1d-87             [-1, 1024, 16]         132,096
  MyConv1dPadSame-88             [-1, 1024, 16]               0
       Bottleneck-89             [-1, 1024, 16]               0
      BatchNorm1d-90             [-1, 1024, 16]           2,048
             ReLU-91             [-1, 1024, 16]               0
           Linear-92                    [-1, 2]           2,050
================================================================
Total params: 637,826
Trainable params: 637,826
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 5.09
Params size (MB): 2.43
Estimated Total Size (MB): 7.53
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 16, base_filters: 128, kernel_size: 16, n_block: 16
************************************************************
************************************************************
(2000, 1, 16) Counter({1: 1000, 0: 1000})
(2000, 1, 16) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 128, 16]           2,176
   MyConv1dPadSame-2              [-1, 128, 16]               0
       BatchNorm1d-3              [-1, 128, 16]             256
              ReLU-4              [-1, 128, 16]               0
            Conv1d-5              [-1, 128, 16]           2,176
   MyConv1dPadSame-6              [-1, 128, 16]               0
       BatchNorm1d-7              [-1, 128, 16]             256
              ReLU-8              [-1, 128, 16]               0
           Dropout-9              [-1, 128, 16]               0
           Conv1d-10              [-1, 128, 16]           2,176
  MyConv1dPadSame-11              [-1, 128, 16]               0
       Bottleneck-12              [-1, 128, 16]               0
      BatchNorm1d-13              [-1, 128, 16]             256
             ReLU-14              [-1, 128, 16]               0
          Dropout-15              [-1, 128, 16]               0
           Conv1d-16               [-1, 128, 8]           2,176
  MyConv1dPadSame-17               [-1, 128, 8]               0
      BatchNorm1d-18               [-1, 128, 8]             256
             ReLU-19               [-1, 128, 8]               0
          Dropout-20               [-1, 128, 8]               0
           Conv1d-21               [-1, 128, 8]           2,176
  MyConv1dPadSame-22               [-1, 128, 8]               0
        MaxPool1d-23               [-1, 128, 8]               0
MyMaxPool1dPadSame-24               [-1, 128, 8]               0
       Bottleneck-25               [-1, 128, 8]               0
      BatchNorm1d-26               [-1, 128, 8]             256
             ReLU-27               [-1, 128, 8]               0
          Dropout-28               [-1, 128, 8]               0
           Conv1d-29               [-1, 128, 8]           2,176
  MyConv1dPadSame-30               [-1, 128, 8]               0
      BatchNorm1d-31               [-1, 128, 8]             256
             ReLU-32               [-1, 128, 8]               0
          Dropout-33               [-1, 128, 8]               0
           Conv1d-34               [-1, 128, 8]           2,176
  MyConv1dPadSame-35               [-1, 128, 8]               0
       Bottleneck-36               [-1, 128, 8]               0
      BatchNorm1d-37               [-1, 128, 8]             256
             ReLU-38               [-1, 128, 8]               0
          Dropout-39               [-1, 128, 8]               0
           Conv1d-40               [-1, 128, 4]           2,176
  MyConv1dPadSame-41               [-1, 128, 4]               0
      BatchNorm1d-42               [-1, 128, 4]             256
             ReLU-43               [-1, 128, 4]               0
          Dropout-44               [-1, 128, 4]               0
           Conv1d-45               [-1, 128, 4]           2,176
  MyConv1dPadSame-46               [-1, 128, 4]               0
        MaxPool1d-47               [-1, 128, 4]               0
MyMaxPool1dPadSame-48               [-1, 128, 4]               0
       Bottleneck-49               [-1, 128, 4]               0
      BatchNorm1d-50               [-1, 128, 4]             256
             ReLU-51               [-1, 128, 4]               0
          Dropout-52               [-1, 128, 4]               0
           Conv1d-53               [-1, 256, 4]           4,352
  MyConv1dPadSame-54               [-1, 256, 4]               0
      BatchNorm1d-55               [-1, 256, 4]             512
             ReLU-56               [-1, 256, 4]               0
          Dropout-57               [-1, 256, 4]               0
           Conv1d-58               [-1, 256, 4]           8,448
  MyConv1dPadSame-59               [-1, 256, 4]               0
       Bottleneck-60               [-1, 256, 4]               0
      BatchNorm1d-61               [-1, 256, 4]             512
             ReLU-62               [-1, 256, 4]               0
          Dropout-63               [-1, 256, 4]               0
           Conv1d-64               [-1, 256, 2]           8,448
  MyConv1dPadSame-65               [-1, 256, 2]               0
      BatchNorm1d-66               [-1, 256, 2]             512
             ReLU-67               [-1, 256, 2]               0
          Dropout-68               [-1, 256, 2]               0
           Conv1d-69               [-1, 256, 2]           8,448
  MyConv1dPadSame-70               [-1, 256, 2]               0
        MaxPool1d-71               [-1, 256, 2]               0
MyMaxPool1dPadSame-72               [-1, 256, 2]               0
       Bottleneck-73               [-1, 256, 2]               0
      BatchNorm1d-74               [-1, 256, 2]             512
             ReLU-75               [-1, 256, 2]               0
          Dropout-76               [-1, 256, 2]               0
           Conv1d-77               [-1, 256, 2]           8,448
  MyConv1dPadSame-78               [-1, 256, 2]               0
      BatchNorm1d-79               [-1, 256, 2]             512
             ReLU-80               [-1, 256, 2]               0
          Dropout-81               [-1, 256, 2]               0
           Conv1d-82               [-1, 256, 2]           8,448
  MyConv1dPadSame-83               [-1, 256, 2]               0
       Bottleneck-84               [-1, 256, 2]               0
      BatchNorm1d-85               [-1, 256, 2]             512
             ReLU-86               [-1, 256, 2]               0
          Dropout-87               [-1, 256, 2]               0
           Conv1d-88               [-1, 256, 1]           8,448
  MyConv1dPadSame-89               [-1, 256, 1]               0
      BatchNorm1d-90               [-1, 256, 1]             512
             ReLU-91               [-1, 256, 1]               0
          Dropout-92               [-1, 256, 1]               0
           Conv1d-93               [-1, 256, 1]           8,448
  MyConv1dPadSame-94               [-1, 256, 1]               0
        MaxPool1d-95               [-1, 256, 1]               0
MyMaxPool1dPadSame-96               [-1, 256, 1]               0
       Bottleneck-97               [-1, 256, 1]               0
      BatchNorm1d-98               [-1, 256, 1]             512
             ReLU-99               [-1, 256, 1]               0
         Dropout-100               [-1, 256, 1]               0
          Conv1d-101               [-1, 512, 1]          16,896
 MyConv1dPadSame-102               [-1, 512, 1]               0
     BatchNorm1d-103               [-1, 512, 1]           1,024
            ReLU-104               [-1, 512, 1]               0
         Dropout-105               [-1, 512, 1]               0
          Conv1d-106               [-1, 512, 1]          33,280
 MyConv1dPadSame-107               [-1, 512, 1]               0
      Bottleneck-108               [-1, 512, 1]               0
     BatchNorm1d-109               [-1, 512, 1]           1,024
            ReLU-110               [-1, 512, 1]               0
         Dropout-111               [-1, 512, 1]               0
          Conv1d-112               [-1, 512, 1]          33,280
 MyConv1dPadSame-113               [-1, 512, 1]               0
     BatchNorm1d-114               [-1, 512, 1]           1,024
            ReLU-115               [-1, 512, 1]               0
         Dropout-116               [-1, 512, 1]               0
          Conv1d-117               [-1, 512, 1]          33,280
 MyConv1dPadSame-118               [-1, 512, 1]               0
       MaxPool1d-119               [-1, 512, 1]               0
MyMaxPool1dPadSame-120               [-1, 512, 1]               0
      Bottleneck-121               [-1, 512, 1]               0
     BatchNorm1d-122               [-1, 512, 1]           1,024
            ReLU-123               [-1, 512, 1]               0
         Dropout-124               [-1, 512, 1]               0
          Conv1d-125               [-1, 512, 1]          33,280
 MyConv1dPadSame-126               [-1, 512, 1]               0
     BatchNorm1d-127               [-1, 512, 1]           1,024
            ReLU-128               [-1, 512, 1]               0
         Dropout-129               [-1, 512, 1]               0
          Conv1d-130               [-1, 512, 1]          33,280
 MyConv1dPadSame-131               [-1, 512, 1]               0
      Bottleneck-132               [-1, 512, 1]               0
     BatchNorm1d-133               [-1, 512, 1]           1,024
            ReLU-134               [-1, 512, 1]               0
         Dropout-135               [-1, 512, 1]               0
          Conv1d-136               [-1, 512, 1]          33,280
 MyConv1dPadSame-137               [-1, 512, 1]               0
     BatchNorm1d-138               [-1, 512, 1]           1,024
            ReLU-139               [-1, 512, 1]               0
         Dropout-140               [-1, 512, 1]               0
          Conv1d-141               [-1, 512, 1]          33,280
 MyConv1dPadSame-142               [-1, 512, 1]               0
       MaxPool1d-143               [-1, 512, 1]               0
MyMaxPool1dPadSame-144               [-1, 512, 1]               0
      Bottleneck-145               [-1, 512, 1]               0
     BatchNorm1d-146               [-1, 512, 1]           1,024
            ReLU-147               [-1, 512, 1]               0
         Dropout-148               [-1, 512, 1]               0
          Conv1d-149              [-1, 1024, 1]          66,560
 MyConv1dPadSame-150              [-1, 1024, 1]               0
     BatchNorm1d-151              [-1, 1024, 1]           2,048
            ReLU-152              [-1, 1024, 1]               0
         Dropout-153              [-1, 1024, 1]               0
          Conv1d-154              [-1, 1024, 1]         132,096
 MyConv1dPadSame-155              [-1, 1024, 1]               0
      Bottleneck-156              [-1, 1024, 1]               0
     BatchNorm1d-157              [-1, 1024, 1]           2,048
            ReLU-158              [-1, 1024, 1]               0
         Dropout-159              [-1, 1024, 1]               0
          Conv1d-160              [-1, 1024, 1]         132,096
 MyConv1dPadSame-161              [-1, 1024, 1]               0
     BatchNorm1d-162              [-1, 1024, 1]           2,048
            ReLU-163              [-1, 1024, 1]               0
         Dropout-164              [-1, 1024, 1]               0
          Conv1d-165              [-1, 1024, 1]         132,096
 MyConv1dPadSame-166              [-1, 1024, 1]               0
       MaxPool1d-167              [-1, 1024, 1]               0
MyMaxPool1dPadSame-168              [-1, 1024, 1]               0
      Bottleneck-169              [-1, 1024, 1]               0
     BatchNorm1d-170              [-1, 1024, 1]           2,048
            ReLU-171              [-1, 1024, 1]               0
         Dropout-172              [-1, 1024, 1]               0
          Conv1d-173              [-1, 1024, 1]         132,096
 MyConv1dPadSame-174              [-1, 1024, 1]               0
     BatchNorm1d-175              [-1, 1024, 1]           2,048
            ReLU-176              [-1, 1024, 1]               0
         Dropout-177              [-1, 1024, 1]               0
          Conv1d-178              [-1, 1024, 1]         132,096
 MyConv1dPadSame-179              [-1, 1024, 1]               0
      Bottleneck-180              [-1, 1024, 1]               0
     BatchNorm1d-181              [-1, 1024, 1]           2,048
            ReLU-182              [-1, 1024, 1]               0
         Dropout-183              [-1, 1024, 1]               0
          Conv1d-184              [-1, 1024, 1]         132,096
 MyConv1dPadSame-185              [-1, 1024, 1]               0
     BatchNorm1d-186              [-1, 1024, 1]           2,048
            ReLU-187              [-1, 1024, 1]               0
         Dropout-188              [-1, 1024, 1]               0
          Conv1d-189              [-1, 1024, 1]         132,096
 MyConv1dPadSame-190              [-1, 1024, 1]               0
       MaxPool1d-191              [-1, 1024, 1]               0
MyMaxPool1dPadSame-192              [-1, 1024, 1]               0
      Bottleneck-193              [-1, 1024, 1]               0
     BatchNorm1d-194              [-1, 1024, 1]           2,048
            ReLU-195              [-1, 1024, 1]               0
          Linear-196                    [-1, 2]           2,050
================================================================
Total params: 1,357,186
Trainable params: 1,357,186
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 1.23
Params size (MB): 5.18
Estimated Total Size (MB): 6.41
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 8, kernel_size: 2, n_block: 2
************************************************************
************************************************************
(2000, 1, 64) Counter({1: 1000, 0: 1000})
(2000, 1, 64) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1                [-1, 8, 64]              24
   MyConv1dPadSame-2                [-1, 8, 64]               0
       BatchNorm1d-3                [-1, 8, 64]              16
              ReLU-4                [-1, 8, 64]               0
            Conv1d-5                [-1, 8, 64]              24
   MyConv1dPadSame-6                [-1, 8, 64]               0
       BatchNorm1d-7                [-1, 8, 64]              16
              ReLU-8                [-1, 8, 64]               0
           Dropout-9                [-1, 8, 64]               0
           Conv1d-10                [-1, 8, 64]              24
  MyConv1dPadSame-11                [-1, 8, 64]               0
       Bottleneck-12                [-1, 8, 64]               0
      BatchNorm1d-13                [-1, 8, 64]              16
             ReLU-14                [-1, 8, 64]               0
          Dropout-15                [-1, 8, 64]               0
           Conv1d-16               [-1, 16, 64]              48
  MyConv1dPadSame-17               [-1, 16, 64]               0
      BatchNorm1d-18               [-1, 16, 64]              32
             ReLU-19               [-1, 16, 64]               0
          Dropout-20               [-1, 16, 64]               0
           Conv1d-21               [-1, 16, 64]              80
  MyConv1dPadSame-22               [-1, 16, 64]               0
       Bottleneck-23               [-1, 16, 64]               0
      BatchNorm1d-24               [-1, 16, 64]              32
             ReLU-25               [-1, 16, 64]               0
           Linear-26                    [-1, 2]              34
================================================================
Total params: 346
Trainable params: 346
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.14
Params size (MB): 0.00
Estimated Total Size (MB): 0.14
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 8, kernel_size: 2, n_block: 4
************************************************************
************************************************************
(2000, 1, 64) Counter({0: 1000, 1: 1000})
(2000, 1, 64) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1                [-1, 8, 64]              24
   MyConv1dPadSame-2                [-1, 8, 64]               0
       BatchNorm1d-3                [-1, 8, 64]              16
              ReLU-4                [-1, 8, 64]               0
            Conv1d-5                [-1, 8, 64]              24
   MyConv1dPadSame-6                [-1, 8, 64]               0
       BatchNorm1d-7                [-1, 8, 64]              16
              ReLU-8                [-1, 8, 64]               0
           Dropout-9                [-1, 8, 64]               0
           Conv1d-10                [-1, 8, 64]              24
  MyConv1dPadSame-11                [-1, 8, 64]               0
       Bottleneck-12                [-1, 8, 64]               0
      BatchNorm1d-13                [-1, 8, 64]              16
             ReLU-14                [-1, 8, 64]               0
          Dropout-15                [-1, 8, 64]               0
           Conv1d-16               [-1, 16, 64]              48
  MyConv1dPadSame-17               [-1, 16, 64]               0
      BatchNorm1d-18               [-1, 16, 64]              32
             ReLU-19               [-1, 16, 64]               0
          Dropout-20               [-1, 16, 64]               0
           Conv1d-21               [-1, 16, 64]              80
  MyConv1dPadSame-22               [-1, 16, 64]               0
       Bottleneck-23               [-1, 16, 64]               0
      BatchNorm1d-24               [-1, 16, 64]              32
             ReLU-25               [-1, 16, 64]               0
          Dropout-26               [-1, 16, 64]               0
           Conv1d-27               [-1, 32, 64]             160
  MyConv1dPadSame-28               [-1, 32, 64]               0
      BatchNorm1d-29               [-1, 32, 64]              64
             ReLU-30               [-1, 32, 64]               0
          Dropout-31               [-1, 32, 64]               0
           Conv1d-32               [-1, 32, 64]             288
  MyConv1dPadSame-33               [-1, 32, 64]               0
       Bottleneck-34               [-1, 32, 64]               0
      BatchNorm1d-35               [-1, 32, 64]              64
             ReLU-36               [-1, 32, 64]               0
          Dropout-37               [-1, 32, 64]               0
           Conv1d-38               [-1, 64, 64]             576
  MyConv1dPadSame-39               [-1, 64, 64]               0
      BatchNorm1d-40               [-1, 64, 64]             128
             ReLU-41               [-1, 64, 64]               0
          Dropout-42               [-1, 64, 64]               0
           Conv1d-43               [-1, 64, 64]           1,088
  MyConv1dPadSame-44               [-1, 64, 64]               0
       Bottleneck-45               [-1, 64, 64]               0
      BatchNorm1d-46               [-1, 64, 64]             128
             ReLU-47               [-1, 64, 64]               0
           Linear-48                    [-1, 2]             130
================================================================
Total params: 2,938
Trainable params: 2,938
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.63
Params size (MB): 0.01
Estimated Total Size (MB): 0.64
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 8, kernel_size: 2, n_block: 8
************************************************************
************************************************************
(2000, 1, 64) Counter({1: 1000, 0: 1000})
(2000, 1, 64) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1                [-1, 8, 64]              24
   MyConv1dPadSame-2                [-1, 8, 64]               0
       BatchNorm1d-3                [-1, 8, 64]              16
              ReLU-4                [-1, 8, 64]               0
            Conv1d-5                [-1, 8, 64]              24
   MyConv1dPadSame-6                [-1, 8, 64]               0
       BatchNorm1d-7                [-1, 8, 64]              16
              ReLU-8                [-1, 8, 64]               0
           Dropout-9                [-1, 8, 64]               0
           Conv1d-10                [-1, 8, 64]              24
  MyConv1dPadSame-11                [-1, 8, 64]               0
       Bottleneck-12                [-1, 8, 64]               0
      BatchNorm1d-13                [-1, 8, 64]              16
             ReLU-14                [-1, 8, 64]               0
          Dropout-15                [-1, 8, 64]               0
           Conv1d-16                [-1, 8, 64]              24
  MyConv1dPadSame-17                [-1, 8, 64]               0
      BatchNorm1d-18                [-1, 8, 64]              16
             ReLU-19                [-1, 8, 64]               0
          Dropout-20                [-1, 8, 64]               0
           Conv1d-21                [-1, 8, 64]              24
  MyConv1dPadSame-22                [-1, 8, 64]               0
       Bottleneck-23                [-1, 8, 64]               0
      BatchNorm1d-24                [-1, 8, 64]              16
             ReLU-25                [-1, 8, 64]               0
          Dropout-26                [-1, 8, 64]               0
           Conv1d-27               [-1, 16, 64]              48
  MyConv1dPadSame-28               [-1, 16, 64]               0
      BatchNorm1d-29               [-1, 16, 64]              32
             ReLU-30               [-1, 16, 64]               0
          Dropout-31               [-1, 16, 64]               0
           Conv1d-32               [-1, 16, 64]              80
  MyConv1dPadSame-33               [-1, 16, 64]               0
       Bottleneck-34               [-1, 16, 64]               0
      BatchNorm1d-35               [-1, 16, 64]              32
             ReLU-36               [-1, 16, 64]               0
          Dropout-37               [-1, 16, 64]               0
           Conv1d-38               [-1, 16, 64]              80
  MyConv1dPadSame-39               [-1, 16, 64]               0
      BatchNorm1d-40               [-1, 16, 64]              32
             ReLU-41               [-1, 16, 64]               0
          Dropout-42               [-1, 16, 64]               0
           Conv1d-43               [-1, 16, 64]              80
  MyConv1dPadSame-44               [-1, 16, 64]               0
       Bottleneck-45               [-1, 16, 64]               0
      BatchNorm1d-46               [-1, 16, 64]              32
             ReLU-47               [-1, 16, 64]               0
          Dropout-48               [-1, 16, 64]               0
           Conv1d-49               [-1, 32, 64]             160
  MyConv1dPadSame-50               [-1, 32, 64]               0
      BatchNorm1d-51               [-1, 32, 64]              64
             ReLU-52               [-1, 32, 64]               0
          Dropout-53               [-1, 32, 64]               0
           Conv1d-54               [-1, 32, 64]             288
  MyConv1dPadSame-55               [-1, 32, 64]               0
       Bottleneck-56               [-1, 32, 64]               0
      BatchNorm1d-57               [-1, 32, 64]              64
             ReLU-58               [-1, 32, 64]               0
          Dropout-59               [-1, 32, 64]               0
           Conv1d-60               [-1, 32, 64]             288
  MyConv1dPadSame-61               [-1, 32, 64]               0
      BatchNorm1d-62               [-1, 32, 64]              64
             ReLU-63               [-1, 32, 64]               0
          Dropout-64               [-1, 32, 64]               0
           Conv1d-65               [-1, 32, 64]             288
  MyConv1dPadSame-66               [-1, 32, 64]               0
       Bottleneck-67               [-1, 32, 64]               0
      BatchNorm1d-68               [-1, 32, 64]              64
             ReLU-69               [-1, 32, 64]               0
          Dropout-70               [-1, 32, 64]               0
           Conv1d-71               [-1, 64, 64]             576
  MyConv1dPadSame-72               [-1, 64, 64]               0
      BatchNorm1d-73               [-1, 64, 64]             128
             ReLU-74               [-1, 64, 64]               0
          Dropout-75               [-1, 64, 64]               0
           Conv1d-76               [-1, 64, 64]           1,088
  MyConv1dPadSame-77               [-1, 64, 64]               0
       Bottleneck-78               [-1, 64, 64]               0
      BatchNorm1d-79               [-1, 64, 64]             128
             ReLU-80               [-1, 64, 64]               0
          Dropout-81               [-1, 64, 64]               0
           Conv1d-82               [-1, 64, 64]           1,088
  MyConv1dPadSame-83               [-1, 64, 64]               0
      BatchNorm1d-84               [-1, 64, 64]             128
             ReLU-85               [-1, 64, 64]               0
          Dropout-86               [-1, 64, 64]               0
           Conv1d-87               [-1, 64, 64]           1,088
  MyConv1dPadSame-88               [-1, 64, 64]               0
       Bottleneck-89               [-1, 64, 64]               0
      BatchNorm1d-90               [-1, 64, 64]             128
             ReLU-91               [-1, 64, 64]               0
           Linear-92                    [-1, 2]             130
================================================================
Total params: 6,378
Trainable params: 6,378
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 1.27
Params size (MB): 0.02
Estimated Total Size (MB): 1.30
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 8, kernel_size: 2, n_block: 16
************************************************************
************************************************************
(2000, 1, 64) Counter({1: 1000, 0: 1000})
(2000, 1, 64) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1                [-1, 8, 64]              24
   MyConv1dPadSame-2                [-1, 8, 64]               0
       BatchNorm1d-3                [-1, 8, 64]              16
              ReLU-4                [-1, 8, 64]               0
            Conv1d-5                [-1, 8, 64]              24
   MyConv1dPadSame-6                [-1, 8, 64]               0
       BatchNorm1d-7                [-1, 8, 64]              16
              ReLU-8                [-1, 8, 64]               0
           Dropout-9                [-1, 8, 64]               0
           Conv1d-10                [-1, 8, 64]              24
  MyConv1dPadSame-11                [-1, 8, 64]               0
       Bottleneck-12                [-1, 8, 64]               0
      BatchNorm1d-13                [-1, 8, 64]              16
             ReLU-14                [-1, 8, 64]               0
          Dropout-15                [-1, 8, 64]               0
           Conv1d-16                [-1, 8, 32]              24
  MyConv1dPadSame-17                [-1, 8, 32]               0
      BatchNorm1d-18                [-1, 8, 32]              16
             ReLU-19                [-1, 8, 32]               0
          Dropout-20                [-1, 8, 32]               0
           Conv1d-21                [-1, 8, 32]              24
  MyConv1dPadSame-22                [-1, 8, 32]               0
        MaxPool1d-23                [-1, 8, 32]               0
MyMaxPool1dPadSame-24                [-1, 8, 32]               0
       Bottleneck-25                [-1, 8, 32]               0
      BatchNorm1d-26                [-1, 8, 32]              16
             ReLU-27                [-1, 8, 32]               0
          Dropout-28                [-1, 8, 32]               0
           Conv1d-29                [-1, 8, 32]              24
  MyConv1dPadSame-30                [-1, 8, 32]               0
      BatchNorm1d-31                [-1, 8, 32]              16
             ReLU-32                [-1, 8, 32]               0
          Dropout-33                [-1, 8, 32]               0
           Conv1d-34                [-1, 8, 32]              24
  MyConv1dPadSame-35                [-1, 8, 32]               0
       Bottleneck-36                [-1, 8, 32]               0
      BatchNorm1d-37                [-1, 8, 32]              16
             ReLU-38                [-1, 8, 32]               0
          Dropout-39                [-1, 8, 32]               0
           Conv1d-40                [-1, 8, 16]              24
  MyConv1dPadSame-41                [-1, 8, 16]               0
      BatchNorm1d-42                [-1, 8, 16]              16
             ReLU-43                [-1, 8, 16]               0
          Dropout-44                [-1, 8, 16]               0
           Conv1d-45                [-1, 8, 16]              24
  MyConv1dPadSame-46                [-1, 8, 16]               0
        MaxPool1d-47                [-1, 8, 16]               0
MyMaxPool1dPadSame-48                [-1, 8, 16]               0
       Bottleneck-49                [-1, 8, 16]               0
      BatchNorm1d-50                [-1, 8, 16]              16
             ReLU-51                [-1, 8, 16]               0
          Dropout-52                [-1, 8, 16]               0
           Conv1d-53               [-1, 16, 16]              48
  MyConv1dPadSame-54               [-1, 16, 16]               0
      BatchNorm1d-55               [-1, 16, 16]              32
             ReLU-56               [-1, 16, 16]               0
          Dropout-57               [-1, 16, 16]               0
           Conv1d-58               [-1, 16, 16]              80
  MyConv1dPadSame-59               [-1, 16, 16]               0
       Bottleneck-60               [-1, 16, 16]               0
      BatchNorm1d-61               [-1, 16, 16]              32
             ReLU-62               [-1, 16, 16]               0
          Dropout-63               [-1, 16, 16]               0
           Conv1d-64                [-1, 16, 8]              80
  MyConv1dPadSame-65                [-1, 16, 8]               0
      BatchNorm1d-66                [-1, 16, 8]              32
             ReLU-67                [-1, 16, 8]               0
          Dropout-68                [-1, 16, 8]               0
           Conv1d-69                [-1, 16, 8]              80
  MyConv1dPadSame-70                [-1, 16, 8]               0
        MaxPool1d-71                [-1, 16, 8]               0
MyMaxPool1dPadSame-72                [-1, 16, 8]               0
       Bottleneck-73                [-1, 16, 8]               0
      BatchNorm1d-74                [-1, 16, 8]              32
             ReLU-75                [-1, 16, 8]               0
          Dropout-76                [-1, 16, 8]               0
           Conv1d-77                [-1, 16, 8]              80
  MyConv1dPadSame-78                [-1, 16, 8]               0
      BatchNorm1d-79                [-1, 16, 8]              32
             ReLU-80                [-1, 16, 8]               0
          Dropout-81                [-1, 16, 8]               0
           Conv1d-82                [-1, 16, 8]              80
  MyConv1dPadSame-83                [-1, 16, 8]               0
       Bottleneck-84                [-1, 16, 8]               0
      BatchNorm1d-85                [-1, 16, 8]              32
             ReLU-86                [-1, 16, 8]               0
          Dropout-87                [-1, 16, 8]               0
           Conv1d-88                [-1, 16, 4]              80
  MyConv1dPadSame-89                [-1, 16, 4]               0
      BatchNorm1d-90                [-1, 16, 4]              32
             ReLU-91                [-1, 16, 4]               0
          Dropout-92                [-1, 16, 4]               0
           Conv1d-93                [-1, 16, 4]              80
  MyConv1dPadSame-94                [-1, 16, 4]               0
        MaxPool1d-95                [-1, 16, 4]               0
MyMaxPool1dPadSame-96                [-1, 16, 4]               0
       Bottleneck-97                [-1, 16, 4]               0
      BatchNorm1d-98                [-1, 16, 4]              32
             ReLU-99                [-1, 16, 4]               0
         Dropout-100                [-1, 16, 4]               0
          Conv1d-101                [-1, 32, 4]             160
 MyConv1dPadSame-102                [-1, 32, 4]               0
     BatchNorm1d-103                [-1, 32, 4]              64
            ReLU-104                [-1, 32, 4]               0
         Dropout-105                [-1, 32, 4]               0
          Conv1d-106                [-1, 32, 4]             288
 MyConv1dPadSame-107                [-1, 32, 4]               0
      Bottleneck-108                [-1, 32, 4]               0
     BatchNorm1d-109                [-1, 32, 4]              64
            ReLU-110                [-1, 32, 4]               0
         Dropout-111                [-1, 32, 4]               0
          Conv1d-112                [-1, 32, 2]             288
 MyConv1dPadSame-113                [-1, 32, 2]               0
     BatchNorm1d-114                [-1, 32, 2]              64
            ReLU-115                [-1, 32, 2]               0
         Dropout-116                [-1, 32, 2]               0
          Conv1d-117                [-1, 32, 2]             288
 MyConv1dPadSame-118                [-1, 32, 2]               0
       MaxPool1d-119                [-1, 32, 2]               0
MyMaxPool1dPadSame-120                [-1, 32, 2]               0
      Bottleneck-121                [-1, 32, 2]               0
     BatchNorm1d-122                [-1, 32, 2]              64
            ReLU-123                [-1, 32, 2]               0
         Dropout-124                [-1, 32, 2]               0
          Conv1d-125                [-1, 32, 2]             288
 MyConv1dPadSame-126                [-1, 32, 2]               0
     BatchNorm1d-127                [-1, 32, 2]              64
            ReLU-128                [-1, 32, 2]               0
         Dropout-129                [-1, 32, 2]               0
          Conv1d-130                [-1, 32, 2]             288
 MyConv1dPadSame-131                [-1, 32, 2]               0
      Bottleneck-132                [-1, 32, 2]               0
     BatchNorm1d-133                [-1, 32, 2]              64
            ReLU-134                [-1, 32, 2]               0
         Dropout-135                [-1, 32, 2]               0
          Conv1d-136                [-1, 32, 1]             288
 MyConv1dPadSame-137                [-1, 32, 1]               0
     BatchNorm1d-138                [-1, 32, 1]              64
            ReLU-139                [-1, 32, 1]               0
         Dropout-140                [-1, 32, 1]               0
          Conv1d-141                [-1, 32, 1]             288
 MyConv1dPadSame-142                [-1, 32, 1]               0
       MaxPool1d-143                [-1, 32, 1]               0
MyMaxPool1dPadSame-144                [-1, 32, 1]               0
      Bottleneck-145                [-1, 32, 1]               0
     BatchNorm1d-146                [-1, 32, 1]              64
            ReLU-147                [-1, 32, 1]               0
         Dropout-148                [-1, 32, 1]               0
          Conv1d-149                [-1, 64, 1]             576
 MyConv1dPadSame-150                [-1, 64, 1]               0
     BatchNorm1d-151                [-1, 64, 1]             128
            ReLU-152                [-1, 64, 1]               0
         Dropout-153                [-1, 64, 1]               0
          Conv1d-154                [-1, 64, 1]           1,088
 MyConv1dPadSame-155                [-1, 64, 1]               0
      Bottleneck-156                [-1, 64, 1]               0
     BatchNorm1d-157                [-1, 64, 1]             128
            ReLU-158                [-1, 64, 1]               0
         Dropout-159                [-1, 64, 1]               0
          Conv1d-160                [-1, 64, 1]           1,088
 MyConv1dPadSame-161                [-1, 64, 1]               0
     BatchNorm1d-162                [-1, 64, 1]             128
            ReLU-163                [-1, 64, 1]               0
         Dropout-164                [-1, 64, 1]               0
          Conv1d-165                [-1, 64, 1]           1,088
 MyConv1dPadSame-166                [-1, 64, 1]               0
       MaxPool1d-167                [-1, 64, 1]               0
MyMaxPool1dPadSame-168                [-1, 64, 1]               0
      Bottleneck-169                [-1, 64, 1]               0
     BatchNorm1d-170                [-1, 64, 1]             128
            ReLU-171                [-1, 64, 1]               0
         Dropout-172                [-1, 64, 1]               0
          Conv1d-173                [-1, 64, 1]           1,088
 MyConv1dPadSame-174                [-1, 64, 1]               0
     BatchNorm1d-175                [-1, 64, 1]             128
            ReLU-176                [-1, 64, 1]               0
         Dropout-177                [-1, 64, 1]               0
          Conv1d-178                [-1, 64, 1]           1,088
 MyConv1dPadSame-179                [-1, 64, 1]               0
      Bottleneck-180                [-1, 64, 1]               0
     BatchNorm1d-181                [-1, 64, 1]             128
            ReLU-182                [-1, 64, 1]               0
         Dropout-183                [-1, 64, 1]               0
          Conv1d-184                [-1, 64, 1]           1,088
 MyConv1dPadSame-185                [-1, 64, 1]               0
     BatchNorm1d-186                [-1, 64, 1]             128
            ReLU-187                [-1, 64, 1]               0
         Dropout-188                [-1, 64, 1]               0
          Conv1d-189                [-1, 64, 1]           1,088
 MyConv1dPadSame-190                [-1, 64, 1]               0
       MaxPool1d-191                [-1, 64, 1]               0
MyMaxPool1dPadSame-192                [-1, 64, 1]               0
      Bottleneck-193                [-1, 64, 1]               0
     BatchNorm1d-194                [-1, 64, 1]             128
            ReLU-195                [-1, 64, 1]               0
          Linear-196                    [-1, 2]             130
================================================================
Total params: 13,258
Trainable params: 13,258
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.22
Params size (MB): 0.05
Estimated Total Size (MB): 0.27
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 8, kernel_size: 4, n_block: 2
************************************************************
************************************************************
(2000, 1, 64) Counter({0: 1000, 1: 1000})
(2000, 1, 64) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1                [-1, 8, 64]              40
   MyConv1dPadSame-2                [-1, 8, 64]               0
       BatchNorm1d-3                [-1, 8, 64]              16
              ReLU-4                [-1, 8, 64]               0
            Conv1d-5                [-1, 8, 64]              40
   MyConv1dPadSame-6                [-1, 8, 64]               0
       BatchNorm1d-7                [-1, 8, 64]              16
              ReLU-8                [-1, 8, 64]               0
           Dropout-9                [-1, 8, 64]               0
           Conv1d-10                [-1, 8, 64]              40
  MyConv1dPadSame-11                [-1, 8, 64]               0
       Bottleneck-12                [-1, 8, 64]               0
      BatchNorm1d-13                [-1, 8, 64]              16
             ReLU-14                [-1, 8, 64]               0
          Dropout-15                [-1, 8, 64]               0
           Conv1d-16               [-1, 16, 64]              80
  MyConv1dPadSame-17               [-1, 16, 64]               0
      BatchNorm1d-18               [-1, 16, 64]              32
             ReLU-19               [-1, 16, 64]               0
          Dropout-20               [-1, 16, 64]               0
           Conv1d-21               [-1, 16, 64]             144
  MyConv1dPadSame-22               [-1, 16, 64]               0
       Bottleneck-23               [-1, 16, 64]               0
      BatchNorm1d-24               [-1, 16, 64]              32
             ReLU-25               [-1, 16, 64]               0
           Linear-26                    [-1, 2]              34
================================================================
Total params: 490
Trainable params: 490
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.14
Params size (MB): 0.00
Estimated Total Size (MB): 0.14
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 8, kernel_size: 4, n_block: 4
************************************************************
************************************************************
(2000, 1, 64) Counter({1: 1000, 0: 1000})
(2000, 1, 64) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1                [-1, 8, 64]              40
   MyConv1dPadSame-2                [-1, 8, 64]               0
       BatchNorm1d-3                [-1, 8, 64]              16
              ReLU-4                [-1, 8, 64]               0
            Conv1d-5                [-1, 8, 64]              40
   MyConv1dPadSame-6                [-1, 8, 64]               0
       BatchNorm1d-7                [-1, 8, 64]              16
              ReLU-8                [-1, 8, 64]               0
           Dropout-9                [-1, 8, 64]               0
           Conv1d-10                [-1, 8, 64]              40
  MyConv1dPadSame-11                [-1, 8, 64]               0
       Bottleneck-12                [-1, 8, 64]               0
      BatchNorm1d-13                [-1, 8, 64]              16
             ReLU-14                [-1, 8, 64]               0
          Dropout-15                [-1, 8, 64]               0
           Conv1d-16               [-1, 16, 64]              80
  MyConv1dPadSame-17               [-1, 16, 64]               0
      BatchNorm1d-18               [-1, 16, 64]              32
             ReLU-19               [-1, 16, 64]               0
          Dropout-20               [-1, 16, 64]               0
           Conv1d-21               [-1, 16, 64]             144
  MyConv1dPadSame-22               [-1, 16, 64]               0
       Bottleneck-23               [-1, 16, 64]               0
      BatchNorm1d-24               [-1, 16, 64]              32
             ReLU-25               [-1, 16, 64]               0
          Dropout-26               [-1, 16, 64]               0
           Conv1d-27               [-1, 32, 64]             288
  MyConv1dPadSame-28               [-1, 32, 64]               0
      BatchNorm1d-29               [-1, 32, 64]              64
             ReLU-30               [-1, 32, 64]               0
          Dropout-31               [-1, 32, 64]               0
           Conv1d-32               [-1, 32, 64]             544
  MyConv1dPadSame-33               [-1, 32, 64]               0
       Bottleneck-34               [-1, 32, 64]               0
      BatchNorm1d-35               [-1, 32, 64]              64
             ReLU-36               [-1, 32, 64]               0
          Dropout-37               [-1, 32, 64]               0
           Conv1d-38               [-1, 64, 64]           1,088
  MyConv1dPadSame-39               [-1, 64, 64]               0
      BatchNorm1d-40               [-1, 64, 64]             128
             ReLU-41               [-1, 64, 64]               0
          Dropout-42               [-1, 64, 64]               0
           Conv1d-43               [-1, 64, 64]           2,112
  MyConv1dPadSame-44               [-1, 64, 64]               0
       Bottleneck-45               [-1, 64, 64]               0
      BatchNorm1d-46               [-1, 64, 64]             128
             ReLU-47               [-1, 64, 64]               0
           Linear-48                    [-1, 2]             130
================================================================
Total params: 5,002
Trainable params: 5,002
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.63
Params size (MB): 0.02
Estimated Total Size (MB): 0.65
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 8, kernel_size: 4, n_block: 8
************************************************************
************************************************************
(2000, 1, 64) Counter({1: 1000, 0: 1000})
(2000, 1, 64) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1                [-1, 8, 64]              40
   MyConv1dPadSame-2                [-1, 8, 64]               0
       BatchNorm1d-3                [-1, 8, 64]              16
              ReLU-4                [-1, 8, 64]               0
            Conv1d-5                [-1, 8, 64]              40
   MyConv1dPadSame-6                [-1, 8, 64]               0
       BatchNorm1d-7                [-1, 8, 64]              16
              ReLU-8                [-1, 8, 64]               0
           Dropout-9                [-1, 8, 64]               0
           Conv1d-10                [-1, 8, 64]              40
  MyConv1dPadSame-11                [-1, 8, 64]               0
       Bottleneck-12                [-1, 8, 64]               0
      BatchNorm1d-13                [-1, 8, 64]              16
             ReLU-14                [-1, 8, 64]               0
          Dropout-15                [-1, 8, 64]               0
           Conv1d-16                [-1, 8, 64]              40
  MyConv1dPadSame-17                [-1, 8, 64]               0
      BatchNorm1d-18                [-1, 8, 64]              16
             ReLU-19                [-1, 8, 64]               0
          Dropout-20                [-1, 8, 64]               0
           Conv1d-21                [-1, 8, 64]              40
  MyConv1dPadSame-22                [-1, 8, 64]               0
       Bottleneck-23                [-1, 8, 64]               0
      BatchNorm1d-24                [-1, 8, 64]              16
             ReLU-25                [-1, 8, 64]               0
          Dropout-26                [-1, 8, 64]               0
           Conv1d-27               [-1, 16, 64]              80
  MyConv1dPadSame-28               [-1, 16, 64]               0
      BatchNorm1d-29               [-1, 16, 64]              32
             ReLU-30               [-1, 16, 64]               0
          Dropout-31               [-1, 16, 64]               0
           Conv1d-32               [-1, 16, 64]             144
  MyConv1dPadSame-33               [-1, 16, 64]               0
       Bottleneck-34               [-1, 16, 64]               0
      BatchNorm1d-35               [-1, 16, 64]              32
             ReLU-36               [-1, 16, 64]               0
          Dropout-37               [-1, 16, 64]               0
           Conv1d-38               [-1, 16, 64]             144
  MyConv1dPadSame-39               [-1, 16, 64]               0
      BatchNorm1d-40               [-1, 16, 64]              32
             ReLU-41               [-1, 16, 64]               0
          Dropout-42               [-1, 16, 64]               0
           Conv1d-43               [-1, 16, 64]             144
  MyConv1dPadSame-44               [-1, 16, 64]               0
       Bottleneck-45               [-1, 16, 64]               0
      BatchNorm1d-46               [-1, 16, 64]              32
             ReLU-47               [-1, 16, 64]               0
          Dropout-48               [-1, 16, 64]               0
           Conv1d-49               [-1, 32, 64]             288
  MyConv1dPadSame-50               [-1, 32, 64]               0
      BatchNorm1d-51               [-1, 32, 64]              64
             ReLU-52               [-1, 32, 64]               0
          Dropout-53               [-1, 32, 64]               0
           Conv1d-54               [-1, 32, 64]             544
  MyConv1dPadSame-55               [-1, 32, 64]               0
       Bottleneck-56               [-1, 32, 64]               0
      BatchNorm1d-57               [-1, 32, 64]              64
             ReLU-58               [-1, 32, 64]               0
          Dropout-59               [-1, 32, 64]               0
           Conv1d-60               [-1, 32, 64]             544
  MyConv1dPadSame-61               [-1, 32, 64]               0
      BatchNorm1d-62               [-1, 32, 64]              64
             ReLU-63               [-1, 32, 64]               0
          Dropout-64               [-1, 32, 64]               0
           Conv1d-65               [-1, 32, 64]             544
  MyConv1dPadSame-66               [-1, 32, 64]               0
       Bottleneck-67               [-1, 32, 64]               0
      BatchNorm1d-68               [-1, 32, 64]              64
             ReLU-69               [-1, 32, 64]               0
          Dropout-70               [-1, 32, 64]               0
           Conv1d-71               [-1, 64, 64]           1,088
  MyConv1dPadSame-72               [-1, 64, 64]               0
      BatchNorm1d-73               [-1, 64, 64]             128
             ReLU-74               [-1, 64, 64]               0
          Dropout-75               [-1, 64, 64]               0
           Conv1d-76               [-1, 64, 64]           2,112
  MyConv1dPadSame-77               [-1, 64, 64]               0
       Bottleneck-78               [-1, 64, 64]               0
      BatchNorm1d-79               [-1, 64, 64]             128
             ReLU-80               [-1, 64, 64]               0
          Dropout-81               [-1, 64, 64]               0
           Conv1d-82               [-1, 64, 64]           2,112
  MyConv1dPadSame-83               [-1, 64, 64]               0
      BatchNorm1d-84               [-1, 64, 64]             128
             ReLU-85               [-1, 64, 64]               0
          Dropout-86               [-1, 64, 64]               0
           Conv1d-87               [-1, 64, 64]           2,112
  MyConv1dPadSame-88               [-1, 64, 64]               0
       Bottleneck-89               [-1, 64, 64]               0
      BatchNorm1d-90               [-1, 64, 64]             128
             ReLU-91               [-1, 64, 64]               0
           Linear-92                    [-1, 2]             130
================================================================
Total params: 11,162
Trainable params: 11,162
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 1.27
Params size (MB): 0.04
Estimated Total Size (MB): 1.32
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 8, kernel_size: 4, n_block: 16
************************************************************
************************************************************
(2000, 1, 64) Counter({1: 1000, 0: 1000})
(2000, 1, 64) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1                [-1, 8, 64]              40
   MyConv1dPadSame-2                [-1, 8, 64]               0
       BatchNorm1d-3                [-1, 8, 64]              16
              ReLU-4                [-1, 8, 64]               0
            Conv1d-5                [-1, 8, 64]              40
   MyConv1dPadSame-6                [-1, 8, 64]               0
       BatchNorm1d-7                [-1, 8, 64]              16
              ReLU-8                [-1, 8, 64]               0
           Dropout-9                [-1, 8, 64]               0
           Conv1d-10                [-1, 8, 64]              40
  MyConv1dPadSame-11                [-1, 8, 64]               0
       Bottleneck-12                [-1, 8, 64]               0
      BatchNorm1d-13                [-1, 8, 64]              16
             ReLU-14                [-1, 8, 64]               0
          Dropout-15                [-1, 8, 64]               0
           Conv1d-16                [-1, 8, 32]              40
  MyConv1dPadSame-17                [-1, 8, 32]               0
      BatchNorm1d-18                [-1, 8, 32]              16
             ReLU-19                [-1, 8, 32]               0
          Dropout-20                [-1, 8, 32]               0
           Conv1d-21                [-1, 8, 32]              40
  MyConv1dPadSame-22                [-1, 8, 32]               0
        MaxPool1d-23                [-1, 8, 32]               0
MyMaxPool1dPadSame-24                [-1, 8, 32]               0
       Bottleneck-25                [-1, 8, 32]               0
      BatchNorm1d-26                [-1, 8, 32]              16
             ReLU-27                [-1, 8, 32]               0
          Dropout-28                [-1, 8, 32]               0
           Conv1d-29                [-1, 8, 32]              40
  MyConv1dPadSame-30                [-1, 8, 32]               0
      BatchNorm1d-31                [-1, 8, 32]              16
             ReLU-32                [-1, 8, 32]               0
          Dropout-33                [-1, 8, 32]               0
           Conv1d-34                [-1, 8, 32]              40
  MyConv1dPadSame-35                [-1, 8, 32]               0
       Bottleneck-36                [-1, 8, 32]               0
      BatchNorm1d-37                [-1, 8, 32]              16
             ReLU-38                [-1, 8, 32]               0
          Dropout-39                [-1, 8, 32]               0
           Conv1d-40                [-1, 8, 16]              40
  MyConv1dPadSame-41                [-1, 8, 16]               0
      BatchNorm1d-42                [-1, 8, 16]              16
             ReLU-43                [-1, 8, 16]               0
          Dropout-44                [-1, 8, 16]               0
           Conv1d-45                [-1, 8, 16]              40
  MyConv1dPadSame-46                [-1, 8, 16]               0
        MaxPool1d-47                [-1, 8, 16]               0
MyMaxPool1dPadSame-48                [-1, 8, 16]               0
       Bottleneck-49                [-1, 8, 16]               0
      BatchNorm1d-50                [-1, 8, 16]              16
             ReLU-51                [-1, 8, 16]               0
          Dropout-52                [-1, 8, 16]               0
           Conv1d-53               [-1, 16, 16]              80
  MyConv1dPadSame-54               [-1, 16, 16]               0
      BatchNorm1d-55               [-1, 16, 16]              32
             ReLU-56               [-1, 16, 16]               0
          Dropout-57               [-1, 16, 16]               0
           Conv1d-58               [-1, 16, 16]             144
  MyConv1dPadSame-59               [-1, 16, 16]               0
       Bottleneck-60               [-1, 16, 16]               0
      BatchNorm1d-61               [-1, 16, 16]              32
             ReLU-62               [-1, 16, 16]               0
          Dropout-63               [-1, 16, 16]               0
           Conv1d-64                [-1, 16, 8]             144
  MyConv1dPadSame-65                [-1, 16, 8]               0
      BatchNorm1d-66                [-1, 16, 8]              32
             ReLU-67                [-1, 16, 8]               0
          Dropout-68                [-1, 16, 8]               0
           Conv1d-69                [-1, 16, 8]             144
  MyConv1dPadSame-70                [-1, 16, 8]               0
        MaxPool1d-71                [-1, 16, 8]               0
MyMaxPool1dPadSame-72                [-1, 16, 8]               0
       Bottleneck-73                [-1, 16, 8]               0
      BatchNorm1d-74                [-1, 16, 8]              32
             ReLU-75                [-1, 16, 8]               0
          Dropout-76                [-1, 16, 8]               0
           Conv1d-77                [-1, 16, 8]             144
  MyConv1dPadSame-78                [-1, 16, 8]               0
      BatchNorm1d-79                [-1, 16, 8]              32
             ReLU-80                [-1, 16, 8]               0
          Dropout-81                [-1, 16, 8]               0
           Conv1d-82                [-1, 16, 8]             144
  MyConv1dPadSame-83                [-1, 16, 8]               0
       Bottleneck-84                [-1, 16, 8]               0
      BatchNorm1d-85                [-1, 16, 8]              32
             ReLU-86                [-1, 16, 8]               0
          Dropout-87                [-1, 16, 8]               0
           Conv1d-88                [-1, 16, 4]             144
  MyConv1dPadSame-89                [-1, 16, 4]               0
      BatchNorm1d-90                [-1, 16, 4]              32
             ReLU-91                [-1, 16, 4]               0
          Dropout-92                [-1, 16, 4]               0
           Conv1d-93                [-1, 16, 4]             144
  MyConv1dPadSame-94                [-1, 16, 4]               0
        MaxPool1d-95                [-1, 16, 4]               0
MyMaxPool1dPadSame-96                [-1, 16, 4]               0
       Bottleneck-97                [-1, 16, 4]               0
      BatchNorm1d-98                [-1, 16, 4]              32
             ReLU-99                [-1, 16, 4]               0
         Dropout-100                [-1, 16, 4]               0
          Conv1d-101                [-1, 32, 4]             288
 MyConv1dPadSame-102                [-1, 32, 4]               0
     BatchNorm1d-103                [-1, 32, 4]              64
            ReLU-104                [-1, 32, 4]               0
         Dropout-105                [-1, 32, 4]               0
          Conv1d-106                [-1, 32, 4]             544
 MyConv1dPadSame-107                [-1, 32, 4]               0
      Bottleneck-108                [-1, 32, 4]               0
     BatchNorm1d-109                [-1, 32, 4]              64
            ReLU-110                [-1, 32, 4]               0
         Dropout-111                [-1, 32, 4]               0
          Conv1d-112                [-1, 32, 2]             544
 MyConv1dPadSame-113                [-1, 32, 2]               0
     BatchNorm1d-114                [-1, 32, 2]              64
            ReLU-115                [-1, 32, 2]               0
         Dropout-116                [-1, 32, 2]               0
          Conv1d-117                [-1, 32, 2]             544
 MyConv1dPadSame-118                [-1, 32, 2]               0
       MaxPool1d-119                [-1, 32, 2]               0
MyMaxPool1dPadSame-120                [-1, 32, 2]               0
      Bottleneck-121                [-1, 32, 2]               0
     BatchNorm1d-122                [-1, 32, 2]              64
            ReLU-123                [-1, 32, 2]               0
         Dropout-124                [-1, 32, 2]               0
          Conv1d-125                [-1, 32, 2]             544
 MyConv1dPadSame-126                [-1, 32, 2]               0
     BatchNorm1d-127                [-1, 32, 2]              64
            ReLU-128                [-1, 32, 2]               0
         Dropout-129                [-1, 32, 2]               0
          Conv1d-130                [-1, 32, 2]             544
 MyConv1dPadSame-131                [-1, 32, 2]               0
      Bottleneck-132                [-1, 32, 2]               0
     BatchNorm1d-133                [-1, 32, 2]              64
            ReLU-134                [-1, 32, 2]               0
         Dropout-135                [-1, 32, 2]               0
          Conv1d-136                [-1, 32, 1]             544
 MyConv1dPadSame-137                [-1, 32, 1]               0
     BatchNorm1d-138                [-1, 32, 1]              64
            ReLU-139                [-1, 32, 1]               0
         Dropout-140                [-1, 32, 1]               0
          Conv1d-141                [-1, 32, 1]             544
 MyConv1dPadSame-142                [-1, 32, 1]               0
       MaxPool1d-143                [-1, 32, 1]               0
MyMaxPool1dPadSame-144                [-1, 32, 1]               0
      Bottleneck-145                [-1, 32, 1]               0
     BatchNorm1d-146                [-1, 32, 1]              64
            ReLU-147                [-1, 32, 1]               0
         Dropout-148                [-1, 32, 1]               0
          Conv1d-149                [-1, 64, 1]           1,088
 MyConv1dPadSame-150                [-1, 64, 1]               0
     BatchNorm1d-151                [-1, 64, 1]             128
            ReLU-152                [-1, 64, 1]               0
         Dropout-153                [-1, 64, 1]               0
          Conv1d-154                [-1, 64, 1]           2,112
 MyConv1dPadSame-155                [-1, 64, 1]               0
      Bottleneck-156                [-1, 64, 1]               0
     BatchNorm1d-157                [-1, 64, 1]             128
            ReLU-158                [-1, 64, 1]               0
         Dropout-159                [-1, 64, 1]               0
          Conv1d-160                [-1, 64, 1]           2,112
 MyConv1dPadSame-161                [-1, 64, 1]               0
     BatchNorm1d-162                [-1, 64, 1]             128
            ReLU-163                [-1, 64, 1]               0
         Dropout-164                [-1, 64, 1]               0
          Conv1d-165                [-1, 64, 1]           2,112
 MyConv1dPadSame-166                [-1, 64, 1]               0
       MaxPool1d-167                [-1, 64, 1]               0
MyMaxPool1dPadSame-168                [-1, 64, 1]               0
      Bottleneck-169                [-1, 64, 1]               0
     BatchNorm1d-170                [-1, 64, 1]             128
            ReLU-171                [-1, 64, 1]               0
         Dropout-172                [-1, 64, 1]               0
          Conv1d-173                [-1, 64, 1]           2,112
 MyConv1dPadSame-174                [-1, 64, 1]               0
     BatchNorm1d-175                [-1, 64, 1]             128
            ReLU-176                [-1, 64, 1]               0
         Dropout-177                [-1, 64, 1]               0
          Conv1d-178                [-1, 64, 1]           2,112
 MyConv1dPadSame-179                [-1, 64, 1]               0
      Bottleneck-180                [-1, 64, 1]               0
     BatchNorm1d-181                [-1, 64, 1]             128
            ReLU-182                [-1, 64, 1]               0
         Dropout-183                [-1, 64, 1]               0
          Conv1d-184                [-1, 64, 1]           2,112
 MyConv1dPadSame-185                [-1, 64, 1]               0
     BatchNorm1d-186                [-1, 64, 1]             128
            ReLU-187                [-1, 64, 1]               0
         Dropout-188                [-1, 64, 1]               0
          Conv1d-189                [-1, 64, 1]           2,112
 MyConv1dPadSame-190                [-1, 64, 1]               0
       MaxPool1d-191                [-1, 64, 1]               0
MyMaxPool1dPadSame-192                [-1, 64, 1]               0
      Bottleneck-193                [-1, 64, 1]               0
     BatchNorm1d-194                [-1, 64, 1]             128
            ReLU-195                [-1, 64, 1]               0
          Linear-196                    [-1, 2]             130
================================================================
Total params: 23,482
Trainable params: 23,482
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.22
Params size (MB): 0.09
Estimated Total Size (MB): 0.31
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 8, kernel_size: 8, n_block: 2
************************************************************
************************************************************
(2000, 1, 64) Counter({1: 1000, 0: 1000})
(2000, 1, 64) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1                [-1, 8, 64]              72
   MyConv1dPadSame-2                [-1, 8, 64]               0
       BatchNorm1d-3                [-1, 8, 64]              16
              ReLU-4                [-1, 8, 64]               0
            Conv1d-5                [-1, 8, 64]              72
   MyConv1dPadSame-6                [-1, 8, 64]               0
       BatchNorm1d-7                [-1, 8, 64]              16
              ReLU-8                [-1, 8, 64]               0
           Dropout-9                [-1, 8, 64]               0
           Conv1d-10                [-1, 8, 64]              72
  MyConv1dPadSame-11                [-1, 8, 64]               0
       Bottleneck-12                [-1, 8, 64]               0
      BatchNorm1d-13                [-1, 8, 64]              16
             ReLU-14                [-1, 8, 64]               0
          Dropout-15                [-1, 8, 64]               0
           Conv1d-16               [-1, 16, 64]             144
  MyConv1dPadSame-17               [-1, 16, 64]               0
      BatchNorm1d-18               [-1, 16, 64]              32
             ReLU-19               [-1, 16, 64]               0
          Dropout-20               [-1, 16, 64]               0
           Conv1d-21               [-1, 16, 64]             272
  MyConv1dPadSame-22               [-1, 16, 64]               0
       Bottleneck-23               [-1, 16, 64]               0
      BatchNorm1d-24               [-1, 16, 64]              32
             ReLU-25               [-1, 16, 64]               0
           Linear-26                    [-1, 2]              34
================================================================
Total params: 778
Trainable params: 778
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.14
Params size (MB): 0.00
Estimated Total Size (MB): 0.14
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 8, kernel_size: 8, n_block: 4
************************************************************
************************************************************
(2000, 1, 64) Counter({0: 1000, 1: 1000})
(2000, 1, 64) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1                [-1, 8, 64]              72
   MyConv1dPadSame-2                [-1, 8, 64]               0
       BatchNorm1d-3                [-1, 8, 64]              16
              ReLU-4                [-1, 8, 64]               0
            Conv1d-5                [-1, 8, 64]              72
   MyConv1dPadSame-6                [-1, 8, 64]               0
       BatchNorm1d-7                [-1, 8, 64]              16
              ReLU-8                [-1, 8, 64]               0
           Dropout-9                [-1, 8, 64]               0
           Conv1d-10                [-1, 8, 64]              72
  MyConv1dPadSame-11                [-1, 8, 64]               0
       Bottleneck-12                [-1, 8, 64]               0
      BatchNorm1d-13                [-1, 8, 64]              16
             ReLU-14                [-1, 8, 64]               0
          Dropout-15                [-1, 8, 64]               0
           Conv1d-16               [-1, 16, 64]             144
  MyConv1dPadSame-17               [-1, 16, 64]               0
      BatchNorm1d-18               [-1, 16, 64]              32
             ReLU-19               [-1, 16, 64]               0
          Dropout-20               [-1, 16, 64]               0
           Conv1d-21               [-1, 16, 64]             272
  MyConv1dPadSame-22               [-1, 16, 64]               0
       Bottleneck-23               [-1, 16, 64]               0
      BatchNorm1d-24               [-1, 16, 64]              32
             ReLU-25               [-1, 16, 64]               0
          Dropout-26               [-1, 16, 64]               0
           Conv1d-27               [-1, 32, 64]             544
  MyConv1dPadSame-28               [-1, 32, 64]               0
      BatchNorm1d-29               [-1, 32, 64]              64
             ReLU-30               [-1, 32, 64]               0
          Dropout-31               [-1, 32, 64]               0
           Conv1d-32               [-1, 32, 64]           1,056
  MyConv1dPadSame-33               [-1, 32, 64]               0
       Bottleneck-34               [-1, 32, 64]               0
      BatchNorm1d-35               [-1, 32, 64]              64
             ReLU-36               [-1, 32, 64]               0
          Dropout-37               [-1, 32, 64]               0
           Conv1d-38               [-1, 64, 64]           2,112
  MyConv1dPadSame-39               [-1, 64, 64]               0
      BatchNorm1d-40               [-1, 64, 64]             128
             ReLU-41               [-1, 64, 64]               0
          Dropout-42               [-1, 64, 64]               0
           Conv1d-43               [-1, 64, 64]           4,160
  MyConv1dPadSame-44               [-1, 64, 64]               0
       Bottleneck-45               [-1, 64, 64]               0
      BatchNorm1d-46               [-1, 64, 64]             128
             ReLU-47               [-1, 64, 64]               0
           Linear-48                    [-1, 2]             130
================================================================
Total params: 9,130
Trainable params: 9,130
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.63
Params size (MB): 0.03
Estimated Total Size (MB): 0.66
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 8, kernel_size: 8, n_block: 8
************************************************************
************************************************************
(2000, 1, 64) Counter({1: 1000, 0: 1000})
(2000, 1, 64) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1                [-1, 8, 64]              72
   MyConv1dPadSame-2                [-1, 8, 64]               0
       BatchNorm1d-3                [-1, 8, 64]              16
              ReLU-4                [-1, 8, 64]               0
            Conv1d-5                [-1, 8, 64]              72
   MyConv1dPadSame-6                [-1, 8, 64]               0
       BatchNorm1d-7                [-1, 8, 64]              16
              ReLU-8                [-1, 8, 64]               0
           Dropout-9                [-1, 8, 64]               0
           Conv1d-10                [-1, 8, 64]              72
  MyConv1dPadSame-11                [-1, 8, 64]               0
       Bottleneck-12                [-1, 8, 64]               0
      BatchNorm1d-13                [-1, 8, 64]              16
             ReLU-14                [-1, 8, 64]               0
          Dropout-15                [-1, 8, 64]               0
           Conv1d-16                [-1, 8, 64]              72
  MyConv1dPadSame-17                [-1, 8, 64]               0
      BatchNorm1d-18                [-1, 8, 64]              16
             ReLU-19                [-1, 8, 64]               0
          Dropout-20                [-1, 8, 64]               0
           Conv1d-21                [-1, 8, 64]              72
  MyConv1dPadSame-22                [-1, 8, 64]               0
       Bottleneck-23                [-1, 8, 64]               0
      BatchNorm1d-24                [-1, 8, 64]              16
             ReLU-25                [-1, 8, 64]               0
          Dropout-26                [-1, 8, 64]               0
           Conv1d-27               [-1, 16, 64]             144
  MyConv1dPadSame-28               [-1, 16, 64]               0
      BatchNorm1d-29               [-1, 16, 64]              32
             ReLU-30               [-1, 16, 64]               0
          Dropout-31               [-1, 16, 64]               0
           Conv1d-32               [-1, 16, 64]             272
  MyConv1dPadSame-33               [-1, 16, 64]               0
       Bottleneck-34               [-1, 16, 64]               0
      BatchNorm1d-35               [-1, 16, 64]              32
             ReLU-36               [-1, 16, 64]               0
          Dropout-37               [-1, 16, 64]               0
           Conv1d-38               [-1, 16, 64]             272
  MyConv1dPadSame-39               [-1, 16, 64]               0
      BatchNorm1d-40               [-1, 16, 64]              32
             ReLU-41               [-1, 16, 64]               0
          Dropout-42               [-1, 16, 64]               0
           Conv1d-43               [-1, 16, 64]             272
  MyConv1dPadSame-44               [-1, 16, 64]               0
       Bottleneck-45               [-1, 16, 64]               0
      BatchNorm1d-46               [-1, 16, 64]              32
             ReLU-47               [-1, 16, 64]               0
          Dropout-48               [-1, 16, 64]               0
           Conv1d-49               [-1, 32, 64]             544
  MyConv1dPadSame-50               [-1, 32, 64]               0
      BatchNorm1d-51               [-1, 32, 64]              64
             ReLU-52               [-1, 32, 64]               0
          Dropout-53               [-1, 32, 64]               0
           Conv1d-54               [-1, 32, 64]           1,056
  MyConv1dPadSame-55               [-1, 32, 64]               0
       Bottleneck-56               [-1, 32, 64]               0
      BatchNorm1d-57               [-1, 32, 64]              64
             ReLU-58               [-1, 32, 64]               0
          Dropout-59               [-1, 32, 64]               0
           Conv1d-60               [-1, 32, 64]           1,056
  MyConv1dPadSame-61               [-1, 32, 64]               0
      BatchNorm1d-62               [-1, 32, 64]              64
             ReLU-63               [-1, 32, 64]               0
          Dropout-64               [-1, 32, 64]               0
           Conv1d-65               [-1, 32, 64]           1,056
  MyConv1dPadSame-66               [-1, 32, 64]               0
       Bottleneck-67               [-1, 32, 64]               0
      BatchNorm1d-68               [-1, 32, 64]              64
             ReLU-69               [-1, 32, 64]               0
          Dropout-70               [-1, 32, 64]               0
           Conv1d-71               [-1, 64, 64]           2,112
  MyConv1dPadSame-72               [-1, 64, 64]               0
      BatchNorm1d-73               [-1, 64, 64]             128
             ReLU-74               [-1, 64, 64]               0
          Dropout-75               [-1, 64, 64]               0
           Conv1d-76               [-1, 64, 64]           4,160
  MyConv1dPadSame-77               [-1, 64, 64]               0
       Bottleneck-78               [-1, 64, 64]               0
      BatchNorm1d-79               [-1, 64, 64]             128
             ReLU-80               [-1, 64, 64]               0
          Dropout-81               [-1, 64, 64]               0
           Conv1d-82               [-1, 64, 64]           4,160
  MyConv1dPadSame-83               [-1, 64, 64]               0
      BatchNorm1d-84               [-1, 64, 64]             128
             ReLU-85               [-1, 64, 64]               0
          Dropout-86               [-1, 64, 64]               0
           Conv1d-87               [-1, 64, 64]           4,160
  MyConv1dPadSame-88               [-1, 64, 64]               0
       Bottleneck-89               [-1, 64, 64]               0
      BatchNorm1d-90               [-1, 64, 64]             128
             ReLU-91               [-1, 64, 64]               0
           Linear-92                    [-1, 2]             130
================================================================
Total params: 20,730
Trainable params: 20,730
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 1.27
Params size (MB): 0.08
Estimated Total Size (MB): 1.35
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 8, kernel_size: 8, n_block: 16
************************************************************
************************************************************
(2000, 1, 64) Counter({1: 1000, 0: 1000})
(2000, 1, 64) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1                [-1, 8, 64]              72
   MyConv1dPadSame-2                [-1, 8, 64]               0
       BatchNorm1d-3                [-1, 8, 64]              16
              ReLU-4                [-1, 8, 64]               0
            Conv1d-5                [-1, 8, 64]              72
   MyConv1dPadSame-6                [-1, 8, 64]               0
       BatchNorm1d-7                [-1, 8, 64]              16
              ReLU-8                [-1, 8, 64]               0
           Dropout-9                [-1, 8, 64]               0
           Conv1d-10                [-1, 8, 64]              72
  MyConv1dPadSame-11                [-1, 8, 64]               0
       Bottleneck-12                [-1, 8, 64]               0
      BatchNorm1d-13                [-1, 8, 64]              16
             ReLU-14                [-1, 8, 64]               0
          Dropout-15                [-1, 8, 64]               0
           Conv1d-16                [-1, 8, 32]              72
  MyConv1dPadSame-17                [-1, 8, 32]               0
      BatchNorm1d-18                [-1, 8, 32]              16
             ReLU-19                [-1, 8, 32]               0
          Dropout-20                [-1, 8, 32]               0
           Conv1d-21                [-1, 8, 32]              72
  MyConv1dPadSame-22                [-1, 8, 32]               0
        MaxPool1d-23                [-1, 8, 32]               0
MyMaxPool1dPadSame-24                [-1, 8, 32]               0
       Bottleneck-25                [-1, 8, 32]               0
      BatchNorm1d-26                [-1, 8, 32]              16
             ReLU-27                [-1, 8, 32]               0
          Dropout-28                [-1, 8, 32]               0
           Conv1d-29                [-1, 8, 32]              72
  MyConv1dPadSame-30                [-1, 8, 32]               0
      BatchNorm1d-31                [-1, 8, 32]              16
             ReLU-32                [-1, 8, 32]               0
          Dropout-33                [-1, 8, 32]               0
           Conv1d-34                [-1, 8, 32]              72
  MyConv1dPadSame-35                [-1, 8, 32]               0
       Bottleneck-36                [-1, 8, 32]               0
      BatchNorm1d-37                [-1, 8, 32]              16
             ReLU-38                [-1, 8, 32]               0
          Dropout-39                [-1, 8, 32]               0
           Conv1d-40                [-1, 8, 16]              72
  MyConv1dPadSame-41                [-1, 8, 16]               0
      BatchNorm1d-42                [-1, 8, 16]              16
             ReLU-43                [-1, 8, 16]               0
          Dropout-44                [-1, 8, 16]               0
           Conv1d-45                [-1, 8, 16]              72
  MyConv1dPadSame-46                [-1, 8, 16]               0
        MaxPool1d-47                [-1, 8, 16]               0
MyMaxPool1dPadSame-48                [-1, 8, 16]               0
       Bottleneck-49                [-1, 8, 16]               0
      BatchNorm1d-50                [-1, 8, 16]              16
             ReLU-51                [-1, 8, 16]               0
          Dropout-52                [-1, 8, 16]               0
           Conv1d-53               [-1, 16, 16]             144
  MyConv1dPadSame-54               [-1, 16, 16]               0
      BatchNorm1d-55               [-1, 16, 16]              32
             ReLU-56               [-1, 16, 16]               0
          Dropout-57               [-1, 16, 16]               0
           Conv1d-58               [-1, 16, 16]             272
  MyConv1dPadSame-59               [-1, 16, 16]               0
       Bottleneck-60               [-1, 16, 16]               0
      BatchNorm1d-61               [-1, 16, 16]              32
             ReLU-62               [-1, 16, 16]               0
          Dropout-63               [-1, 16, 16]               0
           Conv1d-64                [-1, 16, 8]             272
  MyConv1dPadSame-65                [-1, 16, 8]               0
      BatchNorm1d-66                [-1, 16, 8]              32
             ReLU-67                [-1, 16, 8]               0
          Dropout-68                [-1, 16, 8]               0
           Conv1d-69                [-1, 16, 8]             272
  MyConv1dPadSame-70                [-1, 16, 8]               0
        MaxPool1d-71                [-1, 16, 8]               0
MyMaxPool1dPadSame-72                [-1, 16, 8]               0
       Bottleneck-73                [-1, 16, 8]               0
      BatchNorm1d-74                [-1, 16, 8]              32
             ReLU-75                [-1, 16, 8]               0
          Dropout-76                [-1, 16, 8]               0
           Conv1d-77                [-1, 16, 8]             272
  MyConv1dPadSame-78                [-1, 16, 8]               0
      BatchNorm1d-79                [-1, 16, 8]              32
             ReLU-80                [-1, 16, 8]               0
          Dropout-81                [-1, 16, 8]               0
           Conv1d-82                [-1, 16, 8]             272
  MyConv1dPadSame-83                [-1, 16, 8]               0
       Bottleneck-84                [-1, 16, 8]               0
      BatchNorm1d-85                [-1, 16, 8]              32
             ReLU-86                [-1, 16, 8]               0
          Dropout-87                [-1, 16, 8]               0
           Conv1d-88                [-1, 16, 4]             272
  MyConv1dPadSame-89                [-1, 16, 4]               0
      BatchNorm1d-90                [-1, 16, 4]              32
             ReLU-91                [-1, 16, 4]               0
          Dropout-92                [-1, 16, 4]               0
           Conv1d-93                [-1, 16, 4]             272
  MyConv1dPadSame-94                [-1, 16, 4]               0
        MaxPool1d-95                [-1, 16, 4]               0
MyMaxPool1dPadSame-96                [-1, 16, 4]               0
       Bottleneck-97                [-1, 16, 4]               0
      BatchNorm1d-98                [-1, 16, 4]              32
             ReLU-99                [-1, 16, 4]               0
         Dropout-100                [-1, 16, 4]               0
          Conv1d-101                [-1, 32, 4]             544
 MyConv1dPadSame-102                [-1, 32, 4]               0
     BatchNorm1d-103                [-1, 32, 4]              64
            ReLU-104                [-1, 32, 4]               0
         Dropout-105                [-1, 32, 4]               0
          Conv1d-106                [-1, 32, 4]           1,056
 MyConv1dPadSame-107                [-1, 32, 4]               0
      Bottleneck-108                [-1, 32, 4]               0
     BatchNorm1d-109                [-1, 32, 4]              64
            ReLU-110                [-1, 32, 4]               0
         Dropout-111                [-1, 32, 4]               0
          Conv1d-112                [-1, 32, 2]           1,056
 MyConv1dPadSame-113                [-1, 32, 2]               0
     BatchNorm1d-114                [-1, 32, 2]              64
            ReLU-115                [-1, 32, 2]               0
         Dropout-116                [-1, 32, 2]               0
          Conv1d-117                [-1, 32, 2]           1,056
 MyConv1dPadSame-118                [-1, 32, 2]               0
       MaxPool1d-119                [-1, 32, 2]               0
MyMaxPool1dPadSame-120                [-1, 32, 2]               0
      Bottleneck-121                [-1, 32, 2]               0
     BatchNorm1d-122                [-1, 32, 2]              64
            ReLU-123                [-1, 32, 2]               0
         Dropout-124                [-1, 32, 2]               0
          Conv1d-125                [-1, 32, 2]           1,056
 MyConv1dPadSame-126                [-1, 32, 2]               0
     BatchNorm1d-127                [-1, 32, 2]              64
            ReLU-128                [-1, 32, 2]               0
         Dropout-129                [-1, 32, 2]               0
          Conv1d-130                [-1, 32, 2]           1,056
 MyConv1dPadSame-131                [-1, 32, 2]               0
      Bottleneck-132                [-1, 32, 2]               0
     BatchNorm1d-133                [-1, 32, 2]              64
            ReLU-134                [-1, 32, 2]               0
         Dropout-135                [-1, 32, 2]               0
          Conv1d-136                [-1, 32, 1]           1,056
 MyConv1dPadSame-137                [-1, 32, 1]               0
     BatchNorm1d-138                [-1, 32, 1]              64
            ReLU-139                [-1, 32, 1]               0
         Dropout-140                [-1, 32, 1]               0
          Conv1d-141                [-1, 32, 1]           1,056
 MyConv1dPadSame-142                [-1, 32, 1]               0
       MaxPool1d-143                [-1, 32, 1]               0
MyMaxPool1dPadSame-144                [-1, 32, 1]               0
      Bottleneck-145                [-1, 32, 1]               0
     BatchNorm1d-146                [-1, 32, 1]              64
            ReLU-147                [-1, 32, 1]               0
         Dropout-148                [-1, 32, 1]               0
          Conv1d-149                [-1, 64, 1]           2,112
 MyConv1dPadSame-150                [-1, 64, 1]               0
     BatchNorm1d-151                [-1, 64, 1]             128
            ReLU-152                [-1, 64, 1]               0
         Dropout-153                [-1, 64, 1]               0
          Conv1d-154                [-1, 64, 1]           4,160
 MyConv1dPadSame-155                [-1, 64, 1]               0
      Bottleneck-156                [-1, 64, 1]               0
     BatchNorm1d-157                [-1, 64, 1]             128
            ReLU-158                [-1, 64, 1]               0
         Dropout-159                [-1, 64, 1]               0
          Conv1d-160                [-1, 64, 1]           4,160
 MyConv1dPadSame-161                [-1, 64, 1]               0
     BatchNorm1d-162                [-1, 64, 1]             128
            ReLU-163                [-1, 64, 1]               0
         Dropout-164                [-1, 64, 1]               0
          Conv1d-165                [-1, 64, 1]           4,160
 MyConv1dPadSame-166                [-1, 64, 1]               0
       MaxPool1d-167                [-1, 64, 1]               0
MyMaxPool1dPadSame-168                [-1, 64, 1]               0
      Bottleneck-169                [-1, 64, 1]               0
     BatchNorm1d-170                [-1, 64, 1]             128
            ReLU-171                [-1, 64, 1]               0
         Dropout-172                [-1, 64, 1]               0
          Conv1d-173                [-1, 64, 1]           4,160
 MyConv1dPadSame-174                [-1, 64, 1]               0
     BatchNorm1d-175                [-1, 64, 1]             128
            ReLU-176                [-1, 64, 1]               0
         Dropout-177                [-1, 64, 1]               0
          Conv1d-178                [-1, 64, 1]           4,160
 MyConv1dPadSame-179                [-1, 64, 1]               0
      Bottleneck-180                [-1, 64, 1]               0
     BatchNorm1d-181                [-1, 64, 1]             128
            ReLU-182                [-1, 64, 1]               0
         Dropout-183                [-1, 64, 1]               0
          Conv1d-184                [-1, 64, 1]           4,160
 MyConv1dPadSame-185                [-1, 64, 1]               0
     BatchNorm1d-186                [-1, 64, 1]             128
            ReLU-187                [-1, 64, 1]               0
         Dropout-188                [-1, 64, 1]               0
          Conv1d-189                [-1, 64, 1]           4,160
 MyConv1dPadSame-190                [-1, 64, 1]               0
       MaxPool1d-191                [-1, 64, 1]               0
MyMaxPool1dPadSame-192                [-1, 64, 1]               0
      Bottleneck-193                [-1, 64, 1]               0
     BatchNorm1d-194                [-1, 64, 1]             128
            ReLU-195                [-1, 64, 1]               0
          Linear-196                    [-1, 2]             130
================================================================
Total params: 43,930
Trainable params: 43,930
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.22
Params size (MB): 0.17
Estimated Total Size (MB): 0.39
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 8, kernel_size: 16, n_block: 2
************************************************************
************************************************************
(2000, 1, 64) Counter({0: 1000, 1: 1000})
(2000, 1, 64) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1                [-1, 8, 64]             136
   MyConv1dPadSame-2                [-1, 8, 64]               0
       BatchNorm1d-3                [-1, 8, 64]              16
              ReLU-4                [-1, 8, 64]               0
            Conv1d-5                [-1, 8, 64]             136
   MyConv1dPadSame-6                [-1, 8, 64]               0
       BatchNorm1d-7                [-1, 8, 64]              16
              ReLU-8                [-1, 8, 64]               0
           Dropout-9                [-1, 8, 64]               0
           Conv1d-10                [-1, 8, 64]             136
  MyConv1dPadSame-11                [-1, 8, 64]               0
       Bottleneck-12                [-1, 8, 64]               0
      BatchNorm1d-13                [-1, 8, 64]              16
             ReLU-14                [-1, 8, 64]               0
          Dropout-15                [-1, 8, 64]               0
           Conv1d-16               [-1, 16, 64]             272
  MyConv1dPadSame-17               [-1, 16, 64]               0
      BatchNorm1d-18               [-1, 16, 64]              32
             ReLU-19               [-1, 16, 64]               0
          Dropout-20               [-1, 16, 64]               0
           Conv1d-21               [-1, 16, 64]             528
  MyConv1dPadSame-22               [-1, 16, 64]               0
       Bottleneck-23               [-1, 16, 64]               0
      BatchNorm1d-24               [-1, 16, 64]              32
             ReLU-25               [-1, 16, 64]               0
           Linear-26                    [-1, 2]              34
================================================================
Total params: 1,354
Trainable params: 1,354
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.14
Params size (MB): 0.01
Estimated Total Size (MB): 0.14
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 8, kernel_size: 16, n_block: 4
************************************************************
************************************************************
(2000, 1, 64) Counter({1: 1000, 0: 1000})
(2000, 1, 64) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1                [-1, 8, 64]             136
   MyConv1dPadSame-2                [-1, 8, 64]               0
       BatchNorm1d-3                [-1, 8, 64]              16
              ReLU-4                [-1, 8, 64]               0
            Conv1d-5                [-1, 8, 64]             136
   MyConv1dPadSame-6                [-1, 8, 64]               0
       BatchNorm1d-7                [-1, 8, 64]              16
              ReLU-8                [-1, 8, 64]               0
           Dropout-9                [-1, 8, 64]               0
           Conv1d-10                [-1, 8, 64]             136
  MyConv1dPadSame-11                [-1, 8, 64]               0
       Bottleneck-12                [-1, 8, 64]               0
      BatchNorm1d-13                [-1, 8, 64]              16
             ReLU-14                [-1, 8, 64]               0
          Dropout-15                [-1, 8, 64]               0
           Conv1d-16               [-1, 16, 64]             272
  MyConv1dPadSame-17               [-1, 16, 64]               0
      BatchNorm1d-18               [-1, 16, 64]              32
             ReLU-19               [-1, 16, 64]               0
          Dropout-20               [-1, 16, 64]               0
           Conv1d-21               [-1, 16, 64]             528
  MyConv1dPadSame-22               [-1, 16, 64]               0
       Bottleneck-23               [-1, 16, 64]               0
      BatchNorm1d-24               [-1, 16, 64]              32
             ReLU-25               [-1, 16, 64]               0
          Dropout-26               [-1, 16, 64]               0
           Conv1d-27               [-1, 32, 64]           1,056
  MyConv1dPadSame-28               [-1, 32, 64]               0
      BatchNorm1d-29               [-1, 32, 64]              64
             ReLU-30               [-1, 32, 64]               0
          Dropout-31               [-1, 32, 64]               0
           Conv1d-32               [-1, 32, 64]           2,080
  MyConv1dPadSame-33               [-1, 32, 64]               0
       Bottleneck-34               [-1, 32, 64]               0
      BatchNorm1d-35               [-1, 32, 64]              64
             ReLU-36               [-1, 32, 64]               0
          Dropout-37               [-1, 32, 64]               0
           Conv1d-38               [-1, 64, 64]           4,160
  MyConv1dPadSame-39               [-1, 64, 64]               0
      BatchNorm1d-40               [-1, 64, 64]             128
             ReLU-41               [-1, 64, 64]               0
          Dropout-42               [-1, 64, 64]               0
           Conv1d-43               [-1, 64, 64]           8,256
  MyConv1dPadSame-44               [-1, 64, 64]               0
       Bottleneck-45               [-1, 64, 64]               0
      BatchNorm1d-46               [-1, 64, 64]             128
             ReLU-47               [-1, 64, 64]               0
           Linear-48                    [-1, 2]             130
================================================================
Total params: 17,386
Trainable params: 17,386
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.63
Params size (MB): 0.07
Estimated Total Size (MB): 0.70
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 8, kernel_size: 16, n_block: 8
************************************************************
************************************************************
(2000, 1, 64) Counter({0: 1000, 1: 1000})
(2000, 1, 64) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1                [-1, 8, 64]             136
   MyConv1dPadSame-2                [-1, 8, 64]               0
       BatchNorm1d-3                [-1, 8, 64]              16
              ReLU-4                [-1, 8, 64]               0
            Conv1d-5                [-1, 8, 64]             136
   MyConv1dPadSame-6                [-1, 8, 64]               0
       BatchNorm1d-7                [-1, 8, 64]              16
              ReLU-8                [-1, 8, 64]               0
           Dropout-9                [-1, 8, 64]               0
           Conv1d-10                [-1, 8, 64]             136
  MyConv1dPadSame-11                [-1, 8, 64]               0
       Bottleneck-12                [-1, 8, 64]               0
      BatchNorm1d-13                [-1, 8, 64]              16
             ReLU-14                [-1, 8, 64]               0
          Dropout-15                [-1, 8, 64]               0
           Conv1d-16                [-1, 8, 64]             136
  MyConv1dPadSame-17                [-1, 8, 64]               0
      BatchNorm1d-18                [-1, 8, 64]              16
             ReLU-19                [-1, 8, 64]               0
          Dropout-20                [-1, 8, 64]               0
           Conv1d-21                [-1, 8, 64]             136
  MyConv1dPadSame-22                [-1, 8, 64]               0
       Bottleneck-23                [-1, 8, 64]               0
      BatchNorm1d-24                [-1, 8, 64]              16
             ReLU-25                [-1, 8, 64]               0
          Dropout-26                [-1, 8, 64]               0
           Conv1d-27               [-1, 16, 64]             272
  MyConv1dPadSame-28               [-1, 16, 64]               0
      BatchNorm1d-29               [-1, 16, 64]              32
             ReLU-30               [-1, 16, 64]               0
          Dropout-31               [-1, 16, 64]               0
           Conv1d-32               [-1, 16, 64]             528
  MyConv1dPadSame-33               [-1, 16, 64]               0
       Bottleneck-34               [-1, 16, 64]               0
      BatchNorm1d-35               [-1, 16, 64]              32
             ReLU-36               [-1, 16, 64]               0
          Dropout-37               [-1, 16, 64]               0
           Conv1d-38               [-1, 16, 64]             528
  MyConv1dPadSame-39               [-1, 16, 64]               0
      BatchNorm1d-40               [-1, 16, 64]              32
             ReLU-41               [-1, 16, 64]               0
          Dropout-42               [-1, 16, 64]               0
           Conv1d-43               [-1, 16, 64]             528
  MyConv1dPadSame-44               [-1, 16, 64]               0
       Bottleneck-45               [-1, 16, 64]               0
      BatchNorm1d-46               [-1, 16, 64]              32
             ReLU-47               [-1, 16, 64]               0
          Dropout-48               [-1, 16, 64]               0
           Conv1d-49               [-1, 32, 64]           1,056
  MyConv1dPadSame-50               [-1, 32, 64]               0
      BatchNorm1d-51               [-1, 32, 64]              64
             ReLU-52               [-1, 32, 64]               0
          Dropout-53               [-1, 32, 64]               0
           Conv1d-54               [-1, 32, 64]           2,080
  MyConv1dPadSame-55               [-1, 32, 64]               0
       Bottleneck-56               [-1, 32, 64]               0
      BatchNorm1d-57               [-1, 32, 64]              64
             ReLU-58               [-1, 32, 64]               0
          Dropout-59               [-1, 32, 64]               0
           Conv1d-60               [-1, 32, 64]           2,080
  MyConv1dPadSame-61               [-1, 32, 64]               0
      BatchNorm1d-62               [-1, 32, 64]              64
             ReLU-63               [-1, 32, 64]               0
          Dropout-64               [-1, 32, 64]               0
           Conv1d-65               [-1, 32, 64]           2,080
  MyConv1dPadSame-66               [-1, 32, 64]               0
       Bottleneck-67               [-1, 32, 64]               0
      BatchNorm1d-68               [-1, 32, 64]              64
             ReLU-69               [-1, 32, 64]               0
          Dropout-70               [-1, 32, 64]               0
           Conv1d-71               [-1, 64, 64]           4,160
  MyConv1dPadSame-72               [-1, 64, 64]               0
      BatchNorm1d-73               [-1, 64, 64]             128
             ReLU-74               [-1, 64, 64]               0
          Dropout-75               [-1, 64, 64]               0
           Conv1d-76               [-1, 64, 64]           8,256
  MyConv1dPadSame-77               [-1, 64, 64]               0
       Bottleneck-78               [-1, 64, 64]               0
      BatchNorm1d-79               [-1, 64, 64]             128
             ReLU-80               [-1, 64, 64]               0
          Dropout-81               [-1, 64, 64]               0
           Conv1d-82               [-1, 64, 64]           8,256
  MyConv1dPadSame-83               [-1, 64, 64]               0
      BatchNorm1d-84               [-1, 64, 64]             128
             ReLU-85               [-1, 64, 64]               0
          Dropout-86               [-1, 64, 64]               0
           Conv1d-87               [-1, 64, 64]           8,256
  MyConv1dPadSame-88               [-1, 64, 64]               0
       Bottleneck-89               [-1, 64, 64]               0
      BatchNorm1d-90               [-1, 64, 64]             128
             ReLU-91               [-1, 64, 64]               0
           Linear-92                    [-1, 2]             130
================================================================
Total params: 39,866
Trainable params: 39,866
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 1.27
Params size (MB): 0.15
Estimated Total Size (MB): 1.43
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 8, kernel_size: 16, n_block: 16
************************************************************
************************************************************
(2000, 1, 64) Counter({0: 1000, 1: 1000})
(2000, 1, 64) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1                [-1, 8, 64]             136
   MyConv1dPadSame-2                [-1, 8, 64]               0
       BatchNorm1d-3                [-1, 8, 64]              16
              ReLU-4                [-1, 8, 64]               0
            Conv1d-5                [-1, 8, 64]             136
   MyConv1dPadSame-6                [-1, 8, 64]               0
       BatchNorm1d-7                [-1, 8, 64]              16
              ReLU-8                [-1, 8, 64]               0
           Dropout-9                [-1, 8, 64]               0
           Conv1d-10                [-1, 8, 64]             136
  MyConv1dPadSame-11                [-1, 8, 64]               0
       Bottleneck-12                [-1, 8, 64]               0
      BatchNorm1d-13                [-1, 8, 64]              16
             ReLU-14                [-1, 8, 64]               0
          Dropout-15                [-1, 8, 64]               0
           Conv1d-16                [-1, 8, 32]             136
  MyConv1dPadSame-17                [-1, 8, 32]               0
      BatchNorm1d-18                [-1, 8, 32]              16
             ReLU-19                [-1, 8, 32]               0
          Dropout-20                [-1, 8, 32]               0
           Conv1d-21                [-1, 8, 32]             136
  MyConv1dPadSame-22                [-1, 8, 32]               0
        MaxPool1d-23                [-1, 8, 32]               0
MyMaxPool1dPadSame-24                [-1, 8, 32]               0
       Bottleneck-25                [-1, 8, 32]               0
      BatchNorm1d-26                [-1, 8, 32]              16
             ReLU-27                [-1, 8, 32]               0
          Dropout-28                [-1, 8, 32]               0
           Conv1d-29                [-1, 8, 32]             136
  MyConv1dPadSame-30                [-1, 8, 32]               0
      BatchNorm1d-31                [-1, 8, 32]              16
             ReLU-32                [-1, 8, 32]               0
          Dropout-33                [-1, 8, 32]               0
           Conv1d-34                [-1, 8, 32]             136
  MyConv1dPadSame-35                [-1, 8, 32]               0
       Bottleneck-36                [-1, 8, 32]               0
      BatchNorm1d-37                [-1, 8, 32]              16
             ReLU-38                [-1, 8, 32]               0
          Dropout-39                [-1, 8, 32]               0
           Conv1d-40                [-1, 8, 16]             136
  MyConv1dPadSame-41                [-1, 8, 16]               0
      BatchNorm1d-42                [-1, 8, 16]              16
             ReLU-43                [-1, 8, 16]               0
          Dropout-44                [-1, 8, 16]               0
           Conv1d-45                [-1, 8, 16]             136
  MyConv1dPadSame-46                [-1, 8, 16]               0
        MaxPool1d-47                [-1, 8, 16]               0
MyMaxPool1dPadSame-48                [-1, 8, 16]               0
       Bottleneck-49                [-1, 8, 16]               0
      BatchNorm1d-50                [-1, 8, 16]              16
             ReLU-51                [-1, 8, 16]               0
          Dropout-52                [-1, 8, 16]               0
           Conv1d-53               [-1, 16, 16]             272
  MyConv1dPadSame-54               [-1, 16, 16]               0
      BatchNorm1d-55               [-1, 16, 16]              32
             ReLU-56               [-1, 16, 16]               0
          Dropout-57               [-1, 16, 16]               0
           Conv1d-58               [-1, 16, 16]             528
  MyConv1dPadSame-59               [-1, 16, 16]               0
       Bottleneck-60               [-1, 16, 16]               0
      BatchNorm1d-61               [-1, 16, 16]              32
             ReLU-62               [-1, 16, 16]               0
          Dropout-63               [-1, 16, 16]               0
           Conv1d-64                [-1, 16, 8]             528
  MyConv1dPadSame-65                [-1, 16, 8]               0
      BatchNorm1d-66                [-1, 16, 8]              32
             ReLU-67                [-1, 16, 8]               0
          Dropout-68                [-1, 16, 8]               0
           Conv1d-69                [-1, 16, 8]             528
  MyConv1dPadSame-70                [-1, 16, 8]               0
        MaxPool1d-71                [-1, 16, 8]               0
MyMaxPool1dPadSame-72                [-1, 16, 8]               0
       Bottleneck-73                [-1, 16, 8]               0
      BatchNorm1d-74                [-1, 16, 8]              32
             ReLU-75                [-1, 16, 8]               0
          Dropout-76                [-1, 16, 8]               0
           Conv1d-77                [-1, 16, 8]             528
  MyConv1dPadSame-78                [-1, 16, 8]               0
      BatchNorm1d-79                [-1, 16, 8]              32
             ReLU-80                [-1, 16, 8]               0
          Dropout-81                [-1, 16, 8]               0
           Conv1d-82                [-1, 16, 8]             528
  MyConv1dPadSame-83                [-1, 16, 8]               0
       Bottleneck-84                [-1, 16, 8]               0
      BatchNorm1d-85                [-1, 16, 8]              32
             ReLU-86                [-1, 16, 8]               0
          Dropout-87                [-1, 16, 8]               0
           Conv1d-88                [-1, 16, 4]             528
  MyConv1dPadSame-89                [-1, 16, 4]               0
      BatchNorm1d-90                [-1, 16, 4]              32
             ReLU-91                [-1, 16, 4]               0
          Dropout-92                [-1, 16, 4]               0
           Conv1d-93                [-1, 16, 4]             528
  MyConv1dPadSame-94                [-1, 16, 4]               0
        MaxPool1d-95                [-1, 16, 4]               0
MyMaxPool1dPadSame-96                [-1, 16, 4]               0
       Bottleneck-97                [-1, 16, 4]               0
      BatchNorm1d-98                [-1, 16, 4]              32
             ReLU-99                [-1, 16, 4]               0
         Dropout-100                [-1, 16, 4]               0
          Conv1d-101                [-1, 32, 4]           1,056
 MyConv1dPadSame-102                [-1, 32, 4]               0
     BatchNorm1d-103                [-1, 32, 4]              64
            ReLU-104                [-1, 32, 4]               0
         Dropout-105                [-1, 32, 4]               0
          Conv1d-106                [-1, 32, 4]           2,080
 MyConv1dPadSame-107                [-1, 32, 4]               0
      Bottleneck-108                [-1, 32, 4]               0
     BatchNorm1d-109                [-1, 32, 4]              64
            ReLU-110                [-1, 32, 4]               0
         Dropout-111                [-1, 32, 4]               0
          Conv1d-112                [-1, 32, 2]           2,080
 MyConv1dPadSame-113                [-1, 32, 2]               0
     BatchNorm1d-114                [-1, 32, 2]              64
            ReLU-115                [-1, 32, 2]               0
         Dropout-116                [-1, 32, 2]               0
          Conv1d-117                [-1, 32, 2]           2,080
 MyConv1dPadSame-118                [-1, 32, 2]               0
       MaxPool1d-119                [-1, 32, 2]               0
MyMaxPool1dPadSame-120                [-1, 32, 2]               0
      Bottleneck-121                [-1, 32, 2]               0
     BatchNorm1d-122                [-1, 32, 2]              64
            ReLU-123                [-1, 32, 2]               0
         Dropout-124                [-1, 32, 2]               0
          Conv1d-125                [-1, 32, 2]           2,080
 MyConv1dPadSame-126                [-1, 32, 2]               0
     BatchNorm1d-127                [-1, 32, 2]              64
            ReLU-128                [-1, 32, 2]               0
         Dropout-129                [-1, 32, 2]               0
          Conv1d-130                [-1, 32, 2]           2,080
 MyConv1dPadSame-131                [-1, 32, 2]               0
      Bottleneck-132                [-1, 32, 2]               0
     BatchNorm1d-133                [-1, 32, 2]              64
            ReLU-134                [-1, 32, 2]               0
         Dropout-135                [-1, 32, 2]               0
          Conv1d-136                [-1, 32, 1]           2,080
 MyConv1dPadSame-137                [-1, 32, 1]               0
     BatchNorm1d-138                [-1, 32, 1]              64
            ReLU-139                [-1, 32, 1]               0
         Dropout-140                [-1, 32, 1]               0
          Conv1d-141                [-1, 32, 1]           2,080
 MyConv1dPadSame-142                [-1, 32, 1]               0
       MaxPool1d-143                [-1, 32, 1]               0
MyMaxPool1dPadSame-144                [-1, 32, 1]               0
      Bottleneck-145                [-1, 32, 1]               0
     BatchNorm1d-146                [-1, 32, 1]              64
            ReLU-147                [-1, 32, 1]               0
         Dropout-148                [-1, 32, 1]               0
          Conv1d-149                [-1, 64, 1]           4,160
 MyConv1dPadSame-150                [-1, 64, 1]               0
     BatchNorm1d-151                [-1, 64, 1]             128
            ReLU-152                [-1, 64, 1]               0
         Dropout-153                [-1, 64, 1]               0
          Conv1d-154                [-1, 64, 1]           8,256
 MyConv1dPadSame-155                [-1, 64, 1]               0
      Bottleneck-156                [-1, 64, 1]               0
     BatchNorm1d-157                [-1, 64, 1]             128
            ReLU-158                [-1, 64, 1]               0
         Dropout-159                [-1, 64, 1]               0
          Conv1d-160                [-1, 64, 1]           8,256
 MyConv1dPadSame-161                [-1, 64, 1]               0
     BatchNorm1d-162                [-1, 64, 1]             128
            ReLU-163                [-1, 64, 1]               0
         Dropout-164                [-1, 64, 1]               0
          Conv1d-165                [-1, 64, 1]           8,256
 MyConv1dPadSame-166                [-1, 64, 1]               0
       MaxPool1d-167                [-1, 64, 1]               0
MyMaxPool1dPadSame-168                [-1, 64, 1]               0
      Bottleneck-169                [-1, 64, 1]               0
     BatchNorm1d-170                [-1, 64, 1]             128
            ReLU-171                [-1, 64, 1]               0
         Dropout-172                [-1, 64, 1]               0
          Conv1d-173                [-1, 64, 1]           8,256
 MyConv1dPadSame-174                [-1, 64, 1]               0
     BatchNorm1d-175                [-1, 64, 1]             128
            ReLU-176                [-1, 64, 1]               0
         Dropout-177                [-1, 64, 1]               0
          Conv1d-178                [-1, 64, 1]           8,256
 MyConv1dPadSame-179                [-1, 64, 1]               0
      Bottleneck-180                [-1, 64, 1]               0
     BatchNorm1d-181                [-1, 64, 1]             128
            ReLU-182                [-1, 64, 1]               0
         Dropout-183                [-1, 64, 1]               0
          Conv1d-184                [-1, 64, 1]           8,256
 MyConv1dPadSame-185                [-1, 64, 1]               0
     BatchNorm1d-186                [-1, 64, 1]             128
            ReLU-187                [-1, 64, 1]               0
         Dropout-188                [-1, 64, 1]               0
          Conv1d-189                [-1, 64, 1]           8,256
 MyConv1dPadSame-190                [-1, 64, 1]               0
       MaxPool1d-191                [-1, 64, 1]               0
MyMaxPool1dPadSame-192                [-1, 64, 1]               0
      Bottleneck-193                [-1, 64, 1]               0
     BatchNorm1d-194                [-1, 64, 1]             128
            ReLU-195                [-1, 64, 1]               0
          Linear-196                    [-1, 2]             130
================================================================
Total params: 84,826
Trainable params: 84,826
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.22
Params size (MB): 0.32
Estimated Total Size (MB): 0.54
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 16, kernel_size: 2, n_block: 2
************************************************************
************************************************************
(2000, 1, 64) Counter({0: 1000, 1: 1000})
(2000, 1, 64) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 16, 64]              48
   MyConv1dPadSame-2               [-1, 16, 64]               0
       BatchNorm1d-3               [-1, 16, 64]              32
              ReLU-4               [-1, 16, 64]               0
            Conv1d-5               [-1, 16, 64]              48
   MyConv1dPadSame-6               [-1, 16, 64]               0
       BatchNorm1d-7               [-1, 16, 64]              32
              ReLU-8               [-1, 16, 64]               0
           Dropout-9               [-1, 16, 64]               0
           Conv1d-10               [-1, 16, 64]              48
  MyConv1dPadSame-11               [-1, 16, 64]               0
       Bottleneck-12               [-1, 16, 64]               0
      BatchNorm1d-13               [-1, 16, 64]              32
             ReLU-14               [-1, 16, 64]               0
          Dropout-15               [-1, 16, 64]               0
           Conv1d-16               [-1, 32, 64]              96
  MyConv1dPadSame-17               [-1, 32, 64]               0
      BatchNorm1d-18               [-1, 32, 64]              64
             ReLU-19               [-1, 32, 64]               0
          Dropout-20               [-1, 32, 64]               0
           Conv1d-21               [-1, 32, 64]             160
  MyConv1dPadSame-22               [-1, 32, 64]               0
       Bottleneck-23               [-1, 32, 64]               0
      BatchNorm1d-24               [-1, 32, 64]              64
             ReLU-25               [-1, 32, 64]               0
           Linear-26                    [-1, 2]              66
================================================================
Total params: 690
Trainable params: 690
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.27
Params size (MB): 0.00
Estimated Total Size (MB): 0.28
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 16, kernel_size: 2, n_block: 4
************************************************************
************************************************************
(2000, 1, 64) Counter({1: 1000, 0: 1000})
(2000, 1, 64) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 16, 64]              48
   MyConv1dPadSame-2               [-1, 16, 64]               0
       BatchNorm1d-3               [-1, 16, 64]              32
              ReLU-4               [-1, 16, 64]               0
            Conv1d-5               [-1, 16, 64]              48
   MyConv1dPadSame-6               [-1, 16, 64]               0
       BatchNorm1d-7               [-1, 16, 64]              32
              ReLU-8               [-1, 16, 64]               0
           Dropout-9               [-1, 16, 64]               0
           Conv1d-10               [-1, 16, 64]              48
  MyConv1dPadSame-11               [-1, 16, 64]               0
       Bottleneck-12               [-1, 16, 64]               0
      BatchNorm1d-13               [-1, 16, 64]              32
             ReLU-14               [-1, 16, 64]               0
          Dropout-15               [-1, 16, 64]               0
           Conv1d-16               [-1, 32, 64]              96
  MyConv1dPadSame-17               [-1, 32, 64]               0
      BatchNorm1d-18               [-1, 32, 64]              64
             ReLU-19               [-1, 32, 64]               0
          Dropout-20               [-1, 32, 64]               0
           Conv1d-21               [-1, 32, 64]             160
  MyConv1dPadSame-22               [-1, 32, 64]               0
       Bottleneck-23               [-1, 32, 64]               0
      BatchNorm1d-24               [-1, 32, 64]              64
             ReLU-25               [-1, 32, 64]               0
          Dropout-26               [-1, 32, 64]               0
           Conv1d-27               [-1, 64, 64]             320
  MyConv1dPadSame-28               [-1, 64, 64]               0
      BatchNorm1d-29               [-1, 64, 64]             128
             ReLU-30               [-1, 64, 64]               0
          Dropout-31               [-1, 64, 64]               0
           Conv1d-32               [-1, 64, 64]             576
  MyConv1dPadSame-33               [-1, 64, 64]               0
       Bottleneck-34               [-1, 64, 64]               0
      BatchNorm1d-35               [-1, 64, 64]             128
             ReLU-36               [-1, 64, 64]               0
          Dropout-37               [-1, 64, 64]               0
           Conv1d-38              [-1, 128, 64]           1,152
  MyConv1dPadSame-39              [-1, 128, 64]               0
      BatchNorm1d-40              [-1, 128, 64]             256
             ReLU-41              [-1, 128, 64]               0
          Dropout-42              [-1, 128, 64]               0
           Conv1d-43              [-1, 128, 64]           2,176
  MyConv1dPadSame-44              [-1, 128, 64]               0
       Bottleneck-45              [-1, 128, 64]               0
      BatchNorm1d-46              [-1, 128, 64]             256
             ReLU-47              [-1, 128, 64]               0
           Linear-48                    [-1, 2]             258
================================================================
Total params: 5,874
Trainable params: 5,874
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 1.26
Params size (MB): 0.02
Estimated Total Size (MB): 1.28
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 16, kernel_size: 2, n_block: 8
************************************************************
************************************************************
(2000, 1, 64) Counter({1: 1000, 0: 1000})
(2000, 1, 64) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 16, 64]              48
   MyConv1dPadSame-2               [-1, 16, 64]               0
       BatchNorm1d-3               [-1, 16, 64]              32
              ReLU-4               [-1, 16, 64]               0
            Conv1d-5               [-1, 16, 64]              48
   MyConv1dPadSame-6               [-1, 16, 64]               0
       BatchNorm1d-7               [-1, 16, 64]              32
              ReLU-8               [-1, 16, 64]               0
           Dropout-9               [-1, 16, 64]               0
           Conv1d-10               [-1, 16, 64]              48
  MyConv1dPadSame-11               [-1, 16, 64]               0
       Bottleneck-12               [-1, 16, 64]               0
      BatchNorm1d-13               [-1, 16, 64]              32
             ReLU-14               [-1, 16, 64]               0
          Dropout-15               [-1, 16, 64]               0
           Conv1d-16               [-1, 16, 64]              48
  MyConv1dPadSame-17               [-1, 16, 64]               0
      BatchNorm1d-18               [-1, 16, 64]              32
             ReLU-19               [-1, 16, 64]               0
          Dropout-20               [-1, 16, 64]               0
           Conv1d-21               [-1, 16, 64]              48
  MyConv1dPadSame-22               [-1, 16, 64]               0
       Bottleneck-23               [-1, 16, 64]               0
      BatchNorm1d-24               [-1, 16, 64]              32
             ReLU-25               [-1, 16, 64]               0
          Dropout-26               [-1, 16, 64]               0
           Conv1d-27               [-1, 32, 64]              96
  MyConv1dPadSame-28               [-1, 32, 64]               0
      BatchNorm1d-29               [-1, 32, 64]              64
             ReLU-30               [-1, 32, 64]               0
          Dropout-31               [-1, 32, 64]               0
           Conv1d-32               [-1, 32, 64]             160
  MyConv1dPadSame-33               [-1, 32, 64]               0
       Bottleneck-34               [-1, 32, 64]               0
      BatchNorm1d-35               [-1, 32, 64]              64
             ReLU-36               [-1, 32, 64]               0
          Dropout-37               [-1, 32, 64]               0
           Conv1d-38               [-1, 32, 64]             160
  MyConv1dPadSame-39               [-1, 32, 64]               0
      BatchNorm1d-40               [-1, 32, 64]              64
             ReLU-41               [-1, 32, 64]               0
          Dropout-42               [-1, 32, 64]               0
           Conv1d-43               [-1, 32, 64]             160
  MyConv1dPadSame-44               [-1, 32, 64]               0
       Bottleneck-45               [-1, 32, 64]               0
      BatchNorm1d-46               [-1, 32, 64]              64
             ReLU-47               [-1, 32, 64]               0
          Dropout-48               [-1, 32, 64]               0
           Conv1d-49               [-1, 64, 64]             320
  MyConv1dPadSame-50               [-1, 64, 64]               0
      BatchNorm1d-51               [-1, 64, 64]             128
             ReLU-52               [-1, 64, 64]               0
          Dropout-53               [-1, 64, 64]               0
           Conv1d-54               [-1, 64, 64]             576
  MyConv1dPadSame-55               [-1, 64, 64]               0
       Bottleneck-56               [-1, 64, 64]               0
      BatchNorm1d-57               [-1, 64, 64]             128
             ReLU-58               [-1, 64, 64]               0
          Dropout-59               [-1, 64, 64]               0
           Conv1d-60               [-1, 64, 64]             576
  MyConv1dPadSame-61               [-1, 64, 64]               0
      BatchNorm1d-62               [-1, 64, 64]             128
             ReLU-63               [-1, 64, 64]               0
          Dropout-64               [-1, 64, 64]               0
           Conv1d-65               [-1, 64, 64]             576
  MyConv1dPadSame-66               [-1, 64, 64]               0
       Bottleneck-67               [-1, 64, 64]               0
      BatchNorm1d-68               [-1, 64, 64]             128
             ReLU-69               [-1, 64, 64]               0
          Dropout-70               [-1, 64, 64]               0
           Conv1d-71              [-1, 128, 64]           1,152
  MyConv1dPadSame-72              [-1, 128, 64]               0
      BatchNorm1d-73              [-1, 128, 64]             256
             ReLU-74              [-1, 128, 64]               0
          Dropout-75              [-1, 128, 64]               0
           Conv1d-76              [-1, 128, 64]           2,176
  MyConv1dPadSame-77              [-1, 128, 64]               0
       Bottleneck-78              [-1, 128, 64]               0
      BatchNorm1d-79              [-1, 128, 64]             256
             ReLU-80              [-1, 128, 64]               0
          Dropout-81              [-1, 128, 64]               0
           Conv1d-82              [-1, 128, 64]           2,176
  MyConv1dPadSame-83              [-1, 128, 64]               0
      BatchNorm1d-84              [-1, 128, 64]             256
             ReLU-85              [-1, 128, 64]               0
          Dropout-86              [-1, 128, 64]               0
           Conv1d-87              [-1, 128, 64]           2,176
  MyConv1dPadSame-88              [-1, 128, 64]               0
       Bottleneck-89              [-1, 128, 64]               0
      BatchNorm1d-90              [-1, 128, 64]             256
             ReLU-91              [-1, 128, 64]               0
           Linear-92                    [-1, 2]             258
================================================================
Total params: 12,754
Trainable params: 12,754
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 2.55
Params size (MB): 0.05
Estimated Total Size (MB): 2.60
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 16, kernel_size: 2, n_block: 16
************************************************************
************************************************************
(2000, 1, 64) Counter({0: 1000, 1: 1000})
(2000, 1, 64) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 16, 64]              48
   MyConv1dPadSame-2               [-1, 16, 64]               0
       BatchNorm1d-3               [-1, 16, 64]              32
              ReLU-4               [-1, 16, 64]               0
            Conv1d-5               [-1, 16, 64]              48
   MyConv1dPadSame-6               [-1, 16, 64]               0
       BatchNorm1d-7               [-1, 16, 64]              32
              ReLU-8               [-1, 16, 64]               0
           Dropout-9               [-1, 16, 64]               0
           Conv1d-10               [-1, 16, 64]              48
  MyConv1dPadSame-11               [-1, 16, 64]               0
       Bottleneck-12               [-1, 16, 64]               0
      BatchNorm1d-13               [-1, 16, 64]              32
             ReLU-14               [-1, 16, 64]               0
          Dropout-15               [-1, 16, 64]               0
           Conv1d-16               [-1, 16, 32]              48
  MyConv1dPadSame-17               [-1, 16, 32]               0
      BatchNorm1d-18               [-1, 16, 32]              32
             ReLU-19               [-1, 16, 32]               0
          Dropout-20               [-1, 16, 32]               0
           Conv1d-21               [-1, 16, 32]              48
  MyConv1dPadSame-22               [-1, 16, 32]               0
        MaxPool1d-23               [-1, 16, 32]               0
MyMaxPool1dPadSame-24               [-1, 16, 32]               0
       Bottleneck-25               [-1, 16, 32]               0
      BatchNorm1d-26               [-1, 16, 32]              32
             ReLU-27               [-1, 16, 32]               0
          Dropout-28               [-1, 16, 32]               0
           Conv1d-29               [-1, 16, 32]              48
  MyConv1dPadSame-30               [-1, 16, 32]               0
      BatchNorm1d-31               [-1, 16, 32]              32
             ReLU-32               [-1, 16, 32]               0
          Dropout-33               [-1, 16, 32]               0
           Conv1d-34               [-1, 16, 32]              48
  MyConv1dPadSame-35               [-1, 16, 32]               0
       Bottleneck-36               [-1, 16, 32]               0
      BatchNorm1d-37               [-1, 16, 32]              32
             ReLU-38               [-1, 16, 32]               0
          Dropout-39               [-1, 16, 32]               0
           Conv1d-40               [-1, 16, 16]              48
  MyConv1dPadSame-41               [-1, 16, 16]               0
      BatchNorm1d-42               [-1, 16, 16]              32
             ReLU-43               [-1, 16, 16]               0
          Dropout-44               [-1, 16, 16]               0
           Conv1d-45               [-1, 16, 16]              48
  MyConv1dPadSame-46               [-1, 16, 16]               0
        MaxPool1d-47               [-1, 16, 16]               0
MyMaxPool1dPadSame-48               [-1, 16, 16]               0
       Bottleneck-49               [-1, 16, 16]               0
      BatchNorm1d-50               [-1, 16, 16]              32
             ReLU-51               [-1, 16, 16]               0
          Dropout-52               [-1, 16, 16]               0
           Conv1d-53               [-1, 32, 16]              96
  MyConv1dPadSame-54               [-1, 32, 16]               0
      BatchNorm1d-55               [-1, 32, 16]              64
             ReLU-56               [-1, 32, 16]               0
          Dropout-57               [-1, 32, 16]               0
           Conv1d-58               [-1, 32, 16]             160
  MyConv1dPadSame-59               [-1, 32, 16]               0
       Bottleneck-60               [-1, 32, 16]               0
      BatchNorm1d-61               [-1, 32, 16]              64
             ReLU-62               [-1, 32, 16]               0
          Dropout-63               [-1, 32, 16]               0
           Conv1d-64                [-1, 32, 8]             160
  MyConv1dPadSame-65                [-1, 32, 8]               0
      BatchNorm1d-66                [-1, 32, 8]              64
             ReLU-67                [-1, 32, 8]               0
          Dropout-68                [-1, 32, 8]               0
           Conv1d-69                [-1, 32, 8]             160
  MyConv1dPadSame-70                [-1, 32, 8]               0
        MaxPool1d-71                [-1, 32, 8]               0
MyMaxPool1dPadSame-72                [-1, 32, 8]               0
       Bottleneck-73                [-1, 32, 8]               0
      BatchNorm1d-74                [-1, 32, 8]              64
             ReLU-75                [-1, 32, 8]               0
          Dropout-76                [-1, 32, 8]               0
           Conv1d-77                [-1, 32, 8]             160
  MyConv1dPadSame-78                [-1, 32, 8]               0
      BatchNorm1d-79                [-1, 32, 8]              64
             ReLU-80                [-1, 32, 8]               0
          Dropout-81                [-1, 32, 8]               0
           Conv1d-82                [-1, 32, 8]             160
  MyConv1dPadSame-83                [-1, 32, 8]               0
       Bottleneck-84                [-1, 32, 8]               0
      BatchNorm1d-85                [-1, 32, 8]              64
             ReLU-86                [-1, 32, 8]               0
          Dropout-87                [-1, 32, 8]               0
           Conv1d-88                [-1, 32, 4]             160
  MyConv1dPadSame-89                [-1, 32, 4]               0
      BatchNorm1d-90                [-1, 32, 4]              64
             ReLU-91                [-1, 32, 4]               0
          Dropout-92                [-1, 32, 4]               0
           Conv1d-93                [-1, 32, 4]             160
  MyConv1dPadSame-94                [-1, 32, 4]               0
        MaxPool1d-95                [-1, 32, 4]               0
MyMaxPool1dPadSame-96                [-1, 32, 4]               0
       Bottleneck-97                [-1, 32, 4]               0
      BatchNorm1d-98                [-1, 32, 4]              64
             ReLU-99                [-1, 32, 4]               0
         Dropout-100                [-1, 32, 4]               0
          Conv1d-101                [-1, 64, 4]             320
 MyConv1dPadSame-102                [-1, 64, 4]               0
     BatchNorm1d-103                [-1, 64, 4]             128
            ReLU-104                [-1, 64, 4]               0
         Dropout-105                [-1, 64, 4]               0
          Conv1d-106                [-1, 64, 4]             576
 MyConv1dPadSame-107                [-1, 64, 4]               0
      Bottleneck-108                [-1, 64, 4]               0
     BatchNorm1d-109                [-1, 64, 4]             128
            ReLU-110                [-1, 64, 4]               0
         Dropout-111                [-1, 64, 4]               0
          Conv1d-112                [-1, 64, 2]             576
 MyConv1dPadSame-113                [-1, 64, 2]               0
     BatchNorm1d-114                [-1, 64, 2]             128
            ReLU-115                [-1, 64, 2]               0
         Dropout-116                [-1, 64, 2]               0
          Conv1d-117                [-1, 64, 2]             576
 MyConv1dPadSame-118                [-1, 64, 2]               0
       MaxPool1d-119                [-1, 64, 2]               0
MyMaxPool1dPadSame-120                [-1, 64, 2]               0
      Bottleneck-121                [-1, 64, 2]               0
     BatchNorm1d-122                [-1, 64, 2]             128
            ReLU-123                [-1, 64, 2]               0
         Dropout-124                [-1, 64, 2]               0
          Conv1d-125                [-1, 64, 2]             576
 MyConv1dPadSame-126                [-1, 64, 2]               0
     BatchNorm1d-127                [-1, 64, 2]             128
            ReLU-128                [-1, 64, 2]               0
         Dropout-129                [-1, 64, 2]               0
          Conv1d-130                [-1, 64, 2]             576
 MyConv1dPadSame-131                [-1, 64, 2]               0
      Bottleneck-132                [-1, 64, 2]               0
     BatchNorm1d-133                [-1, 64, 2]             128
            ReLU-134                [-1, 64, 2]               0
         Dropout-135                [-1, 64, 2]               0
          Conv1d-136                [-1, 64, 1]             576
 MyConv1dPadSame-137                [-1, 64, 1]               0
     BatchNorm1d-138                [-1, 64, 1]             128
            ReLU-139                [-1, 64, 1]               0
         Dropout-140                [-1, 64, 1]               0
          Conv1d-141                [-1, 64, 1]             576
 MyConv1dPadSame-142                [-1, 64, 1]               0
       MaxPool1d-143                [-1, 64, 1]               0
MyMaxPool1dPadSame-144                [-1, 64, 1]               0
      Bottleneck-145                [-1, 64, 1]               0
     BatchNorm1d-146                [-1, 64, 1]             128
            ReLU-147                [-1, 64, 1]               0
         Dropout-148                [-1, 64, 1]               0
          Conv1d-149               [-1, 128, 1]           1,152
 MyConv1dPadSame-150               [-1, 128, 1]               0
     BatchNorm1d-151               [-1, 128, 1]             256
            ReLU-152               [-1, 128, 1]               0
         Dropout-153               [-1, 128, 1]               0
          Conv1d-154               [-1, 128, 1]           2,176
 MyConv1dPadSame-155               [-1, 128, 1]               0
      Bottleneck-156               [-1, 128, 1]               0
     BatchNorm1d-157               [-1, 128, 1]             256
            ReLU-158               [-1, 128, 1]               0
         Dropout-159               [-1, 128, 1]               0
          Conv1d-160               [-1, 128, 1]           2,176
 MyConv1dPadSame-161               [-1, 128, 1]               0
     BatchNorm1d-162               [-1, 128, 1]             256
            ReLU-163               [-1, 128, 1]               0
         Dropout-164               [-1, 128, 1]               0
          Conv1d-165               [-1, 128, 1]           2,176
 MyConv1dPadSame-166               [-1, 128, 1]               0
       MaxPool1d-167               [-1, 128, 1]               0
MyMaxPool1dPadSame-168               [-1, 128, 1]               0
      Bottleneck-169               [-1, 128, 1]               0
     BatchNorm1d-170               [-1, 128, 1]             256
            ReLU-171               [-1, 128, 1]               0
         Dropout-172               [-1, 128, 1]               0
          Conv1d-173               [-1, 128, 1]           2,176
 MyConv1dPadSame-174               [-1, 128, 1]               0
     BatchNorm1d-175               [-1, 128, 1]             256
            ReLU-176               [-1, 128, 1]               0
         Dropout-177               [-1, 128, 1]               0
          Conv1d-178               [-1, 128, 1]           2,176
 MyConv1dPadSame-179               [-1, 128, 1]               0
      Bottleneck-180               [-1, 128, 1]               0
     BatchNorm1d-181               [-1, 128, 1]             256
            ReLU-182               [-1, 128, 1]               0
         Dropout-183               [-1, 128, 1]               0
          Conv1d-184               [-1, 128, 1]           2,176
 MyConv1dPadSame-185               [-1, 128, 1]               0
     BatchNorm1d-186               [-1, 128, 1]             256
            ReLU-187               [-1, 128, 1]               0
         Dropout-188               [-1, 128, 1]               0
          Conv1d-189               [-1, 128, 1]           2,176
 MyConv1dPadSame-190               [-1, 128, 1]               0
       MaxPool1d-191               [-1, 128, 1]               0
MyMaxPool1dPadSame-192               [-1, 128, 1]               0
      Bottleneck-193               [-1, 128, 1]               0
     BatchNorm1d-194               [-1, 128, 1]             256
            ReLU-195               [-1, 128, 1]               0
          Linear-196                    [-1, 2]             258
================================================================
Total params: 26,514
Trainable params: 26,514
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.44
Params size (MB): 0.10
Estimated Total Size (MB): 0.54
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 16, kernel_size: 4, n_block: 2
************************************************************
************************************************************
(2000, 1, 64) Counter({0: 1000, 1: 1000})
(2000, 1, 64) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 16, 64]              80
   MyConv1dPadSame-2               [-1, 16, 64]               0
       BatchNorm1d-3               [-1, 16, 64]              32
              ReLU-4               [-1, 16, 64]               0
            Conv1d-5               [-1, 16, 64]              80
   MyConv1dPadSame-6               [-1, 16, 64]               0
       BatchNorm1d-7               [-1, 16, 64]              32
              ReLU-8               [-1, 16, 64]               0
           Dropout-9               [-1, 16, 64]               0
           Conv1d-10               [-1, 16, 64]              80
  MyConv1dPadSame-11               [-1, 16, 64]               0
       Bottleneck-12               [-1, 16, 64]               0
      BatchNorm1d-13               [-1, 16, 64]              32
             ReLU-14               [-1, 16, 64]               0
          Dropout-15               [-1, 16, 64]               0
           Conv1d-16               [-1, 32, 64]             160
  MyConv1dPadSame-17               [-1, 32, 64]               0
      BatchNorm1d-18               [-1, 32, 64]              64
             ReLU-19               [-1, 32, 64]               0
          Dropout-20               [-1, 32, 64]               0
           Conv1d-21               [-1, 32, 64]             288
  MyConv1dPadSame-22               [-1, 32, 64]               0
       Bottleneck-23               [-1, 32, 64]               0
      BatchNorm1d-24               [-1, 32, 64]              64
             ReLU-25               [-1, 32, 64]               0
           Linear-26                    [-1, 2]              66
================================================================
Total params: 978
Trainable params: 978
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.27
Params size (MB): 0.00
Estimated Total Size (MB): 0.28
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 16, kernel_size: 4, n_block: 4
************************************************************
************************************************************
(2000, 1, 64) Counter({1: 1000, 0: 1000})
(2000, 1, 64) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 16, 64]              80
   MyConv1dPadSame-2               [-1, 16, 64]               0
       BatchNorm1d-3               [-1, 16, 64]              32
              ReLU-4               [-1, 16, 64]               0
            Conv1d-5               [-1, 16, 64]              80
   MyConv1dPadSame-6               [-1, 16, 64]               0
       BatchNorm1d-7               [-1, 16, 64]              32
              ReLU-8               [-1, 16, 64]               0
           Dropout-9               [-1, 16, 64]               0
           Conv1d-10               [-1, 16, 64]              80
  MyConv1dPadSame-11               [-1, 16, 64]               0
       Bottleneck-12               [-1, 16, 64]               0
      BatchNorm1d-13               [-1, 16, 64]              32
             ReLU-14               [-1, 16, 64]               0
          Dropout-15               [-1, 16, 64]               0
           Conv1d-16               [-1, 32, 64]             160
  MyConv1dPadSame-17               [-1, 32, 64]               0
      BatchNorm1d-18               [-1, 32, 64]              64
             ReLU-19               [-1, 32, 64]               0
          Dropout-20               [-1, 32, 64]               0
           Conv1d-21               [-1, 32, 64]             288
  MyConv1dPadSame-22               [-1, 32, 64]               0
       Bottleneck-23               [-1, 32, 64]               0
      BatchNorm1d-24               [-1, 32, 64]              64
             ReLU-25               [-1, 32, 64]               0
          Dropout-26               [-1, 32, 64]               0
           Conv1d-27               [-1, 64, 64]             576
  MyConv1dPadSame-28               [-1, 64, 64]               0
      BatchNorm1d-29               [-1, 64, 64]             128
             ReLU-30               [-1, 64, 64]               0
          Dropout-31               [-1, 64, 64]               0
           Conv1d-32               [-1, 64, 64]           1,088
  MyConv1dPadSame-33               [-1, 64, 64]               0
       Bottleneck-34               [-1, 64, 64]               0
      BatchNorm1d-35               [-1, 64, 64]             128
             ReLU-36               [-1, 64, 64]               0
          Dropout-37               [-1, 64, 64]               0
           Conv1d-38              [-1, 128, 64]           2,176
  MyConv1dPadSame-39              [-1, 128, 64]               0
      BatchNorm1d-40              [-1, 128, 64]             256
             ReLU-41              [-1, 128, 64]               0
          Dropout-42              [-1, 128, 64]               0
           Conv1d-43              [-1, 128, 64]           4,224
  MyConv1dPadSame-44              [-1, 128, 64]               0
       Bottleneck-45              [-1, 128, 64]               0
      BatchNorm1d-46              [-1, 128, 64]             256
             ReLU-47              [-1, 128, 64]               0
           Linear-48                    [-1, 2]             258
================================================================
Total params: 10,002
Trainable params: 10,002
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 1.26
Params size (MB): 0.04
Estimated Total Size (MB): 1.30
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 16, kernel_size: 4, n_block: 8
************************************************************
************************************************************
(2000, 1, 64) Counter({0: 1000, 1: 1000})
(2000, 1, 64) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 16, 64]              80
   MyConv1dPadSame-2               [-1, 16, 64]               0
       BatchNorm1d-3               [-1, 16, 64]              32
              ReLU-4               [-1, 16, 64]               0
            Conv1d-5               [-1, 16, 64]              80
   MyConv1dPadSame-6               [-1, 16, 64]               0
       BatchNorm1d-7               [-1, 16, 64]              32
              ReLU-8               [-1, 16, 64]               0
           Dropout-9               [-1, 16, 64]               0
           Conv1d-10               [-1, 16, 64]              80
  MyConv1dPadSame-11               [-1, 16, 64]               0
       Bottleneck-12               [-1, 16, 64]               0
      BatchNorm1d-13               [-1, 16, 64]              32
             ReLU-14               [-1, 16, 64]               0
          Dropout-15               [-1, 16, 64]               0
           Conv1d-16               [-1, 16, 64]              80
  MyConv1dPadSame-17               [-1, 16, 64]               0
      BatchNorm1d-18               [-1, 16, 64]              32
             ReLU-19               [-1, 16, 64]               0
          Dropout-20               [-1, 16, 64]               0
           Conv1d-21               [-1, 16, 64]              80
  MyConv1dPadSame-22               [-1, 16, 64]               0
       Bottleneck-23               [-1, 16, 64]               0
      BatchNorm1d-24               [-1, 16, 64]              32
             ReLU-25               [-1, 16, 64]               0
          Dropout-26               [-1, 16, 64]               0
           Conv1d-27               [-1, 32, 64]             160
  MyConv1dPadSame-28               [-1, 32, 64]               0
      BatchNorm1d-29               [-1, 32, 64]              64
             ReLU-30               [-1, 32, 64]               0
          Dropout-31               [-1, 32, 64]               0
           Conv1d-32               [-1, 32, 64]             288
  MyConv1dPadSame-33               [-1, 32, 64]               0
       Bottleneck-34               [-1, 32, 64]               0
      BatchNorm1d-35               [-1, 32, 64]              64
             ReLU-36               [-1, 32, 64]               0
          Dropout-37               [-1, 32, 64]               0
           Conv1d-38               [-1, 32, 64]             288
  MyConv1dPadSame-39               [-1, 32, 64]               0
      BatchNorm1d-40               [-1, 32, 64]              64
             ReLU-41               [-1, 32, 64]               0
          Dropout-42               [-1, 32, 64]               0
           Conv1d-43               [-1, 32, 64]             288
  MyConv1dPadSame-44               [-1, 32, 64]               0
       Bottleneck-45               [-1, 32, 64]               0
      BatchNorm1d-46               [-1, 32, 64]              64
             ReLU-47               [-1, 32, 64]               0
          Dropout-48               [-1, 32, 64]               0
           Conv1d-49               [-1, 64, 64]             576
  MyConv1dPadSame-50               [-1, 64, 64]               0
      BatchNorm1d-51               [-1, 64, 64]             128
             ReLU-52               [-1, 64, 64]               0
          Dropout-53               [-1, 64, 64]               0
           Conv1d-54               [-1, 64, 64]           1,088
  MyConv1dPadSame-55               [-1, 64, 64]               0
       Bottleneck-56               [-1, 64, 64]               0
      BatchNorm1d-57               [-1, 64, 64]             128
             ReLU-58               [-1, 64, 64]               0
          Dropout-59               [-1, 64, 64]               0
           Conv1d-60               [-1, 64, 64]           1,088
  MyConv1dPadSame-61               [-1, 64, 64]               0
      BatchNorm1d-62               [-1, 64, 64]             128
             ReLU-63               [-1, 64, 64]               0
          Dropout-64               [-1, 64, 64]               0
           Conv1d-65               [-1, 64, 64]           1,088
  MyConv1dPadSame-66               [-1, 64, 64]               0
       Bottleneck-67               [-1, 64, 64]               0
      BatchNorm1d-68               [-1, 64, 64]             128
             ReLU-69               [-1, 64, 64]               0
          Dropout-70               [-1, 64, 64]               0
           Conv1d-71              [-1, 128, 64]           2,176
  MyConv1dPadSame-72              [-1, 128, 64]               0
      BatchNorm1d-73              [-1, 128, 64]             256
             ReLU-74              [-1, 128, 64]               0
          Dropout-75              [-1, 128, 64]               0
           Conv1d-76              [-1, 128, 64]           4,224
  MyConv1dPadSame-77              [-1, 128, 64]               0
       Bottleneck-78              [-1, 128, 64]               0
      BatchNorm1d-79              [-1, 128, 64]             256
             ReLU-80              [-1, 128, 64]               0
          Dropout-81              [-1, 128, 64]               0
           Conv1d-82              [-1, 128, 64]           4,224
  MyConv1dPadSame-83              [-1, 128, 64]               0
      BatchNorm1d-84              [-1, 128, 64]             256
             ReLU-85              [-1, 128, 64]               0
          Dropout-86              [-1, 128, 64]               0
           Conv1d-87              [-1, 128, 64]           4,224
  MyConv1dPadSame-88              [-1, 128, 64]               0
       Bottleneck-89              [-1, 128, 64]               0
      BatchNorm1d-90              [-1, 128, 64]             256
             ReLU-91              [-1, 128, 64]               0
           Linear-92                    [-1, 2]             258
================================================================
Total params: 22,322
Trainable params: 22,322
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 2.55
Params size (MB): 0.09
Estimated Total Size (MB): 2.63
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 16, kernel_size: 4, n_block: 16
************************************************************
************************************************************
(2000, 1, 64) Counter({1: 1000, 0: 1000})
(2000, 1, 64) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 16, 64]              80
   MyConv1dPadSame-2               [-1, 16, 64]               0
       BatchNorm1d-3               [-1, 16, 64]              32
              ReLU-4               [-1, 16, 64]               0
            Conv1d-5               [-1, 16, 64]              80
   MyConv1dPadSame-6               [-1, 16, 64]               0
       BatchNorm1d-7               [-1, 16, 64]              32
              ReLU-8               [-1, 16, 64]               0
           Dropout-9               [-1, 16, 64]               0
           Conv1d-10               [-1, 16, 64]              80
  MyConv1dPadSame-11               [-1, 16, 64]               0
       Bottleneck-12               [-1, 16, 64]               0
      BatchNorm1d-13               [-1, 16, 64]              32
             ReLU-14               [-1, 16, 64]               0
          Dropout-15               [-1, 16, 64]               0
           Conv1d-16               [-1, 16, 32]              80
  MyConv1dPadSame-17               [-1, 16, 32]               0
      BatchNorm1d-18               [-1, 16, 32]              32
             ReLU-19               [-1, 16, 32]               0
          Dropout-20               [-1, 16, 32]               0
           Conv1d-21               [-1, 16, 32]              80
  MyConv1dPadSame-22               [-1, 16, 32]               0
        MaxPool1d-23               [-1, 16, 32]               0
MyMaxPool1dPadSame-24               [-1, 16, 32]               0
       Bottleneck-25               [-1, 16, 32]               0
      BatchNorm1d-26               [-1, 16, 32]              32
             ReLU-27               [-1, 16, 32]               0
          Dropout-28               [-1, 16, 32]               0
           Conv1d-29               [-1, 16, 32]              80
  MyConv1dPadSame-30               [-1, 16, 32]               0
      BatchNorm1d-31               [-1, 16, 32]              32
             ReLU-32               [-1, 16, 32]               0
          Dropout-33               [-1, 16, 32]               0
           Conv1d-34               [-1, 16, 32]              80
  MyConv1dPadSame-35               [-1, 16, 32]               0
       Bottleneck-36               [-1, 16, 32]               0
      BatchNorm1d-37               [-1, 16, 32]              32
             ReLU-38               [-1, 16, 32]               0
          Dropout-39               [-1, 16, 32]               0
           Conv1d-40               [-1, 16, 16]              80
  MyConv1dPadSame-41               [-1, 16, 16]               0
      BatchNorm1d-42               [-1, 16, 16]              32
             ReLU-43               [-1, 16, 16]               0
          Dropout-44               [-1, 16, 16]               0
           Conv1d-45               [-1, 16, 16]              80
  MyConv1dPadSame-46               [-1, 16, 16]               0
        MaxPool1d-47               [-1, 16, 16]               0
MyMaxPool1dPadSame-48               [-1, 16, 16]               0
       Bottleneck-49               [-1, 16, 16]               0
      BatchNorm1d-50               [-1, 16, 16]              32
             ReLU-51               [-1, 16, 16]               0
          Dropout-52               [-1, 16, 16]               0
           Conv1d-53               [-1, 32, 16]             160
  MyConv1dPadSame-54               [-1, 32, 16]               0
      BatchNorm1d-55               [-1, 32, 16]              64
             ReLU-56               [-1, 32, 16]               0
          Dropout-57               [-1, 32, 16]               0
           Conv1d-58               [-1, 32, 16]             288
  MyConv1dPadSame-59               [-1, 32, 16]               0
       Bottleneck-60               [-1, 32, 16]               0
      BatchNorm1d-61               [-1, 32, 16]              64
             ReLU-62               [-1, 32, 16]               0
          Dropout-63               [-1, 32, 16]               0
           Conv1d-64                [-1, 32, 8]             288
  MyConv1dPadSame-65                [-1, 32, 8]               0
      BatchNorm1d-66                [-1, 32, 8]              64
             ReLU-67                [-1, 32, 8]               0
          Dropout-68                [-1, 32, 8]               0
           Conv1d-69                [-1, 32, 8]             288
  MyConv1dPadSame-70                [-1, 32, 8]               0
        MaxPool1d-71                [-1, 32, 8]               0
MyMaxPool1dPadSame-72                [-1, 32, 8]               0
       Bottleneck-73                [-1, 32, 8]               0
      BatchNorm1d-74                [-1, 32, 8]              64
             ReLU-75                [-1, 32, 8]               0
          Dropout-76                [-1, 32, 8]               0
           Conv1d-77                [-1, 32, 8]             288
  MyConv1dPadSame-78                [-1, 32, 8]               0
      BatchNorm1d-79                [-1, 32, 8]              64
             ReLU-80                [-1, 32, 8]               0
          Dropout-81                [-1, 32, 8]               0
           Conv1d-82                [-1, 32, 8]             288
  MyConv1dPadSame-83                [-1, 32, 8]               0
       Bottleneck-84                [-1, 32, 8]               0
      BatchNorm1d-85                [-1, 32, 8]              64
             ReLU-86                [-1, 32, 8]               0
          Dropout-87                [-1, 32, 8]               0
           Conv1d-88                [-1, 32, 4]             288
  MyConv1dPadSame-89                [-1, 32, 4]               0
      BatchNorm1d-90                [-1, 32, 4]              64
             ReLU-91                [-1, 32, 4]               0
          Dropout-92                [-1, 32, 4]               0
           Conv1d-93                [-1, 32, 4]             288
  MyConv1dPadSame-94                [-1, 32, 4]               0
        MaxPool1d-95                [-1, 32, 4]               0
MyMaxPool1dPadSame-96                [-1, 32, 4]               0
       Bottleneck-97                [-1, 32, 4]               0
      BatchNorm1d-98                [-1, 32, 4]              64
             ReLU-99                [-1, 32, 4]               0
         Dropout-100                [-1, 32, 4]               0
          Conv1d-101                [-1, 64, 4]             576
 MyConv1dPadSame-102                [-1, 64, 4]               0
     BatchNorm1d-103                [-1, 64, 4]             128
            ReLU-104                [-1, 64, 4]               0
         Dropout-105                [-1, 64, 4]               0
          Conv1d-106                [-1, 64, 4]           1,088
 MyConv1dPadSame-107                [-1, 64, 4]               0
      Bottleneck-108                [-1, 64, 4]               0
     BatchNorm1d-109                [-1, 64, 4]             128
            ReLU-110                [-1, 64, 4]               0
         Dropout-111                [-1, 64, 4]               0
          Conv1d-112                [-1, 64, 2]           1,088
 MyConv1dPadSame-113                [-1, 64, 2]               0
     BatchNorm1d-114                [-1, 64, 2]             128
            ReLU-115                [-1, 64, 2]               0
         Dropout-116                [-1, 64, 2]               0
          Conv1d-117                [-1, 64, 2]           1,088
 MyConv1dPadSame-118                [-1, 64, 2]               0
       MaxPool1d-119                [-1, 64, 2]               0
MyMaxPool1dPadSame-120                [-1, 64, 2]               0
      Bottleneck-121                [-1, 64, 2]               0
     BatchNorm1d-122                [-1, 64, 2]             128
            ReLU-123                [-1, 64, 2]               0
         Dropout-124                [-1, 64, 2]               0
          Conv1d-125                [-1, 64, 2]           1,088
 MyConv1dPadSame-126                [-1, 64, 2]               0
     BatchNorm1d-127                [-1, 64, 2]             128
            ReLU-128                [-1, 64, 2]               0
         Dropout-129                [-1, 64, 2]               0
          Conv1d-130                [-1, 64, 2]           1,088
 MyConv1dPadSame-131                [-1, 64, 2]               0
      Bottleneck-132                [-1, 64, 2]               0
     BatchNorm1d-133                [-1, 64, 2]             128
            ReLU-134                [-1, 64, 2]               0
         Dropout-135                [-1, 64, 2]               0
          Conv1d-136                [-1, 64, 1]           1,088
 MyConv1dPadSame-137                [-1, 64, 1]               0
     BatchNorm1d-138                [-1, 64, 1]             128
            ReLU-139                [-1, 64, 1]               0
         Dropout-140                [-1, 64, 1]               0
          Conv1d-141                [-1, 64, 1]           1,088
 MyConv1dPadSame-142                [-1, 64, 1]               0
       MaxPool1d-143                [-1, 64, 1]               0
MyMaxPool1dPadSame-144                [-1, 64, 1]               0
      Bottleneck-145                [-1, 64, 1]               0
     BatchNorm1d-146                [-1, 64, 1]             128
            ReLU-147                [-1, 64, 1]               0
         Dropout-148                [-1, 64, 1]               0
          Conv1d-149               [-1, 128, 1]           2,176
 MyConv1dPadSame-150               [-1, 128, 1]               0
     BatchNorm1d-151               [-1, 128, 1]             256
            ReLU-152               [-1, 128, 1]               0
         Dropout-153               [-1, 128, 1]               0
          Conv1d-154               [-1, 128, 1]           4,224
 MyConv1dPadSame-155               [-1, 128, 1]               0
      Bottleneck-156               [-1, 128, 1]               0
     BatchNorm1d-157               [-1, 128, 1]             256
            ReLU-158               [-1, 128, 1]               0
         Dropout-159               [-1, 128, 1]               0
          Conv1d-160               [-1, 128, 1]           4,224
 MyConv1dPadSame-161               [-1, 128, 1]               0
     BatchNorm1d-162               [-1, 128, 1]             256
            ReLU-163               [-1, 128, 1]               0
         Dropout-164               [-1, 128, 1]               0
          Conv1d-165               [-1, 128, 1]           4,224
 MyConv1dPadSame-166               [-1, 128, 1]               0
       MaxPool1d-167               [-1, 128, 1]               0
MyMaxPool1dPadSame-168               [-1, 128, 1]               0
      Bottleneck-169               [-1, 128, 1]               0
     BatchNorm1d-170               [-1, 128, 1]             256
            ReLU-171               [-1, 128, 1]               0
         Dropout-172               [-1, 128, 1]               0
          Conv1d-173               [-1, 128, 1]           4,224
 MyConv1dPadSame-174               [-1, 128, 1]               0
     BatchNorm1d-175               [-1, 128, 1]             256
            ReLU-176               [-1, 128, 1]               0
         Dropout-177               [-1, 128, 1]               0
          Conv1d-178               [-1, 128, 1]           4,224
 MyConv1dPadSame-179               [-1, 128, 1]               0
      Bottleneck-180               [-1, 128, 1]               0
     BatchNorm1d-181               [-1, 128, 1]             256
            ReLU-182               [-1, 128, 1]               0
         Dropout-183               [-1, 128, 1]               0
          Conv1d-184               [-1, 128, 1]           4,224
 MyConv1dPadSame-185               [-1, 128, 1]               0
     BatchNorm1d-186               [-1, 128, 1]             256
            ReLU-187               [-1, 128, 1]               0
         Dropout-188               [-1, 128, 1]               0
          Conv1d-189               [-1, 128, 1]           4,224
 MyConv1dPadSame-190               [-1, 128, 1]               0
       MaxPool1d-191               [-1, 128, 1]               0
MyMaxPool1dPadSame-192               [-1, 128, 1]               0
      Bottleneck-193               [-1, 128, 1]               0
     BatchNorm1d-194               [-1, 128, 1]             256
            ReLU-195               [-1, 128, 1]               0
          Linear-196                    [-1, 2]             258
================================================================
Total params: 46,962
Trainable params: 46,962
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.44
Params size (MB): 0.18
Estimated Total Size (MB): 0.62
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 16, kernel_size: 8, n_block: 2
************************************************************
************************************************************
(2000, 1, 64) Counter({1: 1000, 0: 1000})
(2000, 1, 64) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 16, 64]             144
   MyConv1dPadSame-2               [-1, 16, 64]               0
       BatchNorm1d-3               [-1, 16, 64]              32
              ReLU-4               [-1, 16, 64]               0
            Conv1d-5               [-1, 16, 64]             144
   MyConv1dPadSame-6               [-1, 16, 64]               0
       BatchNorm1d-7               [-1, 16, 64]              32
              ReLU-8               [-1, 16, 64]               0
           Dropout-9               [-1, 16, 64]               0
           Conv1d-10               [-1, 16, 64]             144
  MyConv1dPadSame-11               [-1, 16, 64]               0
       Bottleneck-12               [-1, 16, 64]               0
      BatchNorm1d-13               [-1, 16, 64]              32
             ReLU-14               [-1, 16, 64]               0
          Dropout-15               [-1, 16, 64]               0
           Conv1d-16               [-1, 32, 64]             288
  MyConv1dPadSame-17               [-1, 32, 64]               0
      BatchNorm1d-18               [-1, 32, 64]              64
             ReLU-19               [-1, 32, 64]               0
          Dropout-20               [-1, 32, 64]               0
           Conv1d-21               [-1, 32, 64]             544
  MyConv1dPadSame-22               [-1, 32, 64]               0
       Bottleneck-23               [-1, 32, 64]               0
      BatchNorm1d-24               [-1, 32, 64]              64
             ReLU-25               [-1, 32, 64]               0
           Linear-26                    [-1, 2]              66
================================================================
Total params: 1,554
Trainable params: 1,554
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.27
Params size (MB): 0.01
Estimated Total Size (MB): 0.28
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 16, kernel_size: 8, n_block: 4
************************************************************
************************************************************
(2000, 1, 64) Counter({1: 1000, 0: 1000})
(2000, 1, 64) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 16, 64]             144
   MyConv1dPadSame-2               [-1, 16, 64]               0
       BatchNorm1d-3               [-1, 16, 64]              32
              ReLU-4               [-1, 16, 64]               0
            Conv1d-5               [-1, 16, 64]             144
   MyConv1dPadSame-6               [-1, 16, 64]               0
       BatchNorm1d-7               [-1, 16, 64]              32
              ReLU-8               [-1, 16, 64]               0
           Dropout-9               [-1, 16, 64]               0
           Conv1d-10               [-1, 16, 64]             144
  MyConv1dPadSame-11               [-1, 16, 64]               0
       Bottleneck-12               [-1, 16, 64]               0
      BatchNorm1d-13               [-1, 16, 64]              32
             ReLU-14               [-1, 16, 64]               0
          Dropout-15               [-1, 16, 64]               0
           Conv1d-16               [-1, 32, 64]             288
  MyConv1dPadSame-17               [-1, 32, 64]               0
      BatchNorm1d-18               [-1, 32, 64]              64
             ReLU-19               [-1, 32, 64]               0
          Dropout-20               [-1, 32, 64]               0
           Conv1d-21               [-1, 32, 64]             544
  MyConv1dPadSame-22               [-1, 32, 64]               0
       Bottleneck-23               [-1, 32, 64]               0
      BatchNorm1d-24               [-1, 32, 64]              64
             ReLU-25               [-1, 32, 64]               0
          Dropout-26               [-1, 32, 64]               0
           Conv1d-27               [-1, 64, 64]           1,088
  MyConv1dPadSame-28               [-1, 64, 64]               0
      BatchNorm1d-29               [-1, 64, 64]             128
             ReLU-30               [-1, 64, 64]               0
          Dropout-31               [-1, 64, 64]               0
           Conv1d-32               [-1, 64, 64]           2,112
  MyConv1dPadSame-33               [-1, 64, 64]               0
       Bottleneck-34               [-1, 64, 64]               0
      BatchNorm1d-35               [-1, 64, 64]             128
             ReLU-36               [-1, 64, 64]               0
          Dropout-37               [-1, 64, 64]               0
           Conv1d-38              [-1, 128, 64]           4,224
  MyConv1dPadSame-39              [-1, 128, 64]               0
      BatchNorm1d-40              [-1, 128, 64]             256
             ReLU-41              [-1, 128, 64]               0
          Dropout-42              [-1, 128, 64]               0
           Conv1d-43              [-1, 128, 64]           8,320
  MyConv1dPadSame-44              [-1, 128, 64]               0
       Bottleneck-45              [-1, 128, 64]               0
      BatchNorm1d-46              [-1, 128, 64]             256
             ReLU-47              [-1, 128, 64]               0
           Linear-48                    [-1, 2]             258
================================================================
Total params: 18,258
Trainable params: 18,258
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 1.26
Params size (MB): 0.07
Estimated Total Size (MB): 1.33
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 16, kernel_size: 8, n_block: 8
************************************************************
************************************************************
(2000, 1, 64) Counter({0: 1000, 1: 1000})
(2000, 1, 64) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 16, 64]             144
   MyConv1dPadSame-2               [-1, 16, 64]               0
       BatchNorm1d-3               [-1, 16, 64]              32
              ReLU-4               [-1, 16, 64]               0
            Conv1d-5               [-1, 16, 64]             144
   MyConv1dPadSame-6               [-1, 16, 64]               0
       BatchNorm1d-7               [-1, 16, 64]              32
              ReLU-8               [-1, 16, 64]               0
           Dropout-9               [-1, 16, 64]               0
           Conv1d-10               [-1, 16, 64]             144
  MyConv1dPadSame-11               [-1, 16, 64]               0
       Bottleneck-12               [-1, 16, 64]               0
      BatchNorm1d-13               [-1, 16, 64]              32
             ReLU-14               [-1, 16, 64]               0
          Dropout-15               [-1, 16, 64]               0
           Conv1d-16               [-1, 16, 64]             144
  MyConv1dPadSame-17               [-1, 16, 64]               0
      BatchNorm1d-18               [-1, 16, 64]              32
             ReLU-19               [-1, 16, 64]               0
          Dropout-20               [-1, 16, 64]               0
           Conv1d-21               [-1, 16, 64]             144
  MyConv1dPadSame-22               [-1, 16, 64]               0
       Bottleneck-23               [-1, 16, 64]               0
      BatchNorm1d-24               [-1, 16, 64]              32
             ReLU-25               [-1, 16, 64]               0
          Dropout-26               [-1, 16, 64]               0
           Conv1d-27               [-1, 32, 64]             288
  MyConv1dPadSame-28               [-1, 32, 64]               0
      BatchNorm1d-29               [-1, 32, 64]              64
             ReLU-30               [-1, 32, 64]               0
          Dropout-31               [-1, 32, 64]               0
           Conv1d-32               [-1, 32, 64]             544
  MyConv1dPadSame-33               [-1, 32, 64]               0
       Bottleneck-34               [-1, 32, 64]               0
      BatchNorm1d-35               [-1, 32, 64]              64
             ReLU-36               [-1, 32, 64]               0
          Dropout-37               [-1, 32, 64]               0
           Conv1d-38               [-1, 32, 64]             544
  MyConv1dPadSame-39               [-1, 32, 64]               0
      BatchNorm1d-40               [-1, 32, 64]              64
             ReLU-41               [-1, 32, 64]               0
          Dropout-42               [-1, 32, 64]               0
           Conv1d-43               [-1, 32, 64]             544
  MyConv1dPadSame-44               [-1, 32, 64]               0
       Bottleneck-45               [-1, 32, 64]               0
      BatchNorm1d-46               [-1, 32, 64]              64
             ReLU-47               [-1, 32, 64]               0
          Dropout-48               [-1, 32, 64]               0
           Conv1d-49               [-1, 64, 64]           1,088
  MyConv1dPadSame-50               [-1, 64, 64]               0
      BatchNorm1d-51               [-1, 64, 64]             128
             ReLU-52               [-1, 64, 64]               0
          Dropout-53               [-1, 64, 64]               0
           Conv1d-54               [-1, 64, 64]           2,112
  MyConv1dPadSame-55               [-1, 64, 64]               0
       Bottleneck-56               [-1, 64, 64]               0
      BatchNorm1d-57               [-1, 64, 64]             128
             ReLU-58               [-1, 64, 64]               0
          Dropout-59               [-1, 64, 64]               0
           Conv1d-60               [-1, 64, 64]           2,112
  MyConv1dPadSame-61               [-1, 64, 64]               0
      BatchNorm1d-62               [-1, 64, 64]             128
             ReLU-63               [-1, 64, 64]               0
          Dropout-64               [-1, 64, 64]               0
           Conv1d-65               [-1, 64, 64]           2,112
  MyConv1dPadSame-66               [-1, 64, 64]               0
       Bottleneck-67               [-1, 64, 64]               0
      BatchNorm1d-68               [-1, 64, 64]             128
             ReLU-69               [-1, 64, 64]               0
          Dropout-70               [-1, 64, 64]               0
           Conv1d-71              [-1, 128, 64]           4,224
  MyConv1dPadSame-72              [-1, 128, 64]               0
      BatchNorm1d-73              [-1, 128, 64]             256
             ReLU-74              [-1, 128, 64]               0
          Dropout-75              [-1, 128, 64]               0
           Conv1d-76              [-1, 128, 64]           8,320
  MyConv1dPadSame-77              [-1, 128, 64]               0
       Bottleneck-78              [-1, 128, 64]               0
      BatchNorm1d-79              [-1, 128, 64]             256
             ReLU-80              [-1, 128, 64]               0
          Dropout-81              [-1, 128, 64]               0
           Conv1d-82              [-1, 128, 64]           8,320
  MyConv1dPadSame-83              [-1, 128, 64]               0
      BatchNorm1d-84              [-1, 128, 64]             256
             ReLU-85              [-1, 128, 64]               0
          Dropout-86              [-1, 128, 64]               0
           Conv1d-87              [-1, 128, 64]           8,320
  MyConv1dPadSame-88              [-1, 128, 64]               0
       Bottleneck-89              [-1, 128, 64]               0
      BatchNorm1d-90              [-1, 128, 64]             256
             ReLU-91              [-1, 128, 64]               0
           Linear-92                    [-1, 2]             258
================================================================
Total params: 41,458
Trainable params: 41,458
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 2.55
Params size (MB): 0.16
Estimated Total Size (MB): 2.71
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 16, kernel_size: 8, n_block: 16
************************************************************
************************************************************
(2000, 1, 64) Counter({0: 1000, 1: 1000})
(2000, 1, 64) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 16, 64]             144
   MyConv1dPadSame-2               [-1, 16, 64]               0
       BatchNorm1d-3               [-1, 16, 64]              32
              ReLU-4               [-1, 16, 64]               0
            Conv1d-5               [-1, 16, 64]             144
   MyConv1dPadSame-6               [-1, 16, 64]               0
       BatchNorm1d-7               [-1, 16, 64]              32
              ReLU-8               [-1, 16, 64]               0
           Dropout-9               [-1, 16, 64]               0
           Conv1d-10               [-1, 16, 64]             144
  MyConv1dPadSame-11               [-1, 16, 64]               0
       Bottleneck-12               [-1, 16, 64]               0
      BatchNorm1d-13               [-1, 16, 64]              32
             ReLU-14               [-1, 16, 64]               0
          Dropout-15               [-1, 16, 64]               0
           Conv1d-16               [-1, 16, 32]             144
  MyConv1dPadSame-17               [-1, 16, 32]               0
      BatchNorm1d-18               [-1, 16, 32]              32
             ReLU-19               [-1, 16, 32]               0
          Dropout-20               [-1, 16, 32]               0
           Conv1d-21               [-1, 16, 32]             144
  MyConv1dPadSame-22               [-1, 16, 32]               0
        MaxPool1d-23               [-1, 16, 32]               0
MyMaxPool1dPadSame-24               [-1, 16, 32]               0
       Bottleneck-25               [-1, 16, 32]               0
      BatchNorm1d-26               [-1, 16, 32]              32
             ReLU-27               [-1, 16, 32]               0
          Dropout-28               [-1, 16, 32]               0
           Conv1d-29               [-1, 16, 32]             144
  MyConv1dPadSame-30               [-1, 16, 32]               0
      BatchNorm1d-31               [-1, 16, 32]              32
             ReLU-32               [-1, 16, 32]               0
          Dropout-33               [-1, 16, 32]               0
           Conv1d-34               [-1, 16, 32]             144
  MyConv1dPadSame-35               [-1, 16, 32]               0
       Bottleneck-36               [-1, 16, 32]               0
      BatchNorm1d-37               [-1, 16, 32]              32
             ReLU-38               [-1, 16, 32]               0
          Dropout-39               [-1, 16, 32]               0
           Conv1d-40               [-1, 16, 16]             144
  MyConv1dPadSame-41               [-1, 16, 16]               0
      BatchNorm1d-42               [-1, 16, 16]              32
             ReLU-43               [-1, 16, 16]               0
          Dropout-44               [-1, 16, 16]               0
           Conv1d-45               [-1, 16, 16]             144
  MyConv1dPadSame-46               [-1, 16, 16]               0
        MaxPool1d-47               [-1, 16, 16]               0
MyMaxPool1dPadSame-48               [-1, 16, 16]               0
       Bottleneck-49               [-1, 16, 16]               0
      BatchNorm1d-50               [-1, 16, 16]              32
             ReLU-51               [-1, 16, 16]               0
          Dropout-52               [-1, 16, 16]               0
           Conv1d-53               [-1, 32, 16]             288
  MyConv1dPadSame-54               [-1, 32, 16]               0
      BatchNorm1d-55               [-1, 32, 16]              64
             ReLU-56               [-1, 32, 16]               0
          Dropout-57               [-1, 32, 16]               0
           Conv1d-58               [-1, 32, 16]             544
  MyConv1dPadSame-59               [-1, 32, 16]               0
       Bottleneck-60               [-1, 32, 16]               0
      BatchNorm1d-61               [-1, 32, 16]              64
             ReLU-62               [-1, 32, 16]               0
          Dropout-63               [-1, 32, 16]               0
           Conv1d-64                [-1, 32, 8]             544
  MyConv1dPadSame-65                [-1, 32, 8]               0
      BatchNorm1d-66                [-1, 32, 8]              64
             ReLU-67                [-1, 32, 8]               0
          Dropout-68                [-1, 32, 8]               0
           Conv1d-69                [-1, 32, 8]             544
  MyConv1dPadSame-70                [-1, 32, 8]               0
        MaxPool1d-71                [-1, 32, 8]               0
MyMaxPool1dPadSame-72                [-1, 32, 8]               0
       Bottleneck-73                [-1, 32, 8]               0
      BatchNorm1d-74                [-1, 32, 8]              64
             ReLU-75                [-1, 32, 8]               0
          Dropout-76                [-1, 32, 8]               0
           Conv1d-77                [-1, 32, 8]             544
  MyConv1dPadSame-78                [-1, 32, 8]               0
      BatchNorm1d-79                [-1, 32, 8]              64
             ReLU-80                [-1, 32, 8]               0
          Dropout-81                [-1, 32, 8]               0
           Conv1d-82                [-1, 32, 8]             544
  MyConv1dPadSame-83                [-1, 32, 8]               0
       Bottleneck-84                [-1, 32, 8]               0
      BatchNorm1d-85                [-1, 32, 8]              64
             ReLU-86                [-1, 32, 8]               0
          Dropout-87                [-1, 32, 8]               0
           Conv1d-88                [-1, 32, 4]             544
  MyConv1dPadSame-89                [-1, 32, 4]               0
      BatchNorm1d-90                [-1, 32, 4]              64
             ReLU-91                [-1, 32, 4]               0
          Dropout-92                [-1, 32, 4]               0
           Conv1d-93                [-1, 32, 4]             544
  MyConv1dPadSame-94                [-1, 32, 4]               0
        MaxPool1d-95                [-1, 32, 4]               0
MyMaxPool1dPadSame-96                [-1, 32, 4]               0
       Bottleneck-97                [-1, 32, 4]               0
      BatchNorm1d-98                [-1, 32, 4]              64
             ReLU-99                [-1, 32, 4]               0
         Dropout-100                [-1, 32, 4]               0
          Conv1d-101                [-1, 64, 4]           1,088
 MyConv1dPadSame-102                [-1, 64, 4]               0
     BatchNorm1d-103                [-1, 64, 4]             128
            ReLU-104                [-1, 64, 4]               0
         Dropout-105                [-1, 64, 4]               0
          Conv1d-106                [-1, 64, 4]           2,112
 MyConv1dPadSame-107                [-1, 64, 4]               0
      Bottleneck-108                [-1, 64, 4]               0
     BatchNorm1d-109                [-1, 64, 4]             128
            ReLU-110                [-1, 64, 4]               0
         Dropout-111                [-1, 64, 4]               0
          Conv1d-112                [-1, 64, 2]           2,112
 MyConv1dPadSame-113                [-1, 64, 2]               0
     BatchNorm1d-114                [-1, 64, 2]             128
            ReLU-115                [-1, 64, 2]               0
         Dropout-116                [-1, 64, 2]               0
          Conv1d-117                [-1, 64, 2]           2,112
 MyConv1dPadSame-118                [-1, 64, 2]               0
       MaxPool1d-119                [-1, 64, 2]               0
MyMaxPool1dPadSame-120                [-1, 64, 2]               0
      Bottleneck-121                [-1, 64, 2]               0
     BatchNorm1d-122                [-1, 64, 2]             128
            ReLU-123                [-1, 64, 2]               0
         Dropout-124                [-1, 64, 2]               0
          Conv1d-125                [-1, 64, 2]           2,112
 MyConv1dPadSame-126                [-1, 64, 2]               0
     BatchNorm1d-127                [-1, 64, 2]             128
            ReLU-128                [-1, 64, 2]               0
         Dropout-129                [-1, 64, 2]               0
          Conv1d-130                [-1, 64, 2]           2,112
 MyConv1dPadSame-131                [-1, 64, 2]               0
      Bottleneck-132                [-1, 64, 2]               0
     BatchNorm1d-133                [-1, 64, 2]             128
            ReLU-134                [-1, 64, 2]               0
         Dropout-135                [-1, 64, 2]               0
          Conv1d-136                [-1, 64, 1]           2,112
 MyConv1dPadSame-137                [-1, 64, 1]               0
     BatchNorm1d-138                [-1, 64, 1]             128
            ReLU-139                [-1, 64, 1]               0
         Dropout-140                [-1, 64, 1]               0
          Conv1d-141                [-1, 64, 1]           2,112
 MyConv1dPadSame-142                [-1, 64, 1]               0
       MaxPool1d-143                [-1, 64, 1]               0
MyMaxPool1dPadSame-144                [-1, 64, 1]               0
      Bottleneck-145                [-1, 64, 1]               0
     BatchNorm1d-146                [-1, 64, 1]             128
            ReLU-147                [-1, 64, 1]               0
         Dropout-148                [-1, 64, 1]               0
          Conv1d-149               [-1, 128, 1]           4,224
 MyConv1dPadSame-150               [-1, 128, 1]               0
     BatchNorm1d-151               [-1, 128, 1]             256
            ReLU-152               [-1, 128, 1]               0
         Dropout-153               [-1, 128, 1]               0
          Conv1d-154               [-1, 128, 1]           8,320
 MyConv1dPadSame-155               [-1, 128, 1]               0
      Bottleneck-156               [-1, 128, 1]               0
     BatchNorm1d-157               [-1, 128, 1]             256
            ReLU-158               [-1, 128, 1]               0
         Dropout-159               [-1, 128, 1]               0
          Conv1d-160               [-1, 128, 1]           8,320
 MyConv1dPadSame-161               [-1, 128, 1]               0
     BatchNorm1d-162               [-1, 128, 1]             256
            ReLU-163               [-1, 128, 1]               0
         Dropout-164               [-1, 128, 1]               0
          Conv1d-165               [-1, 128, 1]           8,320
 MyConv1dPadSame-166               [-1, 128, 1]               0
       MaxPool1d-167               [-1, 128, 1]               0
MyMaxPool1dPadSame-168               [-1, 128, 1]               0
      Bottleneck-169               [-1, 128, 1]               0
     BatchNorm1d-170               [-1, 128, 1]             256
            ReLU-171               [-1, 128, 1]               0
         Dropout-172               [-1, 128, 1]               0
          Conv1d-173               [-1, 128, 1]           8,320
 MyConv1dPadSame-174               [-1, 128, 1]               0
     BatchNorm1d-175               [-1, 128, 1]             256
            ReLU-176               [-1, 128, 1]               0
         Dropout-177               [-1, 128, 1]               0
          Conv1d-178               [-1, 128, 1]           8,320
 MyConv1dPadSame-179               [-1, 128, 1]               0
      Bottleneck-180               [-1, 128, 1]               0
     BatchNorm1d-181               [-1, 128, 1]             256
            ReLU-182               [-1, 128, 1]               0
         Dropout-183               [-1, 128, 1]               0
          Conv1d-184               [-1, 128, 1]           8,320
 MyConv1dPadSame-185               [-1, 128, 1]               0
     BatchNorm1d-186               [-1, 128, 1]             256
            ReLU-187               [-1, 128, 1]               0
         Dropout-188               [-1, 128, 1]               0
          Conv1d-189               [-1, 128, 1]           8,320
 MyConv1dPadSame-190               [-1, 128, 1]               0
       MaxPool1d-191               [-1, 128, 1]               0
MyMaxPool1dPadSame-192               [-1, 128, 1]               0
      Bottleneck-193               [-1, 128, 1]               0
     BatchNorm1d-194               [-1, 128, 1]             256
            ReLU-195               [-1, 128, 1]               0
          Linear-196                    [-1, 2]             258
================================================================
Total params: 87,858
Trainable params: 87,858
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.44
Params size (MB): 0.34
Estimated Total Size (MB): 0.77
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 16, kernel_size: 16, n_block: 2
************************************************************
************************************************************
(2000, 1, 64) Counter({0: 1000, 1: 1000})
(2000, 1, 64) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 16, 64]             272
   MyConv1dPadSame-2               [-1, 16, 64]               0
       BatchNorm1d-3               [-1, 16, 64]              32
              ReLU-4               [-1, 16, 64]               0
            Conv1d-5               [-1, 16, 64]             272
   MyConv1dPadSame-6               [-1, 16, 64]               0
       BatchNorm1d-7               [-1, 16, 64]              32
              ReLU-8               [-1, 16, 64]               0
           Dropout-9               [-1, 16, 64]               0
           Conv1d-10               [-1, 16, 64]             272
  MyConv1dPadSame-11               [-1, 16, 64]               0
       Bottleneck-12               [-1, 16, 64]               0
      BatchNorm1d-13               [-1, 16, 64]              32
             ReLU-14               [-1, 16, 64]               0
          Dropout-15               [-1, 16, 64]               0
           Conv1d-16               [-1, 32, 64]             544
  MyConv1dPadSame-17               [-1, 32, 64]               0
      BatchNorm1d-18               [-1, 32, 64]              64
             ReLU-19               [-1, 32, 64]               0
          Dropout-20               [-1, 32, 64]               0
           Conv1d-21               [-1, 32, 64]           1,056
  MyConv1dPadSame-22               [-1, 32, 64]               0
       Bottleneck-23               [-1, 32, 64]               0
      BatchNorm1d-24               [-1, 32, 64]              64
             ReLU-25               [-1, 32, 64]               0
           Linear-26                    [-1, 2]              66
================================================================
Total params: 2,706
Trainable params: 2,706
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.27
Params size (MB): 0.01
Estimated Total Size (MB): 0.28
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 16, kernel_size: 16, n_block: 4
************************************************************
************************************************************
(2000, 1, 64) Counter({0: 1000, 1: 1000})
(2000, 1, 64) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 16, 64]             272
   MyConv1dPadSame-2               [-1, 16, 64]               0
       BatchNorm1d-3               [-1, 16, 64]              32
              ReLU-4               [-1, 16, 64]               0
            Conv1d-5               [-1, 16, 64]             272
   MyConv1dPadSame-6               [-1, 16, 64]               0
       BatchNorm1d-7               [-1, 16, 64]              32
              ReLU-8               [-1, 16, 64]               0
           Dropout-9               [-1, 16, 64]               0
           Conv1d-10               [-1, 16, 64]             272
  MyConv1dPadSame-11               [-1, 16, 64]               0
       Bottleneck-12               [-1, 16, 64]               0
      BatchNorm1d-13               [-1, 16, 64]              32
             ReLU-14               [-1, 16, 64]               0
          Dropout-15               [-1, 16, 64]               0
           Conv1d-16               [-1, 32, 64]             544
  MyConv1dPadSame-17               [-1, 32, 64]               0
      BatchNorm1d-18               [-1, 32, 64]              64
             ReLU-19               [-1, 32, 64]               0
          Dropout-20               [-1, 32, 64]               0
           Conv1d-21               [-1, 32, 64]           1,056
  MyConv1dPadSame-22               [-1, 32, 64]               0
       Bottleneck-23               [-1, 32, 64]               0
      BatchNorm1d-24               [-1, 32, 64]              64
             ReLU-25               [-1, 32, 64]               0
          Dropout-26               [-1, 32, 64]               0
           Conv1d-27               [-1, 64, 64]           2,112
  MyConv1dPadSame-28               [-1, 64, 64]               0
      BatchNorm1d-29               [-1, 64, 64]             128
             ReLU-30               [-1, 64, 64]               0
          Dropout-31               [-1, 64, 64]               0
           Conv1d-32               [-1, 64, 64]           4,160
  MyConv1dPadSame-33               [-1, 64, 64]               0
       Bottleneck-34               [-1, 64, 64]               0
      BatchNorm1d-35               [-1, 64, 64]             128
             ReLU-36               [-1, 64, 64]               0
          Dropout-37               [-1, 64, 64]               0
           Conv1d-38              [-1, 128, 64]           8,320
  MyConv1dPadSame-39              [-1, 128, 64]               0
      BatchNorm1d-40              [-1, 128, 64]             256
             ReLU-41              [-1, 128, 64]               0
          Dropout-42              [-1, 128, 64]               0
           Conv1d-43              [-1, 128, 64]          16,512
  MyConv1dPadSame-44              [-1, 128, 64]               0
       Bottleneck-45              [-1, 128, 64]               0
      BatchNorm1d-46              [-1, 128, 64]             256
             ReLU-47              [-1, 128, 64]               0
           Linear-48                    [-1, 2]             258
================================================================
Total params: 34,770
Trainable params: 34,770
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 1.26
Params size (MB): 0.13
Estimated Total Size (MB): 1.39
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 16, kernel_size: 16, n_block: 8
************************************************************
************************************************************
(2000, 1, 64) Counter({1: 1000, 0: 1000})
(2000, 1, 64) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 16, 64]             272
   MyConv1dPadSame-2               [-1, 16, 64]               0
       BatchNorm1d-3               [-1, 16, 64]              32
              ReLU-4               [-1, 16, 64]               0
            Conv1d-5               [-1, 16, 64]             272
   MyConv1dPadSame-6               [-1, 16, 64]               0
       BatchNorm1d-7               [-1, 16, 64]              32
              ReLU-8               [-1, 16, 64]               0
           Dropout-9               [-1, 16, 64]               0
           Conv1d-10               [-1, 16, 64]             272
  MyConv1dPadSame-11               [-1, 16, 64]               0
       Bottleneck-12               [-1, 16, 64]               0
      BatchNorm1d-13               [-1, 16, 64]              32
             ReLU-14               [-1, 16, 64]               0
          Dropout-15               [-1, 16, 64]               0
           Conv1d-16               [-1, 16, 64]             272
  MyConv1dPadSame-17               [-1, 16, 64]               0
      BatchNorm1d-18               [-1, 16, 64]              32
             ReLU-19               [-1, 16, 64]               0
          Dropout-20               [-1, 16, 64]               0
           Conv1d-21               [-1, 16, 64]             272
  MyConv1dPadSame-22               [-1, 16, 64]               0
       Bottleneck-23               [-1, 16, 64]               0
      BatchNorm1d-24               [-1, 16, 64]              32
             ReLU-25               [-1, 16, 64]               0
          Dropout-26               [-1, 16, 64]               0
           Conv1d-27               [-1, 32, 64]             544
  MyConv1dPadSame-28               [-1, 32, 64]               0
      BatchNorm1d-29               [-1, 32, 64]              64
             ReLU-30               [-1, 32, 64]               0
          Dropout-31               [-1, 32, 64]               0
           Conv1d-32               [-1, 32, 64]           1,056
  MyConv1dPadSame-33               [-1, 32, 64]               0
       Bottleneck-34               [-1, 32, 64]               0
      BatchNorm1d-35               [-1, 32, 64]              64
             ReLU-36               [-1, 32, 64]               0
          Dropout-37               [-1, 32, 64]               0
           Conv1d-38               [-1, 32, 64]           1,056
  MyConv1dPadSame-39               [-1, 32, 64]               0
      BatchNorm1d-40               [-1, 32, 64]              64
             ReLU-41               [-1, 32, 64]               0
          Dropout-42               [-1, 32, 64]               0
           Conv1d-43               [-1, 32, 64]           1,056
  MyConv1dPadSame-44               [-1, 32, 64]               0
       Bottleneck-45               [-1, 32, 64]               0
      BatchNorm1d-46               [-1, 32, 64]              64
             ReLU-47               [-1, 32, 64]               0
          Dropout-48               [-1, 32, 64]               0
           Conv1d-49               [-1, 64, 64]           2,112
  MyConv1dPadSame-50               [-1, 64, 64]               0
      BatchNorm1d-51               [-1, 64, 64]             128
             ReLU-52               [-1, 64, 64]               0
          Dropout-53               [-1, 64, 64]               0
           Conv1d-54               [-1, 64, 64]           4,160
  MyConv1dPadSame-55               [-1, 64, 64]               0
       Bottleneck-56               [-1, 64, 64]               0
      BatchNorm1d-57               [-1, 64, 64]             128
             ReLU-58               [-1, 64, 64]               0
          Dropout-59               [-1, 64, 64]               0
           Conv1d-60               [-1, 64, 64]           4,160
  MyConv1dPadSame-61               [-1, 64, 64]               0
      BatchNorm1d-62               [-1, 64, 64]             128
             ReLU-63               [-1, 64, 64]               0
          Dropout-64               [-1, 64, 64]               0
           Conv1d-65               [-1, 64, 64]           4,160
  MyConv1dPadSame-66               [-1, 64, 64]               0
       Bottleneck-67               [-1, 64, 64]               0
      BatchNorm1d-68               [-1, 64, 64]             128
             ReLU-69               [-1, 64, 64]               0
          Dropout-70               [-1, 64, 64]               0
           Conv1d-71              [-1, 128, 64]           8,320
  MyConv1dPadSame-72              [-1, 128, 64]               0
      BatchNorm1d-73              [-1, 128, 64]             256
             ReLU-74              [-1, 128, 64]               0
          Dropout-75              [-1, 128, 64]               0
           Conv1d-76              [-1, 128, 64]          16,512
  MyConv1dPadSame-77              [-1, 128, 64]               0
       Bottleneck-78              [-1, 128, 64]               0
      BatchNorm1d-79              [-1, 128, 64]             256
             ReLU-80              [-1, 128, 64]               0
          Dropout-81              [-1, 128, 64]               0
           Conv1d-82              [-1, 128, 64]          16,512
  MyConv1dPadSame-83              [-1, 128, 64]               0
      BatchNorm1d-84              [-1, 128, 64]             256
             ReLU-85              [-1, 128, 64]               0
          Dropout-86              [-1, 128, 64]               0
           Conv1d-87              [-1, 128, 64]          16,512
  MyConv1dPadSame-88              [-1, 128, 64]               0
       Bottleneck-89              [-1, 128, 64]               0
      BatchNorm1d-90              [-1, 128, 64]             256
             ReLU-91              [-1, 128, 64]               0
           Linear-92                    [-1, 2]             258
================================================================
Total params: 79,730
Trainable params: 79,730
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 2.55
Params size (MB): 0.30
Estimated Total Size (MB): 2.85
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 16, kernel_size: 16, n_block: 16
************************************************************
************************************************************
(2000, 1, 64) Counter({0: 1000, 1: 1000})
(2000, 1, 64) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 16, 64]             272
   MyConv1dPadSame-2               [-1, 16, 64]               0
       BatchNorm1d-3               [-1, 16, 64]              32
              ReLU-4               [-1, 16, 64]               0
            Conv1d-5               [-1, 16, 64]             272
   MyConv1dPadSame-6               [-1, 16, 64]               0
       BatchNorm1d-7               [-1, 16, 64]              32
              ReLU-8               [-1, 16, 64]               0
           Dropout-9               [-1, 16, 64]               0
           Conv1d-10               [-1, 16, 64]             272
  MyConv1dPadSame-11               [-1, 16, 64]               0
       Bottleneck-12               [-1, 16, 64]               0
      BatchNorm1d-13               [-1, 16, 64]              32
             ReLU-14               [-1, 16, 64]               0
          Dropout-15               [-1, 16, 64]               0
           Conv1d-16               [-1, 16, 32]             272
  MyConv1dPadSame-17               [-1, 16, 32]               0
      BatchNorm1d-18               [-1, 16, 32]              32
             ReLU-19               [-1, 16, 32]               0
          Dropout-20               [-1, 16, 32]               0
           Conv1d-21               [-1, 16, 32]             272
  MyConv1dPadSame-22               [-1, 16, 32]               0
        MaxPool1d-23               [-1, 16, 32]               0
MyMaxPool1dPadSame-24               [-1, 16, 32]               0
       Bottleneck-25               [-1, 16, 32]               0
      BatchNorm1d-26               [-1, 16, 32]              32
             ReLU-27               [-1, 16, 32]               0
          Dropout-28               [-1, 16, 32]               0
           Conv1d-29               [-1, 16, 32]             272
  MyConv1dPadSame-30               [-1, 16, 32]               0
      BatchNorm1d-31               [-1, 16, 32]              32
             ReLU-32               [-1, 16, 32]               0
          Dropout-33               [-1, 16, 32]               0
           Conv1d-34               [-1, 16, 32]             272
  MyConv1dPadSame-35               [-1, 16, 32]               0
       Bottleneck-36               [-1, 16, 32]               0
      BatchNorm1d-37               [-1, 16, 32]              32
             ReLU-38               [-1, 16, 32]               0
          Dropout-39               [-1, 16, 32]               0
           Conv1d-40               [-1, 16, 16]             272
  MyConv1dPadSame-41               [-1, 16, 16]               0
      BatchNorm1d-42               [-1, 16, 16]              32
             ReLU-43               [-1, 16, 16]               0
          Dropout-44               [-1, 16, 16]               0
           Conv1d-45               [-1, 16, 16]             272
  MyConv1dPadSame-46               [-1, 16, 16]               0
        MaxPool1d-47               [-1, 16, 16]               0
MyMaxPool1dPadSame-48               [-1, 16, 16]               0
       Bottleneck-49               [-1, 16, 16]               0
      BatchNorm1d-50               [-1, 16, 16]              32
             ReLU-51               [-1, 16, 16]               0
          Dropout-52               [-1, 16, 16]               0
           Conv1d-53               [-1, 32, 16]             544
  MyConv1dPadSame-54               [-1, 32, 16]               0
      BatchNorm1d-55               [-1, 32, 16]              64
             ReLU-56               [-1, 32, 16]               0
          Dropout-57               [-1, 32, 16]               0
           Conv1d-58               [-1, 32, 16]           1,056
  MyConv1dPadSame-59               [-1, 32, 16]               0
       Bottleneck-60               [-1, 32, 16]               0
      BatchNorm1d-61               [-1, 32, 16]              64
             ReLU-62               [-1, 32, 16]               0
          Dropout-63               [-1, 32, 16]               0
           Conv1d-64                [-1, 32, 8]           1,056
  MyConv1dPadSame-65                [-1, 32, 8]               0
      BatchNorm1d-66                [-1, 32, 8]              64
             ReLU-67                [-1, 32, 8]               0
          Dropout-68                [-1, 32, 8]               0
           Conv1d-69                [-1, 32, 8]           1,056
  MyConv1dPadSame-70                [-1, 32, 8]               0
        MaxPool1d-71                [-1, 32, 8]               0
MyMaxPool1dPadSame-72                [-1, 32, 8]               0
       Bottleneck-73                [-1, 32, 8]               0
      BatchNorm1d-74                [-1, 32, 8]              64
             ReLU-75                [-1, 32, 8]               0
          Dropout-76                [-1, 32, 8]               0
           Conv1d-77                [-1, 32, 8]           1,056
  MyConv1dPadSame-78                [-1, 32, 8]               0
      BatchNorm1d-79                [-1, 32, 8]              64
             ReLU-80                [-1, 32, 8]               0
          Dropout-81                [-1, 32, 8]               0
           Conv1d-82                [-1, 32, 8]           1,056
  MyConv1dPadSame-83                [-1, 32, 8]               0
       Bottleneck-84                [-1, 32, 8]               0
      BatchNorm1d-85                [-1, 32, 8]              64
             ReLU-86                [-1, 32, 8]               0
          Dropout-87                [-1, 32, 8]               0
           Conv1d-88                [-1, 32, 4]           1,056
  MyConv1dPadSame-89                [-1, 32, 4]               0
      BatchNorm1d-90                [-1, 32, 4]              64
             ReLU-91                [-1, 32, 4]               0
          Dropout-92                [-1, 32, 4]               0
           Conv1d-93                [-1, 32, 4]           1,056
  MyConv1dPadSame-94                [-1, 32, 4]               0
        MaxPool1d-95                [-1, 32, 4]               0
MyMaxPool1dPadSame-96                [-1, 32, 4]               0
       Bottleneck-97                [-1, 32, 4]               0
      BatchNorm1d-98                [-1, 32, 4]              64
             ReLU-99                [-1, 32, 4]               0
         Dropout-100                [-1, 32, 4]               0
          Conv1d-101                [-1, 64, 4]           2,112
 MyConv1dPadSame-102                [-1, 64, 4]               0
     BatchNorm1d-103                [-1, 64, 4]             128
            ReLU-104                [-1, 64, 4]               0
         Dropout-105                [-1, 64, 4]               0
          Conv1d-106                [-1, 64, 4]           4,160
 MyConv1dPadSame-107                [-1, 64, 4]               0
      Bottleneck-108                [-1, 64, 4]               0
     BatchNorm1d-109                [-1, 64, 4]             128
            ReLU-110                [-1, 64, 4]               0
         Dropout-111                [-1, 64, 4]               0
          Conv1d-112                [-1, 64, 2]           4,160
 MyConv1dPadSame-113                [-1, 64, 2]               0
     BatchNorm1d-114                [-1, 64, 2]             128
            ReLU-115                [-1, 64, 2]               0
         Dropout-116                [-1, 64, 2]               0
          Conv1d-117                [-1, 64, 2]           4,160
 MyConv1dPadSame-118                [-1, 64, 2]               0
       MaxPool1d-119                [-1, 64, 2]               0
MyMaxPool1dPadSame-120                [-1, 64, 2]               0
      Bottleneck-121                [-1, 64, 2]               0
     BatchNorm1d-122                [-1, 64, 2]             128
            ReLU-123                [-1, 64, 2]               0
         Dropout-124                [-1, 64, 2]               0
          Conv1d-125                [-1, 64, 2]           4,160
 MyConv1dPadSame-126                [-1, 64, 2]               0
     BatchNorm1d-127                [-1, 64, 2]             128
            ReLU-128                [-1, 64, 2]               0
         Dropout-129                [-1, 64, 2]               0
          Conv1d-130                [-1, 64, 2]           4,160
 MyConv1dPadSame-131                [-1, 64, 2]               0
      Bottleneck-132                [-1, 64, 2]               0
     BatchNorm1d-133                [-1, 64, 2]             128
            ReLU-134                [-1, 64, 2]               0
         Dropout-135                [-1, 64, 2]               0
          Conv1d-136                [-1, 64, 1]           4,160
 MyConv1dPadSame-137                [-1, 64, 1]               0
     BatchNorm1d-138                [-1, 64, 1]             128
            ReLU-139                [-1, 64, 1]               0
         Dropout-140                [-1, 64, 1]               0
          Conv1d-141                [-1, 64, 1]           4,160
 MyConv1dPadSame-142                [-1, 64, 1]               0
       MaxPool1d-143                [-1, 64, 1]               0
MyMaxPool1dPadSame-144                [-1, 64, 1]               0
      Bottleneck-145                [-1, 64, 1]               0
     BatchNorm1d-146                [-1, 64, 1]             128
            ReLU-147                [-1, 64, 1]               0
         Dropout-148                [-1, 64, 1]               0
          Conv1d-149               [-1, 128, 1]           8,320
 MyConv1dPadSame-150               [-1, 128, 1]               0
     BatchNorm1d-151               [-1, 128, 1]             256
            ReLU-152               [-1, 128, 1]               0
         Dropout-153               [-1, 128, 1]               0
          Conv1d-154               [-1, 128, 1]          16,512
 MyConv1dPadSame-155               [-1, 128, 1]               0
      Bottleneck-156               [-1, 128, 1]               0
     BatchNorm1d-157               [-1, 128, 1]             256
            ReLU-158               [-1, 128, 1]               0
         Dropout-159               [-1, 128, 1]               0
          Conv1d-160               [-1, 128, 1]          16,512
 MyConv1dPadSame-161               [-1, 128, 1]               0
     BatchNorm1d-162               [-1, 128, 1]             256
            ReLU-163               [-1, 128, 1]               0
         Dropout-164               [-1, 128, 1]               0
          Conv1d-165               [-1, 128, 1]          16,512
 MyConv1dPadSame-166               [-1, 128, 1]               0
       MaxPool1d-167               [-1, 128, 1]               0
MyMaxPool1dPadSame-168               [-1, 128, 1]               0
      Bottleneck-169               [-1, 128, 1]               0
     BatchNorm1d-170               [-1, 128, 1]             256
            ReLU-171               [-1, 128, 1]               0
         Dropout-172               [-1, 128, 1]               0
          Conv1d-173               [-1, 128, 1]          16,512
 MyConv1dPadSame-174               [-1, 128, 1]               0
     BatchNorm1d-175               [-1, 128, 1]             256
            ReLU-176               [-1, 128, 1]               0
         Dropout-177               [-1, 128, 1]               0
          Conv1d-178               [-1, 128, 1]          16,512
 MyConv1dPadSame-179               [-1, 128, 1]               0
      Bottleneck-180               [-1, 128, 1]               0
     BatchNorm1d-181               [-1, 128, 1]             256
            ReLU-182               [-1, 128, 1]               0
         Dropout-183               [-1, 128, 1]               0
          Conv1d-184               [-1, 128, 1]          16,512
 MyConv1dPadSame-185               [-1, 128, 1]               0
     BatchNorm1d-186               [-1, 128, 1]             256
            ReLU-187               [-1, 128, 1]               0
         Dropout-188               [-1, 128, 1]               0
          Conv1d-189               [-1, 128, 1]          16,512
 MyConv1dPadSame-190               [-1, 128, 1]               0
       MaxPool1d-191               [-1, 128, 1]               0
MyMaxPool1dPadSame-192               [-1, 128, 1]               0
      Bottleneck-193               [-1, 128, 1]               0
     BatchNorm1d-194               [-1, 128, 1]             256
            ReLU-195               [-1, 128, 1]               0
          Linear-196                    [-1, 2]             258
================================================================
Total params: 169,650
Trainable params: 169,650
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.44
Params size (MB): 0.65
Estimated Total Size (MB): 1.08
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 32, kernel_size: 2, n_block: 2
************************************************************
************************************************************
(2000, 1, 64) Counter({0: 1000, 1: 1000})
(2000, 1, 64) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 32, 64]              96
   MyConv1dPadSame-2               [-1, 32, 64]               0
       BatchNorm1d-3               [-1, 32, 64]              64
              ReLU-4               [-1, 32, 64]               0
            Conv1d-5               [-1, 32, 64]              96
   MyConv1dPadSame-6               [-1, 32, 64]               0
       BatchNorm1d-7               [-1, 32, 64]              64
              ReLU-8               [-1, 32, 64]               0
           Dropout-9               [-1, 32, 64]               0
           Conv1d-10               [-1, 32, 64]              96
  MyConv1dPadSame-11               [-1, 32, 64]               0
       Bottleneck-12               [-1, 32, 64]               0
      BatchNorm1d-13               [-1, 32, 64]              64
             ReLU-14               [-1, 32, 64]               0
          Dropout-15               [-1, 32, 64]               0
           Conv1d-16               [-1, 64, 64]             192
  MyConv1dPadSame-17               [-1, 64, 64]               0
      BatchNorm1d-18               [-1, 64, 64]             128
             ReLU-19               [-1, 64, 64]               0
          Dropout-20               [-1, 64, 64]               0
           Conv1d-21               [-1, 64, 64]             320
  MyConv1dPadSame-22               [-1, 64, 64]               0
       Bottleneck-23               [-1, 64, 64]               0
      BatchNorm1d-24               [-1, 64, 64]             128
             ReLU-25               [-1, 64, 64]               0
           Linear-26                    [-1, 2]             130
================================================================
Total params: 1,378
Trainable params: 1,378
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.55
Params size (MB): 0.01
Estimated Total Size (MB): 0.55
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 32, kernel_size: 2, n_block: 4
************************************************************
************************************************************
(2000, 1, 64) Counter({1: 1000, 0: 1000})
(2000, 1, 64) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 32, 64]              96
   MyConv1dPadSame-2               [-1, 32, 64]               0
       BatchNorm1d-3               [-1, 32, 64]              64
              ReLU-4               [-1, 32, 64]               0
            Conv1d-5               [-1, 32, 64]              96
   MyConv1dPadSame-6               [-1, 32, 64]               0
       BatchNorm1d-7               [-1, 32, 64]              64
              ReLU-8               [-1, 32, 64]               0
           Dropout-9               [-1, 32, 64]               0
           Conv1d-10               [-1, 32, 64]              96
  MyConv1dPadSame-11               [-1, 32, 64]               0
       Bottleneck-12               [-1, 32, 64]               0
      BatchNorm1d-13               [-1, 32, 64]              64
             ReLU-14               [-1, 32, 64]               0
          Dropout-15               [-1, 32, 64]               0
           Conv1d-16               [-1, 64, 64]             192
  MyConv1dPadSame-17               [-1, 64, 64]               0
      BatchNorm1d-18               [-1, 64, 64]             128
             ReLU-19               [-1, 64, 64]               0
          Dropout-20               [-1, 64, 64]               0
           Conv1d-21               [-1, 64, 64]             320
  MyConv1dPadSame-22               [-1, 64, 64]               0
       Bottleneck-23               [-1, 64, 64]               0
      BatchNorm1d-24               [-1, 64, 64]             128
             ReLU-25               [-1, 64, 64]               0
          Dropout-26               [-1, 64, 64]               0
           Conv1d-27              [-1, 128, 64]             640
  MyConv1dPadSame-28              [-1, 128, 64]               0
      BatchNorm1d-29              [-1, 128, 64]             256
             ReLU-30              [-1, 128, 64]               0
          Dropout-31              [-1, 128, 64]               0
           Conv1d-32              [-1, 128, 64]           1,152
  MyConv1dPadSame-33              [-1, 128, 64]               0
       Bottleneck-34              [-1, 128, 64]               0
      BatchNorm1d-35              [-1, 128, 64]             256
             ReLU-36              [-1, 128, 64]               0
          Dropout-37              [-1, 128, 64]               0
           Conv1d-38              [-1, 256, 64]           2,304
  MyConv1dPadSame-39              [-1, 256, 64]               0
      BatchNorm1d-40              [-1, 256, 64]             512
             ReLU-41              [-1, 256, 64]               0
          Dropout-42              [-1, 256, 64]               0
           Conv1d-43              [-1, 256, 64]           4,352
  MyConv1dPadSame-44              [-1, 256, 64]               0
       Bottleneck-45              [-1, 256, 64]               0
      BatchNorm1d-46              [-1, 256, 64]             512
             ReLU-47              [-1, 256, 64]               0
           Linear-48                    [-1, 2]             514
================================================================
Total params: 11,746
Trainable params: 11,746
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 2.52
Params size (MB): 0.04
Estimated Total Size (MB): 2.56
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 32, kernel_size: 2, n_block: 8
************************************************************
************************************************************
(2000, 1, 64) Counter({0: 1000, 1: 1000})
(2000, 1, 64) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 32, 64]              96
   MyConv1dPadSame-2               [-1, 32, 64]               0
       BatchNorm1d-3               [-1, 32, 64]              64
              ReLU-4               [-1, 32, 64]               0
            Conv1d-5               [-1, 32, 64]              96
   MyConv1dPadSame-6               [-1, 32, 64]               0
       BatchNorm1d-7               [-1, 32, 64]              64
              ReLU-8               [-1, 32, 64]               0
           Dropout-9               [-1, 32, 64]               0
           Conv1d-10               [-1, 32, 64]              96
  MyConv1dPadSame-11               [-1, 32, 64]               0
       Bottleneck-12               [-1, 32, 64]               0
      BatchNorm1d-13               [-1, 32, 64]              64
             ReLU-14               [-1, 32, 64]               0
          Dropout-15               [-1, 32, 64]               0
           Conv1d-16               [-1, 32, 64]              96
  MyConv1dPadSame-17               [-1, 32, 64]               0
      BatchNorm1d-18               [-1, 32, 64]              64
             ReLU-19               [-1, 32, 64]               0
          Dropout-20               [-1, 32, 64]               0
           Conv1d-21               [-1, 32, 64]              96
  MyConv1dPadSame-22               [-1, 32, 64]               0
       Bottleneck-23               [-1, 32, 64]               0
      BatchNorm1d-24               [-1, 32, 64]              64
             ReLU-25               [-1, 32, 64]               0
          Dropout-26               [-1, 32, 64]               0
           Conv1d-27               [-1, 64, 64]             192
  MyConv1dPadSame-28               [-1, 64, 64]               0
      BatchNorm1d-29               [-1, 64, 64]             128
             ReLU-30               [-1, 64, 64]               0
          Dropout-31               [-1, 64, 64]               0
           Conv1d-32               [-1, 64, 64]             320
  MyConv1dPadSame-33               [-1, 64, 64]               0
       Bottleneck-34               [-1, 64, 64]               0
      BatchNorm1d-35               [-1, 64, 64]             128
             ReLU-36               [-1, 64, 64]               0
          Dropout-37               [-1, 64, 64]               0
           Conv1d-38               [-1, 64, 64]             320
  MyConv1dPadSame-39               [-1, 64, 64]               0
      BatchNorm1d-40               [-1, 64, 64]             128
             ReLU-41               [-1, 64, 64]               0
          Dropout-42               [-1, 64, 64]               0
           Conv1d-43               [-1, 64, 64]             320
  MyConv1dPadSame-44               [-1, 64, 64]               0
       Bottleneck-45               [-1, 64, 64]               0
      BatchNorm1d-46               [-1, 64, 64]             128
             ReLU-47               [-1, 64, 64]               0
          Dropout-48               [-1, 64, 64]               0
           Conv1d-49              [-1, 128, 64]             640
  MyConv1dPadSame-50              [-1, 128, 64]               0
      BatchNorm1d-51              [-1, 128, 64]             256
             ReLU-52              [-1, 128, 64]               0
          Dropout-53              [-1, 128, 64]               0
           Conv1d-54              [-1, 128, 64]           1,152
  MyConv1dPadSame-55              [-1, 128, 64]               0
       Bottleneck-56              [-1, 128, 64]               0
      BatchNorm1d-57              [-1, 128, 64]             256
             ReLU-58              [-1, 128, 64]               0
          Dropout-59              [-1, 128, 64]               0
           Conv1d-60              [-1, 128, 64]           1,152
  MyConv1dPadSame-61              [-1, 128, 64]               0
      BatchNorm1d-62              [-1, 128, 64]             256
             ReLU-63              [-1, 128, 64]               0
          Dropout-64              [-1, 128, 64]               0
           Conv1d-65              [-1, 128, 64]           1,152
  MyConv1dPadSame-66              [-1, 128, 64]               0
       Bottleneck-67              [-1, 128, 64]               0
      BatchNorm1d-68              [-1, 128, 64]             256
             ReLU-69              [-1, 128, 64]               0
          Dropout-70              [-1, 128, 64]               0
           Conv1d-71              [-1, 256, 64]           2,304
  MyConv1dPadSame-72              [-1, 256, 64]               0
      BatchNorm1d-73              [-1, 256, 64]             512
             ReLU-74              [-1, 256, 64]               0
          Dropout-75              [-1, 256, 64]               0
           Conv1d-76              [-1, 256, 64]           4,352
  MyConv1dPadSame-77              [-1, 256, 64]               0
       Bottleneck-78              [-1, 256, 64]               0
      BatchNorm1d-79              [-1, 256, 64]             512
             ReLU-80              [-1, 256, 64]               0
          Dropout-81              [-1, 256, 64]               0
           Conv1d-82              [-1, 256, 64]           4,352
  MyConv1dPadSame-83              [-1, 256, 64]               0
      BatchNorm1d-84              [-1, 256, 64]             512
             ReLU-85              [-1, 256, 64]               0
          Dropout-86              [-1, 256, 64]               0
           Conv1d-87              [-1, 256, 64]           4,352
  MyConv1dPadSame-88              [-1, 256, 64]               0
       Bottleneck-89              [-1, 256, 64]               0
      BatchNorm1d-90              [-1, 256, 64]             512
             ReLU-91              [-1, 256, 64]               0
           Linear-92                    [-1, 2]             514
================================================================
Total params: 25,506
Trainable params: 25,506
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 5.09
Params size (MB): 0.10
Estimated Total Size (MB): 5.19
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 32, kernel_size: 2, n_block: 16
************************************************************
************************************************************
(2000, 1, 64) Counter({1: 1000, 0: 1000})
(2000, 1, 64) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 32, 64]              96
   MyConv1dPadSame-2               [-1, 32, 64]               0
       BatchNorm1d-3               [-1, 32, 64]              64
              ReLU-4               [-1, 32, 64]               0
            Conv1d-5               [-1, 32, 64]              96
   MyConv1dPadSame-6               [-1, 32, 64]               0
       BatchNorm1d-7               [-1, 32, 64]              64
              ReLU-8               [-1, 32, 64]               0
           Dropout-9               [-1, 32, 64]               0
           Conv1d-10               [-1, 32, 64]              96
  MyConv1dPadSame-11               [-1, 32, 64]               0
       Bottleneck-12               [-1, 32, 64]               0
      BatchNorm1d-13               [-1, 32, 64]              64
             ReLU-14               [-1, 32, 64]               0
          Dropout-15               [-1, 32, 64]               0
           Conv1d-16               [-1, 32, 32]              96
  MyConv1dPadSame-17               [-1, 32, 32]               0
      BatchNorm1d-18               [-1, 32, 32]              64
             ReLU-19               [-1, 32, 32]               0
          Dropout-20               [-1, 32, 32]               0
           Conv1d-21               [-1, 32, 32]              96
  MyConv1dPadSame-22               [-1, 32, 32]               0
        MaxPool1d-23               [-1, 32, 32]               0
MyMaxPool1dPadSame-24               [-1, 32, 32]               0
       Bottleneck-25               [-1, 32, 32]               0
      BatchNorm1d-26               [-1, 32, 32]              64
             ReLU-27               [-1, 32, 32]               0
          Dropout-28               [-1, 32, 32]               0
           Conv1d-29               [-1, 32, 32]              96
  MyConv1dPadSame-30               [-1, 32, 32]               0
      BatchNorm1d-31               [-1, 32, 32]              64
             ReLU-32               [-1, 32, 32]               0
          Dropout-33               [-1, 32, 32]               0
           Conv1d-34               [-1, 32, 32]              96
  MyConv1dPadSame-35               [-1, 32, 32]               0
       Bottleneck-36               [-1, 32, 32]               0
      BatchNorm1d-37               [-1, 32, 32]              64
             ReLU-38               [-1, 32, 32]               0
          Dropout-39               [-1, 32, 32]               0
           Conv1d-40               [-1, 32, 16]              96
  MyConv1dPadSame-41               [-1, 32, 16]               0
      BatchNorm1d-42               [-1, 32, 16]              64
             ReLU-43               [-1, 32, 16]               0
          Dropout-44               [-1, 32, 16]               0
           Conv1d-45               [-1, 32, 16]              96
  MyConv1dPadSame-46               [-1, 32, 16]               0
        MaxPool1d-47               [-1, 32, 16]               0
MyMaxPool1dPadSame-48               [-1, 32, 16]               0
       Bottleneck-49               [-1, 32, 16]               0
      BatchNorm1d-50               [-1, 32, 16]              64
             ReLU-51               [-1, 32, 16]               0
          Dropout-52               [-1, 32, 16]               0
           Conv1d-53               [-1, 64, 16]             192
  MyConv1dPadSame-54               [-1, 64, 16]               0
      BatchNorm1d-55               [-1, 64, 16]             128
             ReLU-56               [-1, 64, 16]               0
          Dropout-57               [-1, 64, 16]               0
           Conv1d-58               [-1, 64, 16]             320
  MyConv1dPadSame-59               [-1, 64, 16]               0
       Bottleneck-60               [-1, 64, 16]               0
      BatchNorm1d-61               [-1, 64, 16]             128
             ReLU-62               [-1, 64, 16]               0
          Dropout-63               [-1, 64, 16]               0
           Conv1d-64                [-1, 64, 8]             320
  MyConv1dPadSame-65                [-1, 64, 8]               0
      BatchNorm1d-66                [-1, 64, 8]             128
             ReLU-67                [-1, 64, 8]               0
          Dropout-68                [-1, 64, 8]               0
           Conv1d-69                [-1, 64, 8]             320
  MyConv1dPadSame-70                [-1, 64, 8]               0
        MaxPool1d-71                [-1, 64, 8]               0
MyMaxPool1dPadSame-72                [-1, 64, 8]               0
       Bottleneck-73                [-1, 64, 8]               0
      BatchNorm1d-74                [-1, 64, 8]             128
             ReLU-75                [-1, 64, 8]               0
          Dropout-76                [-1, 64, 8]               0
           Conv1d-77                [-1, 64, 8]             320
  MyConv1dPadSame-78                [-1, 64, 8]               0
      BatchNorm1d-79                [-1, 64, 8]             128
             ReLU-80                [-1, 64, 8]               0
          Dropout-81                [-1, 64, 8]               0
           Conv1d-82                [-1, 64, 8]             320
  MyConv1dPadSame-83                [-1, 64, 8]               0
       Bottleneck-84                [-1, 64, 8]               0
      BatchNorm1d-85                [-1, 64, 8]             128
             ReLU-86                [-1, 64, 8]               0
          Dropout-87                [-1, 64, 8]               0
           Conv1d-88                [-1, 64, 4]             320
  MyConv1dPadSame-89                [-1, 64, 4]               0
      BatchNorm1d-90                [-1, 64, 4]             128
             ReLU-91                [-1, 64, 4]               0
          Dropout-92                [-1, 64, 4]               0
           Conv1d-93                [-1, 64, 4]             320
  MyConv1dPadSame-94                [-1, 64, 4]               0
        MaxPool1d-95                [-1, 64, 4]               0
MyMaxPool1dPadSame-96                [-1, 64, 4]               0
       Bottleneck-97                [-1, 64, 4]               0
      BatchNorm1d-98                [-1, 64, 4]             128
             ReLU-99                [-1, 64, 4]               0
         Dropout-100                [-1, 64, 4]               0
          Conv1d-101               [-1, 128, 4]             640
 MyConv1dPadSame-102               [-1, 128, 4]               0
     BatchNorm1d-103               [-1, 128, 4]             256
            ReLU-104               [-1, 128, 4]               0
         Dropout-105               [-1, 128, 4]               0
          Conv1d-106               [-1, 128, 4]           1,152
 MyConv1dPadSame-107               [-1, 128, 4]               0
      Bottleneck-108               [-1, 128, 4]               0
     BatchNorm1d-109               [-1, 128, 4]             256
            ReLU-110               [-1, 128, 4]               0
         Dropout-111               [-1, 128, 4]               0
          Conv1d-112               [-1, 128, 2]           1,152
 MyConv1dPadSame-113               [-1, 128, 2]               0
     BatchNorm1d-114               [-1, 128, 2]             256
            ReLU-115               [-1, 128, 2]               0
         Dropout-116               [-1, 128, 2]               0
          Conv1d-117               [-1, 128, 2]           1,152
 MyConv1dPadSame-118               [-1, 128, 2]               0
       MaxPool1d-119               [-1, 128, 2]               0
MyMaxPool1dPadSame-120               [-1, 128, 2]               0
      Bottleneck-121               [-1, 128, 2]               0
     BatchNorm1d-122               [-1, 128, 2]             256
            ReLU-123               [-1, 128, 2]               0
         Dropout-124               [-1, 128, 2]               0
          Conv1d-125               [-1, 128, 2]           1,152
 MyConv1dPadSame-126               [-1, 128, 2]               0
     BatchNorm1d-127               [-1, 128, 2]             256
            ReLU-128               [-1, 128, 2]               0
         Dropout-129               [-1, 128, 2]               0
          Conv1d-130               [-1, 128, 2]           1,152
 MyConv1dPadSame-131               [-1, 128, 2]               0
      Bottleneck-132               [-1, 128, 2]               0
     BatchNorm1d-133               [-1, 128, 2]             256
            ReLU-134               [-1, 128, 2]               0
         Dropout-135               [-1, 128, 2]               0
          Conv1d-136               [-1, 128, 1]           1,152
 MyConv1dPadSame-137               [-1, 128, 1]               0
     BatchNorm1d-138               [-1, 128, 1]             256
            ReLU-139               [-1, 128, 1]               0
         Dropout-140               [-1, 128, 1]               0
          Conv1d-141               [-1, 128, 1]           1,152
 MyConv1dPadSame-142               [-1, 128, 1]               0
       MaxPool1d-143               [-1, 128, 1]               0
MyMaxPool1dPadSame-144               [-1, 128, 1]               0
      Bottleneck-145               [-1, 128, 1]               0
     BatchNorm1d-146               [-1, 128, 1]             256
            ReLU-147               [-1, 128, 1]               0
         Dropout-148               [-1, 128, 1]               0
          Conv1d-149               [-1, 256, 1]           2,304
 MyConv1dPadSame-150               [-1, 256, 1]               0
     BatchNorm1d-151               [-1, 256, 1]             512
            ReLU-152               [-1, 256, 1]               0
         Dropout-153               [-1, 256, 1]               0
          Conv1d-154               [-1, 256, 1]           4,352
 MyConv1dPadSame-155               [-1, 256, 1]               0
      Bottleneck-156               [-1, 256, 1]               0
     BatchNorm1d-157               [-1, 256, 1]             512
            ReLU-158               [-1, 256, 1]               0
         Dropout-159               [-1, 256, 1]               0
          Conv1d-160               [-1, 256, 1]           4,352
 MyConv1dPadSame-161               [-1, 256, 1]               0
     BatchNorm1d-162               [-1, 256, 1]             512
            ReLU-163               [-1, 256, 1]               0
         Dropout-164               [-1, 256, 1]               0
          Conv1d-165               [-1, 256, 1]           4,352
 MyConv1dPadSame-166               [-1, 256, 1]               0
       MaxPool1d-167               [-1, 256, 1]               0
MyMaxPool1dPadSame-168               [-1, 256, 1]               0
      Bottleneck-169               [-1, 256, 1]               0
     BatchNorm1d-170               [-1, 256, 1]             512
            ReLU-171               [-1, 256, 1]               0
         Dropout-172               [-1, 256, 1]               0
          Conv1d-173               [-1, 256, 1]           4,352
 MyConv1dPadSame-174               [-1, 256, 1]               0
     BatchNorm1d-175               [-1, 256, 1]             512
            ReLU-176               [-1, 256, 1]               0
         Dropout-177               [-1, 256, 1]               0
          Conv1d-178               [-1, 256, 1]           4,352
 MyConv1dPadSame-179               [-1, 256, 1]               0
      Bottleneck-180               [-1, 256, 1]               0
     BatchNorm1d-181               [-1, 256, 1]             512
            ReLU-182               [-1, 256, 1]               0
         Dropout-183               [-1, 256, 1]               0
          Conv1d-184               [-1, 256, 1]           4,352
 MyConv1dPadSame-185               [-1, 256, 1]               0
     BatchNorm1d-186               [-1, 256, 1]             512
            ReLU-187               [-1, 256, 1]               0
         Dropout-188               [-1, 256, 1]               0
          Conv1d-189               [-1, 256, 1]           4,352
 MyConv1dPadSame-190               [-1, 256, 1]               0
       MaxPool1d-191               [-1, 256, 1]               0
MyMaxPool1dPadSame-192               [-1, 256, 1]               0
      Bottleneck-193               [-1, 256, 1]               0
     BatchNorm1d-194               [-1, 256, 1]             512
            ReLU-195               [-1, 256, 1]               0
          Linear-196                    [-1, 2]             514
================================================================
Total params: 53,026
Trainable params: 53,026
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.87
Params size (MB): 0.20
Estimated Total Size (MB): 1.07
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 32, kernel_size: 4, n_block: 2
************************************************************
************************************************************
(2000, 1, 64) Counter({1: 1000, 0: 1000})
(2000, 1, 64) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 32, 64]             160
   MyConv1dPadSame-2               [-1, 32, 64]               0
       BatchNorm1d-3               [-1, 32, 64]              64
              ReLU-4               [-1, 32, 64]               0
            Conv1d-5               [-1, 32, 64]             160
   MyConv1dPadSame-6               [-1, 32, 64]               0
       BatchNorm1d-7               [-1, 32, 64]              64
              ReLU-8               [-1, 32, 64]               0
           Dropout-9               [-1, 32, 64]               0
           Conv1d-10               [-1, 32, 64]             160
  MyConv1dPadSame-11               [-1, 32, 64]               0
       Bottleneck-12               [-1, 32, 64]               0
      BatchNorm1d-13               [-1, 32, 64]              64
             ReLU-14               [-1, 32, 64]               0
          Dropout-15               [-1, 32, 64]               0
           Conv1d-16               [-1, 64, 64]             320
  MyConv1dPadSame-17               [-1, 64, 64]               0
      BatchNorm1d-18               [-1, 64, 64]             128
             ReLU-19               [-1, 64, 64]               0
          Dropout-20               [-1, 64, 64]               0
           Conv1d-21               [-1, 64, 64]             576
  MyConv1dPadSame-22               [-1, 64, 64]               0
       Bottleneck-23               [-1, 64, 64]               0
      BatchNorm1d-24               [-1, 64, 64]             128
             ReLU-25               [-1, 64, 64]               0
           Linear-26                    [-1, 2]             130
================================================================
Total params: 1,954
Trainable params: 1,954
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.55
Params size (MB): 0.01
Estimated Total Size (MB): 0.55
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 32, kernel_size: 4, n_block: 4
************************************************************
************************************************************
(2000, 1, 64) Counter({0: 1000, 1: 1000})
(2000, 1, 64) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 32, 64]             160
   MyConv1dPadSame-2               [-1, 32, 64]               0
       BatchNorm1d-3               [-1, 32, 64]              64
              ReLU-4               [-1, 32, 64]               0
            Conv1d-5               [-1, 32, 64]             160
   MyConv1dPadSame-6               [-1, 32, 64]               0
       BatchNorm1d-7               [-1, 32, 64]              64
              ReLU-8               [-1, 32, 64]               0
           Dropout-9               [-1, 32, 64]               0
           Conv1d-10               [-1, 32, 64]             160
  MyConv1dPadSame-11               [-1, 32, 64]               0
       Bottleneck-12               [-1, 32, 64]               0
      BatchNorm1d-13               [-1, 32, 64]              64
             ReLU-14               [-1, 32, 64]               0
          Dropout-15               [-1, 32, 64]               0
           Conv1d-16               [-1, 64, 64]             320
  MyConv1dPadSame-17               [-1, 64, 64]               0
      BatchNorm1d-18               [-1, 64, 64]             128
             ReLU-19               [-1, 64, 64]               0
          Dropout-20               [-1, 64, 64]               0
           Conv1d-21               [-1, 64, 64]             576
  MyConv1dPadSame-22               [-1, 64, 64]               0
       Bottleneck-23               [-1, 64, 64]               0
      BatchNorm1d-24               [-1, 64, 64]             128
             ReLU-25               [-1, 64, 64]               0
          Dropout-26               [-1, 64, 64]               0
           Conv1d-27              [-1, 128, 64]           1,152
  MyConv1dPadSame-28              [-1, 128, 64]               0
      BatchNorm1d-29              [-1, 128, 64]             256
             ReLU-30              [-1, 128, 64]               0
          Dropout-31              [-1, 128, 64]               0
           Conv1d-32              [-1, 128, 64]           2,176
  MyConv1dPadSame-33              [-1, 128, 64]               0
       Bottleneck-34              [-1, 128, 64]               0
      BatchNorm1d-35              [-1, 128, 64]             256
             ReLU-36              [-1, 128, 64]               0
          Dropout-37              [-1, 128, 64]               0
           Conv1d-38              [-1, 256, 64]           4,352
  MyConv1dPadSame-39              [-1, 256, 64]               0
      BatchNorm1d-40              [-1, 256, 64]             512
             ReLU-41              [-1, 256, 64]               0
          Dropout-42              [-1, 256, 64]               0
           Conv1d-43              [-1, 256, 64]           8,448
  MyConv1dPadSame-44              [-1, 256, 64]               0
       Bottleneck-45              [-1, 256, 64]               0
      BatchNorm1d-46              [-1, 256, 64]             512
             ReLU-47              [-1, 256, 64]               0
           Linear-48                    [-1, 2]             514
================================================================
Total params: 20,002
Trainable params: 20,002
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 2.52
Params size (MB): 0.08
Estimated Total Size (MB): 2.59
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 32, kernel_size: 4, n_block: 8
************************************************************
************************************************************
(2000, 1, 64) Counter({0: 1000, 1: 1000})
(2000, 1, 64) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 32, 64]             160
   MyConv1dPadSame-2               [-1, 32, 64]               0
       BatchNorm1d-3               [-1, 32, 64]              64
              ReLU-4               [-1, 32, 64]               0
            Conv1d-5               [-1, 32, 64]             160
   MyConv1dPadSame-6               [-1, 32, 64]               0
       BatchNorm1d-7               [-1, 32, 64]              64
              ReLU-8               [-1, 32, 64]               0
           Dropout-9               [-1, 32, 64]               0
           Conv1d-10               [-1, 32, 64]             160
  MyConv1dPadSame-11               [-1, 32, 64]               0
       Bottleneck-12               [-1, 32, 64]               0
      BatchNorm1d-13               [-1, 32, 64]              64
             ReLU-14               [-1, 32, 64]               0
          Dropout-15               [-1, 32, 64]               0
           Conv1d-16               [-1, 32, 64]             160
  MyConv1dPadSame-17               [-1, 32, 64]               0
      BatchNorm1d-18               [-1, 32, 64]              64
             ReLU-19               [-1, 32, 64]               0
          Dropout-20               [-1, 32, 64]               0
           Conv1d-21               [-1, 32, 64]             160
  MyConv1dPadSame-22               [-1, 32, 64]               0
       Bottleneck-23               [-1, 32, 64]               0
      BatchNorm1d-24               [-1, 32, 64]              64
             ReLU-25               [-1, 32, 64]               0
          Dropout-26               [-1, 32, 64]               0
           Conv1d-27               [-1, 64, 64]             320
  MyConv1dPadSame-28               [-1, 64, 64]               0
      BatchNorm1d-29               [-1, 64, 64]             128
             ReLU-30               [-1, 64, 64]               0
          Dropout-31               [-1, 64, 64]               0
           Conv1d-32               [-1, 64, 64]             576
  MyConv1dPadSame-33               [-1, 64, 64]               0
       Bottleneck-34               [-1, 64, 64]               0
      BatchNorm1d-35               [-1, 64, 64]             128
             ReLU-36               [-1, 64, 64]               0
          Dropout-37               [-1, 64, 64]               0
           Conv1d-38               [-1, 64, 64]             576
  MyConv1dPadSame-39               [-1, 64, 64]               0
      BatchNorm1d-40               [-1, 64, 64]             128
             ReLU-41               [-1, 64, 64]               0
          Dropout-42               [-1, 64, 64]               0
           Conv1d-43               [-1, 64, 64]             576
  MyConv1dPadSame-44               [-1, 64, 64]               0
       Bottleneck-45               [-1, 64, 64]               0
      BatchNorm1d-46               [-1, 64, 64]             128
             ReLU-47               [-1, 64, 64]               0
          Dropout-48               [-1, 64, 64]               0
           Conv1d-49              [-1, 128, 64]           1,152
  MyConv1dPadSame-50              [-1, 128, 64]               0
      BatchNorm1d-51              [-1, 128, 64]             256
             ReLU-52              [-1, 128, 64]               0
          Dropout-53              [-1, 128, 64]               0
           Conv1d-54              [-1, 128, 64]           2,176
  MyConv1dPadSame-55              [-1, 128, 64]               0
       Bottleneck-56              [-1, 128, 64]               0
      BatchNorm1d-57              [-1, 128, 64]             256
             ReLU-58              [-1, 128, 64]               0
          Dropout-59              [-1, 128, 64]               0
           Conv1d-60              [-1, 128, 64]           2,176
  MyConv1dPadSame-61              [-1, 128, 64]               0
      BatchNorm1d-62              [-1, 128, 64]             256
             ReLU-63              [-1, 128, 64]               0
          Dropout-64              [-1, 128, 64]               0
           Conv1d-65              [-1, 128, 64]           2,176
  MyConv1dPadSame-66              [-1, 128, 64]               0
       Bottleneck-67              [-1, 128, 64]               0
      BatchNorm1d-68              [-1, 128, 64]             256
             ReLU-69              [-1, 128, 64]               0
          Dropout-70              [-1, 128, 64]               0
           Conv1d-71              [-1, 256, 64]           4,352
  MyConv1dPadSame-72              [-1, 256, 64]               0
      BatchNorm1d-73              [-1, 256, 64]             512
             ReLU-74              [-1, 256, 64]               0
          Dropout-75              [-1, 256, 64]               0
           Conv1d-76              [-1, 256, 64]           8,448
  MyConv1dPadSame-77              [-1, 256, 64]               0
       Bottleneck-78              [-1, 256, 64]               0
      BatchNorm1d-79              [-1, 256, 64]             512
             ReLU-80              [-1, 256, 64]               0
          Dropout-81              [-1, 256, 64]               0
           Conv1d-82              [-1, 256, 64]           8,448
  MyConv1dPadSame-83              [-1, 256, 64]               0
      BatchNorm1d-84              [-1, 256, 64]             512
             ReLU-85              [-1, 256, 64]               0
          Dropout-86              [-1, 256, 64]               0
           Conv1d-87              [-1, 256, 64]           8,448
  MyConv1dPadSame-88              [-1, 256, 64]               0
       Bottleneck-89              [-1, 256, 64]               0
      BatchNorm1d-90              [-1, 256, 64]             512
             ReLU-91              [-1, 256, 64]               0
           Linear-92                    [-1, 2]             514
================================================================
Total params: 44,642
Trainable params: 44,642
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 5.09
Params size (MB): 0.17
Estimated Total Size (MB): 5.26
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 32, kernel_size: 4, n_block: 16
************************************************************
************************************************************
(2000, 1, 64) Counter({0: 1000, 1: 1000})
(2000, 1, 64) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 32, 64]             160
   MyConv1dPadSame-2               [-1, 32, 64]               0
       BatchNorm1d-3               [-1, 32, 64]              64
              ReLU-4               [-1, 32, 64]               0
            Conv1d-5               [-1, 32, 64]             160
   MyConv1dPadSame-6               [-1, 32, 64]               0
       BatchNorm1d-7               [-1, 32, 64]              64
              ReLU-8               [-1, 32, 64]               0
           Dropout-9               [-1, 32, 64]               0
           Conv1d-10               [-1, 32, 64]             160
  MyConv1dPadSame-11               [-1, 32, 64]               0
       Bottleneck-12               [-1, 32, 64]               0
      BatchNorm1d-13               [-1, 32, 64]              64
             ReLU-14               [-1, 32, 64]               0
          Dropout-15               [-1, 32, 64]               0
           Conv1d-16               [-1, 32, 32]             160
  MyConv1dPadSame-17               [-1, 32, 32]               0
      BatchNorm1d-18               [-1, 32, 32]              64
             ReLU-19               [-1, 32, 32]               0
          Dropout-20               [-1, 32, 32]               0
           Conv1d-21               [-1, 32, 32]             160
  MyConv1dPadSame-22               [-1, 32, 32]               0
        MaxPool1d-23               [-1, 32, 32]               0
MyMaxPool1dPadSame-24               [-1, 32, 32]               0
       Bottleneck-25               [-1, 32, 32]               0
      BatchNorm1d-26               [-1, 32, 32]              64
             ReLU-27               [-1, 32, 32]               0
          Dropout-28               [-1, 32, 32]               0
           Conv1d-29               [-1, 32, 32]             160
  MyConv1dPadSame-30               [-1, 32, 32]               0
      BatchNorm1d-31               [-1, 32, 32]              64
             ReLU-32               [-1, 32, 32]               0
          Dropout-33               [-1, 32, 32]               0
           Conv1d-34               [-1, 32, 32]             160
  MyConv1dPadSame-35               [-1, 32, 32]               0
       Bottleneck-36               [-1, 32, 32]               0
      BatchNorm1d-37               [-1, 32, 32]              64
             ReLU-38               [-1, 32, 32]               0
          Dropout-39               [-1, 32, 32]               0
           Conv1d-40               [-1, 32, 16]             160
  MyConv1dPadSame-41               [-1, 32, 16]               0
      BatchNorm1d-42               [-1, 32, 16]              64
             ReLU-43               [-1, 32, 16]               0
          Dropout-44               [-1, 32, 16]               0
           Conv1d-45               [-1, 32, 16]             160
  MyConv1dPadSame-46               [-1, 32, 16]               0
        MaxPool1d-47               [-1, 32, 16]               0
MyMaxPool1dPadSame-48               [-1, 32, 16]               0
       Bottleneck-49               [-1, 32, 16]               0
      BatchNorm1d-50               [-1, 32, 16]              64
             ReLU-51               [-1, 32, 16]               0
          Dropout-52               [-1, 32, 16]               0
           Conv1d-53               [-1, 64, 16]             320
  MyConv1dPadSame-54               [-1, 64, 16]               0
      BatchNorm1d-55               [-1, 64, 16]             128
             ReLU-56               [-1, 64, 16]               0
          Dropout-57               [-1, 64, 16]               0
           Conv1d-58               [-1, 64, 16]             576
  MyConv1dPadSame-59               [-1, 64, 16]               0
       Bottleneck-60               [-1, 64, 16]               0
      BatchNorm1d-61               [-1, 64, 16]             128
             ReLU-62               [-1, 64, 16]               0
          Dropout-63               [-1, 64, 16]               0
           Conv1d-64                [-1, 64, 8]             576
  MyConv1dPadSame-65                [-1, 64, 8]               0
      BatchNorm1d-66                [-1, 64, 8]             128
             ReLU-67                [-1, 64, 8]               0
          Dropout-68                [-1, 64, 8]               0
           Conv1d-69                [-1, 64, 8]             576
  MyConv1dPadSame-70                [-1, 64, 8]               0
        MaxPool1d-71                [-1, 64, 8]               0
MyMaxPool1dPadSame-72                [-1, 64, 8]               0
       Bottleneck-73                [-1, 64, 8]               0
      BatchNorm1d-74                [-1, 64, 8]             128
             ReLU-75                [-1, 64, 8]               0
          Dropout-76                [-1, 64, 8]               0
           Conv1d-77                [-1, 64, 8]             576
  MyConv1dPadSame-78                [-1, 64, 8]               0
      BatchNorm1d-79                [-1, 64, 8]             128
             ReLU-80                [-1, 64, 8]               0
          Dropout-81                [-1, 64, 8]               0
           Conv1d-82                [-1, 64, 8]             576
  MyConv1dPadSame-83                [-1, 64, 8]               0
       Bottleneck-84                [-1, 64, 8]               0
      BatchNorm1d-85                [-1, 64, 8]             128
             ReLU-86                [-1, 64, 8]               0
          Dropout-87                [-1, 64, 8]               0
           Conv1d-88                [-1, 64, 4]             576
  MyConv1dPadSame-89                [-1, 64, 4]               0
      BatchNorm1d-90                [-1, 64, 4]             128
             ReLU-91                [-1, 64, 4]               0
          Dropout-92                [-1, 64, 4]               0
           Conv1d-93                [-1, 64, 4]             576
  MyConv1dPadSame-94                [-1, 64, 4]               0
        MaxPool1d-95                [-1, 64, 4]               0
MyMaxPool1dPadSame-96                [-1, 64, 4]               0
       Bottleneck-97                [-1, 64, 4]               0
      BatchNorm1d-98                [-1, 64, 4]             128
             ReLU-99                [-1, 64, 4]               0
         Dropout-100                [-1, 64, 4]               0
          Conv1d-101               [-1, 128, 4]           1,152
 MyConv1dPadSame-102               [-1, 128, 4]               0
     BatchNorm1d-103               [-1, 128, 4]             256
            ReLU-104               [-1, 128, 4]               0
         Dropout-105               [-1, 128, 4]               0
          Conv1d-106               [-1, 128, 4]           2,176
 MyConv1dPadSame-107               [-1, 128, 4]               0
      Bottleneck-108               [-1, 128, 4]               0
     BatchNorm1d-109               [-1, 128, 4]             256
            ReLU-110               [-1, 128, 4]               0
         Dropout-111               [-1, 128, 4]               0
          Conv1d-112               [-1, 128, 2]           2,176
 MyConv1dPadSame-113               [-1, 128, 2]               0
     BatchNorm1d-114               [-1, 128, 2]             256
            ReLU-115               [-1, 128, 2]               0
         Dropout-116               [-1, 128, 2]               0
          Conv1d-117               [-1, 128, 2]           2,176
 MyConv1dPadSame-118               [-1, 128, 2]               0
       MaxPool1d-119               [-1, 128, 2]               0
MyMaxPool1dPadSame-120               [-1, 128, 2]               0
      Bottleneck-121               [-1, 128, 2]               0
     BatchNorm1d-122               [-1, 128, 2]             256
            ReLU-123               [-1, 128, 2]               0
         Dropout-124               [-1, 128, 2]               0
          Conv1d-125               [-1, 128, 2]           2,176
 MyConv1dPadSame-126               [-1, 128, 2]               0
     BatchNorm1d-127               [-1, 128, 2]             256
            ReLU-128               [-1, 128, 2]               0
         Dropout-129               [-1, 128, 2]               0
          Conv1d-130               [-1, 128, 2]           2,176
 MyConv1dPadSame-131               [-1, 128, 2]               0
      Bottleneck-132               [-1, 128, 2]               0
     BatchNorm1d-133               [-1, 128, 2]             256
            ReLU-134               [-1, 128, 2]               0
         Dropout-135               [-1, 128, 2]               0
          Conv1d-136               [-1, 128, 1]           2,176
 MyConv1dPadSame-137               [-1, 128, 1]               0
     BatchNorm1d-138               [-1, 128, 1]             256
            ReLU-139               [-1, 128, 1]               0
         Dropout-140               [-1, 128, 1]               0
          Conv1d-141               [-1, 128, 1]           2,176
 MyConv1dPadSame-142               [-1, 128, 1]               0
       MaxPool1d-143               [-1, 128, 1]               0
MyMaxPool1dPadSame-144               [-1, 128, 1]               0
      Bottleneck-145               [-1, 128, 1]               0
     BatchNorm1d-146               [-1, 128, 1]             256
            ReLU-147               [-1, 128, 1]               0
         Dropout-148               [-1, 128, 1]               0
          Conv1d-149               [-1, 256, 1]           4,352
 MyConv1dPadSame-150               [-1, 256, 1]               0
     BatchNorm1d-151               [-1, 256, 1]             512
            ReLU-152               [-1, 256, 1]               0
         Dropout-153               [-1, 256, 1]               0
          Conv1d-154               [-1, 256, 1]           8,448
 MyConv1dPadSame-155               [-1, 256, 1]               0
      Bottleneck-156               [-1, 256, 1]               0
     BatchNorm1d-157               [-1, 256, 1]             512
            ReLU-158               [-1, 256, 1]               0
         Dropout-159               [-1, 256, 1]               0
          Conv1d-160               [-1, 256, 1]           8,448
 MyConv1dPadSame-161               [-1, 256, 1]               0
     BatchNorm1d-162               [-1, 256, 1]             512
            ReLU-163               [-1, 256, 1]               0
         Dropout-164               [-1, 256, 1]               0
          Conv1d-165               [-1, 256, 1]           8,448
 MyConv1dPadSame-166               [-1, 256, 1]               0
       MaxPool1d-167               [-1, 256, 1]               0
MyMaxPool1dPadSame-168               [-1, 256, 1]               0
      Bottleneck-169               [-1, 256, 1]               0
     BatchNorm1d-170               [-1, 256, 1]             512
            ReLU-171               [-1, 256, 1]               0
         Dropout-172               [-1, 256, 1]               0
          Conv1d-173               [-1, 256, 1]           8,448
 MyConv1dPadSame-174               [-1, 256, 1]               0
     BatchNorm1d-175               [-1, 256, 1]             512
            ReLU-176               [-1, 256, 1]               0
         Dropout-177               [-1, 256, 1]               0
          Conv1d-178               [-1, 256, 1]           8,448
 MyConv1dPadSame-179               [-1, 256, 1]               0
      Bottleneck-180               [-1, 256, 1]               0
     BatchNorm1d-181               [-1, 256, 1]             512
            ReLU-182               [-1, 256, 1]               0
         Dropout-183               [-1, 256, 1]               0
          Conv1d-184               [-1, 256, 1]           8,448
 MyConv1dPadSame-185               [-1, 256, 1]               0
     BatchNorm1d-186               [-1, 256, 1]             512
            ReLU-187               [-1, 256, 1]               0
         Dropout-188               [-1, 256, 1]               0
          Conv1d-189               [-1, 256, 1]           8,448
 MyConv1dPadSame-190               [-1, 256, 1]               0
       MaxPool1d-191               [-1, 256, 1]               0
MyMaxPool1dPadSame-192               [-1, 256, 1]               0
      Bottleneck-193               [-1, 256, 1]               0
     BatchNorm1d-194               [-1, 256, 1]             512
            ReLU-195               [-1, 256, 1]               0
          Linear-196                    [-1, 2]             514
================================================================
Total params: 93,922
Trainable params: 93,922
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.87
Params size (MB): 0.36
Estimated Total Size (MB): 1.23
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 32, kernel_size: 8, n_block: 2
************************************************************
************************************************************
(2000, 1, 64) Counter({0: 1000, 1: 1000})
(2000, 1, 64) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 32, 64]             288
   MyConv1dPadSame-2               [-1, 32, 64]               0
       BatchNorm1d-3               [-1, 32, 64]              64
              ReLU-4               [-1, 32, 64]               0
            Conv1d-5               [-1, 32, 64]             288
   MyConv1dPadSame-6               [-1, 32, 64]               0
       BatchNorm1d-7               [-1, 32, 64]              64
              ReLU-8               [-1, 32, 64]               0
           Dropout-9               [-1, 32, 64]               0
           Conv1d-10               [-1, 32, 64]             288
  MyConv1dPadSame-11               [-1, 32, 64]               0
       Bottleneck-12               [-1, 32, 64]               0
      BatchNorm1d-13               [-1, 32, 64]              64
             ReLU-14               [-1, 32, 64]               0
          Dropout-15               [-1, 32, 64]               0
           Conv1d-16               [-1, 64, 64]             576
  MyConv1dPadSame-17               [-1, 64, 64]               0
      BatchNorm1d-18               [-1, 64, 64]             128
             ReLU-19               [-1, 64, 64]               0
          Dropout-20               [-1, 64, 64]               0
           Conv1d-21               [-1, 64, 64]           1,088
  MyConv1dPadSame-22               [-1, 64, 64]               0
       Bottleneck-23               [-1, 64, 64]               0
      BatchNorm1d-24               [-1, 64, 64]             128
             ReLU-25               [-1, 64, 64]               0
           Linear-26                    [-1, 2]             130
================================================================
Total params: 3,106
Trainable params: 3,106
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.55
Params size (MB): 0.01
Estimated Total Size (MB): 0.56
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 32, kernel_size: 8, n_block: 4
************************************************************
************************************************************
(2000, 1, 64) Counter({0: 1000, 1: 1000})
(2000, 1, 64) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 32, 64]             288
   MyConv1dPadSame-2               [-1, 32, 64]               0
       BatchNorm1d-3               [-1, 32, 64]              64
              ReLU-4               [-1, 32, 64]               0
            Conv1d-5               [-1, 32, 64]             288
   MyConv1dPadSame-6               [-1, 32, 64]               0
       BatchNorm1d-7               [-1, 32, 64]              64
              ReLU-8               [-1, 32, 64]               0
           Dropout-9               [-1, 32, 64]               0
           Conv1d-10               [-1, 32, 64]             288
  MyConv1dPadSame-11               [-1, 32, 64]               0
       Bottleneck-12               [-1, 32, 64]               0
      BatchNorm1d-13               [-1, 32, 64]              64
             ReLU-14               [-1, 32, 64]               0
          Dropout-15               [-1, 32, 64]               0
           Conv1d-16               [-1, 64, 64]             576
  MyConv1dPadSame-17               [-1, 64, 64]               0
      BatchNorm1d-18               [-1, 64, 64]             128
             ReLU-19               [-1, 64, 64]               0
          Dropout-20               [-1, 64, 64]               0
           Conv1d-21               [-1, 64, 64]           1,088
  MyConv1dPadSame-22               [-1, 64, 64]               0
       Bottleneck-23               [-1, 64, 64]               0
      BatchNorm1d-24               [-1, 64, 64]             128
             ReLU-25               [-1, 64, 64]               0
          Dropout-26               [-1, 64, 64]               0
           Conv1d-27              [-1, 128, 64]           2,176
  MyConv1dPadSame-28              [-1, 128, 64]               0
      BatchNorm1d-29              [-1, 128, 64]             256
             ReLU-30              [-1, 128, 64]               0
          Dropout-31              [-1, 128, 64]               0
           Conv1d-32              [-1, 128, 64]           4,224
  MyConv1dPadSame-33              [-1, 128, 64]               0
       Bottleneck-34              [-1, 128, 64]               0
      BatchNorm1d-35              [-1, 128, 64]             256
             ReLU-36              [-1, 128, 64]               0
          Dropout-37              [-1, 128, 64]               0
           Conv1d-38              [-1, 256, 64]           8,448
  MyConv1dPadSame-39              [-1, 256, 64]               0
      BatchNorm1d-40              [-1, 256, 64]             512
             ReLU-41              [-1, 256, 64]               0
          Dropout-42              [-1, 256, 64]               0
           Conv1d-43              [-1, 256, 64]          16,640
  MyConv1dPadSame-44              [-1, 256, 64]               0
       Bottleneck-45              [-1, 256, 64]               0
      BatchNorm1d-46              [-1, 256, 64]             512
             ReLU-47              [-1, 256, 64]               0
           Linear-48                    [-1, 2]             514
================================================================
Total params: 36,514
Trainable params: 36,514
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 2.52
Params size (MB): 0.14
Estimated Total Size (MB): 2.66
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 32, kernel_size: 8, n_block: 8
************************************************************
************************************************************
(2000, 1, 64) Counter({0: 1000, 1: 1000})
(2000, 1, 64) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 32, 64]             288
   MyConv1dPadSame-2               [-1, 32, 64]               0
       BatchNorm1d-3               [-1, 32, 64]              64
              ReLU-4               [-1, 32, 64]               0
            Conv1d-5               [-1, 32, 64]             288
   MyConv1dPadSame-6               [-1, 32, 64]               0
       BatchNorm1d-7               [-1, 32, 64]              64
              ReLU-8               [-1, 32, 64]               0
           Dropout-9               [-1, 32, 64]               0
           Conv1d-10               [-1, 32, 64]             288
  MyConv1dPadSame-11               [-1, 32, 64]               0
       Bottleneck-12               [-1, 32, 64]               0
      BatchNorm1d-13               [-1, 32, 64]              64
             ReLU-14               [-1, 32, 64]               0
          Dropout-15               [-1, 32, 64]               0
           Conv1d-16               [-1, 32, 64]             288
  MyConv1dPadSame-17               [-1, 32, 64]               0
      BatchNorm1d-18               [-1, 32, 64]              64
             ReLU-19               [-1, 32, 64]               0
          Dropout-20               [-1, 32, 64]               0
           Conv1d-21               [-1, 32, 64]             288
  MyConv1dPadSame-22               [-1, 32, 64]               0
       Bottleneck-23               [-1, 32, 64]               0
      BatchNorm1d-24               [-1, 32, 64]              64
             ReLU-25               [-1, 32, 64]               0
          Dropout-26               [-1, 32, 64]               0
           Conv1d-27               [-1, 64, 64]             576
  MyConv1dPadSame-28               [-1, 64, 64]               0
      BatchNorm1d-29               [-1, 64, 64]             128
             ReLU-30               [-1, 64, 64]               0
          Dropout-31               [-1, 64, 64]               0
           Conv1d-32               [-1, 64, 64]           1,088
  MyConv1dPadSame-33               [-1, 64, 64]               0
       Bottleneck-34               [-1, 64, 64]               0
      BatchNorm1d-35               [-1, 64, 64]             128
             ReLU-36               [-1, 64, 64]               0
          Dropout-37               [-1, 64, 64]               0
           Conv1d-38               [-1, 64, 64]           1,088
  MyConv1dPadSame-39               [-1, 64, 64]               0
      BatchNorm1d-40               [-1, 64, 64]             128
             ReLU-41               [-1, 64, 64]               0
          Dropout-42               [-1, 64, 64]               0
           Conv1d-43               [-1, 64, 64]           1,088
  MyConv1dPadSame-44               [-1, 64, 64]               0
       Bottleneck-45               [-1, 64, 64]               0
      BatchNorm1d-46               [-1, 64, 64]             128
             ReLU-47               [-1, 64, 64]               0
          Dropout-48               [-1, 64, 64]               0
           Conv1d-49              [-1, 128, 64]           2,176
  MyConv1dPadSame-50              [-1, 128, 64]               0
      BatchNorm1d-51              [-1, 128, 64]             256
             ReLU-52              [-1, 128, 64]               0
          Dropout-53              [-1, 128, 64]               0
           Conv1d-54              [-1, 128, 64]           4,224
  MyConv1dPadSame-55              [-1, 128, 64]               0
       Bottleneck-56              [-1, 128, 64]               0
      BatchNorm1d-57              [-1, 128, 64]             256
             ReLU-58              [-1, 128, 64]               0
          Dropout-59              [-1, 128, 64]               0
           Conv1d-60              [-1, 128, 64]           4,224
  MyConv1dPadSame-61              [-1, 128, 64]               0
      BatchNorm1d-62              [-1, 128, 64]             256
             ReLU-63              [-1, 128, 64]               0
          Dropout-64              [-1, 128, 64]               0
           Conv1d-65              [-1, 128, 64]           4,224
  MyConv1dPadSame-66              [-1, 128, 64]               0
       Bottleneck-67              [-1, 128, 64]               0
      BatchNorm1d-68              [-1, 128, 64]             256
             ReLU-69              [-1, 128, 64]               0
          Dropout-70              [-1, 128, 64]               0
           Conv1d-71              [-1, 256, 64]           8,448
  MyConv1dPadSame-72              [-1, 256, 64]               0
      BatchNorm1d-73              [-1, 256, 64]             512
             ReLU-74              [-1, 256, 64]               0
          Dropout-75              [-1, 256, 64]               0
           Conv1d-76              [-1, 256, 64]          16,640
  MyConv1dPadSame-77              [-1, 256, 64]               0
       Bottleneck-78              [-1, 256, 64]               0
      BatchNorm1d-79              [-1, 256, 64]             512
             ReLU-80              [-1, 256, 64]               0
          Dropout-81              [-1, 256, 64]               0
           Conv1d-82              [-1, 256, 64]          16,640
  MyConv1dPadSame-83              [-1, 256, 64]               0
      BatchNorm1d-84              [-1, 256, 64]             512
             ReLU-85              [-1, 256, 64]               0
          Dropout-86              [-1, 256, 64]               0
           Conv1d-87              [-1, 256, 64]          16,640
  MyConv1dPadSame-88              [-1, 256, 64]               0
       Bottleneck-89              [-1, 256, 64]               0
      BatchNorm1d-90              [-1, 256, 64]             512
             ReLU-91              [-1, 256, 64]               0
           Linear-92                    [-1, 2]             514
================================================================
Total params: 82,914
Trainable params: 82,914
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 5.09
Params size (MB): 0.32
Estimated Total Size (MB): 5.41
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 32, kernel_size: 8, n_block: 16
************************************************************
************************************************************
(2000, 1, 64) Counter({0: 1000, 1: 1000})
(2000, 1, 64) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 32, 64]             288
   MyConv1dPadSame-2               [-1, 32, 64]               0
       BatchNorm1d-3               [-1, 32, 64]              64
              ReLU-4               [-1, 32, 64]               0
            Conv1d-5               [-1, 32, 64]             288
   MyConv1dPadSame-6               [-1, 32, 64]               0
       BatchNorm1d-7               [-1, 32, 64]              64
              ReLU-8               [-1, 32, 64]               0
           Dropout-9               [-1, 32, 64]               0
           Conv1d-10               [-1, 32, 64]             288
  MyConv1dPadSame-11               [-1, 32, 64]               0
       Bottleneck-12               [-1, 32, 64]               0
      BatchNorm1d-13               [-1, 32, 64]              64
             ReLU-14               [-1, 32, 64]               0
          Dropout-15               [-1, 32, 64]               0
           Conv1d-16               [-1, 32, 32]             288
  MyConv1dPadSame-17               [-1, 32, 32]               0
      BatchNorm1d-18               [-1, 32, 32]              64
             ReLU-19               [-1, 32, 32]               0
          Dropout-20               [-1, 32, 32]               0
           Conv1d-21               [-1, 32, 32]             288
  MyConv1dPadSame-22               [-1, 32, 32]               0
        MaxPool1d-23               [-1, 32, 32]               0
MyMaxPool1dPadSame-24               [-1, 32, 32]               0
       Bottleneck-25               [-1, 32, 32]               0
      BatchNorm1d-26               [-1, 32, 32]              64
             ReLU-27               [-1, 32, 32]               0
          Dropout-28               [-1, 32, 32]               0
           Conv1d-29               [-1, 32, 32]             288
  MyConv1dPadSame-30               [-1, 32, 32]               0
      BatchNorm1d-31               [-1, 32, 32]              64
             ReLU-32               [-1, 32, 32]               0
          Dropout-33               [-1, 32, 32]               0
           Conv1d-34               [-1, 32, 32]             288
  MyConv1dPadSame-35               [-1, 32, 32]               0
       Bottleneck-36               [-1, 32, 32]               0
      BatchNorm1d-37               [-1, 32, 32]              64
             ReLU-38               [-1, 32, 32]               0
          Dropout-39               [-1, 32, 32]               0
           Conv1d-40               [-1, 32, 16]             288
  MyConv1dPadSame-41               [-1, 32, 16]               0
      BatchNorm1d-42               [-1, 32, 16]              64
             ReLU-43               [-1, 32, 16]               0
          Dropout-44               [-1, 32, 16]               0
           Conv1d-45               [-1, 32, 16]             288
  MyConv1dPadSame-46               [-1, 32, 16]               0
        MaxPool1d-47               [-1, 32, 16]               0
MyMaxPool1dPadSame-48               [-1, 32, 16]               0
       Bottleneck-49               [-1, 32, 16]               0
      BatchNorm1d-50               [-1, 32, 16]              64
             ReLU-51               [-1, 32, 16]               0
          Dropout-52               [-1, 32, 16]               0
           Conv1d-53               [-1, 64, 16]             576
  MyConv1dPadSame-54               [-1, 64, 16]               0
      BatchNorm1d-55               [-1, 64, 16]             128
             ReLU-56               [-1, 64, 16]               0
          Dropout-57               [-1, 64, 16]               0
           Conv1d-58               [-1, 64, 16]           1,088
  MyConv1dPadSame-59               [-1, 64, 16]               0
       Bottleneck-60               [-1, 64, 16]               0
      BatchNorm1d-61               [-1, 64, 16]             128
             ReLU-62               [-1, 64, 16]               0
          Dropout-63               [-1, 64, 16]               0
           Conv1d-64                [-1, 64, 8]           1,088
  MyConv1dPadSame-65                [-1, 64, 8]               0
      BatchNorm1d-66                [-1, 64, 8]             128
             ReLU-67                [-1, 64, 8]               0
          Dropout-68                [-1, 64, 8]               0
           Conv1d-69                [-1, 64, 8]           1,088
  MyConv1dPadSame-70                [-1, 64, 8]               0
        MaxPool1d-71                [-1, 64, 8]               0
MyMaxPool1dPadSame-72                [-1, 64, 8]               0
       Bottleneck-73                [-1, 64, 8]               0
      BatchNorm1d-74                [-1, 64, 8]             128
             ReLU-75                [-1, 64, 8]               0
          Dropout-76                [-1, 64, 8]               0
           Conv1d-77                [-1, 64, 8]           1,088
  MyConv1dPadSame-78                [-1, 64, 8]               0
      BatchNorm1d-79                [-1, 64, 8]             128
             ReLU-80                [-1, 64, 8]               0
          Dropout-81                [-1, 64, 8]               0
           Conv1d-82                [-1, 64, 8]           1,088
  MyConv1dPadSame-83                [-1, 64, 8]               0
       Bottleneck-84                [-1, 64, 8]               0
      BatchNorm1d-85                [-1, 64, 8]             128
             ReLU-86                [-1, 64, 8]               0
          Dropout-87                [-1, 64, 8]               0
           Conv1d-88                [-1, 64, 4]           1,088
  MyConv1dPadSame-89                [-1, 64, 4]               0
      BatchNorm1d-90                [-1, 64, 4]             128
             ReLU-91                [-1, 64, 4]               0
          Dropout-92                [-1, 64, 4]               0
           Conv1d-93                [-1, 64, 4]           1,088
  MyConv1dPadSame-94                [-1, 64, 4]               0
        MaxPool1d-95                [-1, 64, 4]               0
MyMaxPool1dPadSame-96                [-1, 64, 4]               0
       Bottleneck-97                [-1, 64, 4]               0
      BatchNorm1d-98                [-1, 64, 4]             128
             ReLU-99                [-1, 64, 4]               0
         Dropout-100                [-1, 64, 4]               0
          Conv1d-101               [-1, 128, 4]           2,176
 MyConv1dPadSame-102               [-1, 128, 4]               0
     BatchNorm1d-103               [-1, 128, 4]             256
            ReLU-104               [-1, 128, 4]               0
         Dropout-105               [-1, 128, 4]               0
          Conv1d-106               [-1, 128, 4]           4,224
 MyConv1dPadSame-107               [-1, 128, 4]               0
      Bottleneck-108               [-1, 128, 4]               0
     BatchNorm1d-109               [-1, 128, 4]             256
            ReLU-110               [-1, 128, 4]               0
         Dropout-111               [-1, 128, 4]               0
          Conv1d-112               [-1, 128, 2]           4,224
 MyConv1dPadSame-113               [-1, 128, 2]               0
     BatchNorm1d-114               [-1, 128, 2]             256
            ReLU-115               [-1, 128, 2]               0
         Dropout-116               [-1, 128, 2]               0
          Conv1d-117               [-1, 128, 2]           4,224
 MyConv1dPadSame-118               [-1, 128, 2]               0
       MaxPool1d-119               [-1, 128, 2]               0
MyMaxPool1dPadSame-120               [-1, 128, 2]               0
      Bottleneck-121               [-1, 128, 2]               0
     BatchNorm1d-122               [-1, 128, 2]             256
            ReLU-123               [-1, 128, 2]               0
         Dropout-124               [-1, 128, 2]               0
          Conv1d-125               [-1, 128, 2]           4,224
 MyConv1dPadSame-126               [-1, 128, 2]               0
     BatchNorm1d-127               [-1, 128, 2]             256
            ReLU-128               [-1, 128, 2]               0
         Dropout-129               [-1, 128, 2]               0
          Conv1d-130               [-1, 128, 2]           4,224
 MyConv1dPadSame-131               [-1, 128, 2]               0
      Bottleneck-132               [-1, 128, 2]               0
     BatchNorm1d-133               [-1, 128, 2]             256
            ReLU-134               [-1, 128, 2]               0
         Dropout-135               [-1, 128, 2]               0
          Conv1d-136               [-1, 128, 1]           4,224
 MyConv1dPadSame-137               [-1, 128, 1]               0
     BatchNorm1d-138               [-1, 128, 1]             256
            ReLU-139               [-1, 128, 1]               0
         Dropout-140               [-1, 128, 1]               0
          Conv1d-141               [-1, 128, 1]           4,224
 MyConv1dPadSame-142               [-1, 128, 1]               0
       MaxPool1d-143               [-1, 128, 1]               0
MyMaxPool1dPadSame-144               [-1, 128, 1]               0
      Bottleneck-145               [-1, 128, 1]               0
     BatchNorm1d-146               [-1, 128, 1]             256
            ReLU-147               [-1, 128, 1]               0
         Dropout-148               [-1, 128, 1]               0
          Conv1d-149               [-1, 256, 1]           8,448
 MyConv1dPadSame-150               [-1, 256, 1]               0
     BatchNorm1d-151               [-1, 256, 1]             512
            ReLU-152               [-1, 256, 1]               0
         Dropout-153               [-1, 256, 1]               0
          Conv1d-154               [-1, 256, 1]          16,640
 MyConv1dPadSame-155               [-1, 256, 1]               0
      Bottleneck-156               [-1, 256, 1]               0
     BatchNorm1d-157               [-1, 256, 1]             512
            ReLU-158               [-1, 256, 1]               0
         Dropout-159               [-1, 256, 1]               0
          Conv1d-160               [-1, 256, 1]          16,640
 MyConv1dPadSame-161               [-1, 256, 1]               0
     BatchNorm1d-162               [-1, 256, 1]             512
            ReLU-163               [-1, 256, 1]               0
         Dropout-164               [-1, 256, 1]               0
          Conv1d-165               [-1, 256, 1]          16,640
 MyConv1dPadSame-166               [-1, 256, 1]               0
       MaxPool1d-167               [-1, 256, 1]               0
MyMaxPool1dPadSame-168               [-1, 256, 1]               0
      Bottleneck-169               [-1, 256, 1]               0
     BatchNorm1d-170               [-1, 256, 1]             512
            ReLU-171               [-1, 256, 1]               0
         Dropout-172               [-1, 256, 1]               0
          Conv1d-173               [-1, 256, 1]          16,640
 MyConv1dPadSame-174               [-1, 256, 1]               0
     BatchNorm1d-175               [-1, 256, 1]             512
            ReLU-176               [-1, 256, 1]               0
         Dropout-177               [-1, 256, 1]               0
          Conv1d-178               [-1, 256, 1]          16,640
 MyConv1dPadSame-179               [-1, 256, 1]               0
      Bottleneck-180               [-1, 256, 1]               0
     BatchNorm1d-181               [-1, 256, 1]             512
            ReLU-182               [-1, 256, 1]               0
         Dropout-183               [-1, 256, 1]               0
          Conv1d-184               [-1, 256, 1]          16,640
 MyConv1dPadSame-185               [-1, 256, 1]               0
     BatchNorm1d-186               [-1, 256, 1]             512
            ReLU-187               [-1, 256, 1]               0
         Dropout-188               [-1, 256, 1]               0
          Conv1d-189               [-1, 256, 1]          16,640
 MyConv1dPadSame-190               [-1, 256, 1]               0
       MaxPool1d-191               [-1, 256, 1]               0
MyMaxPool1dPadSame-192               [-1, 256, 1]               0
      Bottleneck-193               [-1, 256, 1]               0
     BatchNorm1d-194               [-1, 256, 1]             512
            ReLU-195               [-1, 256, 1]               0
          Linear-196                    [-1, 2]             514
================================================================
Total params: 175,714
Trainable params: 175,714
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.87
Params size (MB): 0.67
Estimated Total Size (MB): 1.54
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 32, kernel_size: 16, n_block: 2
************************************************************
************************************************************
(2000, 1, 64) Counter({1: 1000, 0: 1000})
(2000, 1, 64) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 32, 64]             544
   MyConv1dPadSame-2               [-1, 32, 64]               0
       BatchNorm1d-3               [-1, 32, 64]              64
              ReLU-4               [-1, 32, 64]               0
            Conv1d-5               [-1, 32, 64]             544
   MyConv1dPadSame-6               [-1, 32, 64]               0
       BatchNorm1d-7               [-1, 32, 64]              64
              ReLU-8               [-1, 32, 64]               0
           Dropout-9               [-1, 32, 64]               0
           Conv1d-10               [-1, 32, 64]             544
  MyConv1dPadSame-11               [-1, 32, 64]               0
       Bottleneck-12               [-1, 32, 64]               0
      BatchNorm1d-13               [-1, 32, 64]              64
             ReLU-14               [-1, 32, 64]               0
          Dropout-15               [-1, 32, 64]               0
           Conv1d-16               [-1, 64, 64]           1,088
  MyConv1dPadSame-17               [-1, 64, 64]               0
      BatchNorm1d-18               [-1, 64, 64]             128
             ReLU-19               [-1, 64, 64]               0
          Dropout-20               [-1, 64, 64]               0
           Conv1d-21               [-1, 64, 64]           2,112
  MyConv1dPadSame-22               [-1, 64, 64]               0
       Bottleneck-23               [-1, 64, 64]               0
      BatchNorm1d-24               [-1, 64, 64]             128
             ReLU-25               [-1, 64, 64]               0
           Linear-26                    [-1, 2]             130
================================================================
Total params: 5,410
Trainable params: 5,410
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.55
Params size (MB): 0.02
Estimated Total Size (MB): 0.57
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 32, kernel_size: 16, n_block: 4
************************************************************
************************************************************
(2000, 1, 64) Counter({1: 1000, 0: 1000})
(2000, 1, 64) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 32, 64]             544
   MyConv1dPadSame-2               [-1, 32, 64]               0
       BatchNorm1d-3               [-1, 32, 64]              64
              ReLU-4               [-1, 32, 64]               0
            Conv1d-5               [-1, 32, 64]             544
   MyConv1dPadSame-6               [-1, 32, 64]               0
       BatchNorm1d-7               [-1, 32, 64]              64
              ReLU-8               [-1, 32, 64]               0
           Dropout-9               [-1, 32, 64]               0
           Conv1d-10               [-1, 32, 64]             544
  MyConv1dPadSame-11               [-1, 32, 64]               0
       Bottleneck-12               [-1, 32, 64]               0
      BatchNorm1d-13               [-1, 32, 64]              64
             ReLU-14               [-1, 32, 64]               0
          Dropout-15               [-1, 32, 64]               0
           Conv1d-16               [-1, 64, 64]           1,088
  MyConv1dPadSame-17               [-1, 64, 64]               0
      BatchNorm1d-18               [-1, 64, 64]             128
             ReLU-19               [-1, 64, 64]               0
          Dropout-20               [-1, 64, 64]               0
           Conv1d-21               [-1, 64, 64]           2,112
  MyConv1dPadSame-22               [-1, 64, 64]               0
       Bottleneck-23               [-1, 64, 64]               0
      BatchNorm1d-24               [-1, 64, 64]             128
             ReLU-25               [-1, 64, 64]               0
          Dropout-26               [-1, 64, 64]               0
           Conv1d-27              [-1, 128, 64]           4,224
  MyConv1dPadSame-28              [-1, 128, 64]               0
      BatchNorm1d-29              [-1, 128, 64]             256
             ReLU-30              [-1, 128, 64]               0
          Dropout-31              [-1, 128, 64]               0
           Conv1d-32              [-1, 128, 64]           8,320
  MyConv1dPadSame-33              [-1, 128, 64]               0
       Bottleneck-34              [-1, 128, 64]               0
      BatchNorm1d-35              [-1, 128, 64]             256
             ReLU-36              [-1, 128, 64]               0
          Dropout-37              [-1, 128, 64]               0
           Conv1d-38              [-1, 256, 64]          16,640
  MyConv1dPadSame-39              [-1, 256, 64]               0
      BatchNorm1d-40              [-1, 256, 64]             512
             ReLU-41              [-1, 256, 64]               0
          Dropout-42              [-1, 256, 64]               0
           Conv1d-43              [-1, 256, 64]          33,024
  MyConv1dPadSame-44              [-1, 256, 64]               0
       Bottleneck-45              [-1, 256, 64]               0
      BatchNorm1d-46              [-1, 256, 64]             512
             ReLU-47              [-1, 256, 64]               0
           Linear-48                    [-1, 2]             514
================================================================
Total params: 69,538
Trainable params: 69,538
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 2.52
Params size (MB): 0.27
Estimated Total Size (MB): 2.78
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 32, kernel_size: 16, n_block: 8
************************************************************
************************************************************
(2000, 1, 64) Counter({1: 1000, 0: 1000})
(2000, 1, 64) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 32, 64]             544
   MyConv1dPadSame-2               [-1, 32, 64]               0
       BatchNorm1d-3               [-1, 32, 64]              64
              ReLU-4               [-1, 32, 64]               0
            Conv1d-5               [-1, 32, 64]             544
   MyConv1dPadSame-6               [-1, 32, 64]               0
       BatchNorm1d-7               [-1, 32, 64]              64
              ReLU-8               [-1, 32, 64]               0
           Dropout-9               [-1, 32, 64]               0
           Conv1d-10               [-1, 32, 64]             544
  MyConv1dPadSame-11               [-1, 32, 64]               0
       Bottleneck-12               [-1, 32, 64]               0
      BatchNorm1d-13               [-1, 32, 64]              64
             ReLU-14               [-1, 32, 64]               0
          Dropout-15               [-1, 32, 64]               0
           Conv1d-16               [-1, 32, 64]             544
  MyConv1dPadSame-17               [-1, 32, 64]               0
      BatchNorm1d-18               [-1, 32, 64]              64
             ReLU-19               [-1, 32, 64]               0
          Dropout-20               [-1, 32, 64]               0
           Conv1d-21               [-1, 32, 64]             544
  MyConv1dPadSame-22               [-1, 32, 64]               0
       Bottleneck-23               [-1, 32, 64]               0
      BatchNorm1d-24               [-1, 32, 64]              64
             ReLU-25               [-1, 32, 64]               0
          Dropout-26               [-1, 32, 64]               0
           Conv1d-27               [-1, 64, 64]           1,088
  MyConv1dPadSame-28               [-1, 64, 64]               0
      BatchNorm1d-29               [-1, 64, 64]             128
             ReLU-30               [-1, 64, 64]               0
          Dropout-31               [-1, 64, 64]               0
           Conv1d-32               [-1, 64, 64]           2,112
  MyConv1dPadSame-33               [-1, 64, 64]               0
       Bottleneck-34               [-1, 64, 64]               0
      BatchNorm1d-35               [-1, 64, 64]             128
             ReLU-36               [-1, 64, 64]               0
          Dropout-37               [-1, 64, 64]               0
           Conv1d-38               [-1, 64, 64]           2,112
  MyConv1dPadSame-39               [-1, 64, 64]               0
      BatchNorm1d-40               [-1, 64, 64]             128
             ReLU-41               [-1, 64, 64]               0
          Dropout-42               [-1, 64, 64]               0
           Conv1d-43               [-1, 64, 64]           2,112
  MyConv1dPadSame-44               [-1, 64, 64]               0
       Bottleneck-45               [-1, 64, 64]               0
      BatchNorm1d-46               [-1, 64, 64]             128
             ReLU-47               [-1, 64, 64]               0
          Dropout-48               [-1, 64, 64]               0
           Conv1d-49              [-1, 128, 64]           4,224
  MyConv1dPadSame-50              [-1, 128, 64]               0
      BatchNorm1d-51              [-1, 128, 64]             256
             ReLU-52              [-1, 128, 64]               0
          Dropout-53              [-1, 128, 64]               0
           Conv1d-54              [-1, 128, 64]           8,320
  MyConv1dPadSame-55              [-1, 128, 64]               0
       Bottleneck-56              [-1, 128, 64]               0
      BatchNorm1d-57              [-1, 128, 64]             256
             ReLU-58              [-1, 128, 64]               0
          Dropout-59              [-1, 128, 64]               0
           Conv1d-60              [-1, 128, 64]           8,320
  MyConv1dPadSame-61              [-1, 128, 64]               0
      BatchNorm1d-62              [-1, 128, 64]             256
             ReLU-63              [-1, 128, 64]               0
          Dropout-64              [-1, 128, 64]               0
           Conv1d-65              [-1, 128, 64]           8,320
  MyConv1dPadSame-66              [-1, 128, 64]               0
       Bottleneck-67              [-1, 128, 64]               0
      BatchNorm1d-68              [-1, 128, 64]             256
             ReLU-69              [-1, 128, 64]               0
          Dropout-70              [-1, 128, 64]               0
           Conv1d-71              [-1, 256, 64]          16,640
  MyConv1dPadSame-72              [-1, 256, 64]               0
      BatchNorm1d-73              [-1, 256, 64]             512
             ReLU-74              [-1, 256, 64]               0
          Dropout-75              [-1, 256, 64]               0
           Conv1d-76              [-1, 256, 64]          33,024
  MyConv1dPadSame-77              [-1, 256, 64]               0
       Bottleneck-78              [-1, 256, 64]               0
      BatchNorm1d-79              [-1, 256, 64]             512
             ReLU-80              [-1, 256, 64]               0
          Dropout-81              [-1, 256, 64]               0
           Conv1d-82              [-1, 256, 64]          33,024
  MyConv1dPadSame-83              [-1, 256, 64]               0
      BatchNorm1d-84              [-1, 256, 64]             512
             ReLU-85              [-1, 256, 64]               0
          Dropout-86              [-1, 256, 64]               0
           Conv1d-87              [-1, 256, 64]          33,024
  MyConv1dPadSame-88              [-1, 256, 64]               0
       Bottleneck-89              [-1, 256, 64]               0
      BatchNorm1d-90              [-1, 256, 64]             512
             ReLU-91              [-1, 256, 64]               0
           Linear-92                    [-1, 2]             514
================================================================
Total params: 159,458
Trainable params: 159,458
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 5.09
Params size (MB): 0.61
Estimated Total Size (MB): 5.70
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 32, kernel_size: 16, n_block: 16
************************************************************
************************************************************
(2000, 1, 64) Counter({0: 1000, 1: 1000})
(2000, 1, 64) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 32, 64]             544
   MyConv1dPadSame-2               [-1, 32, 64]               0
       BatchNorm1d-3               [-1, 32, 64]              64
              ReLU-4               [-1, 32, 64]               0
            Conv1d-5               [-1, 32, 64]             544
   MyConv1dPadSame-6               [-1, 32, 64]               0
       BatchNorm1d-7               [-1, 32, 64]              64
              ReLU-8               [-1, 32, 64]               0
           Dropout-9               [-1, 32, 64]               0
           Conv1d-10               [-1, 32, 64]             544
  MyConv1dPadSame-11               [-1, 32, 64]               0
       Bottleneck-12               [-1, 32, 64]               0
      BatchNorm1d-13               [-1, 32, 64]              64
             ReLU-14               [-1, 32, 64]               0
          Dropout-15               [-1, 32, 64]               0
           Conv1d-16               [-1, 32, 32]             544
  MyConv1dPadSame-17               [-1, 32, 32]               0
      BatchNorm1d-18               [-1, 32, 32]              64
             ReLU-19               [-1, 32, 32]               0
          Dropout-20               [-1, 32, 32]               0
           Conv1d-21               [-1, 32, 32]             544
  MyConv1dPadSame-22               [-1, 32, 32]               0
        MaxPool1d-23               [-1, 32, 32]               0
MyMaxPool1dPadSame-24               [-1, 32, 32]               0
       Bottleneck-25               [-1, 32, 32]               0
      BatchNorm1d-26               [-1, 32, 32]              64
             ReLU-27               [-1, 32, 32]               0
          Dropout-28               [-1, 32, 32]               0
           Conv1d-29               [-1, 32, 32]             544
  MyConv1dPadSame-30               [-1, 32, 32]               0
      BatchNorm1d-31               [-1, 32, 32]              64
             ReLU-32               [-1, 32, 32]               0
          Dropout-33               [-1, 32, 32]               0
           Conv1d-34               [-1, 32, 32]             544
  MyConv1dPadSame-35               [-1, 32, 32]               0
       Bottleneck-36               [-1, 32, 32]               0
      BatchNorm1d-37               [-1, 32, 32]              64
             ReLU-38               [-1, 32, 32]               0
          Dropout-39               [-1, 32, 32]               0
           Conv1d-40               [-1, 32, 16]             544
  MyConv1dPadSame-41               [-1, 32, 16]               0
      BatchNorm1d-42               [-1, 32, 16]              64
             ReLU-43               [-1, 32, 16]               0
          Dropout-44               [-1, 32, 16]               0
           Conv1d-45               [-1, 32, 16]             544
  MyConv1dPadSame-46               [-1, 32, 16]               0
        MaxPool1d-47               [-1, 32, 16]               0
MyMaxPool1dPadSame-48               [-1, 32, 16]               0
       Bottleneck-49               [-1, 32, 16]               0
      BatchNorm1d-50               [-1, 32, 16]              64
             ReLU-51               [-1, 32, 16]               0
          Dropout-52               [-1, 32, 16]               0
           Conv1d-53               [-1, 64, 16]           1,088
  MyConv1dPadSame-54               [-1, 64, 16]               0
      BatchNorm1d-55               [-1, 64, 16]             128
             ReLU-56               [-1, 64, 16]               0
          Dropout-57               [-1, 64, 16]               0
           Conv1d-58               [-1, 64, 16]           2,112
  MyConv1dPadSame-59               [-1, 64, 16]               0
       Bottleneck-60               [-1, 64, 16]               0
      BatchNorm1d-61               [-1, 64, 16]             128
             ReLU-62               [-1, 64, 16]               0
          Dropout-63               [-1, 64, 16]               0
           Conv1d-64                [-1, 64, 8]           2,112
  MyConv1dPadSame-65                [-1, 64, 8]               0
      BatchNorm1d-66                [-1, 64, 8]             128
             ReLU-67                [-1, 64, 8]               0
          Dropout-68                [-1, 64, 8]               0
           Conv1d-69                [-1, 64, 8]           2,112
  MyConv1dPadSame-70                [-1, 64, 8]               0
        MaxPool1d-71                [-1, 64, 8]               0
MyMaxPool1dPadSame-72                [-1, 64, 8]               0
       Bottleneck-73                [-1, 64, 8]               0
      BatchNorm1d-74                [-1, 64, 8]             128
             ReLU-75                [-1, 64, 8]               0
          Dropout-76                [-1, 64, 8]               0
           Conv1d-77                [-1, 64, 8]           2,112
  MyConv1dPadSame-78                [-1, 64, 8]               0
      BatchNorm1d-79                [-1, 64, 8]             128
             ReLU-80                [-1, 64, 8]               0
          Dropout-81                [-1, 64, 8]               0
           Conv1d-82                [-1, 64, 8]           2,112
  MyConv1dPadSame-83                [-1, 64, 8]               0
       Bottleneck-84                [-1, 64, 8]               0
      BatchNorm1d-85                [-1, 64, 8]             128
             ReLU-86                [-1, 64, 8]               0
          Dropout-87                [-1, 64, 8]               0
           Conv1d-88                [-1, 64, 4]           2,112
  MyConv1dPadSame-89                [-1, 64, 4]               0
      BatchNorm1d-90                [-1, 64, 4]             128
             ReLU-91                [-1, 64, 4]               0
          Dropout-92                [-1, 64, 4]               0
           Conv1d-93                [-1, 64, 4]           2,112
  MyConv1dPadSame-94                [-1, 64, 4]               0
        MaxPool1d-95                [-1, 64, 4]               0
MyMaxPool1dPadSame-96                [-1, 64, 4]               0
       Bottleneck-97                [-1, 64, 4]               0
      BatchNorm1d-98                [-1, 64, 4]             128
             ReLU-99                [-1, 64, 4]               0
         Dropout-100                [-1, 64, 4]               0
          Conv1d-101               [-1, 128, 4]           4,224
 MyConv1dPadSame-102               [-1, 128, 4]               0
     BatchNorm1d-103               [-1, 128, 4]             256
            ReLU-104               [-1, 128, 4]               0
         Dropout-105               [-1, 128, 4]               0
          Conv1d-106               [-1, 128, 4]           8,320
 MyConv1dPadSame-107               [-1, 128, 4]               0
      Bottleneck-108               [-1, 128, 4]               0
     BatchNorm1d-109               [-1, 128, 4]             256
            ReLU-110               [-1, 128, 4]               0
         Dropout-111               [-1, 128, 4]               0
          Conv1d-112               [-1, 128, 2]           8,320
 MyConv1dPadSame-113               [-1, 128, 2]               0
     BatchNorm1d-114               [-1, 128, 2]             256
            ReLU-115               [-1, 128, 2]               0
         Dropout-116               [-1, 128, 2]               0
          Conv1d-117               [-1, 128, 2]           8,320
 MyConv1dPadSame-118               [-1, 128, 2]               0
       MaxPool1d-119               [-1, 128, 2]               0
MyMaxPool1dPadSame-120               [-1, 128, 2]               0
      Bottleneck-121               [-1, 128, 2]               0
     BatchNorm1d-122               [-1, 128, 2]             256
            ReLU-123               [-1, 128, 2]               0
         Dropout-124               [-1, 128, 2]               0
          Conv1d-125               [-1, 128, 2]           8,320
 MyConv1dPadSame-126               [-1, 128, 2]               0
     BatchNorm1d-127               [-1, 128, 2]             256
            ReLU-128               [-1, 128, 2]               0
         Dropout-129               [-1, 128, 2]               0
          Conv1d-130               [-1, 128, 2]           8,320
 MyConv1dPadSame-131               [-1, 128, 2]               0
      Bottleneck-132               [-1, 128, 2]               0
     BatchNorm1d-133               [-1, 128, 2]             256
            ReLU-134               [-1, 128, 2]               0
         Dropout-135               [-1, 128, 2]               0
          Conv1d-136               [-1, 128, 1]           8,320
 MyConv1dPadSame-137               [-1, 128, 1]               0
     BatchNorm1d-138               [-1, 128, 1]             256
            ReLU-139               [-1, 128, 1]               0
         Dropout-140               [-1, 128, 1]               0
          Conv1d-141               [-1, 128, 1]           8,320
 MyConv1dPadSame-142               [-1, 128, 1]               0
       MaxPool1d-143               [-1, 128, 1]               0
MyMaxPool1dPadSame-144               [-1, 128, 1]               0
      Bottleneck-145               [-1, 128, 1]               0
     BatchNorm1d-146               [-1, 128, 1]             256
            ReLU-147               [-1, 128, 1]               0
         Dropout-148               [-1, 128, 1]               0
          Conv1d-149               [-1, 256, 1]          16,640
 MyConv1dPadSame-150               [-1, 256, 1]               0
     BatchNorm1d-151               [-1, 256, 1]             512
            ReLU-152               [-1, 256, 1]               0
         Dropout-153               [-1, 256, 1]               0
          Conv1d-154               [-1, 256, 1]          33,024
 MyConv1dPadSame-155               [-1, 256, 1]               0
      Bottleneck-156               [-1, 256, 1]               0
     BatchNorm1d-157               [-1, 256, 1]             512
            ReLU-158               [-1, 256, 1]               0
         Dropout-159               [-1, 256, 1]               0
          Conv1d-160               [-1, 256, 1]          33,024
 MyConv1dPadSame-161               [-1, 256, 1]               0
     BatchNorm1d-162               [-1, 256, 1]             512
            ReLU-163               [-1, 256, 1]               0
         Dropout-164               [-1, 256, 1]               0
          Conv1d-165               [-1, 256, 1]          33,024
 MyConv1dPadSame-166               [-1, 256, 1]               0
       MaxPool1d-167               [-1, 256, 1]               0
MyMaxPool1dPadSame-168               [-1, 256, 1]               0
      Bottleneck-169               [-1, 256, 1]               0
     BatchNorm1d-170               [-1, 256, 1]             512
            ReLU-171               [-1, 256, 1]               0
         Dropout-172               [-1, 256, 1]               0
          Conv1d-173               [-1, 256, 1]          33,024
 MyConv1dPadSame-174               [-1, 256, 1]               0
     BatchNorm1d-175               [-1, 256, 1]             512
            ReLU-176               [-1, 256, 1]               0
         Dropout-177               [-1, 256, 1]               0
          Conv1d-178               [-1, 256, 1]          33,024
 MyConv1dPadSame-179               [-1, 256, 1]               0
      Bottleneck-180               [-1, 256, 1]               0
     BatchNorm1d-181               [-1, 256, 1]             512
            ReLU-182               [-1, 256, 1]               0
         Dropout-183               [-1, 256, 1]               0
          Conv1d-184               [-1, 256, 1]          33,024
 MyConv1dPadSame-185               [-1, 256, 1]               0
     BatchNorm1d-186               [-1, 256, 1]             512
            ReLU-187               [-1, 256, 1]               0
         Dropout-188               [-1, 256, 1]               0
          Conv1d-189               [-1, 256, 1]          33,024
 MyConv1dPadSame-190               [-1, 256, 1]               0
       MaxPool1d-191               [-1, 256, 1]               0
MyMaxPool1dPadSame-192               [-1, 256, 1]               0
      Bottleneck-193               [-1, 256, 1]               0
     BatchNorm1d-194               [-1, 256, 1]             512
            ReLU-195               [-1, 256, 1]               0
          Linear-196                    [-1, 2]             514
================================================================
Total params: 339,298
Trainable params: 339,298
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.87
Params size (MB): 1.29
Estimated Total Size (MB): 2.17
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 64, kernel_size: 2, n_block: 2
************************************************************
************************************************************
(2000, 1, 64) Counter({0: 1000, 1: 1000})
(2000, 1, 64) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 64, 64]             192
   MyConv1dPadSame-2               [-1, 64, 64]               0
       BatchNorm1d-3               [-1, 64, 64]             128
              ReLU-4               [-1, 64, 64]               0
            Conv1d-5               [-1, 64, 64]             192
   MyConv1dPadSame-6               [-1, 64, 64]               0
       BatchNorm1d-7               [-1, 64, 64]             128
              ReLU-8               [-1, 64, 64]               0
           Dropout-9               [-1, 64, 64]               0
           Conv1d-10               [-1, 64, 64]             192
  MyConv1dPadSame-11               [-1, 64, 64]               0
       Bottleneck-12               [-1, 64, 64]               0
      BatchNorm1d-13               [-1, 64, 64]             128
             ReLU-14               [-1, 64, 64]               0
          Dropout-15               [-1, 64, 64]               0
           Conv1d-16              [-1, 128, 64]             384
  MyConv1dPadSame-17              [-1, 128, 64]               0
      BatchNorm1d-18              [-1, 128, 64]             256
             ReLU-19              [-1, 128, 64]               0
          Dropout-20              [-1, 128, 64]               0
           Conv1d-21              [-1, 128, 64]             640
  MyConv1dPadSame-22              [-1, 128, 64]               0
       Bottleneck-23              [-1, 128, 64]               0
      BatchNorm1d-24              [-1, 128, 64]             256
             ReLU-25              [-1, 128, 64]               0
           Linear-26                    [-1, 2]             258
================================================================
Total params: 2,754
Trainable params: 2,754
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 1.09
Params size (MB): 0.01
Estimated Total Size (MB): 1.10
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 64, kernel_size: 2, n_block: 4
************************************************************
************************************************************
(2000, 1, 64) Counter({1: 1000, 0: 1000})
(2000, 1, 64) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 64, 64]             192
   MyConv1dPadSame-2               [-1, 64, 64]               0
       BatchNorm1d-3               [-1, 64, 64]             128
              ReLU-4               [-1, 64, 64]               0
            Conv1d-5               [-1, 64, 64]             192
   MyConv1dPadSame-6               [-1, 64, 64]               0
       BatchNorm1d-7               [-1, 64, 64]             128
              ReLU-8               [-1, 64, 64]               0
           Dropout-9               [-1, 64, 64]               0
           Conv1d-10               [-1, 64, 64]             192
  MyConv1dPadSame-11               [-1, 64, 64]               0
       Bottleneck-12               [-1, 64, 64]               0
      BatchNorm1d-13               [-1, 64, 64]             128
             ReLU-14               [-1, 64, 64]               0
          Dropout-15               [-1, 64, 64]               0
           Conv1d-16              [-1, 128, 64]             384
  MyConv1dPadSame-17              [-1, 128, 64]               0
      BatchNorm1d-18              [-1, 128, 64]             256
             ReLU-19              [-1, 128, 64]               0
          Dropout-20              [-1, 128, 64]               0
           Conv1d-21              [-1, 128, 64]             640
  MyConv1dPadSame-22              [-1, 128, 64]               0
       Bottleneck-23              [-1, 128, 64]               0
      BatchNorm1d-24              [-1, 128, 64]             256
             ReLU-25              [-1, 128, 64]               0
          Dropout-26              [-1, 128, 64]               0
           Conv1d-27              [-1, 256, 64]           1,280
  MyConv1dPadSame-28              [-1, 256, 64]               0
      BatchNorm1d-29              [-1, 256, 64]             512
             ReLU-30              [-1, 256, 64]               0
          Dropout-31              [-1, 256, 64]               0
           Conv1d-32              [-1, 256, 64]           2,304
  MyConv1dPadSame-33              [-1, 256, 64]               0
       Bottleneck-34              [-1, 256, 64]               0
      BatchNorm1d-35              [-1, 256, 64]             512
             ReLU-36              [-1, 256, 64]               0
          Dropout-37              [-1, 256, 64]               0
           Conv1d-38              [-1, 512, 64]           4,608
  MyConv1dPadSame-39              [-1, 512, 64]               0
      BatchNorm1d-40              [-1, 512, 64]           1,024
             ReLU-41              [-1, 512, 64]               0
          Dropout-42              [-1, 512, 64]               0
           Conv1d-43              [-1, 512, 64]           8,704
  MyConv1dPadSame-44              [-1, 512, 64]               0
       Bottleneck-45              [-1, 512, 64]               0
      BatchNorm1d-46              [-1, 512, 64]           1,024
             ReLU-47              [-1, 512, 64]               0
           Linear-48                    [-1, 2]           1,026
================================================================
Total params: 23,490
Trainable params: 23,490
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 5.03
Params size (MB): 0.09
Estimated Total Size (MB): 5.12
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 64, kernel_size: 2, n_block: 8
************************************************************
************************************************************
(2000, 1, 64) Counter({1: 1000, 0: 1000})
(2000, 1, 64) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 64, 64]             192
   MyConv1dPadSame-2               [-1, 64, 64]               0
       BatchNorm1d-3               [-1, 64, 64]             128
              ReLU-4               [-1, 64, 64]               0
            Conv1d-5               [-1, 64, 64]             192
   MyConv1dPadSame-6               [-1, 64, 64]               0
       BatchNorm1d-7               [-1, 64, 64]             128
              ReLU-8               [-1, 64, 64]               0
           Dropout-9               [-1, 64, 64]               0
           Conv1d-10               [-1, 64, 64]             192
  MyConv1dPadSame-11               [-1, 64, 64]               0
       Bottleneck-12               [-1, 64, 64]               0
      BatchNorm1d-13               [-1, 64, 64]             128
             ReLU-14               [-1, 64, 64]               0
          Dropout-15               [-1, 64, 64]               0
           Conv1d-16               [-1, 64, 64]             192
  MyConv1dPadSame-17               [-1, 64, 64]               0
      BatchNorm1d-18               [-1, 64, 64]             128
             ReLU-19               [-1, 64, 64]               0
          Dropout-20               [-1, 64, 64]               0
           Conv1d-21               [-1, 64, 64]             192
  MyConv1dPadSame-22               [-1, 64, 64]               0
       Bottleneck-23               [-1, 64, 64]               0
      BatchNorm1d-24               [-1, 64, 64]             128
             ReLU-25               [-1, 64, 64]               0
          Dropout-26               [-1, 64, 64]               0
           Conv1d-27              [-1, 128, 64]             384
  MyConv1dPadSame-28              [-1, 128, 64]               0
      BatchNorm1d-29              [-1, 128, 64]             256
             ReLU-30              [-1, 128, 64]               0
          Dropout-31              [-1, 128, 64]               0
           Conv1d-32              [-1, 128, 64]             640
  MyConv1dPadSame-33              [-1, 128, 64]               0
       Bottleneck-34              [-1, 128, 64]               0
      BatchNorm1d-35              [-1, 128, 64]             256
             ReLU-36              [-1, 128, 64]               0
          Dropout-37              [-1, 128, 64]               0
           Conv1d-38              [-1, 128, 64]             640
  MyConv1dPadSame-39              [-1, 128, 64]               0
      BatchNorm1d-40              [-1, 128, 64]             256
             ReLU-41              [-1, 128, 64]               0
          Dropout-42              [-1, 128, 64]               0
           Conv1d-43              [-1, 128, 64]             640
  MyConv1dPadSame-44              [-1, 128, 64]               0
       Bottleneck-45              [-1, 128, 64]               0
      BatchNorm1d-46              [-1, 128, 64]             256
             ReLU-47              [-1, 128, 64]               0
          Dropout-48              [-1, 128, 64]               0
           Conv1d-49              [-1, 256, 64]           1,280
  MyConv1dPadSame-50              [-1, 256, 64]               0
      BatchNorm1d-51              [-1, 256, 64]             512
             ReLU-52              [-1, 256, 64]               0
          Dropout-53              [-1, 256, 64]               0
           Conv1d-54              [-1, 256, 64]           2,304
  MyConv1dPadSame-55              [-1, 256, 64]               0
       Bottleneck-56              [-1, 256, 64]               0
      BatchNorm1d-57              [-1, 256, 64]             512
             ReLU-58              [-1, 256, 64]               0
          Dropout-59              [-1, 256, 64]               0
           Conv1d-60              [-1, 256, 64]           2,304
  MyConv1dPadSame-61              [-1, 256, 64]               0
      BatchNorm1d-62              [-1, 256, 64]             512
             ReLU-63              [-1, 256, 64]               0
          Dropout-64              [-1, 256, 64]               0
           Conv1d-65              [-1, 256, 64]           2,304
  MyConv1dPadSame-66              [-1, 256, 64]               0
       Bottleneck-67              [-1, 256, 64]               0
      BatchNorm1d-68              [-1, 256, 64]             512
             ReLU-69              [-1, 256, 64]               0
          Dropout-70              [-1, 256, 64]               0
           Conv1d-71              [-1, 512, 64]           4,608
  MyConv1dPadSame-72              [-1, 512, 64]               0
      BatchNorm1d-73              [-1, 512, 64]           1,024
             ReLU-74              [-1, 512, 64]               0
          Dropout-75              [-1, 512, 64]               0
           Conv1d-76              [-1, 512, 64]           8,704
  MyConv1dPadSame-77              [-1, 512, 64]               0
       Bottleneck-78              [-1, 512, 64]               0
      BatchNorm1d-79              [-1, 512, 64]           1,024
             ReLU-80              [-1, 512, 64]               0
          Dropout-81              [-1, 512, 64]               0
           Conv1d-82              [-1, 512, 64]           8,704
  MyConv1dPadSame-83              [-1, 512, 64]               0
      BatchNorm1d-84              [-1, 512, 64]           1,024
             ReLU-85              [-1, 512, 64]               0
          Dropout-86              [-1, 512, 64]               0
           Conv1d-87              [-1, 512, 64]           8,704
  MyConv1dPadSame-88              [-1, 512, 64]               0
       Bottleneck-89              [-1, 512, 64]               0
      BatchNorm1d-90              [-1, 512, 64]           1,024
             ReLU-91              [-1, 512, 64]               0
           Linear-92                    [-1, 2]           1,026
================================================================
Total params: 51,010
Trainable params: 51,010
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 10.19
Params size (MB): 0.19
Estimated Total Size (MB): 10.38
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 64, kernel_size: 2, n_block: 16
************************************************************
************************************************************
(2000, 1, 64) Counter({0: 1000, 1: 1000})
(2000, 1, 64) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 64, 64]             192
   MyConv1dPadSame-2               [-1, 64, 64]               0
       BatchNorm1d-3               [-1, 64, 64]             128
              ReLU-4               [-1, 64, 64]               0
            Conv1d-5               [-1, 64, 64]             192
   MyConv1dPadSame-6               [-1, 64, 64]               0
       BatchNorm1d-7               [-1, 64, 64]             128
              ReLU-8               [-1, 64, 64]               0
           Dropout-9               [-1, 64, 64]               0
           Conv1d-10               [-1, 64, 64]             192
  MyConv1dPadSame-11               [-1, 64, 64]               0
       Bottleneck-12               [-1, 64, 64]               0
      BatchNorm1d-13               [-1, 64, 64]             128
             ReLU-14               [-1, 64, 64]               0
          Dropout-15               [-1, 64, 64]               0
           Conv1d-16               [-1, 64, 32]             192
  MyConv1dPadSame-17               [-1, 64, 32]               0
      BatchNorm1d-18               [-1, 64, 32]             128
             ReLU-19               [-1, 64, 32]               0
          Dropout-20               [-1, 64, 32]               0
           Conv1d-21               [-1, 64, 32]             192
  MyConv1dPadSame-22               [-1, 64, 32]               0
        MaxPool1d-23               [-1, 64, 32]               0
MyMaxPool1dPadSame-24               [-1, 64, 32]               0
       Bottleneck-25               [-1, 64, 32]               0
      BatchNorm1d-26               [-1, 64, 32]             128
             ReLU-27               [-1, 64, 32]               0
          Dropout-28               [-1, 64, 32]               0
           Conv1d-29               [-1, 64, 32]             192
  MyConv1dPadSame-30               [-1, 64, 32]               0
      BatchNorm1d-31               [-1, 64, 32]             128
             ReLU-32               [-1, 64, 32]               0
          Dropout-33               [-1, 64, 32]               0
           Conv1d-34               [-1, 64, 32]             192
  MyConv1dPadSame-35               [-1, 64, 32]               0
       Bottleneck-36               [-1, 64, 32]               0
      BatchNorm1d-37               [-1, 64, 32]             128
             ReLU-38               [-1, 64, 32]               0
          Dropout-39               [-1, 64, 32]               0
           Conv1d-40               [-1, 64, 16]             192
  MyConv1dPadSame-41               [-1, 64, 16]               0
      BatchNorm1d-42               [-1, 64, 16]             128
             ReLU-43               [-1, 64, 16]               0
          Dropout-44               [-1, 64, 16]               0
           Conv1d-45               [-1, 64, 16]             192
  MyConv1dPadSame-46               [-1, 64, 16]               0
        MaxPool1d-47               [-1, 64, 16]               0
MyMaxPool1dPadSame-48               [-1, 64, 16]               0
       Bottleneck-49               [-1, 64, 16]               0
      BatchNorm1d-50               [-1, 64, 16]             128
             ReLU-51               [-1, 64, 16]               0
          Dropout-52               [-1, 64, 16]               0
           Conv1d-53              [-1, 128, 16]             384
  MyConv1dPadSame-54              [-1, 128, 16]               0
      BatchNorm1d-55              [-1, 128, 16]             256
             ReLU-56              [-1, 128, 16]               0
          Dropout-57              [-1, 128, 16]               0
           Conv1d-58              [-1, 128, 16]             640
  MyConv1dPadSame-59              [-1, 128, 16]               0
       Bottleneck-60              [-1, 128, 16]               0
      BatchNorm1d-61              [-1, 128, 16]             256
             ReLU-62              [-1, 128, 16]               0
          Dropout-63              [-1, 128, 16]               0
           Conv1d-64               [-1, 128, 8]             640
  MyConv1dPadSame-65               [-1, 128, 8]               0
      BatchNorm1d-66               [-1, 128, 8]             256
             ReLU-67               [-1, 128, 8]               0
          Dropout-68               [-1, 128, 8]               0
           Conv1d-69               [-1, 128, 8]             640
  MyConv1dPadSame-70               [-1, 128, 8]               0
        MaxPool1d-71               [-1, 128, 8]               0
MyMaxPool1dPadSame-72               [-1, 128, 8]               0
       Bottleneck-73               [-1, 128, 8]               0
      BatchNorm1d-74               [-1, 128, 8]             256
             ReLU-75               [-1, 128, 8]               0
          Dropout-76               [-1, 128, 8]               0
           Conv1d-77               [-1, 128, 8]             640
  MyConv1dPadSame-78               [-1, 128, 8]               0
      BatchNorm1d-79               [-1, 128, 8]             256
             ReLU-80               [-1, 128, 8]               0
          Dropout-81               [-1, 128, 8]               0
           Conv1d-82               [-1, 128, 8]             640
  MyConv1dPadSame-83               [-1, 128, 8]               0
       Bottleneck-84               [-1, 128, 8]               0
      BatchNorm1d-85               [-1, 128, 8]             256
             ReLU-86               [-1, 128, 8]               0
          Dropout-87               [-1, 128, 8]               0
           Conv1d-88               [-1, 128, 4]             640
  MyConv1dPadSame-89               [-1, 128, 4]               0
      BatchNorm1d-90               [-1, 128, 4]             256
             ReLU-91               [-1, 128, 4]               0
          Dropout-92               [-1, 128, 4]               0
           Conv1d-93               [-1, 128, 4]             640
  MyConv1dPadSame-94               [-1, 128, 4]               0
        MaxPool1d-95               [-1, 128, 4]               0
MyMaxPool1dPadSame-96               [-1, 128, 4]               0
       Bottleneck-97               [-1, 128, 4]               0
      BatchNorm1d-98               [-1, 128, 4]             256
             ReLU-99               [-1, 128, 4]               0
         Dropout-100               [-1, 128, 4]               0
          Conv1d-101               [-1, 256, 4]           1,280
 MyConv1dPadSame-102               [-1, 256, 4]               0
     BatchNorm1d-103               [-1, 256, 4]             512
            ReLU-104               [-1, 256, 4]               0
         Dropout-105               [-1, 256, 4]               0
          Conv1d-106               [-1, 256, 4]           2,304
 MyConv1dPadSame-107               [-1, 256, 4]               0
      Bottleneck-108               [-1, 256, 4]               0
     BatchNorm1d-109               [-1, 256, 4]             512
            ReLU-110               [-1, 256, 4]               0
         Dropout-111               [-1, 256, 4]               0
          Conv1d-112               [-1, 256, 2]           2,304
 MyConv1dPadSame-113               [-1, 256, 2]               0
     BatchNorm1d-114               [-1, 256, 2]             512
            ReLU-115               [-1, 256, 2]               0
         Dropout-116               [-1, 256, 2]               0
          Conv1d-117               [-1, 256, 2]           2,304
 MyConv1dPadSame-118               [-1, 256, 2]               0
       MaxPool1d-119               [-1, 256, 2]               0
MyMaxPool1dPadSame-120               [-1, 256, 2]               0
      Bottleneck-121               [-1, 256, 2]               0
     BatchNorm1d-122               [-1, 256, 2]             512
            ReLU-123               [-1, 256, 2]               0
         Dropout-124               [-1, 256, 2]               0
          Conv1d-125               [-1, 256, 2]           2,304
 MyConv1dPadSame-126               [-1, 256, 2]               0
     BatchNorm1d-127               [-1, 256, 2]             512
            ReLU-128               [-1, 256, 2]               0
         Dropout-129               [-1, 256, 2]               0
          Conv1d-130               [-1, 256, 2]           2,304
 MyConv1dPadSame-131               [-1, 256, 2]               0
      Bottleneck-132               [-1, 256, 2]               0
     BatchNorm1d-133               [-1, 256, 2]             512
            ReLU-134               [-1, 256, 2]               0
         Dropout-135               [-1, 256, 2]               0
          Conv1d-136               [-1, 256, 1]           2,304
 MyConv1dPadSame-137               [-1, 256, 1]               0
     BatchNorm1d-138               [-1, 256, 1]             512
            ReLU-139               [-1, 256, 1]               0
         Dropout-140               [-1, 256, 1]               0
          Conv1d-141               [-1, 256, 1]           2,304
 MyConv1dPadSame-142               [-1, 256, 1]               0
       MaxPool1d-143               [-1, 256, 1]               0
MyMaxPool1dPadSame-144               [-1, 256, 1]               0
      Bottleneck-145               [-1, 256, 1]               0
     BatchNorm1d-146               [-1, 256, 1]             512
            ReLU-147               [-1, 256, 1]               0
         Dropout-148               [-1, 256, 1]               0
          Conv1d-149               [-1, 512, 1]           4,608
 MyConv1dPadSame-150               [-1, 512, 1]               0
     BatchNorm1d-151               [-1, 512, 1]           1,024
            ReLU-152               [-1, 512, 1]               0
         Dropout-153               [-1, 512, 1]               0
          Conv1d-154               [-1, 512, 1]           8,704
 MyConv1dPadSame-155               [-1, 512, 1]               0
      Bottleneck-156               [-1, 512, 1]               0
     BatchNorm1d-157               [-1, 512, 1]           1,024
            ReLU-158               [-1, 512, 1]               0
         Dropout-159               [-1, 512, 1]               0
          Conv1d-160               [-1, 512, 1]           8,704
 MyConv1dPadSame-161               [-1, 512, 1]               0
     BatchNorm1d-162               [-1, 512, 1]           1,024
            ReLU-163               [-1, 512, 1]               0
         Dropout-164               [-1, 512, 1]               0
          Conv1d-165               [-1, 512, 1]           8,704
 MyConv1dPadSame-166               [-1, 512, 1]               0
       MaxPool1d-167               [-1, 512, 1]               0
MyMaxPool1dPadSame-168               [-1, 512, 1]               0
      Bottleneck-169               [-1, 512, 1]               0
     BatchNorm1d-170               [-1, 512, 1]           1,024
            ReLU-171               [-1, 512, 1]               0
         Dropout-172               [-1, 512, 1]               0
          Conv1d-173               [-1, 512, 1]           8,704
 MyConv1dPadSame-174               [-1, 512, 1]               0
     BatchNorm1d-175               [-1, 512, 1]           1,024
            ReLU-176               [-1, 512, 1]               0
         Dropout-177               [-1, 512, 1]               0
          Conv1d-178               [-1, 512, 1]           8,704
 MyConv1dPadSame-179               [-1, 512, 1]               0
      Bottleneck-180               [-1, 512, 1]               0
     BatchNorm1d-181               [-1, 512, 1]           1,024
            ReLU-182               [-1, 512, 1]               0
         Dropout-183               [-1, 512, 1]               0
          Conv1d-184               [-1, 512, 1]           8,704
 MyConv1dPadSame-185               [-1, 512, 1]               0
     BatchNorm1d-186               [-1, 512, 1]           1,024
            ReLU-187               [-1, 512, 1]               0
         Dropout-188               [-1, 512, 1]               0
          Conv1d-189               [-1, 512, 1]           8,704
 MyConv1dPadSame-190               [-1, 512, 1]               0
       MaxPool1d-191               [-1, 512, 1]               0
MyMaxPool1dPadSame-192               [-1, 512, 1]               0
      Bottleneck-193               [-1, 512, 1]               0
     BatchNorm1d-194               [-1, 512, 1]           1,024
            ReLU-195               [-1, 512, 1]               0
          Linear-196                    [-1, 2]           1,026
================================================================
Total params: 106,050
Trainable params: 106,050
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 1.74
Params size (MB): 0.40
Estimated Total Size (MB): 2.15
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 64, kernel_size: 4, n_block: 2
************************************************************
************************************************************
(2000, 1, 64) Counter({1: 1000, 0: 1000})
(2000, 1, 64) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 64, 64]             320
   MyConv1dPadSame-2               [-1, 64, 64]               0
       BatchNorm1d-3               [-1, 64, 64]             128
              ReLU-4               [-1, 64, 64]               0
            Conv1d-5               [-1, 64, 64]             320
   MyConv1dPadSame-6               [-1, 64, 64]               0
       BatchNorm1d-7               [-1, 64, 64]             128
              ReLU-8               [-1, 64, 64]               0
           Dropout-9               [-1, 64, 64]               0
           Conv1d-10               [-1, 64, 64]             320
  MyConv1dPadSame-11               [-1, 64, 64]               0
       Bottleneck-12               [-1, 64, 64]               0
      BatchNorm1d-13               [-1, 64, 64]             128
             ReLU-14               [-1, 64, 64]               0
          Dropout-15               [-1, 64, 64]               0
           Conv1d-16              [-1, 128, 64]             640
  MyConv1dPadSame-17              [-1, 128, 64]               0
      BatchNorm1d-18              [-1, 128, 64]             256
             ReLU-19              [-1, 128, 64]               0
          Dropout-20              [-1, 128, 64]               0
           Conv1d-21              [-1, 128, 64]           1,152
  MyConv1dPadSame-22              [-1, 128, 64]               0
       Bottleneck-23              [-1, 128, 64]               0
      BatchNorm1d-24              [-1, 128, 64]             256
             ReLU-25              [-1, 128, 64]               0
           Linear-26                    [-1, 2]             258
================================================================
Total params: 3,906
Trainable params: 3,906
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 1.09
Params size (MB): 0.01
Estimated Total Size (MB): 1.11
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 64, kernel_size: 4, n_block: 4
************************************************************
************************************************************
(2000, 1, 64) Counter({1: 1000, 0: 1000})
(2000, 1, 64) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 64, 64]             320
   MyConv1dPadSame-2               [-1, 64, 64]               0
       BatchNorm1d-3               [-1, 64, 64]             128
              ReLU-4               [-1, 64, 64]               0
            Conv1d-5               [-1, 64, 64]             320
   MyConv1dPadSame-6               [-1, 64, 64]               0
       BatchNorm1d-7               [-1, 64, 64]             128
              ReLU-8               [-1, 64, 64]               0
           Dropout-9               [-1, 64, 64]               0
           Conv1d-10               [-1, 64, 64]             320
  MyConv1dPadSame-11               [-1, 64, 64]               0
       Bottleneck-12               [-1, 64, 64]               0
      BatchNorm1d-13               [-1, 64, 64]             128
             ReLU-14               [-1, 64, 64]               0
          Dropout-15               [-1, 64, 64]               0
           Conv1d-16              [-1, 128, 64]             640
  MyConv1dPadSame-17              [-1, 128, 64]               0
      BatchNorm1d-18              [-1, 128, 64]             256
             ReLU-19              [-1, 128, 64]               0
          Dropout-20              [-1, 128, 64]               0
           Conv1d-21              [-1, 128, 64]           1,152
  MyConv1dPadSame-22              [-1, 128, 64]               0
       Bottleneck-23              [-1, 128, 64]               0
      BatchNorm1d-24              [-1, 128, 64]             256
             ReLU-25              [-1, 128, 64]               0
          Dropout-26              [-1, 128, 64]               0
           Conv1d-27              [-1, 256, 64]           2,304
  MyConv1dPadSame-28              [-1, 256, 64]               0
      BatchNorm1d-29              [-1, 256, 64]             512
             ReLU-30              [-1, 256, 64]               0
          Dropout-31              [-1, 256, 64]               0
           Conv1d-32              [-1, 256, 64]           4,352
  MyConv1dPadSame-33              [-1, 256, 64]               0
       Bottleneck-34              [-1, 256, 64]               0
      BatchNorm1d-35              [-1, 256, 64]             512
             ReLU-36              [-1, 256, 64]               0
          Dropout-37              [-1, 256, 64]               0
           Conv1d-38              [-1, 512, 64]           8,704
  MyConv1dPadSame-39              [-1, 512, 64]               0
      BatchNorm1d-40              [-1, 512, 64]           1,024
             ReLU-41              [-1, 512, 64]               0
          Dropout-42              [-1, 512, 64]               0
           Conv1d-43              [-1, 512, 64]          16,896
  MyConv1dPadSame-44              [-1, 512, 64]               0
       Bottleneck-45              [-1, 512, 64]               0
      BatchNorm1d-46              [-1, 512, 64]           1,024
             ReLU-47              [-1, 512, 64]               0
           Linear-48                    [-1, 2]           1,026
================================================================
Total params: 40,002
Trainable params: 40,002
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 5.03
Params size (MB): 0.15
Estimated Total Size (MB): 5.18
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 64, kernel_size: 4, n_block: 8
************************************************************
************************************************************
(2000, 1, 64) Counter({0: 1000, 1: 1000})
(2000, 1, 64) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 64, 64]             320
   MyConv1dPadSame-2               [-1, 64, 64]               0
       BatchNorm1d-3               [-1, 64, 64]             128
              ReLU-4               [-1, 64, 64]               0
            Conv1d-5               [-1, 64, 64]             320
   MyConv1dPadSame-6               [-1, 64, 64]               0
       BatchNorm1d-7               [-1, 64, 64]             128
              ReLU-8               [-1, 64, 64]               0
           Dropout-9               [-1, 64, 64]               0
           Conv1d-10               [-1, 64, 64]             320
  MyConv1dPadSame-11               [-1, 64, 64]               0
       Bottleneck-12               [-1, 64, 64]               0
      BatchNorm1d-13               [-1, 64, 64]             128
             ReLU-14               [-1, 64, 64]               0
          Dropout-15               [-1, 64, 64]               0
           Conv1d-16               [-1, 64, 64]             320
  MyConv1dPadSame-17               [-1, 64, 64]               0
      BatchNorm1d-18               [-1, 64, 64]             128
             ReLU-19               [-1, 64, 64]               0
          Dropout-20               [-1, 64, 64]               0
           Conv1d-21               [-1, 64, 64]             320
  MyConv1dPadSame-22               [-1, 64, 64]               0
       Bottleneck-23               [-1, 64, 64]               0
      BatchNorm1d-24               [-1, 64, 64]             128
             ReLU-25               [-1, 64, 64]               0
          Dropout-26               [-1, 64, 64]               0
           Conv1d-27              [-1, 128, 64]             640
  MyConv1dPadSame-28              [-1, 128, 64]               0
      BatchNorm1d-29              [-1, 128, 64]             256
             ReLU-30              [-1, 128, 64]               0
          Dropout-31              [-1, 128, 64]               0
           Conv1d-32              [-1, 128, 64]           1,152
  MyConv1dPadSame-33              [-1, 128, 64]               0
       Bottleneck-34              [-1, 128, 64]               0
      BatchNorm1d-35              [-1, 128, 64]             256
             ReLU-36              [-1, 128, 64]               0
          Dropout-37              [-1, 128, 64]               0
           Conv1d-38              [-1, 128, 64]           1,152
  MyConv1dPadSame-39              [-1, 128, 64]               0
      BatchNorm1d-40              [-1, 128, 64]             256
             ReLU-41              [-1, 128, 64]               0
          Dropout-42              [-1, 128, 64]               0
           Conv1d-43              [-1, 128, 64]           1,152
  MyConv1dPadSame-44              [-1, 128, 64]               0
       Bottleneck-45              [-1, 128, 64]               0
      BatchNorm1d-46              [-1, 128, 64]             256
             ReLU-47              [-1, 128, 64]               0
          Dropout-48              [-1, 128, 64]               0
           Conv1d-49              [-1, 256, 64]           2,304
  MyConv1dPadSame-50              [-1, 256, 64]               0
      BatchNorm1d-51              [-1, 256, 64]             512
             ReLU-52              [-1, 256, 64]               0
          Dropout-53              [-1, 256, 64]               0
           Conv1d-54              [-1, 256, 64]           4,352
  MyConv1dPadSame-55              [-1, 256, 64]               0
       Bottleneck-56              [-1, 256, 64]               0
      BatchNorm1d-57              [-1, 256, 64]             512
             ReLU-58              [-1, 256, 64]               0
          Dropout-59              [-1, 256, 64]               0
           Conv1d-60              [-1, 256, 64]           4,352
  MyConv1dPadSame-61              [-1, 256, 64]               0
      BatchNorm1d-62              [-1, 256, 64]             512
             ReLU-63              [-1, 256, 64]               0
          Dropout-64              [-1, 256, 64]               0
           Conv1d-65              [-1, 256, 64]           4,352
  MyConv1dPadSame-66              [-1, 256, 64]               0
       Bottleneck-67              [-1, 256, 64]               0
      BatchNorm1d-68              [-1, 256, 64]             512
             ReLU-69              [-1, 256, 64]               0
          Dropout-70              [-1, 256, 64]               0
           Conv1d-71              [-1, 512, 64]           8,704
  MyConv1dPadSame-72              [-1, 512, 64]               0
      BatchNorm1d-73              [-1, 512, 64]           1,024
             ReLU-74              [-1, 512, 64]               0
          Dropout-75              [-1, 512, 64]               0
           Conv1d-76              [-1, 512, 64]          16,896
  MyConv1dPadSame-77              [-1, 512, 64]               0
       Bottleneck-78              [-1, 512, 64]               0
      BatchNorm1d-79              [-1, 512, 64]           1,024
             ReLU-80              [-1, 512, 64]               0
          Dropout-81              [-1, 512, 64]               0
           Conv1d-82              [-1, 512, 64]          16,896
  MyConv1dPadSame-83              [-1, 512, 64]               0
      BatchNorm1d-84              [-1, 512, 64]           1,024
             ReLU-85              [-1, 512, 64]               0
          Dropout-86              [-1, 512, 64]               0
           Conv1d-87              [-1, 512, 64]          16,896
  MyConv1dPadSame-88              [-1, 512, 64]               0
       Bottleneck-89              [-1, 512, 64]               0
      BatchNorm1d-90              [-1, 512, 64]           1,024
             ReLU-91              [-1, 512, 64]               0
           Linear-92                    [-1, 2]           1,026
================================================================
Total params: 89,282
Trainable params: 89,282
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 10.19
Params size (MB): 0.34
Estimated Total Size (MB): 10.53
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 64, kernel_size: 4, n_block: 16
************************************************************
************************************************************
(2000, 1, 64) Counter({0: 1000, 1: 1000})
(2000, 1, 64) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 64, 64]             320
   MyConv1dPadSame-2               [-1, 64, 64]               0
       BatchNorm1d-3               [-1, 64, 64]             128
              ReLU-4               [-1, 64, 64]               0
            Conv1d-5               [-1, 64, 64]             320
   MyConv1dPadSame-6               [-1, 64, 64]               0
       BatchNorm1d-7               [-1, 64, 64]             128
              ReLU-8               [-1, 64, 64]               0
           Dropout-9               [-1, 64, 64]               0
           Conv1d-10               [-1, 64, 64]             320
  MyConv1dPadSame-11               [-1, 64, 64]               0
       Bottleneck-12               [-1, 64, 64]               0
      BatchNorm1d-13               [-1, 64, 64]             128
             ReLU-14               [-1, 64, 64]               0
          Dropout-15               [-1, 64, 64]               0
           Conv1d-16               [-1, 64, 32]             320
  MyConv1dPadSame-17               [-1, 64, 32]               0
      BatchNorm1d-18               [-1, 64, 32]             128
             ReLU-19               [-1, 64, 32]               0
          Dropout-20               [-1, 64, 32]               0
           Conv1d-21               [-1, 64, 32]             320
  MyConv1dPadSame-22               [-1, 64, 32]               0
        MaxPool1d-23               [-1, 64, 32]               0
MyMaxPool1dPadSame-24               [-1, 64, 32]               0
       Bottleneck-25               [-1, 64, 32]               0
      BatchNorm1d-26               [-1, 64, 32]             128
             ReLU-27               [-1, 64, 32]               0
          Dropout-28               [-1, 64, 32]               0
           Conv1d-29               [-1, 64, 32]             320
  MyConv1dPadSame-30               [-1, 64, 32]               0
      BatchNorm1d-31               [-1, 64, 32]             128
             ReLU-32               [-1, 64, 32]               0
          Dropout-33               [-1, 64, 32]               0
           Conv1d-34               [-1, 64, 32]             320
  MyConv1dPadSame-35               [-1, 64, 32]               0
       Bottleneck-36               [-1, 64, 32]               0
      BatchNorm1d-37               [-1, 64, 32]             128
             ReLU-38               [-1, 64, 32]               0
          Dropout-39               [-1, 64, 32]               0
           Conv1d-40               [-1, 64, 16]             320
  MyConv1dPadSame-41               [-1, 64, 16]               0
      BatchNorm1d-42               [-1, 64, 16]             128
             ReLU-43               [-1, 64, 16]               0
          Dropout-44               [-1, 64, 16]               0
           Conv1d-45               [-1, 64, 16]             320
  MyConv1dPadSame-46               [-1, 64, 16]               0
        MaxPool1d-47               [-1, 64, 16]               0
MyMaxPool1dPadSame-48               [-1, 64, 16]               0
       Bottleneck-49               [-1, 64, 16]               0
      BatchNorm1d-50               [-1, 64, 16]             128
             ReLU-51               [-1, 64, 16]               0
          Dropout-52               [-1, 64, 16]               0
           Conv1d-53              [-1, 128, 16]             640
  MyConv1dPadSame-54              [-1, 128, 16]               0
      BatchNorm1d-55              [-1, 128, 16]             256
             ReLU-56              [-1, 128, 16]               0
          Dropout-57              [-1, 128, 16]               0
           Conv1d-58              [-1, 128, 16]           1,152
  MyConv1dPadSame-59              [-1, 128, 16]               0
       Bottleneck-60              [-1, 128, 16]               0
      BatchNorm1d-61              [-1, 128, 16]             256
             ReLU-62              [-1, 128, 16]               0
          Dropout-63              [-1, 128, 16]               0
           Conv1d-64               [-1, 128, 8]           1,152
  MyConv1dPadSame-65               [-1, 128, 8]               0
      BatchNorm1d-66               [-1, 128, 8]             256
             ReLU-67               [-1, 128, 8]               0
          Dropout-68               [-1, 128, 8]               0
           Conv1d-69               [-1, 128, 8]           1,152
  MyConv1dPadSame-70               [-1, 128, 8]               0
        MaxPool1d-71               [-1, 128, 8]               0
MyMaxPool1dPadSame-72               [-1, 128, 8]               0
       Bottleneck-73               [-1, 128, 8]               0
      BatchNorm1d-74               [-1, 128, 8]             256
             ReLU-75               [-1, 128, 8]               0
          Dropout-76               [-1, 128, 8]               0
           Conv1d-77               [-1, 128, 8]           1,152
  MyConv1dPadSame-78               [-1, 128, 8]               0
      BatchNorm1d-79               [-1, 128, 8]             256
             ReLU-80               [-1, 128, 8]               0
          Dropout-81               [-1, 128, 8]               0
           Conv1d-82               [-1, 128, 8]           1,152
  MyConv1dPadSame-83               [-1, 128, 8]               0
       Bottleneck-84               [-1, 128, 8]               0
      BatchNorm1d-85               [-1, 128, 8]             256
             ReLU-86               [-1, 128, 8]               0
          Dropout-87               [-1, 128, 8]               0
           Conv1d-88               [-1, 128, 4]           1,152
  MyConv1dPadSame-89               [-1, 128, 4]               0
      BatchNorm1d-90               [-1, 128, 4]             256
             ReLU-91               [-1, 128, 4]               0
          Dropout-92               [-1, 128, 4]               0
           Conv1d-93               [-1, 128, 4]           1,152
  MyConv1dPadSame-94               [-1, 128, 4]               0
        MaxPool1d-95               [-1, 128, 4]               0
MyMaxPool1dPadSame-96               [-1, 128, 4]               0
       Bottleneck-97               [-1, 128, 4]               0
      BatchNorm1d-98               [-1, 128, 4]             256
             ReLU-99               [-1, 128, 4]               0
         Dropout-100               [-1, 128, 4]               0
          Conv1d-101               [-1, 256, 4]           2,304
 MyConv1dPadSame-102               [-1, 256, 4]               0
     BatchNorm1d-103               [-1, 256, 4]             512
            ReLU-104               [-1, 256, 4]               0
         Dropout-105               [-1, 256, 4]               0
          Conv1d-106               [-1, 256, 4]           4,352
 MyConv1dPadSame-107               [-1, 256, 4]               0
      Bottleneck-108               [-1, 256, 4]               0
     BatchNorm1d-109               [-1, 256, 4]             512
            ReLU-110               [-1, 256, 4]               0
         Dropout-111               [-1, 256, 4]               0
          Conv1d-112               [-1, 256, 2]           4,352
 MyConv1dPadSame-113               [-1, 256, 2]               0
     BatchNorm1d-114               [-1, 256, 2]             512
            ReLU-115               [-1, 256, 2]               0
         Dropout-116               [-1, 256, 2]               0
          Conv1d-117               [-1, 256, 2]           4,352
 MyConv1dPadSame-118               [-1, 256, 2]               0
       MaxPool1d-119               [-1, 256, 2]               0
MyMaxPool1dPadSame-120               [-1, 256, 2]               0
      Bottleneck-121               [-1, 256, 2]               0
     BatchNorm1d-122               [-1, 256, 2]             512
            ReLU-123               [-1, 256, 2]               0
         Dropout-124               [-1, 256, 2]               0
          Conv1d-125               [-1, 256, 2]           4,352
 MyConv1dPadSame-126               [-1, 256, 2]               0
     BatchNorm1d-127               [-1, 256, 2]             512
            ReLU-128               [-1, 256, 2]               0
         Dropout-129               [-1, 256, 2]               0
          Conv1d-130               [-1, 256, 2]           4,352
 MyConv1dPadSame-131               [-1, 256, 2]               0
      Bottleneck-132               [-1, 256, 2]               0
     BatchNorm1d-133               [-1, 256, 2]             512
            ReLU-134               [-1, 256, 2]               0
         Dropout-135               [-1, 256, 2]               0
          Conv1d-136               [-1, 256, 1]           4,352
 MyConv1dPadSame-137               [-1, 256, 1]               0
     BatchNorm1d-138               [-1, 256, 1]             512
            ReLU-139               [-1, 256, 1]               0
         Dropout-140               [-1, 256, 1]               0
          Conv1d-141               [-1, 256, 1]           4,352
 MyConv1dPadSame-142               [-1, 256, 1]               0
       MaxPool1d-143               [-1, 256, 1]               0
MyMaxPool1dPadSame-144               [-1, 256, 1]               0
      Bottleneck-145               [-1, 256, 1]               0
     BatchNorm1d-146               [-1, 256, 1]             512
            ReLU-147               [-1, 256, 1]               0
         Dropout-148               [-1, 256, 1]               0
          Conv1d-149               [-1, 512, 1]           8,704
 MyConv1dPadSame-150               [-1, 512, 1]               0
     BatchNorm1d-151               [-1, 512, 1]           1,024
            ReLU-152               [-1, 512, 1]               0
         Dropout-153               [-1, 512, 1]               0
          Conv1d-154               [-1, 512, 1]          16,896
 MyConv1dPadSame-155               [-1, 512, 1]               0
      Bottleneck-156               [-1, 512, 1]               0
     BatchNorm1d-157               [-1, 512, 1]           1,024
            ReLU-158               [-1, 512, 1]               0
         Dropout-159               [-1, 512, 1]               0
          Conv1d-160               [-1, 512, 1]          16,896
 MyConv1dPadSame-161               [-1, 512, 1]               0
     BatchNorm1d-162               [-1, 512, 1]           1,024
            ReLU-163               [-1, 512, 1]               0
         Dropout-164               [-1, 512, 1]               0
          Conv1d-165               [-1, 512, 1]          16,896
 MyConv1dPadSame-166               [-1, 512, 1]               0
       MaxPool1d-167               [-1, 512, 1]               0
MyMaxPool1dPadSame-168               [-1, 512, 1]               0
      Bottleneck-169               [-1, 512, 1]               0
     BatchNorm1d-170               [-1, 512, 1]           1,024
            ReLU-171               [-1, 512, 1]               0
         Dropout-172               [-1, 512, 1]               0
          Conv1d-173               [-1, 512, 1]          16,896
 MyConv1dPadSame-174               [-1, 512, 1]               0
     BatchNorm1d-175               [-1, 512, 1]           1,024
            ReLU-176               [-1, 512, 1]               0
         Dropout-177               [-1, 512, 1]               0
          Conv1d-178               [-1, 512, 1]          16,896
 MyConv1dPadSame-179               [-1, 512, 1]               0
      Bottleneck-180               [-1, 512, 1]               0
     BatchNorm1d-181               [-1, 512, 1]           1,024
            ReLU-182               [-1, 512, 1]               0
         Dropout-183               [-1, 512, 1]               0
          Conv1d-184               [-1, 512, 1]          16,896
 MyConv1dPadSame-185               [-1, 512, 1]               0
     BatchNorm1d-186               [-1, 512, 1]           1,024
            ReLU-187               [-1, 512, 1]               0
         Dropout-188               [-1, 512, 1]               0
          Conv1d-189               [-1, 512, 1]          16,896
 MyConv1dPadSame-190               [-1, 512, 1]               0
       MaxPool1d-191               [-1, 512, 1]               0
MyMaxPool1dPadSame-192               [-1, 512, 1]               0
      Bottleneck-193               [-1, 512, 1]               0
     BatchNorm1d-194               [-1, 512, 1]           1,024
            ReLU-195               [-1, 512, 1]               0
          Linear-196                    [-1, 2]           1,026
================================================================
Total params: 187,842
Trainable params: 187,842
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 1.74
Params size (MB): 0.72
Estimated Total Size (MB): 2.46
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 64, kernel_size: 8, n_block: 2
************************************************************
************************************************************
(2000, 1, 64) Counter({1: 1000, 0: 1000})
(2000, 1, 64) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 64, 64]             576
   MyConv1dPadSame-2               [-1, 64, 64]               0
       BatchNorm1d-3               [-1, 64, 64]             128
              ReLU-4               [-1, 64, 64]               0
            Conv1d-5               [-1, 64, 64]             576
   MyConv1dPadSame-6               [-1, 64, 64]               0
       BatchNorm1d-7               [-1, 64, 64]             128
              ReLU-8               [-1, 64, 64]               0
           Dropout-9               [-1, 64, 64]               0
           Conv1d-10               [-1, 64, 64]             576
  MyConv1dPadSame-11               [-1, 64, 64]               0
       Bottleneck-12               [-1, 64, 64]               0
      BatchNorm1d-13               [-1, 64, 64]             128
             ReLU-14               [-1, 64, 64]               0
          Dropout-15               [-1, 64, 64]               0
           Conv1d-16              [-1, 128, 64]           1,152
  MyConv1dPadSame-17              [-1, 128, 64]               0
      BatchNorm1d-18              [-1, 128, 64]             256
             ReLU-19              [-1, 128, 64]               0
          Dropout-20              [-1, 128, 64]               0
           Conv1d-21              [-1, 128, 64]           2,176
  MyConv1dPadSame-22              [-1, 128, 64]               0
       Bottleneck-23              [-1, 128, 64]               0
      BatchNorm1d-24              [-1, 128, 64]             256
             ReLU-25              [-1, 128, 64]               0
           Linear-26                    [-1, 2]             258
================================================================
Total params: 6,210
Trainable params: 6,210
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 1.09
Params size (MB): 0.02
Estimated Total Size (MB): 1.12
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 64, kernel_size: 8, n_block: 4
************************************************************
************************************************************
(2000, 1, 64) Counter({1: 1000, 0: 1000})
(2000, 1, 64) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 64, 64]             576
   MyConv1dPadSame-2               [-1, 64, 64]               0
       BatchNorm1d-3               [-1, 64, 64]             128
              ReLU-4               [-1, 64, 64]               0
            Conv1d-5               [-1, 64, 64]             576
   MyConv1dPadSame-6               [-1, 64, 64]               0
       BatchNorm1d-7               [-1, 64, 64]             128
              ReLU-8               [-1, 64, 64]               0
           Dropout-9               [-1, 64, 64]               0
           Conv1d-10               [-1, 64, 64]             576
  MyConv1dPadSame-11               [-1, 64, 64]               0
       Bottleneck-12               [-1, 64, 64]               0
      BatchNorm1d-13               [-1, 64, 64]             128
             ReLU-14               [-1, 64, 64]               0
          Dropout-15               [-1, 64, 64]               0
           Conv1d-16              [-1, 128, 64]           1,152
  MyConv1dPadSame-17              [-1, 128, 64]               0
      BatchNorm1d-18              [-1, 128, 64]             256
             ReLU-19              [-1, 128, 64]               0
          Dropout-20              [-1, 128, 64]               0
           Conv1d-21              [-1, 128, 64]           2,176
  MyConv1dPadSame-22              [-1, 128, 64]               0
       Bottleneck-23              [-1, 128, 64]               0
      BatchNorm1d-24              [-1, 128, 64]             256
             ReLU-25              [-1, 128, 64]               0
          Dropout-26              [-1, 128, 64]               0
           Conv1d-27              [-1, 256, 64]           4,352
  MyConv1dPadSame-28              [-1, 256, 64]               0
      BatchNorm1d-29              [-1, 256, 64]             512
             ReLU-30              [-1, 256, 64]               0
          Dropout-31              [-1, 256, 64]               0
           Conv1d-32              [-1, 256, 64]           8,448
  MyConv1dPadSame-33              [-1, 256, 64]               0
       Bottleneck-34              [-1, 256, 64]               0
      BatchNorm1d-35              [-1, 256, 64]             512
             ReLU-36              [-1, 256, 64]               0
          Dropout-37              [-1, 256, 64]               0
           Conv1d-38              [-1, 512, 64]          16,896
  MyConv1dPadSame-39              [-1, 512, 64]               0
      BatchNorm1d-40              [-1, 512, 64]           1,024
             ReLU-41              [-1, 512, 64]               0
          Dropout-42              [-1, 512, 64]               0
           Conv1d-43              [-1, 512, 64]          33,280
  MyConv1dPadSame-44              [-1, 512, 64]               0
       Bottleneck-45              [-1, 512, 64]               0
      BatchNorm1d-46              [-1, 512, 64]           1,024
             ReLU-47              [-1, 512, 64]               0
           Linear-48                    [-1, 2]           1,026
================================================================
Total params: 73,026
Trainable params: 73,026
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 5.03
Params size (MB): 0.28
Estimated Total Size (MB): 5.31
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 64, kernel_size: 8, n_block: 8
************************************************************
************************************************************
(2000, 1, 64) Counter({0: 1000, 1: 1000})
(2000, 1, 64) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 64, 64]             576
   MyConv1dPadSame-2               [-1, 64, 64]               0
       BatchNorm1d-3               [-1, 64, 64]             128
              ReLU-4               [-1, 64, 64]               0
            Conv1d-5               [-1, 64, 64]             576
   MyConv1dPadSame-6               [-1, 64, 64]               0
       BatchNorm1d-7               [-1, 64, 64]             128
              ReLU-8               [-1, 64, 64]               0
           Dropout-9               [-1, 64, 64]               0
           Conv1d-10               [-1, 64, 64]             576
  MyConv1dPadSame-11               [-1, 64, 64]               0
       Bottleneck-12               [-1, 64, 64]               0
      BatchNorm1d-13               [-1, 64, 64]             128
             ReLU-14               [-1, 64, 64]               0
          Dropout-15               [-1, 64, 64]               0
           Conv1d-16               [-1, 64, 64]             576
  MyConv1dPadSame-17               [-1, 64, 64]               0
      BatchNorm1d-18               [-1, 64, 64]             128
             ReLU-19               [-1, 64, 64]               0
          Dropout-20               [-1, 64, 64]               0
           Conv1d-21               [-1, 64, 64]             576
  MyConv1dPadSame-22               [-1, 64, 64]               0
       Bottleneck-23               [-1, 64, 64]               0
      BatchNorm1d-24               [-1, 64, 64]             128
             ReLU-25               [-1, 64, 64]               0
          Dropout-26               [-1, 64, 64]               0
           Conv1d-27              [-1, 128, 64]           1,152
  MyConv1dPadSame-28              [-1, 128, 64]               0
      BatchNorm1d-29              [-1, 128, 64]             256
             ReLU-30              [-1, 128, 64]               0
          Dropout-31              [-1, 128, 64]               0
           Conv1d-32              [-1, 128, 64]           2,176
  MyConv1dPadSame-33              [-1, 128, 64]               0
       Bottleneck-34              [-1, 128, 64]               0
      BatchNorm1d-35              [-1, 128, 64]             256
             ReLU-36              [-1, 128, 64]               0
          Dropout-37              [-1, 128, 64]               0
           Conv1d-38              [-1, 128, 64]           2,176
  MyConv1dPadSame-39              [-1, 128, 64]               0
      BatchNorm1d-40              [-1, 128, 64]             256
             ReLU-41              [-1, 128, 64]               0
          Dropout-42              [-1, 128, 64]               0
           Conv1d-43              [-1, 128, 64]           2,176
  MyConv1dPadSame-44              [-1, 128, 64]               0
       Bottleneck-45              [-1, 128, 64]               0
      BatchNorm1d-46              [-1, 128, 64]             256
             ReLU-47              [-1, 128, 64]               0
          Dropout-48              [-1, 128, 64]               0
           Conv1d-49              [-1, 256, 64]           4,352
  MyConv1dPadSame-50              [-1, 256, 64]               0
      BatchNorm1d-51              [-1, 256, 64]             512
             ReLU-52              [-1, 256, 64]               0
          Dropout-53              [-1, 256, 64]               0
           Conv1d-54              [-1, 256, 64]           8,448
  MyConv1dPadSame-55              [-1, 256, 64]               0
       Bottleneck-56              [-1, 256, 64]               0
      BatchNorm1d-57              [-1, 256, 64]             512
             ReLU-58              [-1, 256, 64]               0
          Dropout-59              [-1, 256, 64]               0
           Conv1d-60              [-1, 256, 64]           8,448
  MyConv1dPadSame-61              [-1, 256, 64]               0
      BatchNorm1d-62              [-1, 256, 64]             512
             ReLU-63              [-1, 256, 64]               0
          Dropout-64              [-1, 256, 64]               0
           Conv1d-65              [-1, 256, 64]           8,448
  MyConv1dPadSame-66              [-1, 256, 64]               0
       Bottleneck-67              [-1, 256, 64]               0
      BatchNorm1d-68              [-1, 256, 64]             512
             ReLU-69              [-1, 256, 64]               0
          Dropout-70              [-1, 256, 64]               0
           Conv1d-71              [-1, 512, 64]          16,896
  MyConv1dPadSame-72              [-1, 512, 64]               0
      BatchNorm1d-73              [-1, 512, 64]           1,024
             ReLU-74              [-1, 512, 64]               0
          Dropout-75              [-1, 512, 64]               0
           Conv1d-76              [-1, 512, 64]          33,280
  MyConv1dPadSame-77              [-1, 512, 64]               0
       Bottleneck-78              [-1, 512, 64]               0
      BatchNorm1d-79              [-1, 512, 64]           1,024
             ReLU-80              [-1, 512, 64]               0
          Dropout-81              [-1, 512, 64]               0
           Conv1d-82              [-1, 512, 64]          33,280
  MyConv1dPadSame-83              [-1, 512, 64]               0
      BatchNorm1d-84              [-1, 512, 64]           1,024
             ReLU-85              [-1, 512, 64]               0
          Dropout-86              [-1, 512, 64]               0
           Conv1d-87              [-1, 512, 64]          33,280
  MyConv1dPadSame-88              [-1, 512, 64]               0
       Bottleneck-89              [-1, 512, 64]               0
      BatchNorm1d-90              [-1, 512, 64]           1,024
             ReLU-91              [-1, 512, 64]               0
           Linear-92                    [-1, 2]           1,026
================================================================
Total params: 165,826
Trainable params: 165,826
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 10.19
Params size (MB): 0.63
Estimated Total Size (MB): 10.82
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 64, kernel_size: 8, n_block: 16
************************************************************
************************************************************
(2000, 1, 64) Counter({0: 1000, 1: 1000})
(2000, 1, 64) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 64, 64]             576
   MyConv1dPadSame-2               [-1, 64, 64]               0
       BatchNorm1d-3               [-1, 64, 64]             128
              ReLU-4               [-1, 64, 64]               0
            Conv1d-5               [-1, 64, 64]             576
   MyConv1dPadSame-6               [-1, 64, 64]               0
       BatchNorm1d-7               [-1, 64, 64]             128
              ReLU-8               [-1, 64, 64]               0
           Dropout-9               [-1, 64, 64]               0
           Conv1d-10               [-1, 64, 64]             576
  MyConv1dPadSame-11               [-1, 64, 64]               0
       Bottleneck-12               [-1, 64, 64]               0
      BatchNorm1d-13               [-1, 64, 64]             128
             ReLU-14               [-1, 64, 64]               0
          Dropout-15               [-1, 64, 64]               0
           Conv1d-16               [-1, 64, 32]             576
  MyConv1dPadSame-17               [-1, 64, 32]               0
      BatchNorm1d-18               [-1, 64, 32]             128
             ReLU-19               [-1, 64, 32]               0
          Dropout-20               [-1, 64, 32]               0
           Conv1d-21               [-1, 64, 32]             576
  MyConv1dPadSame-22               [-1, 64, 32]               0
        MaxPool1d-23               [-1, 64, 32]               0
MyMaxPool1dPadSame-24               [-1, 64, 32]               0
       Bottleneck-25               [-1, 64, 32]               0
      BatchNorm1d-26               [-1, 64, 32]             128
             ReLU-27               [-1, 64, 32]               0
          Dropout-28               [-1, 64, 32]               0
           Conv1d-29               [-1, 64, 32]             576
  MyConv1dPadSame-30               [-1, 64, 32]               0
      BatchNorm1d-31               [-1, 64, 32]             128
             ReLU-32               [-1, 64, 32]               0
          Dropout-33               [-1, 64, 32]               0
           Conv1d-34               [-1, 64, 32]             576
  MyConv1dPadSame-35               [-1, 64, 32]               0
       Bottleneck-36               [-1, 64, 32]               0
      BatchNorm1d-37               [-1, 64, 32]             128
             ReLU-38               [-1, 64, 32]               0
          Dropout-39               [-1, 64, 32]               0
           Conv1d-40               [-1, 64, 16]             576
  MyConv1dPadSame-41               [-1, 64, 16]               0
      BatchNorm1d-42               [-1, 64, 16]             128
             ReLU-43               [-1, 64, 16]               0
          Dropout-44               [-1, 64, 16]               0
           Conv1d-45               [-1, 64, 16]             576
  MyConv1dPadSame-46               [-1, 64, 16]               0
        MaxPool1d-47               [-1, 64, 16]               0
MyMaxPool1dPadSame-48               [-1, 64, 16]               0
       Bottleneck-49               [-1, 64, 16]               0
      BatchNorm1d-50               [-1, 64, 16]             128
             ReLU-51               [-1, 64, 16]               0
          Dropout-52               [-1, 64, 16]               0
           Conv1d-53              [-1, 128, 16]           1,152
  MyConv1dPadSame-54              [-1, 128, 16]               0
      BatchNorm1d-55              [-1, 128, 16]             256
             ReLU-56              [-1, 128, 16]               0
          Dropout-57              [-1, 128, 16]               0
           Conv1d-58              [-1, 128, 16]           2,176
  MyConv1dPadSame-59              [-1, 128, 16]               0
       Bottleneck-60              [-1, 128, 16]               0
      BatchNorm1d-61              [-1, 128, 16]             256
             ReLU-62              [-1, 128, 16]               0
          Dropout-63              [-1, 128, 16]               0
           Conv1d-64               [-1, 128, 8]           2,176
  MyConv1dPadSame-65               [-1, 128, 8]               0
      BatchNorm1d-66               [-1, 128, 8]             256
             ReLU-67               [-1, 128, 8]               0
          Dropout-68               [-1, 128, 8]               0
           Conv1d-69               [-1, 128, 8]           2,176
  MyConv1dPadSame-70               [-1, 128, 8]               0
        MaxPool1d-71               [-1, 128, 8]               0
MyMaxPool1dPadSame-72               [-1, 128, 8]               0
       Bottleneck-73               [-1, 128, 8]               0
      BatchNorm1d-74               [-1, 128, 8]             256
             ReLU-75               [-1, 128, 8]               0
          Dropout-76               [-1, 128, 8]               0
           Conv1d-77               [-1, 128, 8]           2,176
  MyConv1dPadSame-78               [-1, 128, 8]               0
      BatchNorm1d-79               [-1, 128, 8]             256
             ReLU-80               [-1, 128, 8]               0
          Dropout-81               [-1, 128, 8]               0
           Conv1d-82               [-1, 128, 8]           2,176
  MyConv1dPadSame-83               [-1, 128, 8]               0
       Bottleneck-84               [-1, 128, 8]               0
      BatchNorm1d-85               [-1, 128, 8]             256
             ReLU-86               [-1, 128, 8]               0
          Dropout-87               [-1, 128, 8]               0
           Conv1d-88               [-1, 128, 4]           2,176
  MyConv1dPadSame-89               [-1, 128, 4]               0
      BatchNorm1d-90               [-1, 128, 4]             256
             ReLU-91               [-1, 128, 4]               0
          Dropout-92               [-1, 128, 4]               0
           Conv1d-93               [-1, 128, 4]           2,176
  MyConv1dPadSame-94               [-1, 128, 4]               0
        MaxPool1d-95               [-1, 128, 4]               0
MyMaxPool1dPadSame-96               [-1, 128, 4]               0
       Bottleneck-97               [-1, 128, 4]               0
      BatchNorm1d-98               [-1, 128, 4]             256
             ReLU-99               [-1, 128, 4]               0
         Dropout-100               [-1, 128, 4]               0
          Conv1d-101               [-1, 256, 4]           4,352
 MyConv1dPadSame-102               [-1, 256, 4]               0
     BatchNorm1d-103               [-1, 256, 4]             512
            ReLU-104               [-1, 256, 4]               0
         Dropout-105               [-1, 256, 4]               0
          Conv1d-106               [-1, 256, 4]           8,448
 MyConv1dPadSame-107               [-1, 256, 4]               0
      Bottleneck-108               [-1, 256, 4]               0
     BatchNorm1d-109               [-1, 256, 4]             512
            ReLU-110               [-1, 256, 4]               0
         Dropout-111               [-1, 256, 4]               0
          Conv1d-112               [-1, 256, 2]           8,448
 MyConv1dPadSame-113               [-1, 256, 2]               0
     BatchNorm1d-114               [-1, 256, 2]             512
            ReLU-115               [-1, 256, 2]               0
         Dropout-116               [-1, 256, 2]               0
          Conv1d-117               [-1, 256, 2]           8,448
 MyConv1dPadSame-118               [-1, 256, 2]               0
       MaxPool1d-119               [-1, 256, 2]               0
MyMaxPool1dPadSame-120               [-1, 256, 2]               0
      Bottleneck-121               [-1, 256, 2]               0
     BatchNorm1d-122               [-1, 256, 2]             512
            ReLU-123               [-1, 256, 2]               0
         Dropout-124               [-1, 256, 2]               0
          Conv1d-125               [-1, 256, 2]           8,448
 MyConv1dPadSame-126               [-1, 256, 2]               0
     BatchNorm1d-127               [-1, 256, 2]             512
            ReLU-128               [-1, 256, 2]               0
         Dropout-129               [-1, 256, 2]               0
          Conv1d-130               [-1, 256, 2]           8,448
 MyConv1dPadSame-131               [-1, 256, 2]               0
      Bottleneck-132               [-1, 256, 2]               0
     BatchNorm1d-133               [-1, 256, 2]             512
            ReLU-134               [-1, 256, 2]               0
         Dropout-135               [-1, 256, 2]               0
          Conv1d-136               [-1, 256, 1]           8,448
 MyConv1dPadSame-137               [-1, 256, 1]               0
     BatchNorm1d-138               [-1, 256, 1]             512
            ReLU-139               [-1, 256, 1]               0
         Dropout-140               [-1, 256, 1]               0
          Conv1d-141               [-1, 256, 1]           8,448
 MyConv1dPadSame-142               [-1, 256, 1]               0
       MaxPool1d-143               [-1, 256, 1]               0
MyMaxPool1dPadSame-144               [-1, 256, 1]               0
      Bottleneck-145               [-1, 256, 1]               0
     BatchNorm1d-146               [-1, 256, 1]             512
            ReLU-147               [-1, 256, 1]               0
         Dropout-148               [-1, 256, 1]               0
          Conv1d-149               [-1, 512, 1]          16,896
 MyConv1dPadSame-150               [-1, 512, 1]               0
     BatchNorm1d-151               [-1, 512, 1]           1,024
            ReLU-152               [-1, 512, 1]               0
         Dropout-153               [-1, 512, 1]               0
          Conv1d-154               [-1, 512, 1]          33,280
 MyConv1dPadSame-155               [-1, 512, 1]               0
      Bottleneck-156               [-1, 512, 1]               0
     BatchNorm1d-157               [-1, 512, 1]           1,024
            ReLU-158               [-1, 512, 1]               0
         Dropout-159               [-1, 512, 1]               0
          Conv1d-160               [-1, 512, 1]          33,280
 MyConv1dPadSame-161               [-1, 512, 1]               0
     BatchNorm1d-162               [-1, 512, 1]           1,024
            ReLU-163               [-1, 512, 1]               0
         Dropout-164               [-1, 512, 1]               0
          Conv1d-165               [-1, 512, 1]          33,280
 MyConv1dPadSame-166               [-1, 512, 1]               0
       MaxPool1d-167               [-1, 512, 1]               0
MyMaxPool1dPadSame-168               [-1, 512, 1]               0
      Bottleneck-169               [-1, 512, 1]               0
     BatchNorm1d-170               [-1, 512, 1]           1,024
            ReLU-171               [-1, 512, 1]               0
         Dropout-172               [-1, 512, 1]               0
          Conv1d-173               [-1, 512, 1]          33,280
 MyConv1dPadSame-174               [-1, 512, 1]               0
     BatchNorm1d-175               [-1, 512, 1]           1,024
            ReLU-176               [-1, 512, 1]               0
         Dropout-177               [-1, 512, 1]               0
          Conv1d-178               [-1, 512, 1]          33,280
 MyConv1dPadSame-179               [-1, 512, 1]               0
      Bottleneck-180               [-1, 512, 1]               0
     BatchNorm1d-181               [-1, 512, 1]           1,024
            ReLU-182               [-1, 512, 1]               0
         Dropout-183               [-1, 512, 1]               0
          Conv1d-184               [-1, 512, 1]          33,280
 MyConv1dPadSame-185               [-1, 512, 1]               0
     BatchNorm1d-186               [-1, 512, 1]           1,024
            ReLU-187               [-1, 512, 1]               0
         Dropout-188               [-1, 512, 1]               0
          Conv1d-189               [-1, 512, 1]          33,280
 MyConv1dPadSame-190               [-1, 512, 1]               0
       MaxPool1d-191               [-1, 512, 1]               0
MyMaxPool1dPadSame-192               [-1, 512, 1]               0
      Bottleneck-193               [-1, 512, 1]               0
     BatchNorm1d-194               [-1, 512, 1]           1,024
            ReLU-195               [-1, 512, 1]               0
          Linear-196                    [-1, 2]           1,026
================================================================
Total params: 351,426
Trainable params: 351,426
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 1.74
Params size (MB): 1.34
Estimated Total Size (MB): 3.08
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 64, kernel_size: 16, n_block: 2
************************************************************
************************************************************
(2000, 1, 64) Counter({1: 1000, 0: 1000})
(2000, 1, 64) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 64, 64]           1,088
   MyConv1dPadSame-2               [-1, 64, 64]               0
       BatchNorm1d-3               [-1, 64, 64]             128
              ReLU-4               [-1, 64, 64]               0
            Conv1d-5               [-1, 64, 64]           1,088
   MyConv1dPadSame-6               [-1, 64, 64]               0
       BatchNorm1d-7               [-1, 64, 64]             128
              ReLU-8               [-1, 64, 64]               0
           Dropout-9               [-1, 64, 64]               0
           Conv1d-10               [-1, 64, 64]           1,088
  MyConv1dPadSame-11               [-1, 64, 64]               0
       Bottleneck-12               [-1, 64, 64]               0
      BatchNorm1d-13               [-1, 64, 64]             128
             ReLU-14               [-1, 64, 64]               0
          Dropout-15               [-1, 64, 64]               0
           Conv1d-16              [-1, 128, 64]           2,176
  MyConv1dPadSame-17              [-1, 128, 64]               0
      BatchNorm1d-18              [-1, 128, 64]             256
             ReLU-19              [-1, 128, 64]               0
          Dropout-20              [-1, 128, 64]               0
           Conv1d-21              [-1, 128, 64]           4,224
  MyConv1dPadSame-22              [-1, 128, 64]               0
       Bottleneck-23              [-1, 128, 64]               0
      BatchNorm1d-24              [-1, 128, 64]             256
             ReLU-25              [-1, 128, 64]               0
           Linear-26                    [-1, 2]             258
================================================================
Total params: 10,818
Trainable params: 10,818
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 1.09
Params size (MB): 0.04
Estimated Total Size (MB): 1.14
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 64, kernel_size: 16, n_block: 4
************************************************************
************************************************************
(2000, 1, 64) Counter({0: 1000, 1: 1000})
(2000, 1, 64) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 64, 64]           1,088
   MyConv1dPadSame-2               [-1, 64, 64]               0
       BatchNorm1d-3               [-1, 64, 64]             128
              ReLU-4               [-1, 64, 64]               0
            Conv1d-5               [-1, 64, 64]           1,088
   MyConv1dPadSame-6               [-1, 64, 64]               0
       BatchNorm1d-7               [-1, 64, 64]             128
              ReLU-8               [-1, 64, 64]               0
           Dropout-9               [-1, 64, 64]               0
           Conv1d-10               [-1, 64, 64]           1,088
  MyConv1dPadSame-11               [-1, 64, 64]               0
       Bottleneck-12               [-1, 64, 64]               0
      BatchNorm1d-13               [-1, 64, 64]             128
             ReLU-14               [-1, 64, 64]               0
          Dropout-15               [-1, 64, 64]               0
           Conv1d-16              [-1, 128, 64]           2,176
  MyConv1dPadSame-17              [-1, 128, 64]               0
      BatchNorm1d-18              [-1, 128, 64]             256
             ReLU-19              [-1, 128, 64]               0
          Dropout-20              [-1, 128, 64]               0
           Conv1d-21              [-1, 128, 64]           4,224
  MyConv1dPadSame-22              [-1, 128, 64]               0
       Bottleneck-23              [-1, 128, 64]               0
      BatchNorm1d-24              [-1, 128, 64]             256
             ReLU-25              [-1, 128, 64]               0
          Dropout-26              [-1, 128, 64]               0
           Conv1d-27              [-1, 256, 64]           8,448
  MyConv1dPadSame-28              [-1, 256, 64]               0
      BatchNorm1d-29              [-1, 256, 64]             512
             ReLU-30              [-1, 256, 64]               0
          Dropout-31              [-1, 256, 64]               0
           Conv1d-32              [-1, 256, 64]          16,640
  MyConv1dPadSame-33              [-1, 256, 64]               0
       Bottleneck-34              [-1, 256, 64]               0
      BatchNorm1d-35              [-1, 256, 64]             512
             ReLU-36              [-1, 256, 64]               0
          Dropout-37              [-1, 256, 64]               0
           Conv1d-38              [-1, 512, 64]          33,280
  MyConv1dPadSame-39              [-1, 512, 64]               0
      BatchNorm1d-40              [-1, 512, 64]           1,024
             ReLU-41              [-1, 512, 64]               0
          Dropout-42              [-1, 512, 64]               0
           Conv1d-43              [-1, 512, 64]          66,048
  MyConv1dPadSame-44              [-1, 512, 64]               0
       Bottleneck-45              [-1, 512, 64]               0
      BatchNorm1d-46              [-1, 512, 64]           1,024
             ReLU-47              [-1, 512, 64]               0
           Linear-48                    [-1, 2]           1,026
================================================================
Total params: 139,074
Trainable params: 139,074
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 5.03
Params size (MB): 0.53
Estimated Total Size (MB): 5.56
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 64, kernel_size: 16, n_block: 8
************************************************************
************************************************************
(2000, 1, 64) Counter({0: 1000, 1: 1000})
(2000, 1, 64) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 64, 64]           1,088
   MyConv1dPadSame-2               [-1, 64, 64]               0
       BatchNorm1d-3               [-1, 64, 64]             128
              ReLU-4               [-1, 64, 64]               0
            Conv1d-5               [-1, 64, 64]           1,088
   MyConv1dPadSame-6               [-1, 64, 64]               0
       BatchNorm1d-7               [-1, 64, 64]             128
              ReLU-8               [-1, 64, 64]               0
           Dropout-9               [-1, 64, 64]               0
           Conv1d-10               [-1, 64, 64]           1,088
  MyConv1dPadSame-11               [-1, 64, 64]               0
       Bottleneck-12               [-1, 64, 64]               0
      BatchNorm1d-13               [-1, 64, 64]             128
             ReLU-14               [-1, 64, 64]               0
          Dropout-15               [-1, 64, 64]               0
           Conv1d-16               [-1, 64, 64]           1,088
  MyConv1dPadSame-17               [-1, 64, 64]               0
      BatchNorm1d-18               [-1, 64, 64]             128
             ReLU-19               [-1, 64, 64]               0
          Dropout-20               [-1, 64, 64]               0
           Conv1d-21               [-1, 64, 64]           1,088
  MyConv1dPadSame-22               [-1, 64, 64]               0
       Bottleneck-23               [-1, 64, 64]               0
      BatchNorm1d-24               [-1, 64, 64]             128
             ReLU-25               [-1, 64, 64]               0
          Dropout-26               [-1, 64, 64]               0
           Conv1d-27              [-1, 128, 64]           2,176
  MyConv1dPadSame-28              [-1, 128, 64]               0
      BatchNorm1d-29              [-1, 128, 64]             256
             ReLU-30              [-1, 128, 64]               0
          Dropout-31              [-1, 128, 64]               0
           Conv1d-32              [-1, 128, 64]           4,224
  MyConv1dPadSame-33              [-1, 128, 64]               0
       Bottleneck-34              [-1, 128, 64]               0
      BatchNorm1d-35              [-1, 128, 64]             256
             ReLU-36              [-1, 128, 64]               0
          Dropout-37              [-1, 128, 64]               0
           Conv1d-38              [-1, 128, 64]           4,224
  MyConv1dPadSame-39              [-1, 128, 64]               0
      BatchNorm1d-40              [-1, 128, 64]             256
             ReLU-41              [-1, 128, 64]               0
          Dropout-42              [-1, 128, 64]               0
           Conv1d-43              [-1, 128, 64]           4,224
  MyConv1dPadSame-44              [-1, 128, 64]               0
       Bottleneck-45              [-1, 128, 64]               0
      BatchNorm1d-46              [-1, 128, 64]             256
             ReLU-47              [-1, 128, 64]               0
          Dropout-48              [-1, 128, 64]               0
           Conv1d-49              [-1, 256, 64]           8,448
  MyConv1dPadSame-50              [-1, 256, 64]               0
      BatchNorm1d-51              [-1, 256, 64]             512
             ReLU-52              [-1, 256, 64]               0
          Dropout-53              [-1, 256, 64]               0
           Conv1d-54              [-1, 256, 64]          16,640
  MyConv1dPadSame-55              [-1, 256, 64]               0
       Bottleneck-56              [-1, 256, 64]               0
      BatchNorm1d-57              [-1, 256, 64]             512
             ReLU-58              [-1, 256, 64]               0
          Dropout-59              [-1, 256, 64]               0
           Conv1d-60              [-1, 256, 64]          16,640
  MyConv1dPadSame-61              [-1, 256, 64]               0
      BatchNorm1d-62              [-1, 256, 64]             512
             ReLU-63              [-1, 256, 64]               0
          Dropout-64              [-1, 256, 64]               0
           Conv1d-65              [-1, 256, 64]          16,640
  MyConv1dPadSame-66              [-1, 256, 64]               0
       Bottleneck-67              [-1, 256, 64]               0
      BatchNorm1d-68              [-1, 256, 64]             512
             ReLU-69              [-1, 256, 64]               0
          Dropout-70              [-1, 256, 64]               0
           Conv1d-71              [-1, 512, 64]          33,280
  MyConv1dPadSame-72              [-1, 512, 64]               0
      BatchNorm1d-73              [-1, 512, 64]           1,024
             ReLU-74              [-1, 512, 64]               0
          Dropout-75              [-1, 512, 64]               0
           Conv1d-76              [-1, 512, 64]          66,048
  MyConv1dPadSame-77              [-1, 512, 64]               0
       Bottleneck-78              [-1, 512, 64]               0
      BatchNorm1d-79              [-1, 512, 64]           1,024
             ReLU-80              [-1, 512, 64]               0
          Dropout-81              [-1, 512, 64]               0
           Conv1d-82              [-1, 512, 64]          66,048
  MyConv1dPadSame-83              [-1, 512, 64]               0
      BatchNorm1d-84              [-1, 512, 64]           1,024
             ReLU-85              [-1, 512, 64]               0
          Dropout-86              [-1, 512, 64]               0
           Conv1d-87              [-1, 512, 64]          66,048
  MyConv1dPadSame-88              [-1, 512, 64]               0
       Bottleneck-89              [-1, 512, 64]               0
      BatchNorm1d-90              [-1, 512, 64]           1,024
             ReLU-91              [-1, 512, 64]               0
           Linear-92                    [-1, 2]           1,026
================================================================
Total params: 318,914
Trainable params: 318,914
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 10.19
Params size (MB): 1.22
Estimated Total Size (MB): 11.40
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 64, kernel_size: 16, n_block: 16
************************************************************
************************************************************
(2000, 1, 64) Counter({0: 1000, 1: 1000})
(2000, 1, 64) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 64, 64]           1,088
   MyConv1dPadSame-2               [-1, 64, 64]               0
       BatchNorm1d-3               [-1, 64, 64]             128
              ReLU-4               [-1, 64, 64]               0
            Conv1d-5               [-1, 64, 64]           1,088
   MyConv1dPadSame-6               [-1, 64, 64]               0
       BatchNorm1d-7               [-1, 64, 64]             128
              ReLU-8               [-1, 64, 64]               0
           Dropout-9               [-1, 64, 64]               0
           Conv1d-10               [-1, 64, 64]           1,088
  MyConv1dPadSame-11               [-1, 64, 64]               0
       Bottleneck-12               [-1, 64, 64]               0
      BatchNorm1d-13               [-1, 64, 64]             128
             ReLU-14               [-1, 64, 64]               0
          Dropout-15               [-1, 64, 64]               0
           Conv1d-16               [-1, 64, 32]           1,088
  MyConv1dPadSame-17               [-1, 64, 32]               0
      BatchNorm1d-18               [-1, 64, 32]             128
             ReLU-19               [-1, 64, 32]               0
          Dropout-20               [-1, 64, 32]               0
           Conv1d-21               [-1, 64, 32]           1,088
  MyConv1dPadSame-22               [-1, 64, 32]               0
        MaxPool1d-23               [-1, 64, 32]               0
MyMaxPool1dPadSame-24               [-1, 64, 32]               0
       Bottleneck-25               [-1, 64, 32]               0
      BatchNorm1d-26               [-1, 64, 32]             128
             ReLU-27               [-1, 64, 32]               0
          Dropout-28               [-1, 64, 32]               0
           Conv1d-29               [-1, 64, 32]           1,088
  MyConv1dPadSame-30               [-1, 64, 32]               0
      BatchNorm1d-31               [-1, 64, 32]             128
             ReLU-32               [-1, 64, 32]               0
          Dropout-33               [-1, 64, 32]               0
           Conv1d-34               [-1, 64, 32]           1,088
  MyConv1dPadSame-35               [-1, 64, 32]               0
       Bottleneck-36               [-1, 64, 32]               0
      BatchNorm1d-37               [-1, 64, 32]             128
             ReLU-38               [-1, 64, 32]               0
          Dropout-39               [-1, 64, 32]               0
           Conv1d-40               [-1, 64, 16]           1,088
  MyConv1dPadSame-41               [-1, 64, 16]               0
      BatchNorm1d-42               [-1, 64, 16]             128
             ReLU-43               [-1, 64, 16]               0
          Dropout-44               [-1, 64, 16]               0
           Conv1d-45               [-1, 64, 16]           1,088
  MyConv1dPadSame-46               [-1, 64, 16]               0
        MaxPool1d-47               [-1, 64, 16]               0
MyMaxPool1dPadSame-48               [-1, 64, 16]               0
       Bottleneck-49               [-1, 64, 16]               0
      BatchNorm1d-50               [-1, 64, 16]             128
             ReLU-51               [-1, 64, 16]               0
          Dropout-52               [-1, 64, 16]               0
           Conv1d-53              [-1, 128, 16]           2,176
  MyConv1dPadSame-54              [-1, 128, 16]               0
      BatchNorm1d-55              [-1, 128, 16]             256
             ReLU-56              [-1, 128, 16]               0
          Dropout-57              [-1, 128, 16]               0
           Conv1d-58              [-1, 128, 16]           4,224
  MyConv1dPadSame-59              [-1, 128, 16]               0
       Bottleneck-60              [-1, 128, 16]               0
      BatchNorm1d-61              [-1, 128, 16]             256
             ReLU-62              [-1, 128, 16]               0
          Dropout-63              [-1, 128, 16]               0
           Conv1d-64               [-1, 128, 8]           4,224
  MyConv1dPadSame-65               [-1, 128, 8]               0
      BatchNorm1d-66               [-1, 128, 8]             256
             ReLU-67               [-1, 128, 8]               0
          Dropout-68               [-1, 128, 8]               0
           Conv1d-69               [-1, 128, 8]           4,224
  MyConv1dPadSame-70               [-1, 128, 8]               0
        MaxPool1d-71               [-1, 128, 8]               0
MyMaxPool1dPadSame-72               [-1, 128, 8]               0
       Bottleneck-73               [-1, 128, 8]               0
      BatchNorm1d-74               [-1, 128, 8]             256
             ReLU-75               [-1, 128, 8]               0
          Dropout-76               [-1, 128, 8]               0
           Conv1d-77               [-1, 128, 8]           4,224
  MyConv1dPadSame-78               [-1, 128, 8]               0
      BatchNorm1d-79               [-1, 128, 8]             256
             ReLU-80               [-1, 128, 8]               0
          Dropout-81               [-1, 128, 8]               0
           Conv1d-82               [-1, 128, 8]           4,224
  MyConv1dPadSame-83               [-1, 128, 8]               0
       Bottleneck-84               [-1, 128, 8]               0
      BatchNorm1d-85               [-1, 128, 8]             256
             ReLU-86               [-1, 128, 8]               0
          Dropout-87               [-1, 128, 8]               0
           Conv1d-88               [-1, 128, 4]           4,224
  MyConv1dPadSame-89               [-1, 128, 4]               0
      BatchNorm1d-90               [-1, 128, 4]             256
             ReLU-91               [-1, 128, 4]               0
          Dropout-92               [-1, 128, 4]               0
           Conv1d-93               [-1, 128, 4]           4,224
  MyConv1dPadSame-94               [-1, 128, 4]               0
        MaxPool1d-95               [-1, 128, 4]               0
MyMaxPool1dPadSame-96               [-1, 128, 4]               0
       Bottleneck-97               [-1, 128, 4]               0
      BatchNorm1d-98               [-1, 128, 4]             256
             ReLU-99               [-1, 128, 4]               0
         Dropout-100               [-1, 128, 4]               0
          Conv1d-101               [-1, 256, 4]           8,448
 MyConv1dPadSame-102               [-1, 256, 4]               0
     BatchNorm1d-103               [-1, 256, 4]             512
            ReLU-104               [-1, 256, 4]               0
         Dropout-105               [-1, 256, 4]               0
          Conv1d-106               [-1, 256, 4]          16,640
 MyConv1dPadSame-107               [-1, 256, 4]               0
      Bottleneck-108               [-1, 256, 4]               0
     BatchNorm1d-109               [-1, 256, 4]             512
            ReLU-110               [-1, 256, 4]               0
         Dropout-111               [-1, 256, 4]               0
          Conv1d-112               [-1, 256, 2]          16,640
 MyConv1dPadSame-113               [-1, 256, 2]               0
     BatchNorm1d-114               [-1, 256, 2]             512
            ReLU-115               [-1, 256, 2]               0
         Dropout-116               [-1, 256, 2]               0
          Conv1d-117               [-1, 256, 2]          16,640
 MyConv1dPadSame-118               [-1, 256, 2]               0
       MaxPool1d-119               [-1, 256, 2]               0
MyMaxPool1dPadSame-120               [-1, 256, 2]               0
      Bottleneck-121               [-1, 256, 2]               0
     BatchNorm1d-122               [-1, 256, 2]             512
            ReLU-123               [-1, 256, 2]               0
         Dropout-124               [-1, 256, 2]               0
          Conv1d-125               [-1, 256, 2]          16,640
 MyConv1dPadSame-126               [-1, 256, 2]               0
     BatchNorm1d-127               [-1, 256, 2]             512
            ReLU-128               [-1, 256, 2]               0
         Dropout-129               [-1, 256, 2]               0
          Conv1d-130               [-1, 256, 2]          16,640
 MyConv1dPadSame-131               [-1, 256, 2]               0
      Bottleneck-132               [-1, 256, 2]               0
     BatchNorm1d-133               [-1, 256, 2]             512
            ReLU-134               [-1, 256, 2]               0
         Dropout-135               [-1, 256, 2]               0
          Conv1d-136               [-1, 256, 1]          16,640
 MyConv1dPadSame-137               [-1, 256, 1]               0
     BatchNorm1d-138               [-1, 256, 1]             512
            ReLU-139               [-1, 256, 1]               0
         Dropout-140               [-1, 256, 1]               0
          Conv1d-141               [-1, 256, 1]          16,640
 MyConv1dPadSame-142               [-1, 256, 1]               0
       MaxPool1d-143               [-1, 256, 1]               0
MyMaxPool1dPadSame-144               [-1, 256, 1]               0
      Bottleneck-145               [-1, 256, 1]               0
     BatchNorm1d-146               [-1, 256, 1]             512
            ReLU-147               [-1, 256, 1]               0
         Dropout-148               [-1, 256, 1]               0
          Conv1d-149               [-1, 512, 1]          33,280
 MyConv1dPadSame-150               [-1, 512, 1]               0
     BatchNorm1d-151               [-1, 512, 1]           1,024
            ReLU-152               [-1, 512, 1]               0
         Dropout-153               [-1, 512, 1]               0
          Conv1d-154               [-1, 512, 1]          66,048
 MyConv1dPadSame-155               [-1, 512, 1]               0
      Bottleneck-156               [-1, 512, 1]               0
     BatchNorm1d-157               [-1, 512, 1]           1,024
            ReLU-158               [-1, 512, 1]               0
         Dropout-159               [-1, 512, 1]               0
          Conv1d-160               [-1, 512, 1]          66,048
 MyConv1dPadSame-161               [-1, 512, 1]               0
     BatchNorm1d-162               [-1, 512, 1]           1,024
            ReLU-163               [-1, 512, 1]               0
         Dropout-164               [-1, 512, 1]               0
          Conv1d-165               [-1, 512, 1]          66,048
 MyConv1dPadSame-166               [-1, 512, 1]               0
       MaxPool1d-167               [-1, 512, 1]               0
MyMaxPool1dPadSame-168               [-1, 512, 1]               0
      Bottleneck-169               [-1, 512, 1]               0
     BatchNorm1d-170               [-1, 512, 1]           1,024
            ReLU-171               [-1, 512, 1]               0
         Dropout-172               [-1, 512, 1]               0
          Conv1d-173               [-1, 512, 1]          66,048
 MyConv1dPadSame-174               [-1, 512, 1]               0
     BatchNorm1d-175               [-1, 512, 1]           1,024
            ReLU-176               [-1, 512, 1]               0
         Dropout-177               [-1, 512, 1]               0
          Conv1d-178               [-1, 512, 1]          66,048
 MyConv1dPadSame-179               [-1, 512, 1]               0
      Bottleneck-180               [-1, 512, 1]               0
     BatchNorm1d-181               [-1, 512, 1]           1,024
            ReLU-182               [-1, 512, 1]               0
         Dropout-183               [-1, 512, 1]               0
          Conv1d-184               [-1, 512, 1]          66,048
 MyConv1dPadSame-185               [-1, 512, 1]               0
     BatchNorm1d-186               [-1, 512, 1]           1,024
            ReLU-187               [-1, 512, 1]               0
         Dropout-188               [-1, 512, 1]               0
          Conv1d-189               [-1, 512, 1]          66,048
 MyConv1dPadSame-190               [-1, 512, 1]               0
       MaxPool1d-191               [-1, 512, 1]               0
MyMaxPool1dPadSame-192               [-1, 512, 1]               0
      Bottleneck-193               [-1, 512, 1]               0
     BatchNorm1d-194               [-1, 512, 1]           1,024
            ReLU-195               [-1, 512, 1]               0
          Linear-196                    [-1, 2]           1,026
================================================================
Total params: 678,594
Trainable params: 678,594
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 1.74
Params size (MB): 2.59
Estimated Total Size (MB): 4.33
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 128, kernel_size: 2, n_block: 2
************************************************************
************************************************************
(2000, 1, 64) Counter({1: 1000, 0: 1000})
(2000, 1, 64) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 128, 64]             384
   MyConv1dPadSame-2              [-1, 128, 64]               0
       BatchNorm1d-3              [-1, 128, 64]             256
              ReLU-4              [-1, 128, 64]               0
            Conv1d-5              [-1, 128, 64]             384
   MyConv1dPadSame-6              [-1, 128, 64]               0
       BatchNorm1d-7              [-1, 128, 64]             256
              ReLU-8              [-1, 128, 64]               0
           Dropout-9              [-1, 128, 64]               0
           Conv1d-10              [-1, 128, 64]             384
  MyConv1dPadSame-11              [-1, 128, 64]               0
       Bottleneck-12              [-1, 128, 64]               0
      BatchNorm1d-13              [-1, 128, 64]             256
             ReLU-14              [-1, 128, 64]               0
          Dropout-15              [-1, 128, 64]               0
           Conv1d-16              [-1, 256, 64]             768
  MyConv1dPadSame-17              [-1, 256, 64]               0
      BatchNorm1d-18              [-1, 256, 64]             512
             ReLU-19              [-1, 256, 64]               0
          Dropout-20              [-1, 256, 64]               0
           Conv1d-21              [-1, 256, 64]           1,280
  MyConv1dPadSame-22              [-1, 256, 64]               0
       Bottleneck-23              [-1, 256, 64]               0
      BatchNorm1d-24              [-1, 256, 64]             512
             ReLU-25              [-1, 256, 64]               0
           Linear-26                    [-1, 2]             514
================================================================
Total params: 5,506
Trainable params: 5,506
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 2.19
Params size (MB): 0.02
Estimated Total Size (MB): 2.21
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 128, kernel_size: 2, n_block: 4
************************************************************
************************************************************
(2000, 1, 64) Counter({0: 1000, 1: 1000})
(2000, 1, 64) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 128, 64]             384
   MyConv1dPadSame-2              [-1, 128, 64]               0
       BatchNorm1d-3              [-1, 128, 64]             256
              ReLU-4              [-1, 128, 64]               0
            Conv1d-5              [-1, 128, 64]             384
   MyConv1dPadSame-6              [-1, 128, 64]               0
       BatchNorm1d-7              [-1, 128, 64]             256
              ReLU-8              [-1, 128, 64]               0
           Dropout-9              [-1, 128, 64]               0
           Conv1d-10              [-1, 128, 64]             384
  MyConv1dPadSame-11              [-1, 128, 64]               0
       Bottleneck-12              [-1, 128, 64]               0
      BatchNorm1d-13              [-1, 128, 64]             256
             ReLU-14              [-1, 128, 64]               0
          Dropout-15              [-1, 128, 64]               0
           Conv1d-16              [-1, 256, 64]             768
  MyConv1dPadSame-17              [-1, 256, 64]               0
      BatchNorm1d-18              [-1, 256, 64]             512
             ReLU-19              [-1, 256, 64]               0
          Dropout-20              [-1, 256, 64]               0
           Conv1d-21              [-1, 256, 64]           1,280
  MyConv1dPadSame-22              [-1, 256, 64]               0
       Bottleneck-23              [-1, 256, 64]               0
      BatchNorm1d-24              [-1, 256, 64]             512
             ReLU-25              [-1, 256, 64]               0
          Dropout-26              [-1, 256, 64]               0
           Conv1d-27              [-1, 512, 64]           2,560
  MyConv1dPadSame-28              [-1, 512, 64]               0
      BatchNorm1d-29              [-1, 512, 64]           1,024
             ReLU-30              [-1, 512, 64]               0
          Dropout-31              [-1, 512, 64]               0
           Conv1d-32              [-1, 512, 64]           4,608
  MyConv1dPadSame-33              [-1, 512, 64]               0
       Bottleneck-34              [-1, 512, 64]               0
      BatchNorm1d-35              [-1, 512, 64]           1,024
             ReLU-36              [-1, 512, 64]               0
          Dropout-37              [-1, 512, 64]               0
           Conv1d-38             [-1, 1024, 64]           9,216
  MyConv1dPadSame-39             [-1, 1024, 64]               0
      BatchNorm1d-40             [-1, 1024, 64]           2,048
             ReLU-41             [-1, 1024, 64]               0
          Dropout-42             [-1, 1024, 64]               0
           Conv1d-43             [-1, 1024, 64]          17,408
  MyConv1dPadSame-44             [-1, 1024, 64]               0
       Bottleneck-45             [-1, 1024, 64]               0
      BatchNorm1d-46             [-1, 1024, 64]           2,048
             ReLU-47             [-1, 1024, 64]               0
           Linear-48                    [-1, 2]           2,050
================================================================
Total params: 46,978
Trainable params: 46,978
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 10.06
Params size (MB): 0.18
Estimated Total Size (MB): 10.24
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 128, kernel_size: 2, n_block: 8
************************************************************
************************************************************
(2000, 1, 64) Counter({0: 1000, 1: 1000})
(2000, 1, 64) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 128, 64]             384
   MyConv1dPadSame-2              [-1, 128, 64]               0
       BatchNorm1d-3              [-1, 128, 64]             256
              ReLU-4              [-1, 128, 64]               0
            Conv1d-5              [-1, 128, 64]             384
   MyConv1dPadSame-6              [-1, 128, 64]               0
       BatchNorm1d-7              [-1, 128, 64]             256
              ReLU-8              [-1, 128, 64]               0
           Dropout-9              [-1, 128, 64]               0
           Conv1d-10              [-1, 128, 64]             384
  MyConv1dPadSame-11              [-1, 128, 64]               0
       Bottleneck-12              [-1, 128, 64]               0
      BatchNorm1d-13              [-1, 128, 64]             256
             ReLU-14              [-1, 128, 64]               0
          Dropout-15              [-1, 128, 64]               0
           Conv1d-16              [-1, 128, 64]             384
  MyConv1dPadSame-17              [-1, 128, 64]               0
      BatchNorm1d-18              [-1, 128, 64]             256
             ReLU-19              [-1, 128, 64]               0
          Dropout-20              [-1, 128, 64]               0
           Conv1d-21              [-1, 128, 64]             384
  MyConv1dPadSame-22              [-1, 128, 64]               0
       Bottleneck-23              [-1, 128, 64]               0
      BatchNorm1d-24              [-1, 128, 64]             256
             ReLU-25              [-1, 128, 64]               0
          Dropout-26              [-1, 128, 64]               0
           Conv1d-27              [-1, 256, 64]             768
  MyConv1dPadSame-28              [-1, 256, 64]               0
      BatchNorm1d-29              [-1, 256, 64]             512
             ReLU-30              [-1, 256, 64]               0
          Dropout-31              [-1, 256, 64]               0
           Conv1d-32              [-1, 256, 64]           1,280
  MyConv1dPadSame-33              [-1, 256, 64]               0
       Bottleneck-34              [-1, 256, 64]               0
      BatchNorm1d-35              [-1, 256, 64]             512
             ReLU-36              [-1, 256, 64]               0
          Dropout-37              [-1, 256, 64]               0
           Conv1d-38              [-1, 256, 64]           1,280
  MyConv1dPadSame-39              [-1, 256, 64]               0
      BatchNorm1d-40              [-1, 256, 64]             512
             ReLU-41              [-1, 256, 64]               0
          Dropout-42              [-1, 256, 64]               0
           Conv1d-43              [-1, 256, 64]           1,280
  MyConv1dPadSame-44              [-1, 256, 64]               0
       Bottleneck-45              [-1, 256, 64]               0
      BatchNorm1d-46              [-1, 256, 64]             512
             ReLU-47              [-1, 256, 64]               0
          Dropout-48              [-1, 256, 64]               0
           Conv1d-49              [-1, 512, 64]           2,560
  MyConv1dPadSame-50              [-1, 512, 64]               0
      BatchNorm1d-51              [-1, 512, 64]           1,024
             ReLU-52              [-1, 512, 64]               0
          Dropout-53              [-1, 512, 64]               0
           Conv1d-54              [-1, 512, 64]           4,608
  MyConv1dPadSame-55              [-1, 512, 64]               0
       Bottleneck-56              [-1, 512, 64]               0
      BatchNorm1d-57              [-1, 512, 64]           1,024
             ReLU-58              [-1, 512, 64]               0
          Dropout-59              [-1, 512, 64]               0
           Conv1d-60              [-1, 512, 64]           4,608
  MyConv1dPadSame-61              [-1, 512, 64]               0
      BatchNorm1d-62              [-1, 512, 64]           1,024
             ReLU-63              [-1, 512, 64]               0
          Dropout-64              [-1, 512, 64]               0
           Conv1d-65              [-1, 512, 64]           4,608
  MyConv1dPadSame-66              [-1, 512, 64]               0
       Bottleneck-67              [-1, 512, 64]               0
      BatchNorm1d-68              [-1, 512, 64]           1,024
             ReLU-69              [-1, 512, 64]               0
          Dropout-70              [-1, 512, 64]               0
           Conv1d-71             [-1, 1024, 64]           9,216
  MyConv1dPadSame-72             [-1, 1024, 64]               0
      BatchNorm1d-73             [-1, 1024, 64]           2,048
             ReLU-74             [-1, 1024, 64]               0
          Dropout-75             [-1, 1024, 64]               0
           Conv1d-76             [-1, 1024, 64]          17,408
  MyConv1dPadSame-77             [-1, 1024, 64]               0
       Bottleneck-78             [-1, 1024, 64]               0
      BatchNorm1d-79             [-1, 1024, 64]           2,048
             ReLU-80             [-1, 1024, 64]               0
          Dropout-81             [-1, 1024, 64]               0
           Conv1d-82             [-1, 1024, 64]          17,408
  MyConv1dPadSame-83             [-1, 1024, 64]               0
      BatchNorm1d-84             [-1, 1024, 64]           2,048
             ReLU-85             [-1, 1024, 64]               0
          Dropout-86             [-1, 1024, 64]               0
           Conv1d-87             [-1, 1024, 64]          17,408
  MyConv1dPadSame-88             [-1, 1024, 64]               0
       Bottleneck-89             [-1, 1024, 64]               0
      BatchNorm1d-90             [-1, 1024, 64]           2,048
             ReLU-91             [-1, 1024, 64]               0
           Linear-92                    [-1, 2]           2,050
================================================================
Total params: 102,018
Trainable params: 102,018
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 20.38
Params size (MB): 0.39
Estimated Total Size (MB): 20.76
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 128, kernel_size: 2, n_block: 16
************************************************************
************************************************************
(2000, 1, 64) Counter({0: 1000, 1: 1000})
(2000, 1, 64) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 128, 64]             384
   MyConv1dPadSame-2              [-1, 128, 64]               0
       BatchNorm1d-3              [-1, 128, 64]             256
              ReLU-4              [-1, 128, 64]               0
            Conv1d-5              [-1, 128, 64]             384
   MyConv1dPadSame-6              [-1, 128, 64]               0
       BatchNorm1d-7              [-1, 128, 64]             256
              ReLU-8              [-1, 128, 64]               0
           Dropout-9              [-1, 128, 64]               0
           Conv1d-10              [-1, 128, 64]             384
  MyConv1dPadSame-11              [-1, 128, 64]               0
       Bottleneck-12              [-1, 128, 64]               0
      BatchNorm1d-13              [-1, 128, 64]             256
             ReLU-14              [-1, 128, 64]               0
          Dropout-15              [-1, 128, 64]               0
           Conv1d-16              [-1, 128, 32]             384
  MyConv1dPadSame-17              [-1, 128, 32]               0
      BatchNorm1d-18              [-1, 128, 32]             256
             ReLU-19              [-1, 128, 32]               0
          Dropout-20              [-1, 128, 32]               0
           Conv1d-21              [-1, 128, 32]             384
  MyConv1dPadSame-22              [-1, 128, 32]               0
        MaxPool1d-23              [-1, 128, 32]               0
MyMaxPool1dPadSame-24              [-1, 128, 32]               0
       Bottleneck-25              [-1, 128, 32]               0
      BatchNorm1d-26              [-1, 128, 32]             256
             ReLU-27              [-1, 128, 32]               0
          Dropout-28              [-1, 128, 32]               0
           Conv1d-29              [-1, 128, 32]             384
  MyConv1dPadSame-30              [-1, 128, 32]               0
      BatchNorm1d-31              [-1, 128, 32]             256
             ReLU-32              [-1, 128, 32]               0
          Dropout-33              [-1, 128, 32]               0
           Conv1d-34              [-1, 128, 32]             384
  MyConv1dPadSame-35              [-1, 128, 32]               0
       Bottleneck-36              [-1, 128, 32]               0
      BatchNorm1d-37              [-1, 128, 32]             256
             ReLU-38              [-1, 128, 32]               0
          Dropout-39              [-1, 128, 32]               0
           Conv1d-40              [-1, 128, 16]             384
  MyConv1dPadSame-41              [-1, 128, 16]               0
      BatchNorm1d-42              [-1, 128, 16]             256
             ReLU-43              [-1, 128, 16]               0
          Dropout-44              [-1, 128, 16]               0
           Conv1d-45              [-1, 128, 16]             384
  MyConv1dPadSame-46              [-1, 128, 16]               0
        MaxPool1d-47              [-1, 128, 16]               0
MyMaxPool1dPadSame-48              [-1, 128, 16]               0
       Bottleneck-49              [-1, 128, 16]               0
      BatchNorm1d-50              [-1, 128, 16]             256
             ReLU-51              [-1, 128, 16]               0
          Dropout-52              [-1, 128, 16]               0
           Conv1d-53              [-1, 256, 16]             768
  MyConv1dPadSame-54              [-1, 256, 16]               0
      BatchNorm1d-55              [-1, 256, 16]             512
             ReLU-56              [-1, 256, 16]               0
          Dropout-57              [-1, 256, 16]               0
           Conv1d-58              [-1, 256, 16]           1,280
  MyConv1dPadSame-59              [-1, 256, 16]               0
       Bottleneck-60              [-1, 256, 16]               0
      BatchNorm1d-61              [-1, 256, 16]             512
             ReLU-62              [-1, 256, 16]               0
          Dropout-63              [-1, 256, 16]               0
           Conv1d-64               [-1, 256, 8]           1,280
  MyConv1dPadSame-65               [-1, 256, 8]               0
      BatchNorm1d-66               [-1, 256, 8]             512
             ReLU-67               [-1, 256, 8]               0
          Dropout-68               [-1, 256, 8]               0
           Conv1d-69               [-1, 256, 8]           1,280
  MyConv1dPadSame-70               [-1, 256, 8]               0
        MaxPool1d-71               [-1, 256, 8]               0
MyMaxPool1dPadSame-72               [-1, 256, 8]               0
       Bottleneck-73               [-1, 256, 8]               0
      BatchNorm1d-74               [-1, 256, 8]             512
             ReLU-75               [-1, 256, 8]               0
          Dropout-76               [-1, 256, 8]               0
           Conv1d-77               [-1, 256, 8]           1,280
  MyConv1dPadSame-78               [-1, 256, 8]               0
      BatchNorm1d-79               [-1, 256, 8]             512
             ReLU-80               [-1, 256, 8]               0
          Dropout-81               [-1, 256, 8]               0
           Conv1d-82               [-1, 256, 8]           1,280
  MyConv1dPadSame-83               [-1, 256, 8]               0
       Bottleneck-84               [-1, 256, 8]               0
      BatchNorm1d-85               [-1, 256, 8]             512
             ReLU-86               [-1, 256, 8]               0
          Dropout-87               [-1, 256, 8]               0
           Conv1d-88               [-1, 256, 4]           1,280
  MyConv1dPadSame-89               [-1, 256, 4]               0
      BatchNorm1d-90               [-1, 256, 4]             512
             ReLU-91               [-1, 256, 4]               0
          Dropout-92               [-1, 256, 4]               0
           Conv1d-93               [-1, 256, 4]           1,280
  MyConv1dPadSame-94               [-1, 256, 4]               0
        MaxPool1d-95               [-1, 256, 4]               0
MyMaxPool1dPadSame-96               [-1, 256, 4]               0
       Bottleneck-97               [-1, 256, 4]               0
      BatchNorm1d-98               [-1, 256, 4]             512
             ReLU-99               [-1, 256, 4]               0
         Dropout-100               [-1, 256, 4]               0
          Conv1d-101               [-1, 512, 4]           2,560
 MyConv1dPadSame-102               [-1, 512, 4]               0
     BatchNorm1d-103               [-1, 512, 4]           1,024
            ReLU-104               [-1, 512, 4]               0
         Dropout-105               [-1, 512, 4]               0
          Conv1d-106               [-1, 512, 4]           4,608
 MyConv1dPadSame-107               [-1, 512, 4]               0
      Bottleneck-108               [-1, 512, 4]               0
     BatchNorm1d-109               [-1, 512, 4]           1,024
            ReLU-110               [-1, 512, 4]               0
         Dropout-111               [-1, 512, 4]               0
          Conv1d-112               [-1, 512, 2]           4,608
 MyConv1dPadSame-113               [-1, 512, 2]               0
     BatchNorm1d-114               [-1, 512, 2]           1,024
            ReLU-115               [-1, 512, 2]               0
         Dropout-116               [-1, 512, 2]               0
          Conv1d-117               [-1, 512, 2]           4,608
 MyConv1dPadSame-118               [-1, 512, 2]               0
       MaxPool1d-119               [-1, 512, 2]               0
MyMaxPool1dPadSame-120               [-1, 512, 2]               0
      Bottleneck-121               [-1, 512, 2]               0
     BatchNorm1d-122               [-1, 512, 2]           1,024
            ReLU-123               [-1, 512, 2]               0
         Dropout-124               [-1, 512, 2]               0
          Conv1d-125               [-1, 512, 2]           4,608
 MyConv1dPadSame-126               [-1, 512, 2]               0
     BatchNorm1d-127               [-1, 512, 2]           1,024
            ReLU-128               [-1, 512, 2]               0
         Dropout-129               [-1, 512, 2]               0
          Conv1d-130               [-1, 512, 2]           4,608
 MyConv1dPadSame-131               [-1, 512, 2]               0
      Bottleneck-132               [-1, 512, 2]               0
     BatchNorm1d-133               [-1, 512, 2]           1,024
            ReLU-134               [-1, 512, 2]               0
         Dropout-135               [-1, 512, 2]               0
          Conv1d-136               [-1, 512, 1]           4,608
 MyConv1dPadSame-137               [-1, 512, 1]               0
     BatchNorm1d-138               [-1, 512, 1]           1,024
            ReLU-139               [-1, 512, 1]               0
         Dropout-140               [-1, 512, 1]               0
          Conv1d-141               [-1, 512, 1]           4,608
 MyConv1dPadSame-142               [-1, 512, 1]               0
       MaxPool1d-143               [-1, 512, 1]               0
MyMaxPool1dPadSame-144               [-1, 512, 1]               0
      Bottleneck-145               [-1, 512, 1]               0
     BatchNorm1d-146               [-1, 512, 1]           1,024
            ReLU-147               [-1, 512, 1]               0
         Dropout-148               [-1, 512, 1]               0
          Conv1d-149              [-1, 1024, 1]           9,216
 MyConv1dPadSame-150              [-1, 1024, 1]               0
     BatchNorm1d-151              [-1, 1024, 1]           2,048
            ReLU-152              [-1, 1024, 1]               0
         Dropout-153              [-1, 1024, 1]               0
          Conv1d-154              [-1, 1024, 1]          17,408
 MyConv1dPadSame-155              [-1, 1024, 1]               0
      Bottleneck-156              [-1, 1024, 1]               0
     BatchNorm1d-157              [-1, 1024, 1]           2,048
            ReLU-158              [-1, 1024, 1]               0
         Dropout-159              [-1, 1024, 1]               0
          Conv1d-160              [-1, 1024, 1]          17,408
 MyConv1dPadSame-161              [-1, 1024, 1]               0
     BatchNorm1d-162              [-1, 1024, 1]           2,048
            ReLU-163              [-1, 1024, 1]               0
         Dropout-164              [-1, 1024, 1]               0
          Conv1d-165              [-1, 1024, 1]          17,408
 MyConv1dPadSame-166              [-1, 1024, 1]               0
       MaxPool1d-167              [-1, 1024, 1]               0
MyMaxPool1dPadSame-168              [-1, 1024, 1]               0
      Bottleneck-169              [-1, 1024, 1]               0
     BatchNorm1d-170              [-1, 1024, 1]           2,048
            ReLU-171              [-1, 1024, 1]               0
         Dropout-172              [-1, 1024, 1]               0
          Conv1d-173              [-1, 1024, 1]          17,408
 MyConv1dPadSame-174              [-1, 1024, 1]               0
     BatchNorm1d-175              [-1, 1024, 1]           2,048
            ReLU-176              [-1, 1024, 1]               0
         Dropout-177              [-1, 1024, 1]               0
          Conv1d-178              [-1, 1024, 1]          17,408
 MyConv1dPadSame-179              [-1, 1024, 1]               0
      Bottleneck-180              [-1, 1024, 1]               0
     BatchNorm1d-181              [-1, 1024, 1]           2,048
            ReLU-182              [-1, 1024, 1]               0
         Dropout-183              [-1, 1024, 1]               0
          Conv1d-184              [-1, 1024, 1]          17,408
 MyConv1dPadSame-185              [-1, 1024, 1]               0
     BatchNorm1d-186              [-1, 1024, 1]           2,048
            ReLU-187              [-1, 1024, 1]               0
         Dropout-188              [-1, 1024, 1]               0
          Conv1d-189              [-1, 1024, 1]          17,408
 MyConv1dPadSame-190              [-1, 1024, 1]               0
       MaxPool1d-191              [-1, 1024, 1]               0
MyMaxPool1dPadSame-192              [-1, 1024, 1]               0
      Bottleneck-193              [-1, 1024, 1]               0
     BatchNorm1d-194              [-1, 1024, 1]           2,048
            ReLU-195              [-1, 1024, 1]               0
          Linear-196                    [-1, 2]           2,050
================================================================
Total params: 212,098
Trainable params: 212,098
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 3.49
Params size (MB): 0.81
Estimated Total Size (MB): 4.30
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 128, kernel_size: 4, n_block: 2
************************************************************
************************************************************
(2000, 1, 64) Counter({1: 1000, 0: 1000})
(2000, 1, 64) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 128, 64]             640
   MyConv1dPadSame-2              [-1, 128, 64]               0
       BatchNorm1d-3              [-1, 128, 64]             256
              ReLU-4              [-1, 128, 64]               0
            Conv1d-5              [-1, 128, 64]             640
   MyConv1dPadSame-6              [-1, 128, 64]               0
       BatchNorm1d-7              [-1, 128, 64]             256
              ReLU-8              [-1, 128, 64]               0
           Dropout-9              [-1, 128, 64]               0
           Conv1d-10              [-1, 128, 64]             640
  MyConv1dPadSame-11              [-1, 128, 64]               0
       Bottleneck-12              [-1, 128, 64]               0
      BatchNorm1d-13              [-1, 128, 64]             256
             ReLU-14              [-1, 128, 64]               0
          Dropout-15              [-1, 128, 64]               0
           Conv1d-16              [-1, 256, 64]           1,280
  MyConv1dPadSame-17              [-1, 256, 64]               0
      BatchNorm1d-18              [-1, 256, 64]             512
             ReLU-19              [-1, 256, 64]               0
          Dropout-20              [-1, 256, 64]               0
           Conv1d-21              [-1, 256, 64]           2,304
  MyConv1dPadSame-22              [-1, 256, 64]               0
       Bottleneck-23              [-1, 256, 64]               0
      BatchNorm1d-24              [-1, 256, 64]             512
             ReLU-25              [-1, 256, 64]               0
           Linear-26                    [-1, 2]             514
================================================================
Total params: 7,810
Trainable params: 7,810
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 2.19
Params size (MB): 0.03
Estimated Total Size (MB): 2.22
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 128, kernel_size: 4, n_block: 4
************************************************************
************************************************************
(2000, 1, 64) Counter({0: 1000, 1: 1000})
(2000, 1, 64) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 128, 64]             640
   MyConv1dPadSame-2              [-1, 128, 64]               0
       BatchNorm1d-3              [-1, 128, 64]             256
              ReLU-4              [-1, 128, 64]               0
            Conv1d-5              [-1, 128, 64]             640
   MyConv1dPadSame-6              [-1, 128, 64]               0
       BatchNorm1d-7              [-1, 128, 64]             256
              ReLU-8              [-1, 128, 64]               0
           Dropout-9              [-1, 128, 64]               0
           Conv1d-10              [-1, 128, 64]             640
  MyConv1dPadSame-11              [-1, 128, 64]               0
       Bottleneck-12              [-1, 128, 64]               0
      BatchNorm1d-13              [-1, 128, 64]             256
             ReLU-14              [-1, 128, 64]               0
          Dropout-15              [-1, 128, 64]               0
           Conv1d-16              [-1, 256, 64]           1,280
  MyConv1dPadSame-17              [-1, 256, 64]               0
      BatchNorm1d-18              [-1, 256, 64]             512
             ReLU-19              [-1, 256, 64]               0
          Dropout-20              [-1, 256, 64]               0
           Conv1d-21              [-1, 256, 64]           2,304
  MyConv1dPadSame-22              [-1, 256, 64]               0
       Bottleneck-23              [-1, 256, 64]               0
      BatchNorm1d-24              [-1, 256, 64]             512
             ReLU-25              [-1, 256, 64]               0
          Dropout-26              [-1, 256, 64]               0
           Conv1d-27              [-1, 512, 64]           4,608
  MyConv1dPadSame-28              [-1, 512, 64]               0
      BatchNorm1d-29              [-1, 512, 64]           1,024
             ReLU-30              [-1, 512, 64]               0
          Dropout-31              [-1, 512, 64]               0
           Conv1d-32              [-1, 512, 64]           8,704
  MyConv1dPadSame-33              [-1, 512, 64]               0
       Bottleneck-34              [-1, 512, 64]               0
      BatchNorm1d-35              [-1, 512, 64]           1,024
             ReLU-36              [-1, 512, 64]               0
          Dropout-37              [-1, 512, 64]               0
           Conv1d-38             [-1, 1024, 64]          17,408
  MyConv1dPadSame-39             [-1, 1024, 64]               0
      BatchNorm1d-40             [-1, 1024, 64]           2,048
             ReLU-41             [-1, 1024, 64]               0
          Dropout-42             [-1, 1024, 64]               0
           Conv1d-43             [-1, 1024, 64]          33,792
  MyConv1dPadSame-44             [-1, 1024, 64]               0
       Bottleneck-45             [-1, 1024, 64]               0
      BatchNorm1d-46             [-1, 1024, 64]           2,048
             ReLU-47             [-1, 1024, 64]               0
           Linear-48                    [-1, 2]           2,050
================================================================
Total params: 80,002
Trainable params: 80,002
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 10.06
Params size (MB): 0.31
Estimated Total Size (MB): 10.37
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 128, kernel_size: 4, n_block: 8
************************************************************
************************************************************
(2000, 1, 64) Counter({0: 1000, 1: 1000})
(2000, 1, 64) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 128, 64]             640
   MyConv1dPadSame-2              [-1, 128, 64]               0
       BatchNorm1d-3              [-1, 128, 64]             256
              ReLU-4              [-1, 128, 64]               0
            Conv1d-5              [-1, 128, 64]             640
   MyConv1dPadSame-6              [-1, 128, 64]               0
       BatchNorm1d-7              [-1, 128, 64]             256
              ReLU-8              [-1, 128, 64]               0
           Dropout-9              [-1, 128, 64]               0
           Conv1d-10              [-1, 128, 64]             640
  MyConv1dPadSame-11              [-1, 128, 64]               0
       Bottleneck-12              [-1, 128, 64]               0
      BatchNorm1d-13              [-1, 128, 64]             256
             ReLU-14              [-1, 128, 64]               0
          Dropout-15              [-1, 128, 64]               0
           Conv1d-16              [-1, 128, 64]             640
  MyConv1dPadSame-17              [-1, 128, 64]               0
      BatchNorm1d-18              [-1, 128, 64]             256
             ReLU-19              [-1, 128, 64]               0
          Dropout-20              [-1, 128, 64]               0
           Conv1d-21              [-1, 128, 64]             640
  MyConv1dPadSame-22              [-1, 128, 64]               0
       Bottleneck-23              [-1, 128, 64]               0
      BatchNorm1d-24              [-1, 128, 64]             256
             ReLU-25              [-1, 128, 64]               0
          Dropout-26              [-1, 128, 64]               0
           Conv1d-27              [-1, 256, 64]           1,280
  MyConv1dPadSame-28              [-1, 256, 64]               0
      BatchNorm1d-29              [-1, 256, 64]             512
             ReLU-30              [-1, 256, 64]               0
          Dropout-31              [-1, 256, 64]               0
           Conv1d-32              [-1, 256, 64]           2,304
  MyConv1dPadSame-33              [-1, 256, 64]               0
       Bottleneck-34              [-1, 256, 64]               0
      BatchNorm1d-35              [-1, 256, 64]             512
             ReLU-36              [-1, 256, 64]               0
          Dropout-37              [-1, 256, 64]               0
           Conv1d-38              [-1, 256, 64]           2,304
  MyConv1dPadSame-39              [-1, 256, 64]               0
      BatchNorm1d-40              [-1, 256, 64]             512
             ReLU-41              [-1, 256, 64]               0
          Dropout-42              [-1, 256, 64]               0
           Conv1d-43              [-1, 256, 64]           2,304
  MyConv1dPadSame-44              [-1, 256, 64]               0
       Bottleneck-45              [-1, 256, 64]               0
      BatchNorm1d-46              [-1, 256, 64]             512
             ReLU-47              [-1, 256, 64]               0
          Dropout-48              [-1, 256, 64]               0
           Conv1d-49              [-1, 512, 64]           4,608
  MyConv1dPadSame-50              [-1, 512, 64]               0
      BatchNorm1d-51              [-1, 512, 64]           1,024
             ReLU-52              [-1, 512, 64]               0
          Dropout-53              [-1, 512, 64]               0
           Conv1d-54              [-1, 512, 64]           8,704
  MyConv1dPadSame-55              [-1, 512, 64]               0
       Bottleneck-56              [-1, 512, 64]               0
      BatchNorm1d-57              [-1, 512, 64]           1,024
             ReLU-58              [-1, 512, 64]               0
          Dropout-59              [-1, 512, 64]               0
           Conv1d-60              [-1, 512, 64]           8,704
  MyConv1dPadSame-61              [-1, 512, 64]               0
      BatchNorm1d-62              [-1, 512, 64]           1,024
             ReLU-63              [-1, 512, 64]               0
          Dropout-64              [-1, 512, 64]               0
           Conv1d-65              [-1, 512, 64]           8,704
  MyConv1dPadSame-66              [-1, 512, 64]               0
       Bottleneck-67              [-1, 512, 64]               0
      BatchNorm1d-68              [-1, 512, 64]           1,024
             ReLU-69              [-1, 512, 64]               0
          Dropout-70              [-1, 512, 64]               0
           Conv1d-71             [-1, 1024, 64]          17,408
  MyConv1dPadSame-72             [-1, 1024, 64]               0
      BatchNorm1d-73             [-1, 1024, 64]           2,048
             ReLU-74             [-1, 1024, 64]               0
          Dropout-75             [-1, 1024, 64]               0
           Conv1d-76             [-1, 1024, 64]          33,792
  MyConv1dPadSame-77             [-1, 1024, 64]               0
       Bottleneck-78             [-1, 1024, 64]               0
      BatchNorm1d-79             [-1, 1024, 64]           2,048
             ReLU-80             [-1, 1024, 64]               0
          Dropout-81             [-1, 1024, 64]               0
           Conv1d-82             [-1, 1024, 64]          33,792
  MyConv1dPadSame-83             [-1, 1024, 64]               0
      BatchNorm1d-84             [-1, 1024, 64]           2,048
             ReLU-85             [-1, 1024, 64]               0
          Dropout-86             [-1, 1024, 64]               0
           Conv1d-87             [-1, 1024, 64]          33,792
  MyConv1dPadSame-88             [-1, 1024, 64]               0
       Bottleneck-89             [-1, 1024, 64]               0
      BatchNorm1d-90             [-1, 1024, 64]           2,048
             ReLU-91             [-1, 1024, 64]               0
           Linear-92                    [-1, 2]           2,050
================================================================
Total params: 178,562
Trainable params: 178,562
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 20.38
Params size (MB): 0.68
Estimated Total Size (MB): 21.06
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 128, kernel_size: 4, n_block: 16
************************************************************
************************************************************
(2000, 1, 64) Counter({0: 1000, 1: 1000})
(2000, 1, 64) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 128, 64]             640
   MyConv1dPadSame-2              [-1, 128, 64]               0
       BatchNorm1d-3              [-1, 128, 64]             256
              ReLU-4              [-1, 128, 64]               0
            Conv1d-5              [-1, 128, 64]             640
   MyConv1dPadSame-6              [-1, 128, 64]               0
       BatchNorm1d-7              [-1, 128, 64]             256
              ReLU-8              [-1, 128, 64]               0
           Dropout-9              [-1, 128, 64]               0
           Conv1d-10              [-1, 128, 64]             640
  MyConv1dPadSame-11              [-1, 128, 64]               0
       Bottleneck-12              [-1, 128, 64]               0
      BatchNorm1d-13              [-1, 128, 64]             256
             ReLU-14              [-1, 128, 64]               0
          Dropout-15              [-1, 128, 64]               0
           Conv1d-16              [-1, 128, 32]             640
  MyConv1dPadSame-17              [-1, 128, 32]               0
      BatchNorm1d-18              [-1, 128, 32]             256
             ReLU-19              [-1, 128, 32]               0
          Dropout-20              [-1, 128, 32]               0
           Conv1d-21              [-1, 128, 32]             640
  MyConv1dPadSame-22              [-1, 128, 32]               0
        MaxPool1d-23              [-1, 128, 32]               0
MyMaxPool1dPadSame-24              [-1, 128, 32]               0
       Bottleneck-25              [-1, 128, 32]               0
      BatchNorm1d-26              [-1, 128, 32]             256
             ReLU-27              [-1, 128, 32]               0
          Dropout-28              [-1, 128, 32]               0
           Conv1d-29              [-1, 128, 32]             640
  MyConv1dPadSame-30              [-1, 128, 32]               0
      BatchNorm1d-31              [-1, 128, 32]             256
             ReLU-32              [-1, 128, 32]               0
          Dropout-33              [-1, 128, 32]               0
           Conv1d-34              [-1, 128, 32]             640
  MyConv1dPadSame-35              [-1, 128, 32]               0
       Bottleneck-36              [-1, 128, 32]               0
      BatchNorm1d-37              [-1, 128, 32]             256
             ReLU-38              [-1, 128, 32]               0
          Dropout-39              [-1, 128, 32]               0
           Conv1d-40              [-1, 128, 16]             640
  MyConv1dPadSame-41              [-1, 128, 16]               0
      BatchNorm1d-42              [-1, 128, 16]             256
             ReLU-43              [-1, 128, 16]               0
          Dropout-44              [-1, 128, 16]               0
           Conv1d-45              [-1, 128, 16]             640
  MyConv1dPadSame-46              [-1, 128, 16]               0
        MaxPool1d-47              [-1, 128, 16]               0
MyMaxPool1dPadSame-48              [-1, 128, 16]               0
       Bottleneck-49              [-1, 128, 16]               0
      BatchNorm1d-50              [-1, 128, 16]             256
             ReLU-51              [-1, 128, 16]               0
          Dropout-52              [-1, 128, 16]               0
           Conv1d-53              [-1, 256, 16]           1,280
  MyConv1dPadSame-54              [-1, 256, 16]               0
      BatchNorm1d-55              [-1, 256, 16]             512
             ReLU-56              [-1, 256, 16]               0
          Dropout-57              [-1, 256, 16]               0
           Conv1d-58              [-1, 256, 16]           2,304
  MyConv1dPadSame-59              [-1, 256, 16]               0
       Bottleneck-60              [-1, 256, 16]               0
      BatchNorm1d-61              [-1, 256, 16]             512
             ReLU-62              [-1, 256, 16]               0
          Dropout-63              [-1, 256, 16]               0
           Conv1d-64               [-1, 256, 8]           2,304
  MyConv1dPadSame-65               [-1, 256, 8]               0
      BatchNorm1d-66               [-1, 256, 8]             512
             ReLU-67               [-1, 256, 8]               0
          Dropout-68               [-1, 256, 8]               0
           Conv1d-69               [-1, 256, 8]           2,304
  MyConv1dPadSame-70               [-1, 256, 8]               0
        MaxPool1d-71               [-1, 256, 8]               0
MyMaxPool1dPadSame-72               [-1, 256, 8]               0
       Bottleneck-73               [-1, 256, 8]               0
      BatchNorm1d-74               [-1, 256, 8]             512
             ReLU-75               [-1, 256, 8]               0
          Dropout-76               [-1, 256, 8]               0
           Conv1d-77               [-1, 256, 8]           2,304
  MyConv1dPadSame-78               [-1, 256, 8]               0
      BatchNorm1d-79               [-1, 256, 8]             512
             ReLU-80               [-1, 256, 8]               0
          Dropout-81               [-1, 256, 8]               0
           Conv1d-82               [-1, 256, 8]           2,304
  MyConv1dPadSame-83               [-1, 256, 8]               0
       Bottleneck-84               [-1, 256, 8]               0
      BatchNorm1d-85               [-1, 256, 8]             512
             ReLU-86               [-1, 256, 8]               0
          Dropout-87               [-1, 256, 8]               0
           Conv1d-88               [-1, 256, 4]           2,304
  MyConv1dPadSame-89               [-1, 256, 4]               0
      BatchNorm1d-90               [-1, 256, 4]             512
             ReLU-91               [-1, 256, 4]               0
          Dropout-92               [-1, 256, 4]               0
           Conv1d-93               [-1, 256, 4]           2,304
  MyConv1dPadSame-94               [-1, 256, 4]               0
        MaxPool1d-95               [-1, 256, 4]               0
MyMaxPool1dPadSame-96               [-1, 256, 4]               0
       Bottleneck-97               [-1, 256, 4]               0
      BatchNorm1d-98               [-1, 256, 4]             512
             ReLU-99               [-1, 256, 4]               0
         Dropout-100               [-1, 256, 4]               0
          Conv1d-101               [-1, 512, 4]           4,608
 MyConv1dPadSame-102               [-1, 512, 4]               0
     BatchNorm1d-103               [-1, 512, 4]           1,024
            ReLU-104               [-1, 512, 4]               0
         Dropout-105               [-1, 512, 4]               0
          Conv1d-106               [-1, 512, 4]           8,704
 MyConv1dPadSame-107               [-1, 512, 4]               0
      Bottleneck-108               [-1, 512, 4]               0
     BatchNorm1d-109               [-1, 512, 4]           1,024
            ReLU-110               [-1, 512, 4]               0
         Dropout-111               [-1, 512, 4]               0
          Conv1d-112               [-1, 512, 2]           8,704
 MyConv1dPadSame-113               [-1, 512, 2]               0
     BatchNorm1d-114               [-1, 512, 2]           1,024
            ReLU-115               [-1, 512, 2]               0
         Dropout-116               [-1, 512, 2]               0
          Conv1d-117               [-1, 512, 2]           8,704
 MyConv1dPadSame-118               [-1, 512, 2]               0
       MaxPool1d-119               [-1, 512, 2]               0
MyMaxPool1dPadSame-120               [-1, 512, 2]               0
      Bottleneck-121               [-1, 512, 2]               0
     BatchNorm1d-122               [-1, 512, 2]           1,024
            ReLU-123               [-1, 512, 2]               0
         Dropout-124               [-1, 512, 2]               0
          Conv1d-125               [-1, 512, 2]           8,704
 MyConv1dPadSame-126               [-1, 512, 2]               0
     BatchNorm1d-127               [-1, 512, 2]           1,024
            ReLU-128               [-1, 512, 2]               0
         Dropout-129               [-1, 512, 2]               0
          Conv1d-130               [-1, 512, 2]           8,704
 MyConv1dPadSame-131               [-1, 512, 2]               0
      Bottleneck-132               [-1, 512, 2]               0
     BatchNorm1d-133               [-1, 512, 2]           1,024
            ReLU-134               [-1, 512, 2]               0
         Dropout-135               [-1, 512, 2]               0
          Conv1d-136               [-1, 512, 1]           8,704
 MyConv1dPadSame-137               [-1, 512, 1]               0
     BatchNorm1d-138               [-1, 512, 1]           1,024
            ReLU-139               [-1, 512, 1]               0
         Dropout-140               [-1, 512, 1]               0
          Conv1d-141               [-1, 512, 1]           8,704
 MyConv1dPadSame-142               [-1, 512, 1]               0
       MaxPool1d-143               [-1, 512, 1]               0
MyMaxPool1dPadSame-144               [-1, 512, 1]               0
      Bottleneck-145               [-1, 512, 1]               0
     BatchNorm1d-146               [-1, 512, 1]           1,024
            ReLU-147               [-1, 512, 1]               0
         Dropout-148               [-1, 512, 1]               0
          Conv1d-149              [-1, 1024, 1]          17,408
 MyConv1dPadSame-150              [-1, 1024, 1]               0
     BatchNorm1d-151              [-1, 1024, 1]           2,048
            ReLU-152              [-1, 1024, 1]               0
         Dropout-153              [-1, 1024, 1]               0
          Conv1d-154              [-1, 1024, 1]          33,792
 MyConv1dPadSame-155              [-1, 1024, 1]               0
      Bottleneck-156              [-1, 1024, 1]               0
     BatchNorm1d-157              [-1, 1024, 1]           2,048
            ReLU-158              [-1, 1024, 1]               0
         Dropout-159              [-1, 1024, 1]               0
          Conv1d-160              [-1, 1024, 1]          33,792
 MyConv1dPadSame-161              [-1, 1024, 1]               0
     BatchNorm1d-162              [-1, 1024, 1]           2,048
            ReLU-163              [-1, 1024, 1]               0
         Dropout-164              [-1, 1024, 1]               0
          Conv1d-165              [-1, 1024, 1]          33,792
 MyConv1dPadSame-166              [-1, 1024, 1]               0
       MaxPool1d-167              [-1, 1024, 1]               0
MyMaxPool1dPadSame-168              [-1, 1024, 1]               0
      Bottleneck-169              [-1, 1024, 1]               0
     BatchNorm1d-170              [-1, 1024, 1]           2,048
            ReLU-171              [-1, 1024, 1]               0
         Dropout-172              [-1, 1024, 1]               0
          Conv1d-173              [-1, 1024, 1]          33,792
 MyConv1dPadSame-174              [-1, 1024, 1]               0
     BatchNorm1d-175              [-1, 1024, 1]           2,048
            ReLU-176              [-1, 1024, 1]               0
         Dropout-177              [-1, 1024, 1]               0
          Conv1d-178              [-1, 1024, 1]          33,792
 MyConv1dPadSame-179              [-1, 1024, 1]               0
      Bottleneck-180              [-1, 1024, 1]               0
     BatchNorm1d-181              [-1, 1024, 1]           2,048
            ReLU-182              [-1, 1024, 1]               0
         Dropout-183              [-1, 1024, 1]               0
          Conv1d-184              [-1, 1024, 1]          33,792
 MyConv1dPadSame-185              [-1, 1024, 1]               0
     BatchNorm1d-186              [-1, 1024, 1]           2,048
            ReLU-187              [-1, 1024, 1]               0
         Dropout-188              [-1, 1024, 1]               0
          Conv1d-189              [-1, 1024, 1]          33,792
 MyConv1dPadSame-190              [-1, 1024, 1]               0
       MaxPool1d-191              [-1, 1024, 1]               0
MyMaxPool1dPadSame-192              [-1, 1024, 1]               0
      Bottleneck-193              [-1, 1024, 1]               0
     BatchNorm1d-194              [-1, 1024, 1]           2,048
            ReLU-195              [-1, 1024, 1]               0
          Linear-196                    [-1, 2]           2,050
================================================================
Total params: 375,682
Trainable params: 375,682
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 3.49
Params size (MB): 1.43
Estimated Total Size (MB): 4.92
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 128, kernel_size: 8, n_block: 2
************************************************************
************************************************************
(2000, 1, 64) Counter({0: 1000, 1: 1000})
(2000, 1, 64) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 128, 64]           1,152
   MyConv1dPadSame-2              [-1, 128, 64]               0
       BatchNorm1d-3              [-1, 128, 64]             256
              ReLU-4              [-1, 128, 64]               0
            Conv1d-5              [-1, 128, 64]           1,152
   MyConv1dPadSame-6              [-1, 128, 64]               0
       BatchNorm1d-7              [-1, 128, 64]             256
              ReLU-8              [-1, 128, 64]               0
           Dropout-9              [-1, 128, 64]               0
           Conv1d-10              [-1, 128, 64]           1,152
  MyConv1dPadSame-11              [-1, 128, 64]               0
       Bottleneck-12              [-1, 128, 64]               0
      BatchNorm1d-13              [-1, 128, 64]             256
             ReLU-14              [-1, 128, 64]               0
          Dropout-15              [-1, 128, 64]               0
           Conv1d-16              [-1, 256, 64]           2,304
  MyConv1dPadSame-17              [-1, 256, 64]               0
      BatchNorm1d-18              [-1, 256, 64]             512
             ReLU-19              [-1, 256, 64]               0
          Dropout-20              [-1, 256, 64]               0
           Conv1d-21              [-1, 256, 64]           4,352
  MyConv1dPadSame-22              [-1, 256, 64]               0
       Bottleneck-23              [-1, 256, 64]               0
      BatchNorm1d-24              [-1, 256, 64]             512
             ReLU-25              [-1, 256, 64]               0
           Linear-26                    [-1, 2]             514
================================================================
Total params: 12,418
Trainable params: 12,418
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 2.19
Params size (MB): 0.05
Estimated Total Size (MB): 2.24
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 128, kernel_size: 8, n_block: 4
************************************************************
************************************************************
(2000, 1, 64) Counter({0: 1000, 1: 1000})
(2000, 1, 64) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 128, 64]           1,152
   MyConv1dPadSame-2              [-1, 128, 64]               0
       BatchNorm1d-3              [-1, 128, 64]             256
              ReLU-4              [-1, 128, 64]               0
            Conv1d-5              [-1, 128, 64]           1,152
   MyConv1dPadSame-6              [-1, 128, 64]               0
       BatchNorm1d-7              [-1, 128, 64]             256
              ReLU-8              [-1, 128, 64]               0
           Dropout-9              [-1, 128, 64]               0
           Conv1d-10              [-1, 128, 64]           1,152
  MyConv1dPadSame-11              [-1, 128, 64]               0
       Bottleneck-12              [-1, 128, 64]               0
      BatchNorm1d-13              [-1, 128, 64]             256
             ReLU-14              [-1, 128, 64]               0
          Dropout-15              [-1, 128, 64]               0
           Conv1d-16              [-1, 256, 64]           2,304
  MyConv1dPadSame-17              [-1, 256, 64]               0
      BatchNorm1d-18              [-1, 256, 64]             512
             ReLU-19              [-1, 256, 64]               0
          Dropout-20              [-1, 256, 64]               0
           Conv1d-21              [-1, 256, 64]           4,352
  MyConv1dPadSame-22              [-1, 256, 64]               0
       Bottleneck-23              [-1, 256, 64]               0
      BatchNorm1d-24              [-1, 256, 64]             512
             ReLU-25              [-1, 256, 64]               0
          Dropout-26              [-1, 256, 64]               0
           Conv1d-27              [-1, 512, 64]           8,704
  MyConv1dPadSame-28              [-1, 512, 64]               0
      BatchNorm1d-29              [-1, 512, 64]           1,024
             ReLU-30              [-1, 512, 64]               0
          Dropout-31              [-1, 512, 64]               0
           Conv1d-32              [-1, 512, 64]          16,896
  MyConv1dPadSame-33              [-1, 512, 64]               0
       Bottleneck-34              [-1, 512, 64]               0
      BatchNorm1d-35              [-1, 512, 64]           1,024
             ReLU-36              [-1, 512, 64]               0
          Dropout-37              [-1, 512, 64]               0
           Conv1d-38             [-1, 1024, 64]          33,792
  MyConv1dPadSame-39             [-1, 1024, 64]               0
      BatchNorm1d-40             [-1, 1024, 64]           2,048
             ReLU-41             [-1, 1024, 64]               0
          Dropout-42             [-1, 1024, 64]               0
           Conv1d-43             [-1, 1024, 64]          66,560
  MyConv1dPadSame-44             [-1, 1024, 64]               0
       Bottleneck-45             [-1, 1024, 64]               0
      BatchNorm1d-46             [-1, 1024, 64]           2,048
             ReLU-47             [-1, 1024, 64]               0
           Linear-48                    [-1, 2]           2,050
================================================================
Total params: 146,050
Trainable params: 146,050
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 10.06
Params size (MB): 0.56
Estimated Total Size (MB): 10.62
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 128, kernel_size: 8, n_block: 8
************************************************************
************************************************************
(2000, 1, 64) Counter({1: 1000, 0: 1000})
(2000, 1, 64) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 128, 64]           1,152
   MyConv1dPadSame-2              [-1, 128, 64]               0
       BatchNorm1d-3              [-1, 128, 64]             256
              ReLU-4              [-1, 128, 64]               0
            Conv1d-5              [-1, 128, 64]           1,152
   MyConv1dPadSame-6              [-1, 128, 64]               0
       BatchNorm1d-7              [-1, 128, 64]             256
              ReLU-8              [-1, 128, 64]               0
           Dropout-9              [-1, 128, 64]               0
           Conv1d-10              [-1, 128, 64]           1,152
  MyConv1dPadSame-11              [-1, 128, 64]               0
       Bottleneck-12              [-1, 128, 64]               0
      BatchNorm1d-13              [-1, 128, 64]             256
             ReLU-14              [-1, 128, 64]               0
          Dropout-15              [-1, 128, 64]               0
           Conv1d-16              [-1, 128, 64]           1,152
  MyConv1dPadSame-17              [-1, 128, 64]               0
      BatchNorm1d-18              [-1, 128, 64]             256
             ReLU-19              [-1, 128, 64]               0
          Dropout-20              [-1, 128, 64]               0
           Conv1d-21              [-1, 128, 64]           1,152
  MyConv1dPadSame-22              [-1, 128, 64]               0
       Bottleneck-23              [-1, 128, 64]               0
      BatchNorm1d-24              [-1, 128, 64]             256
             ReLU-25              [-1, 128, 64]               0
          Dropout-26              [-1, 128, 64]               0
           Conv1d-27              [-1, 256, 64]           2,304
  MyConv1dPadSame-28              [-1, 256, 64]               0
      BatchNorm1d-29              [-1, 256, 64]             512
             ReLU-30              [-1, 256, 64]               0
          Dropout-31              [-1, 256, 64]               0
           Conv1d-32              [-1, 256, 64]           4,352
  MyConv1dPadSame-33              [-1, 256, 64]               0
       Bottleneck-34              [-1, 256, 64]               0
      BatchNorm1d-35              [-1, 256, 64]             512
             ReLU-36              [-1, 256, 64]               0
          Dropout-37              [-1, 256, 64]               0
           Conv1d-38              [-1, 256, 64]           4,352
  MyConv1dPadSame-39              [-1, 256, 64]               0
      BatchNorm1d-40              [-1, 256, 64]             512
             ReLU-41              [-1, 256, 64]               0
          Dropout-42              [-1, 256, 64]               0
           Conv1d-43              [-1, 256, 64]           4,352
  MyConv1dPadSame-44              [-1, 256, 64]               0
       Bottleneck-45              [-1, 256, 64]               0
      BatchNorm1d-46              [-1, 256, 64]             512
             ReLU-47              [-1, 256, 64]               0
          Dropout-48              [-1, 256, 64]               0
           Conv1d-49              [-1, 512, 64]           8,704
  MyConv1dPadSame-50              [-1, 512, 64]               0
      BatchNorm1d-51              [-1, 512, 64]           1,024
             ReLU-52              [-1, 512, 64]               0
          Dropout-53              [-1, 512, 64]               0
           Conv1d-54              [-1, 512, 64]          16,896
  MyConv1dPadSame-55              [-1, 512, 64]               0
       Bottleneck-56              [-1, 512, 64]               0
      BatchNorm1d-57              [-1, 512, 64]           1,024
             ReLU-58              [-1, 512, 64]               0
          Dropout-59              [-1, 512, 64]               0
           Conv1d-60              [-1, 512, 64]          16,896
  MyConv1dPadSame-61              [-1, 512, 64]               0
      BatchNorm1d-62              [-1, 512, 64]           1,024
             ReLU-63              [-1, 512, 64]               0
          Dropout-64              [-1, 512, 64]               0
           Conv1d-65              [-1, 512, 64]          16,896
  MyConv1dPadSame-66              [-1, 512, 64]               0
       Bottleneck-67              [-1, 512, 64]               0
      BatchNorm1d-68              [-1, 512, 64]           1,024
             ReLU-69              [-1, 512, 64]               0
          Dropout-70              [-1, 512, 64]               0
           Conv1d-71             [-1, 1024, 64]          33,792
  MyConv1dPadSame-72             [-1, 1024, 64]               0
      BatchNorm1d-73             [-1, 1024, 64]           2,048
             ReLU-74             [-1, 1024, 64]               0
          Dropout-75             [-1, 1024, 64]               0
           Conv1d-76             [-1, 1024, 64]          66,560
  MyConv1dPadSame-77             [-1, 1024, 64]               0
       Bottleneck-78             [-1, 1024, 64]               0
      BatchNorm1d-79             [-1, 1024, 64]           2,048
             ReLU-80             [-1, 1024, 64]               0
          Dropout-81             [-1, 1024, 64]               0
           Conv1d-82             [-1, 1024, 64]          66,560
  MyConv1dPadSame-83             [-1, 1024, 64]               0
      BatchNorm1d-84             [-1, 1024, 64]           2,048
             ReLU-85             [-1, 1024, 64]               0
          Dropout-86             [-1, 1024, 64]               0
           Conv1d-87             [-1, 1024, 64]          66,560
  MyConv1dPadSame-88             [-1, 1024, 64]               0
       Bottleneck-89             [-1, 1024, 64]               0
      BatchNorm1d-90             [-1, 1024, 64]           2,048
             ReLU-91             [-1, 1024, 64]               0
           Linear-92                    [-1, 2]           2,050
================================================================
Total params: 331,650
Trainable params: 331,650
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 20.38
Params size (MB): 1.27
Estimated Total Size (MB): 21.64
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 128, kernel_size: 8, n_block: 16
************************************************************
************************************************************
(2000, 1, 64) Counter({0: 1000, 1: 1000})
(2000, 1, 64) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 128, 64]           1,152
   MyConv1dPadSame-2              [-1, 128, 64]               0
       BatchNorm1d-3              [-1, 128, 64]             256
              ReLU-4              [-1, 128, 64]               0
            Conv1d-5              [-1, 128, 64]           1,152
   MyConv1dPadSame-6              [-1, 128, 64]               0
       BatchNorm1d-7              [-1, 128, 64]             256
              ReLU-8              [-1, 128, 64]               0
           Dropout-9              [-1, 128, 64]               0
           Conv1d-10              [-1, 128, 64]           1,152
  MyConv1dPadSame-11              [-1, 128, 64]               0
       Bottleneck-12              [-1, 128, 64]               0
      BatchNorm1d-13              [-1, 128, 64]             256
             ReLU-14              [-1, 128, 64]               0
          Dropout-15              [-1, 128, 64]               0
           Conv1d-16              [-1, 128, 32]           1,152
  MyConv1dPadSame-17              [-1, 128, 32]               0
      BatchNorm1d-18              [-1, 128, 32]             256
             ReLU-19              [-1, 128, 32]               0
          Dropout-20              [-1, 128, 32]               0
           Conv1d-21              [-1, 128, 32]           1,152
  MyConv1dPadSame-22              [-1, 128, 32]               0
        MaxPool1d-23              [-1, 128, 32]               0
MyMaxPool1dPadSame-24              [-1, 128, 32]               0
       Bottleneck-25              [-1, 128, 32]               0
      BatchNorm1d-26              [-1, 128, 32]             256
             ReLU-27              [-1, 128, 32]               0
          Dropout-28              [-1, 128, 32]               0
           Conv1d-29              [-1, 128, 32]           1,152
  MyConv1dPadSame-30              [-1, 128, 32]               0
      BatchNorm1d-31              [-1, 128, 32]             256
             ReLU-32              [-1, 128, 32]               0
          Dropout-33              [-1, 128, 32]               0
           Conv1d-34              [-1, 128, 32]           1,152
  MyConv1dPadSame-35              [-1, 128, 32]               0
       Bottleneck-36              [-1, 128, 32]               0
      BatchNorm1d-37              [-1, 128, 32]             256
             ReLU-38              [-1, 128, 32]               0
          Dropout-39              [-1, 128, 32]               0
           Conv1d-40              [-1, 128, 16]           1,152
  MyConv1dPadSame-41              [-1, 128, 16]               0
      BatchNorm1d-42              [-1, 128, 16]             256
             ReLU-43              [-1, 128, 16]               0
          Dropout-44              [-1, 128, 16]               0
           Conv1d-45              [-1, 128, 16]           1,152
  MyConv1dPadSame-46              [-1, 128, 16]               0
        MaxPool1d-47              [-1, 128, 16]               0
MyMaxPool1dPadSame-48              [-1, 128, 16]               0
       Bottleneck-49              [-1, 128, 16]               0
      BatchNorm1d-50              [-1, 128, 16]             256
             ReLU-51              [-1, 128, 16]               0
          Dropout-52              [-1, 128, 16]               0
           Conv1d-53              [-1, 256, 16]           2,304
  MyConv1dPadSame-54              [-1, 256, 16]               0
      BatchNorm1d-55              [-1, 256, 16]             512
             ReLU-56              [-1, 256, 16]               0
          Dropout-57              [-1, 256, 16]               0
           Conv1d-58              [-1, 256, 16]           4,352
  MyConv1dPadSame-59              [-1, 256, 16]               0
       Bottleneck-60              [-1, 256, 16]               0
      BatchNorm1d-61              [-1, 256, 16]             512
             ReLU-62              [-1, 256, 16]               0
          Dropout-63              [-1, 256, 16]               0
           Conv1d-64               [-1, 256, 8]           4,352
  MyConv1dPadSame-65               [-1, 256, 8]               0
      BatchNorm1d-66               [-1, 256, 8]             512
             ReLU-67               [-1, 256, 8]               0
          Dropout-68               [-1, 256, 8]               0
           Conv1d-69               [-1, 256, 8]           4,352
  MyConv1dPadSame-70               [-1, 256, 8]               0
        MaxPool1d-71               [-1, 256, 8]               0
MyMaxPool1dPadSame-72               [-1, 256, 8]               0
       Bottleneck-73               [-1, 256, 8]               0
      BatchNorm1d-74               [-1, 256, 8]             512
             ReLU-75               [-1, 256, 8]               0
          Dropout-76               [-1, 256, 8]               0
           Conv1d-77               [-1, 256, 8]           4,352
  MyConv1dPadSame-78               [-1, 256, 8]               0
      BatchNorm1d-79               [-1, 256, 8]             512
             ReLU-80               [-1, 256, 8]               0
          Dropout-81               [-1, 256, 8]               0
           Conv1d-82               [-1, 256, 8]           4,352
  MyConv1dPadSame-83               [-1, 256, 8]               0
       Bottleneck-84               [-1, 256, 8]               0
      BatchNorm1d-85               [-1, 256, 8]             512
             ReLU-86               [-1, 256, 8]               0
          Dropout-87               [-1, 256, 8]               0
           Conv1d-88               [-1, 256, 4]           4,352
  MyConv1dPadSame-89               [-1, 256, 4]               0
      BatchNorm1d-90               [-1, 256, 4]             512
             ReLU-91               [-1, 256, 4]               0
          Dropout-92               [-1, 256, 4]               0
           Conv1d-93               [-1, 256, 4]           4,352
  MyConv1dPadSame-94               [-1, 256, 4]               0
        MaxPool1d-95               [-1, 256, 4]               0
MyMaxPool1dPadSame-96               [-1, 256, 4]               0
       Bottleneck-97               [-1, 256, 4]               0
      BatchNorm1d-98               [-1, 256, 4]             512
             ReLU-99               [-1, 256, 4]               0
         Dropout-100               [-1, 256, 4]               0
          Conv1d-101               [-1, 512, 4]           8,704
 MyConv1dPadSame-102               [-1, 512, 4]               0
     BatchNorm1d-103               [-1, 512, 4]           1,024
            ReLU-104               [-1, 512, 4]               0
         Dropout-105               [-1, 512, 4]               0
          Conv1d-106               [-1, 512, 4]          16,896
 MyConv1dPadSame-107               [-1, 512, 4]               0
      Bottleneck-108               [-1, 512, 4]               0
     BatchNorm1d-109               [-1, 512, 4]           1,024
            ReLU-110               [-1, 512, 4]               0
         Dropout-111               [-1, 512, 4]               0
          Conv1d-112               [-1, 512, 2]          16,896
 MyConv1dPadSame-113               [-1, 512, 2]               0
     BatchNorm1d-114               [-1, 512, 2]           1,024
            ReLU-115               [-1, 512, 2]               0
         Dropout-116               [-1, 512, 2]               0
          Conv1d-117               [-1, 512, 2]          16,896
 MyConv1dPadSame-118               [-1, 512, 2]               0
       MaxPool1d-119               [-1, 512, 2]               0
MyMaxPool1dPadSame-120               [-1, 512, 2]               0
      Bottleneck-121               [-1, 512, 2]               0
     BatchNorm1d-122               [-1, 512, 2]           1,024
            ReLU-123               [-1, 512, 2]               0
         Dropout-124               [-1, 512, 2]               0
          Conv1d-125               [-1, 512, 2]          16,896
 MyConv1dPadSame-126               [-1, 512, 2]               0
     BatchNorm1d-127               [-1, 512, 2]           1,024
            ReLU-128               [-1, 512, 2]               0
         Dropout-129               [-1, 512, 2]               0
          Conv1d-130               [-1, 512, 2]          16,896
 MyConv1dPadSame-131               [-1, 512, 2]               0
      Bottleneck-132               [-1, 512, 2]               0
     BatchNorm1d-133               [-1, 512, 2]           1,024
            ReLU-134               [-1, 512, 2]               0
         Dropout-135               [-1, 512, 2]               0
          Conv1d-136               [-1, 512, 1]          16,896
 MyConv1dPadSame-137               [-1, 512, 1]               0
     BatchNorm1d-138               [-1, 512, 1]           1,024
            ReLU-139               [-1, 512, 1]               0
         Dropout-140               [-1, 512, 1]               0
          Conv1d-141               [-1, 512, 1]          16,896
 MyConv1dPadSame-142               [-1, 512, 1]               0
       MaxPool1d-143               [-1, 512, 1]               0
MyMaxPool1dPadSame-144               [-1, 512, 1]               0
      Bottleneck-145               [-1, 512, 1]               0
     BatchNorm1d-146               [-1, 512, 1]           1,024
            ReLU-147               [-1, 512, 1]               0
         Dropout-148               [-1, 512, 1]               0
          Conv1d-149              [-1, 1024, 1]          33,792
 MyConv1dPadSame-150              [-1, 1024, 1]               0
     BatchNorm1d-151              [-1, 1024, 1]           2,048
            ReLU-152              [-1, 1024, 1]               0
         Dropout-153              [-1, 1024, 1]               0
          Conv1d-154              [-1, 1024, 1]          66,560
 MyConv1dPadSame-155              [-1, 1024, 1]               0
      Bottleneck-156              [-1, 1024, 1]               0
     BatchNorm1d-157              [-1, 1024, 1]           2,048
            ReLU-158              [-1, 1024, 1]               0
         Dropout-159              [-1, 1024, 1]               0
          Conv1d-160              [-1, 1024, 1]          66,560
 MyConv1dPadSame-161              [-1, 1024, 1]               0
     BatchNorm1d-162              [-1, 1024, 1]           2,048
            ReLU-163              [-1, 1024, 1]               0
         Dropout-164              [-1, 1024, 1]               0
          Conv1d-165              [-1, 1024, 1]          66,560
 MyConv1dPadSame-166              [-1, 1024, 1]               0
       MaxPool1d-167              [-1, 1024, 1]               0
MyMaxPool1dPadSame-168              [-1, 1024, 1]               0
      Bottleneck-169              [-1, 1024, 1]               0
     BatchNorm1d-170              [-1, 1024, 1]           2,048
            ReLU-171              [-1, 1024, 1]               0
         Dropout-172              [-1, 1024, 1]               0
          Conv1d-173              [-1, 1024, 1]          66,560
 MyConv1dPadSame-174              [-1, 1024, 1]               0
     BatchNorm1d-175              [-1, 1024, 1]           2,048
            ReLU-176              [-1, 1024, 1]               0
         Dropout-177              [-1, 1024, 1]               0
          Conv1d-178              [-1, 1024, 1]          66,560
 MyConv1dPadSame-179              [-1, 1024, 1]               0
      Bottleneck-180              [-1, 1024, 1]               0
     BatchNorm1d-181              [-1, 1024, 1]           2,048
            ReLU-182              [-1, 1024, 1]               0
         Dropout-183              [-1, 1024, 1]               0
          Conv1d-184              [-1, 1024, 1]          66,560
 MyConv1dPadSame-185              [-1, 1024, 1]               0
     BatchNorm1d-186              [-1, 1024, 1]           2,048
            ReLU-187              [-1, 1024, 1]               0
         Dropout-188              [-1, 1024, 1]               0
          Conv1d-189              [-1, 1024, 1]          66,560
 MyConv1dPadSame-190              [-1, 1024, 1]               0
       MaxPool1d-191              [-1, 1024, 1]               0
MyMaxPool1dPadSame-192              [-1, 1024, 1]               0
      Bottleneck-193              [-1, 1024, 1]               0
     BatchNorm1d-194              [-1, 1024, 1]           2,048
            ReLU-195              [-1, 1024, 1]               0
          Linear-196                    [-1, 2]           2,050
================================================================
Total params: 702,850
Trainable params: 702,850
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 3.49
Params size (MB): 2.68
Estimated Total Size (MB): 6.17
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 128, kernel_size: 16, n_block: 2
************************************************************
************************************************************
(2000, 1, 64) Counter({0: 1000, 1: 1000})
(2000, 1, 64) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 128, 64]           2,176
   MyConv1dPadSame-2              [-1, 128, 64]               0
       BatchNorm1d-3              [-1, 128, 64]             256
              ReLU-4              [-1, 128, 64]               0
            Conv1d-5              [-1, 128, 64]           2,176
   MyConv1dPadSame-6              [-1, 128, 64]               0
       BatchNorm1d-7              [-1, 128, 64]             256
              ReLU-8              [-1, 128, 64]               0
           Dropout-9              [-1, 128, 64]               0
           Conv1d-10              [-1, 128, 64]           2,176
  MyConv1dPadSame-11              [-1, 128, 64]               0
       Bottleneck-12              [-1, 128, 64]               0
      BatchNorm1d-13              [-1, 128, 64]             256
             ReLU-14              [-1, 128, 64]               0
          Dropout-15              [-1, 128, 64]               0
           Conv1d-16              [-1, 256, 64]           4,352
  MyConv1dPadSame-17              [-1, 256, 64]               0
      BatchNorm1d-18              [-1, 256, 64]             512
             ReLU-19              [-1, 256, 64]               0
          Dropout-20              [-1, 256, 64]               0
           Conv1d-21              [-1, 256, 64]           8,448
  MyConv1dPadSame-22              [-1, 256, 64]               0
       Bottleneck-23              [-1, 256, 64]               0
      BatchNorm1d-24              [-1, 256, 64]             512
             ReLU-25              [-1, 256, 64]               0
           Linear-26                    [-1, 2]             514
================================================================
Total params: 21,634
Trainable params: 21,634
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 2.19
Params size (MB): 0.08
Estimated Total Size (MB): 2.27
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 128, kernel_size: 16, n_block: 4
************************************************************
************************************************************
(2000, 1, 64) Counter({1: 1000, 0: 1000})
(2000, 1, 64) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 128, 64]           2,176
   MyConv1dPadSame-2              [-1, 128, 64]               0
       BatchNorm1d-3              [-1, 128, 64]             256
              ReLU-4              [-1, 128, 64]               0
            Conv1d-5              [-1, 128, 64]           2,176
   MyConv1dPadSame-6              [-1, 128, 64]               0
       BatchNorm1d-7              [-1, 128, 64]             256
              ReLU-8              [-1, 128, 64]               0
           Dropout-9              [-1, 128, 64]               0
           Conv1d-10              [-1, 128, 64]           2,176
  MyConv1dPadSame-11              [-1, 128, 64]               0
       Bottleneck-12              [-1, 128, 64]               0
      BatchNorm1d-13              [-1, 128, 64]             256
             ReLU-14              [-1, 128, 64]               0
          Dropout-15              [-1, 128, 64]               0
           Conv1d-16              [-1, 256, 64]           4,352
  MyConv1dPadSame-17              [-1, 256, 64]               0
      BatchNorm1d-18              [-1, 256, 64]             512
             ReLU-19              [-1, 256, 64]               0
          Dropout-20              [-1, 256, 64]               0
           Conv1d-21              [-1, 256, 64]           8,448
  MyConv1dPadSame-22              [-1, 256, 64]               0
       Bottleneck-23              [-1, 256, 64]               0
      BatchNorm1d-24              [-1, 256, 64]             512
             ReLU-25              [-1, 256, 64]               0
          Dropout-26              [-1, 256, 64]               0
           Conv1d-27              [-1, 512, 64]          16,896
  MyConv1dPadSame-28              [-1, 512, 64]               0
      BatchNorm1d-29              [-1, 512, 64]           1,024
             ReLU-30              [-1, 512, 64]               0
          Dropout-31              [-1, 512, 64]               0
           Conv1d-32              [-1, 512, 64]          33,280
  MyConv1dPadSame-33              [-1, 512, 64]               0
       Bottleneck-34              [-1, 512, 64]               0
      BatchNorm1d-35              [-1, 512, 64]           1,024
             ReLU-36              [-1, 512, 64]               0
          Dropout-37              [-1, 512, 64]               0
           Conv1d-38             [-1, 1024, 64]          66,560
  MyConv1dPadSame-39             [-1, 1024, 64]               0
      BatchNorm1d-40             [-1, 1024, 64]           2,048
             ReLU-41             [-1, 1024, 64]               0
          Dropout-42             [-1, 1024, 64]               0
           Conv1d-43             [-1, 1024, 64]         132,096
  MyConv1dPadSame-44             [-1, 1024, 64]               0
       Bottleneck-45             [-1, 1024, 64]               0
      BatchNorm1d-46             [-1, 1024, 64]           2,048
             ReLU-47             [-1, 1024, 64]               0
           Linear-48                    [-1, 2]           2,050
================================================================
Total params: 278,146
Trainable params: 278,146
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 10.06
Params size (MB): 1.06
Estimated Total Size (MB): 11.12
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 128, kernel_size: 16, n_block: 8
************************************************************
************************************************************
(2000, 1, 64) Counter({0: 1000, 1: 1000})
(2000, 1, 64) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 128, 64]           2,176
   MyConv1dPadSame-2              [-1, 128, 64]               0
       BatchNorm1d-3              [-1, 128, 64]             256
              ReLU-4              [-1, 128, 64]               0
            Conv1d-5              [-1, 128, 64]           2,176
   MyConv1dPadSame-6              [-1, 128, 64]               0
       BatchNorm1d-7              [-1, 128, 64]             256
              ReLU-8              [-1, 128, 64]               0
           Dropout-9              [-1, 128, 64]               0
           Conv1d-10              [-1, 128, 64]           2,176
  MyConv1dPadSame-11              [-1, 128, 64]               0
       Bottleneck-12              [-1, 128, 64]               0
      BatchNorm1d-13              [-1, 128, 64]             256
             ReLU-14              [-1, 128, 64]               0
          Dropout-15              [-1, 128, 64]               0
           Conv1d-16              [-1, 128, 64]           2,176
  MyConv1dPadSame-17              [-1, 128, 64]               0
      BatchNorm1d-18              [-1, 128, 64]             256
             ReLU-19              [-1, 128, 64]               0
          Dropout-20              [-1, 128, 64]               0
           Conv1d-21              [-1, 128, 64]           2,176
  MyConv1dPadSame-22              [-1, 128, 64]               0
       Bottleneck-23              [-1, 128, 64]               0
      BatchNorm1d-24              [-1, 128, 64]             256
             ReLU-25              [-1, 128, 64]               0
          Dropout-26              [-1, 128, 64]               0
           Conv1d-27              [-1, 256, 64]           4,352
  MyConv1dPadSame-28              [-1, 256, 64]               0
      BatchNorm1d-29              [-1, 256, 64]             512
             ReLU-30              [-1, 256, 64]               0
          Dropout-31              [-1, 256, 64]               0
           Conv1d-32              [-1, 256, 64]           8,448
  MyConv1dPadSame-33              [-1, 256, 64]               0
       Bottleneck-34              [-1, 256, 64]               0
      BatchNorm1d-35              [-1, 256, 64]             512
             ReLU-36              [-1, 256, 64]               0
          Dropout-37              [-1, 256, 64]               0
           Conv1d-38              [-1, 256, 64]           8,448
  MyConv1dPadSame-39              [-1, 256, 64]               0
      BatchNorm1d-40              [-1, 256, 64]             512
             ReLU-41              [-1, 256, 64]               0
          Dropout-42              [-1, 256, 64]               0
           Conv1d-43              [-1, 256, 64]           8,448
  MyConv1dPadSame-44              [-1, 256, 64]               0
       Bottleneck-45              [-1, 256, 64]               0
      BatchNorm1d-46              [-1, 256, 64]             512
             ReLU-47              [-1, 256, 64]               0
          Dropout-48              [-1, 256, 64]               0
           Conv1d-49              [-1, 512, 64]          16,896
  MyConv1dPadSame-50              [-1, 512, 64]               0
      BatchNorm1d-51              [-1, 512, 64]           1,024
             ReLU-52              [-1, 512, 64]               0
          Dropout-53              [-1, 512, 64]               0
           Conv1d-54              [-1, 512, 64]          33,280
  MyConv1dPadSame-55              [-1, 512, 64]               0
       Bottleneck-56              [-1, 512, 64]               0
      BatchNorm1d-57              [-1, 512, 64]           1,024
             ReLU-58              [-1, 512, 64]               0
          Dropout-59              [-1, 512, 64]               0
           Conv1d-60              [-1, 512, 64]          33,280
  MyConv1dPadSame-61              [-1, 512, 64]               0
      BatchNorm1d-62              [-1, 512, 64]           1,024
             ReLU-63              [-1, 512, 64]               0
          Dropout-64              [-1, 512, 64]               0
           Conv1d-65              [-1, 512, 64]          33,280
  MyConv1dPadSame-66              [-1, 512, 64]               0
       Bottleneck-67              [-1, 512, 64]               0
      BatchNorm1d-68              [-1, 512, 64]           1,024
             ReLU-69              [-1, 512, 64]               0
          Dropout-70              [-1, 512, 64]               0
           Conv1d-71             [-1, 1024, 64]          66,560
  MyConv1dPadSame-72             [-1, 1024, 64]               0
      BatchNorm1d-73             [-1, 1024, 64]           2,048
             ReLU-74             [-1, 1024, 64]               0
          Dropout-75             [-1, 1024, 64]               0
           Conv1d-76             [-1, 1024, 64]         132,096
  MyConv1dPadSame-77             [-1, 1024, 64]               0
       Bottleneck-78             [-1, 1024, 64]               0
      BatchNorm1d-79             [-1, 1024, 64]           2,048
             ReLU-80             [-1, 1024, 64]               0
          Dropout-81             [-1, 1024, 64]               0
           Conv1d-82             [-1, 1024, 64]         132,096
  MyConv1dPadSame-83             [-1, 1024, 64]               0
      BatchNorm1d-84             [-1, 1024, 64]           2,048
             ReLU-85             [-1, 1024, 64]               0
          Dropout-86             [-1, 1024, 64]               0
           Conv1d-87             [-1, 1024, 64]         132,096
  MyConv1dPadSame-88             [-1, 1024, 64]               0
       Bottleneck-89             [-1, 1024, 64]               0
      BatchNorm1d-90             [-1, 1024, 64]           2,048
             ReLU-91             [-1, 1024, 64]               0
           Linear-92                    [-1, 2]           2,050
================================================================
Total params: 637,826
Trainable params: 637,826
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 20.38
Params size (MB): 2.43
Estimated Total Size (MB): 22.81
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 64, base_filters: 128, kernel_size: 16, n_block: 16
************************************************************
************************************************************
(2000, 1, 64) Counter({0: 1000, 1: 1000})
(2000, 1, 64) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 128, 64]           2,176
   MyConv1dPadSame-2              [-1, 128, 64]               0
       BatchNorm1d-3              [-1, 128, 64]             256
              ReLU-4              [-1, 128, 64]               0
            Conv1d-5              [-1, 128, 64]           2,176
   MyConv1dPadSame-6              [-1, 128, 64]               0
       BatchNorm1d-7              [-1, 128, 64]             256
              ReLU-8              [-1, 128, 64]               0
           Dropout-9              [-1, 128, 64]               0
           Conv1d-10              [-1, 128, 64]           2,176
  MyConv1dPadSame-11              [-1, 128, 64]               0
       Bottleneck-12              [-1, 128, 64]               0
      BatchNorm1d-13              [-1, 128, 64]             256
             ReLU-14              [-1, 128, 64]               0
          Dropout-15              [-1, 128, 64]               0
           Conv1d-16              [-1, 128, 32]           2,176
  MyConv1dPadSame-17              [-1, 128, 32]               0
      BatchNorm1d-18              [-1, 128, 32]             256
             ReLU-19              [-1, 128, 32]               0
          Dropout-20              [-1, 128, 32]               0
           Conv1d-21              [-1, 128, 32]           2,176
  MyConv1dPadSame-22              [-1, 128, 32]               0
        MaxPool1d-23              [-1, 128, 32]               0
MyMaxPool1dPadSame-24              [-1, 128, 32]               0
       Bottleneck-25              [-1, 128, 32]               0
      BatchNorm1d-26              [-1, 128, 32]             256
             ReLU-27              [-1, 128, 32]               0
          Dropout-28              [-1, 128, 32]               0
           Conv1d-29              [-1, 128, 32]           2,176
  MyConv1dPadSame-30              [-1, 128, 32]               0
      BatchNorm1d-31              [-1, 128, 32]             256
             ReLU-32              [-1, 128, 32]               0
          Dropout-33              [-1, 128, 32]               0
           Conv1d-34              [-1, 128, 32]           2,176
  MyConv1dPadSame-35              [-1, 128, 32]               0
       Bottleneck-36              [-1, 128, 32]               0
      BatchNorm1d-37              [-1, 128, 32]             256
             ReLU-38              [-1, 128, 32]               0
          Dropout-39              [-1, 128, 32]               0
           Conv1d-40              [-1, 128, 16]           2,176
  MyConv1dPadSame-41              [-1, 128, 16]               0
      BatchNorm1d-42              [-1, 128, 16]             256
             ReLU-43              [-1, 128, 16]               0
          Dropout-44              [-1, 128, 16]               0
           Conv1d-45              [-1, 128, 16]           2,176
  MyConv1dPadSame-46              [-1, 128, 16]               0
        MaxPool1d-47              [-1, 128, 16]               0
MyMaxPool1dPadSame-48              [-1, 128, 16]               0
       Bottleneck-49              [-1, 128, 16]               0
      BatchNorm1d-50              [-1, 128, 16]             256
             ReLU-51              [-1, 128, 16]               0
          Dropout-52              [-1, 128, 16]               0
           Conv1d-53              [-1, 256, 16]           4,352
  MyConv1dPadSame-54              [-1, 256, 16]               0
      BatchNorm1d-55              [-1, 256, 16]             512
             ReLU-56              [-1, 256, 16]               0
          Dropout-57              [-1, 256, 16]               0
           Conv1d-58              [-1, 256, 16]           8,448
  MyConv1dPadSame-59              [-1, 256, 16]               0
       Bottleneck-60              [-1, 256, 16]               0
      BatchNorm1d-61              [-1, 256, 16]             512
             ReLU-62              [-1, 256, 16]               0
          Dropout-63              [-1, 256, 16]               0
           Conv1d-64               [-1, 256, 8]           8,448
  MyConv1dPadSame-65               [-1, 256, 8]               0
      BatchNorm1d-66               [-1, 256, 8]             512
             ReLU-67               [-1, 256, 8]               0
          Dropout-68               [-1, 256, 8]               0
           Conv1d-69               [-1, 256, 8]           8,448
  MyConv1dPadSame-70               [-1, 256, 8]               0
        MaxPool1d-71               [-1, 256, 8]               0
MyMaxPool1dPadSame-72               [-1, 256, 8]               0
       Bottleneck-73               [-1, 256, 8]               0
      BatchNorm1d-74               [-1, 256, 8]             512
             ReLU-75               [-1, 256, 8]               0
          Dropout-76               [-1, 256, 8]               0
           Conv1d-77               [-1, 256, 8]           8,448
  MyConv1dPadSame-78               [-1, 256, 8]               0
      BatchNorm1d-79               [-1, 256, 8]             512
             ReLU-80               [-1, 256, 8]               0
          Dropout-81               [-1, 256, 8]               0
           Conv1d-82               [-1, 256, 8]           8,448
  MyConv1dPadSame-83               [-1, 256, 8]               0
       Bottleneck-84               [-1, 256, 8]               0
      BatchNorm1d-85               [-1, 256, 8]             512
             ReLU-86               [-1, 256, 8]               0
          Dropout-87               [-1, 256, 8]               0
           Conv1d-88               [-1, 256, 4]           8,448
  MyConv1dPadSame-89               [-1, 256, 4]               0
      BatchNorm1d-90               [-1, 256, 4]             512
             ReLU-91               [-1, 256, 4]               0
          Dropout-92               [-1, 256, 4]               0
           Conv1d-93               [-1, 256, 4]           8,448
  MyConv1dPadSame-94               [-1, 256, 4]               0
        MaxPool1d-95               [-1, 256, 4]               0
MyMaxPool1dPadSame-96               [-1, 256, 4]               0
       Bottleneck-97               [-1, 256, 4]               0
      BatchNorm1d-98               [-1, 256, 4]             512
             ReLU-99               [-1, 256, 4]               0
         Dropout-100               [-1, 256, 4]               0
          Conv1d-101               [-1, 512, 4]          16,896
 MyConv1dPadSame-102               [-1, 512, 4]               0
     BatchNorm1d-103               [-1, 512, 4]           1,024
            ReLU-104               [-1, 512, 4]               0
         Dropout-105               [-1, 512, 4]               0
          Conv1d-106               [-1, 512, 4]          33,280
 MyConv1dPadSame-107               [-1, 512, 4]               0
      Bottleneck-108               [-1, 512, 4]               0
     BatchNorm1d-109               [-1, 512, 4]           1,024
            ReLU-110               [-1, 512, 4]               0
         Dropout-111               [-1, 512, 4]               0
          Conv1d-112               [-1, 512, 2]          33,280
 MyConv1dPadSame-113               [-1, 512, 2]               0
     BatchNorm1d-114               [-1, 512, 2]           1,024
            ReLU-115               [-1, 512, 2]               0
         Dropout-116               [-1, 512, 2]               0
          Conv1d-117               [-1, 512, 2]          33,280
 MyConv1dPadSame-118               [-1, 512, 2]               0
       MaxPool1d-119               [-1, 512, 2]               0
MyMaxPool1dPadSame-120               [-1, 512, 2]               0
      Bottleneck-121               [-1, 512, 2]               0
     BatchNorm1d-122               [-1, 512, 2]           1,024
            ReLU-123               [-1, 512, 2]               0
         Dropout-124               [-1, 512, 2]               0
          Conv1d-125               [-1, 512, 2]          33,280
 MyConv1dPadSame-126               [-1, 512, 2]               0
     BatchNorm1d-127               [-1, 512, 2]           1,024
            ReLU-128               [-1, 512, 2]               0
         Dropout-129               [-1, 512, 2]               0
          Conv1d-130               [-1, 512, 2]          33,280
 MyConv1dPadSame-131               [-1, 512, 2]               0
      Bottleneck-132               [-1, 512, 2]               0
     BatchNorm1d-133               [-1, 512, 2]           1,024
            ReLU-134               [-1, 512, 2]               0
         Dropout-135               [-1, 512, 2]               0
          Conv1d-136               [-1, 512, 1]          33,280
 MyConv1dPadSame-137               [-1, 512, 1]               0
     BatchNorm1d-138               [-1, 512, 1]           1,024
            ReLU-139               [-1, 512, 1]               0
         Dropout-140               [-1, 512, 1]               0
          Conv1d-141               [-1, 512, 1]          33,280
 MyConv1dPadSame-142               [-1, 512, 1]               0
       MaxPool1d-143               [-1, 512, 1]               0
MyMaxPool1dPadSame-144               [-1, 512, 1]               0
      Bottleneck-145               [-1, 512, 1]               0
     BatchNorm1d-146               [-1, 512, 1]           1,024
            ReLU-147               [-1, 512, 1]               0
         Dropout-148               [-1, 512, 1]               0
          Conv1d-149              [-1, 1024, 1]          66,560
 MyConv1dPadSame-150              [-1, 1024, 1]               0
     BatchNorm1d-151              [-1, 1024, 1]           2,048
            ReLU-152              [-1, 1024, 1]               0
         Dropout-153              [-1, 1024, 1]               0
          Conv1d-154              [-1, 1024, 1]         132,096
 MyConv1dPadSame-155              [-1, 1024, 1]               0
      Bottleneck-156              [-1, 1024, 1]               0
     BatchNorm1d-157              [-1, 1024, 1]           2,048
            ReLU-158              [-1, 1024, 1]               0
         Dropout-159              [-1, 1024, 1]               0
          Conv1d-160              [-1, 1024, 1]         132,096
 MyConv1dPadSame-161              [-1, 1024, 1]               0
     BatchNorm1d-162              [-1, 1024, 1]           2,048
            ReLU-163              [-1, 1024, 1]               0
         Dropout-164              [-1, 1024, 1]               0
          Conv1d-165              [-1, 1024, 1]         132,096
 MyConv1dPadSame-166              [-1, 1024, 1]               0
       MaxPool1d-167              [-1, 1024, 1]               0
MyMaxPool1dPadSame-168              [-1, 1024, 1]               0
      Bottleneck-169              [-1, 1024, 1]               0
     BatchNorm1d-170              [-1, 1024, 1]           2,048
            ReLU-171              [-1, 1024, 1]               0
         Dropout-172              [-1, 1024, 1]               0
          Conv1d-173              [-1, 1024, 1]         132,096
 MyConv1dPadSame-174              [-1, 1024, 1]               0
     BatchNorm1d-175              [-1, 1024, 1]           2,048
            ReLU-176              [-1, 1024, 1]               0
         Dropout-177              [-1, 1024, 1]               0
          Conv1d-178              [-1, 1024, 1]         132,096
 MyConv1dPadSame-179              [-1, 1024, 1]               0
      Bottleneck-180              [-1, 1024, 1]               0
     BatchNorm1d-181              [-1, 1024, 1]           2,048
            ReLU-182              [-1, 1024, 1]               0
         Dropout-183              [-1, 1024, 1]               0
          Conv1d-184              [-1, 1024, 1]         132,096
 MyConv1dPadSame-185              [-1, 1024, 1]               0
     BatchNorm1d-186              [-1, 1024, 1]           2,048
            ReLU-187              [-1, 1024, 1]               0
         Dropout-188              [-1, 1024, 1]               0
          Conv1d-189              [-1, 1024, 1]         132,096
 MyConv1dPadSame-190              [-1, 1024, 1]               0
       MaxPool1d-191              [-1, 1024, 1]               0
MyMaxPool1dPadSame-192              [-1, 1024, 1]               0
      Bottleneck-193              [-1, 1024, 1]               0
     BatchNorm1d-194              [-1, 1024, 1]           2,048
            ReLU-195              [-1, 1024, 1]               0
          Linear-196                    [-1, 2]           2,050
================================================================
Total params: 1,357,186
Trainable params: 1,357,186
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 3.49
Params size (MB): 5.18
Estimated Total Size (MB): 8.67
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 8, kernel_size: 2, n_block: 2
************************************************************
************************************************************
(2000, 1, 256) Counter({1: 1000, 0: 1000})
(2000, 1, 256) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 8, 256]              24
   MyConv1dPadSame-2               [-1, 8, 256]               0
       BatchNorm1d-3               [-1, 8, 256]              16
              ReLU-4               [-1, 8, 256]               0
            Conv1d-5               [-1, 8, 256]              24
   MyConv1dPadSame-6               [-1, 8, 256]               0
       BatchNorm1d-7               [-1, 8, 256]              16
              ReLU-8               [-1, 8, 256]               0
           Dropout-9               [-1, 8, 256]               0
           Conv1d-10               [-1, 8, 256]              24
  MyConv1dPadSame-11               [-1, 8, 256]               0
       Bottleneck-12               [-1, 8, 256]               0
      BatchNorm1d-13               [-1, 8, 256]              16
             ReLU-14               [-1, 8, 256]               0
          Dropout-15               [-1, 8, 256]               0
           Conv1d-16              [-1, 16, 256]              48
  MyConv1dPadSame-17              [-1, 16, 256]               0
      BatchNorm1d-18              [-1, 16, 256]              32
             ReLU-19              [-1, 16, 256]               0
          Dropout-20              [-1, 16, 256]               0
           Conv1d-21              [-1, 16, 256]              80
  MyConv1dPadSame-22              [-1, 16, 256]               0
       Bottleneck-23              [-1, 16, 256]               0
      BatchNorm1d-24              [-1, 16, 256]              32
             ReLU-25              [-1, 16, 256]               0
           Linear-26                    [-1, 2]              34
================================================================
Total params: 346
Trainable params: 346
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.55
Params size (MB): 0.00
Estimated Total Size (MB): 0.55
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 8, kernel_size: 2, n_block: 4
************************************************************
************************************************************
(2000, 1, 256) Counter({1: 1000, 0: 1000})
(2000, 1, 256) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 8, 256]              24
   MyConv1dPadSame-2               [-1, 8, 256]               0
       BatchNorm1d-3               [-1, 8, 256]              16
              ReLU-4               [-1, 8, 256]               0
            Conv1d-5               [-1, 8, 256]              24
   MyConv1dPadSame-6               [-1, 8, 256]               0
       BatchNorm1d-7               [-1, 8, 256]              16
              ReLU-8               [-1, 8, 256]               0
           Dropout-9               [-1, 8, 256]               0
           Conv1d-10               [-1, 8, 256]              24
  MyConv1dPadSame-11               [-1, 8, 256]               0
       Bottleneck-12               [-1, 8, 256]               0
      BatchNorm1d-13               [-1, 8, 256]              16
             ReLU-14               [-1, 8, 256]               0
          Dropout-15               [-1, 8, 256]               0
           Conv1d-16              [-1, 16, 256]              48
  MyConv1dPadSame-17              [-1, 16, 256]               0
      BatchNorm1d-18              [-1, 16, 256]              32
             ReLU-19              [-1, 16, 256]               0
          Dropout-20              [-1, 16, 256]               0
           Conv1d-21              [-1, 16, 256]              80
  MyConv1dPadSame-22              [-1, 16, 256]               0
       Bottleneck-23              [-1, 16, 256]               0
      BatchNorm1d-24              [-1, 16, 256]              32
             ReLU-25              [-1, 16, 256]               0
          Dropout-26              [-1, 16, 256]               0
           Conv1d-27              [-1, 32, 256]             160
  MyConv1dPadSame-28              [-1, 32, 256]               0
      BatchNorm1d-29              [-1, 32, 256]              64
             ReLU-30              [-1, 32, 256]               0
          Dropout-31              [-1, 32, 256]               0
           Conv1d-32              [-1, 32, 256]             288
  MyConv1dPadSame-33              [-1, 32, 256]               0
       Bottleneck-34              [-1, 32, 256]               0
      BatchNorm1d-35              [-1, 32, 256]              64
             ReLU-36              [-1, 32, 256]               0
          Dropout-37              [-1, 32, 256]               0
           Conv1d-38              [-1, 64, 256]             576
  MyConv1dPadSame-39              [-1, 64, 256]               0
      BatchNorm1d-40              [-1, 64, 256]             128
             ReLU-41              [-1, 64, 256]               0
          Dropout-42              [-1, 64, 256]               0
           Conv1d-43              [-1, 64, 256]           1,088
  MyConv1dPadSame-44              [-1, 64, 256]               0
       Bottleneck-45              [-1, 64, 256]               0
      BatchNorm1d-46              [-1, 64, 256]             128
             ReLU-47              [-1, 64, 256]               0
           Linear-48                    [-1, 2]             130
================================================================
Total params: 2,938
Trainable params: 2,938
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 2.52
Params size (MB): 0.01
Estimated Total Size (MB): 2.53
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 8, kernel_size: 2, n_block: 8
************************************************************
************************************************************
(2000, 1, 256) Counter({1: 1000, 0: 1000})
(2000, 1, 256) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 8, 256]              24
   MyConv1dPadSame-2               [-1, 8, 256]               0
       BatchNorm1d-3               [-1, 8, 256]              16
              ReLU-4               [-1, 8, 256]               0
            Conv1d-5               [-1, 8, 256]              24
   MyConv1dPadSame-6               [-1, 8, 256]               0
       BatchNorm1d-7               [-1, 8, 256]              16
              ReLU-8               [-1, 8, 256]               0
           Dropout-9               [-1, 8, 256]               0
           Conv1d-10               [-1, 8, 256]              24
  MyConv1dPadSame-11               [-1, 8, 256]               0
       Bottleneck-12               [-1, 8, 256]               0
      BatchNorm1d-13               [-1, 8, 256]              16
             ReLU-14               [-1, 8, 256]               0
          Dropout-15               [-1, 8, 256]               0
           Conv1d-16               [-1, 8, 256]              24
  MyConv1dPadSame-17               [-1, 8, 256]               0
      BatchNorm1d-18               [-1, 8, 256]              16
             ReLU-19               [-1, 8, 256]               0
          Dropout-20               [-1, 8, 256]               0
           Conv1d-21               [-1, 8, 256]              24
  MyConv1dPadSame-22               [-1, 8, 256]               0
       Bottleneck-23               [-1, 8, 256]               0
      BatchNorm1d-24               [-1, 8, 256]              16
             ReLU-25               [-1, 8, 256]               0
          Dropout-26               [-1, 8, 256]               0
           Conv1d-27              [-1, 16, 256]              48
  MyConv1dPadSame-28              [-1, 16, 256]               0
      BatchNorm1d-29              [-1, 16, 256]              32
             ReLU-30              [-1, 16, 256]               0
          Dropout-31              [-1, 16, 256]               0
           Conv1d-32              [-1, 16, 256]              80
  MyConv1dPadSame-33              [-1, 16, 256]               0
       Bottleneck-34              [-1, 16, 256]               0
      BatchNorm1d-35              [-1, 16, 256]              32
             ReLU-36              [-1, 16, 256]               0
          Dropout-37              [-1, 16, 256]               0
           Conv1d-38              [-1, 16, 256]              80
  MyConv1dPadSame-39              [-1, 16, 256]               0
      BatchNorm1d-40              [-1, 16, 256]              32
             ReLU-41              [-1, 16, 256]               0
          Dropout-42              [-1, 16, 256]               0
           Conv1d-43              [-1, 16, 256]              80
  MyConv1dPadSame-44              [-1, 16, 256]               0
       Bottleneck-45              [-1, 16, 256]               0
      BatchNorm1d-46              [-1, 16, 256]              32
             ReLU-47              [-1, 16, 256]               0
          Dropout-48              [-1, 16, 256]               0
           Conv1d-49              [-1, 32, 256]             160
  MyConv1dPadSame-50              [-1, 32, 256]               0
      BatchNorm1d-51              [-1, 32, 256]              64
             ReLU-52              [-1, 32, 256]               0
          Dropout-53              [-1, 32, 256]               0
           Conv1d-54              [-1, 32, 256]             288
  MyConv1dPadSame-55              [-1, 32, 256]               0
       Bottleneck-56              [-1, 32, 256]               0
      BatchNorm1d-57              [-1, 32, 256]              64
             ReLU-58              [-1, 32, 256]               0
          Dropout-59              [-1, 32, 256]               0
           Conv1d-60              [-1, 32, 256]             288
  MyConv1dPadSame-61              [-1, 32, 256]               0
      BatchNorm1d-62              [-1, 32, 256]              64
             ReLU-63              [-1, 32, 256]               0
          Dropout-64              [-1, 32, 256]               0
           Conv1d-65              [-1, 32, 256]             288
  MyConv1dPadSame-66              [-1, 32, 256]               0
       Bottleneck-67              [-1, 32, 256]               0
      BatchNorm1d-68              [-1, 32, 256]              64
             ReLU-69              [-1, 32, 256]               0
          Dropout-70              [-1, 32, 256]               0
           Conv1d-71              [-1, 64, 256]             576
  MyConv1dPadSame-72              [-1, 64, 256]               0
      BatchNorm1d-73              [-1, 64, 256]             128
             ReLU-74              [-1, 64, 256]               0
          Dropout-75              [-1, 64, 256]               0
           Conv1d-76              [-1, 64, 256]           1,088
  MyConv1dPadSame-77              [-1, 64, 256]               0
       Bottleneck-78              [-1, 64, 256]               0
      BatchNorm1d-79              [-1, 64, 256]             128
             ReLU-80              [-1, 64, 256]               0
          Dropout-81              [-1, 64, 256]               0
           Conv1d-82              [-1, 64, 256]           1,088
  MyConv1dPadSame-83              [-1, 64, 256]               0
      BatchNorm1d-84              [-1, 64, 256]             128
             ReLU-85              [-1, 64, 256]               0
          Dropout-86              [-1, 64, 256]               0
           Conv1d-87              [-1, 64, 256]           1,088
  MyConv1dPadSame-88              [-1, 64, 256]               0
       Bottleneck-89              [-1, 64, 256]               0
      BatchNorm1d-90              [-1, 64, 256]             128
             ReLU-91              [-1, 64, 256]               0
           Linear-92                    [-1, 2]             130
================================================================
Total params: 6,378
Trainable params: 6,378
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 5.09
Params size (MB): 0.02
Estimated Total Size (MB): 5.12
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 8, kernel_size: 2, n_block: 16
************************************************************
************************************************************
(2000, 1, 256) Counter({1: 1000, 0: 1000})
(2000, 1, 256) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 8, 256]              24
   MyConv1dPadSame-2               [-1, 8, 256]               0
       BatchNorm1d-3               [-1, 8, 256]              16
              ReLU-4               [-1, 8, 256]               0
            Conv1d-5               [-1, 8, 256]              24
   MyConv1dPadSame-6               [-1, 8, 256]               0
       BatchNorm1d-7               [-1, 8, 256]              16
              ReLU-8               [-1, 8, 256]               0
           Dropout-9               [-1, 8, 256]               0
           Conv1d-10               [-1, 8, 256]              24
  MyConv1dPadSame-11               [-1, 8, 256]               0
       Bottleneck-12               [-1, 8, 256]               0
      BatchNorm1d-13               [-1, 8, 256]              16
             ReLU-14               [-1, 8, 256]               0
          Dropout-15               [-1, 8, 256]               0
           Conv1d-16               [-1, 8, 128]              24
  MyConv1dPadSame-17               [-1, 8, 128]               0
      BatchNorm1d-18               [-1, 8, 128]              16
             ReLU-19               [-1, 8, 128]               0
          Dropout-20               [-1, 8, 128]               0
           Conv1d-21               [-1, 8, 128]              24
  MyConv1dPadSame-22               [-1, 8, 128]               0
        MaxPool1d-23               [-1, 8, 128]               0
MyMaxPool1dPadSame-24               [-1, 8, 128]               0
       Bottleneck-25               [-1, 8, 128]               0
      BatchNorm1d-26               [-1, 8, 128]              16
             ReLU-27               [-1, 8, 128]               0
          Dropout-28               [-1, 8, 128]               0
           Conv1d-29               [-1, 8, 128]              24
  MyConv1dPadSame-30               [-1, 8, 128]               0
      BatchNorm1d-31               [-1, 8, 128]              16
             ReLU-32               [-1, 8, 128]               0
          Dropout-33               [-1, 8, 128]               0
           Conv1d-34               [-1, 8, 128]              24
  MyConv1dPadSame-35               [-1, 8, 128]               0
       Bottleneck-36               [-1, 8, 128]               0
      BatchNorm1d-37               [-1, 8, 128]              16
             ReLU-38               [-1, 8, 128]               0
          Dropout-39               [-1, 8, 128]               0
           Conv1d-40                [-1, 8, 64]              24
  MyConv1dPadSame-41                [-1, 8, 64]               0
      BatchNorm1d-42                [-1, 8, 64]              16
             ReLU-43                [-1, 8, 64]               0
          Dropout-44                [-1, 8, 64]               0
           Conv1d-45                [-1, 8, 64]              24
  MyConv1dPadSame-46                [-1, 8, 64]               0
        MaxPool1d-47                [-1, 8, 64]               0
MyMaxPool1dPadSame-48                [-1, 8, 64]               0
       Bottleneck-49                [-1, 8, 64]               0
      BatchNorm1d-50                [-1, 8, 64]              16
             ReLU-51                [-1, 8, 64]               0
          Dropout-52                [-1, 8, 64]               0
           Conv1d-53               [-1, 16, 64]              48
  MyConv1dPadSame-54               [-1, 16, 64]               0
      BatchNorm1d-55               [-1, 16, 64]              32
             ReLU-56               [-1, 16, 64]               0
          Dropout-57               [-1, 16, 64]               0
           Conv1d-58               [-1, 16, 64]              80
  MyConv1dPadSame-59               [-1, 16, 64]               0
       Bottleneck-60               [-1, 16, 64]               0
      BatchNorm1d-61               [-1, 16, 64]              32
             ReLU-62               [-1, 16, 64]               0
          Dropout-63               [-1, 16, 64]               0
           Conv1d-64               [-1, 16, 32]              80
  MyConv1dPadSame-65               [-1, 16, 32]               0
      BatchNorm1d-66               [-1, 16, 32]              32
             ReLU-67               [-1, 16, 32]               0
          Dropout-68               [-1, 16, 32]               0
           Conv1d-69               [-1, 16, 32]              80
  MyConv1dPadSame-70               [-1, 16, 32]               0
        MaxPool1d-71               [-1, 16, 32]               0
MyMaxPool1dPadSame-72               [-1, 16, 32]               0
       Bottleneck-73               [-1, 16, 32]               0
      BatchNorm1d-74               [-1, 16, 32]              32
             ReLU-75               [-1, 16, 32]               0
          Dropout-76               [-1, 16, 32]               0
           Conv1d-77               [-1, 16, 32]              80
  MyConv1dPadSame-78               [-1, 16, 32]               0
      BatchNorm1d-79               [-1, 16, 32]              32
             ReLU-80               [-1, 16, 32]               0
          Dropout-81               [-1, 16, 32]               0
           Conv1d-82               [-1, 16, 32]              80
  MyConv1dPadSame-83               [-1, 16, 32]               0
       Bottleneck-84               [-1, 16, 32]               0
      BatchNorm1d-85               [-1, 16, 32]              32
             ReLU-86               [-1, 16, 32]               0
          Dropout-87               [-1, 16, 32]               0
           Conv1d-88               [-1, 16, 16]              80
  MyConv1dPadSame-89               [-1, 16, 16]               0
      BatchNorm1d-90               [-1, 16, 16]              32
             ReLU-91               [-1, 16, 16]               0
          Dropout-92               [-1, 16, 16]               0
           Conv1d-93               [-1, 16, 16]              80
  MyConv1dPadSame-94               [-1, 16, 16]               0
        MaxPool1d-95               [-1, 16, 16]               0
MyMaxPool1dPadSame-96               [-1, 16, 16]               0
       Bottleneck-97               [-1, 16, 16]               0
      BatchNorm1d-98               [-1, 16, 16]              32
             ReLU-99               [-1, 16, 16]               0
         Dropout-100               [-1, 16, 16]               0
          Conv1d-101               [-1, 32, 16]             160
 MyConv1dPadSame-102               [-1, 32, 16]               0
     BatchNorm1d-103               [-1, 32, 16]              64
            ReLU-104               [-1, 32, 16]               0
         Dropout-105               [-1, 32, 16]               0
          Conv1d-106               [-1, 32, 16]             288
 MyConv1dPadSame-107               [-1, 32, 16]               0
      Bottleneck-108               [-1, 32, 16]               0
     BatchNorm1d-109               [-1, 32, 16]              64
            ReLU-110               [-1, 32, 16]               0
         Dropout-111               [-1, 32, 16]               0
          Conv1d-112                [-1, 32, 8]             288
 MyConv1dPadSame-113                [-1, 32, 8]               0
     BatchNorm1d-114                [-1, 32, 8]              64
            ReLU-115                [-1, 32, 8]               0
         Dropout-116                [-1, 32, 8]               0
          Conv1d-117                [-1, 32, 8]             288
 MyConv1dPadSame-118                [-1, 32, 8]               0
       MaxPool1d-119                [-1, 32, 8]               0
MyMaxPool1dPadSame-120                [-1, 32, 8]               0
      Bottleneck-121                [-1, 32, 8]               0
     BatchNorm1d-122                [-1, 32, 8]              64
            ReLU-123                [-1, 32, 8]               0
         Dropout-124                [-1, 32, 8]               0
          Conv1d-125                [-1, 32, 8]             288
 MyConv1dPadSame-126                [-1, 32, 8]               0
     BatchNorm1d-127                [-1, 32, 8]              64
            ReLU-128                [-1, 32, 8]               0
         Dropout-129                [-1, 32, 8]               0
          Conv1d-130                [-1, 32, 8]             288
 MyConv1dPadSame-131                [-1, 32, 8]               0
      Bottleneck-132                [-1, 32, 8]               0
     BatchNorm1d-133                [-1, 32, 8]              64
            ReLU-134                [-1, 32, 8]               0
         Dropout-135                [-1, 32, 8]               0
          Conv1d-136                [-1, 32, 4]             288
 MyConv1dPadSame-137                [-1, 32, 4]               0
     BatchNorm1d-138                [-1, 32, 4]              64
            ReLU-139                [-1, 32, 4]               0
         Dropout-140                [-1, 32, 4]               0
          Conv1d-141                [-1, 32, 4]             288
 MyConv1dPadSame-142                [-1, 32, 4]               0
       MaxPool1d-143                [-1, 32, 4]               0
MyMaxPool1dPadSame-144                [-1, 32, 4]               0
      Bottleneck-145                [-1, 32, 4]               0
     BatchNorm1d-146                [-1, 32, 4]              64
            ReLU-147                [-1, 32, 4]               0
         Dropout-148                [-1, 32, 4]               0
          Conv1d-149                [-1, 64, 4]             576
 MyConv1dPadSame-150                [-1, 64, 4]               0
     BatchNorm1d-151                [-1, 64, 4]             128
            ReLU-152                [-1, 64, 4]               0
         Dropout-153                [-1, 64, 4]               0
          Conv1d-154                [-1, 64, 4]           1,088
 MyConv1dPadSame-155                [-1, 64, 4]               0
      Bottleneck-156                [-1, 64, 4]               0
     BatchNorm1d-157                [-1, 64, 4]             128
            ReLU-158                [-1, 64, 4]               0
         Dropout-159                [-1, 64, 4]               0
          Conv1d-160                [-1, 64, 2]           1,088
 MyConv1dPadSame-161                [-1, 64, 2]               0
     BatchNorm1d-162                [-1, 64, 2]             128
            ReLU-163                [-1, 64, 2]               0
         Dropout-164                [-1, 64, 2]               0
          Conv1d-165                [-1, 64, 2]           1,088
 MyConv1dPadSame-166                [-1, 64, 2]               0
       MaxPool1d-167                [-1, 64, 2]               0
MyMaxPool1dPadSame-168                [-1, 64, 2]               0
      Bottleneck-169                [-1, 64, 2]               0
     BatchNorm1d-170                [-1, 64, 2]             128
            ReLU-171                [-1, 64, 2]               0
         Dropout-172                [-1, 64, 2]               0
          Conv1d-173                [-1, 64, 2]           1,088
 MyConv1dPadSame-174                [-1, 64, 2]               0
     BatchNorm1d-175                [-1, 64, 2]             128
            ReLU-176                [-1, 64, 2]               0
         Dropout-177                [-1, 64, 2]               0
          Conv1d-178                [-1, 64, 2]           1,088
 MyConv1dPadSame-179                [-1, 64, 2]               0
      Bottleneck-180                [-1, 64, 2]               0
     BatchNorm1d-181                [-1, 64, 2]             128
            ReLU-182                [-1, 64, 2]               0
         Dropout-183                [-1, 64, 2]               0
          Conv1d-184                [-1, 64, 1]           1,088
 MyConv1dPadSame-185                [-1, 64, 1]               0
     BatchNorm1d-186                [-1, 64, 1]             128
            ReLU-187                [-1, 64, 1]               0
         Dropout-188                [-1, 64, 1]               0
          Conv1d-189                [-1, 64, 1]           1,088
 MyConv1dPadSame-190                [-1, 64, 1]               0
       MaxPool1d-191                [-1, 64, 1]               0
MyMaxPool1dPadSame-192                [-1, 64, 1]               0
      Bottleneck-193                [-1, 64, 1]               0
     BatchNorm1d-194                [-1, 64, 1]             128
            ReLU-195                [-1, 64, 1]               0
          Linear-196                    [-1, 2]             130
================================================================
Total params: 13,258
Trainable params: 13,258
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.83
Params size (MB): 0.05
Estimated Total Size (MB): 0.88
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 8, kernel_size: 4, n_block: 2
************************************************************
************************************************************
(2000, 1, 256) Counter({1: 1000, 0: 1000})
(2000, 1, 256) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 8, 256]              40
   MyConv1dPadSame-2               [-1, 8, 256]               0
       BatchNorm1d-3               [-1, 8, 256]              16
              ReLU-4               [-1, 8, 256]               0
            Conv1d-5               [-1, 8, 256]              40
   MyConv1dPadSame-6               [-1, 8, 256]               0
       BatchNorm1d-7               [-1, 8, 256]              16
              ReLU-8               [-1, 8, 256]               0
           Dropout-9               [-1, 8, 256]               0
           Conv1d-10               [-1, 8, 256]              40
  MyConv1dPadSame-11               [-1, 8, 256]               0
       Bottleneck-12               [-1, 8, 256]               0
      BatchNorm1d-13               [-1, 8, 256]              16
             ReLU-14               [-1, 8, 256]               0
          Dropout-15               [-1, 8, 256]               0
           Conv1d-16              [-1, 16, 256]              80
  MyConv1dPadSame-17              [-1, 16, 256]               0
      BatchNorm1d-18              [-1, 16, 256]              32
             ReLU-19              [-1, 16, 256]               0
          Dropout-20              [-1, 16, 256]               0
           Conv1d-21              [-1, 16, 256]             144
  MyConv1dPadSame-22              [-1, 16, 256]               0
       Bottleneck-23              [-1, 16, 256]               0
      BatchNorm1d-24              [-1, 16, 256]              32
             ReLU-25              [-1, 16, 256]               0
           Linear-26                    [-1, 2]              34
================================================================
Total params: 490
Trainable params: 490
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.55
Params size (MB): 0.00
Estimated Total Size (MB): 0.55
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 8, kernel_size: 4, n_block: 4
************************************************************
************************************************************
(2000, 1, 256) Counter({0: 1000, 1: 1000})
(2000, 1, 256) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 8, 256]              40
   MyConv1dPadSame-2               [-1, 8, 256]               0
       BatchNorm1d-3               [-1, 8, 256]              16
              ReLU-4               [-1, 8, 256]               0
            Conv1d-5               [-1, 8, 256]              40
   MyConv1dPadSame-6               [-1, 8, 256]               0
       BatchNorm1d-7               [-1, 8, 256]              16
              ReLU-8               [-1, 8, 256]               0
           Dropout-9               [-1, 8, 256]               0
           Conv1d-10               [-1, 8, 256]              40
  MyConv1dPadSame-11               [-1, 8, 256]               0
       Bottleneck-12               [-1, 8, 256]               0
      BatchNorm1d-13               [-1, 8, 256]              16
             ReLU-14               [-1, 8, 256]               0
          Dropout-15               [-1, 8, 256]               0
           Conv1d-16              [-1, 16, 256]              80
  MyConv1dPadSame-17              [-1, 16, 256]               0
      BatchNorm1d-18              [-1, 16, 256]              32
             ReLU-19              [-1, 16, 256]               0
          Dropout-20              [-1, 16, 256]               0
           Conv1d-21              [-1, 16, 256]             144
  MyConv1dPadSame-22              [-1, 16, 256]               0
       Bottleneck-23              [-1, 16, 256]               0
      BatchNorm1d-24              [-1, 16, 256]              32
             ReLU-25              [-1, 16, 256]               0
          Dropout-26              [-1, 16, 256]               0
           Conv1d-27              [-1, 32, 256]             288
  MyConv1dPadSame-28              [-1, 32, 256]               0
      BatchNorm1d-29              [-1, 32, 256]              64
             ReLU-30              [-1, 32, 256]               0
          Dropout-31              [-1, 32, 256]               0
           Conv1d-32              [-1, 32, 256]             544
  MyConv1dPadSame-33              [-1, 32, 256]               0
       Bottleneck-34              [-1, 32, 256]               0
      BatchNorm1d-35              [-1, 32, 256]              64
             ReLU-36              [-1, 32, 256]               0
          Dropout-37              [-1, 32, 256]               0
           Conv1d-38              [-1, 64, 256]           1,088
  MyConv1dPadSame-39              [-1, 64, 256]               0
      BatchNorm1d-40              [-1, 64, 256]             128
             ReLU-41              [-1, 64, 256]               0
          Dropout-42              [-1, 64, 256]               0
           Conv1d-43              [-1, 64, 256]           2,112
  MyConv1dPadSame-44              [-1, 64, 256]               0
       Bottleneck-45              [-1, 64, 256]               0
      BatchNorm1d-46              [-1, 64, 256]             128
             ReLU-47              [-1, 64, 256]               0
           Linear-48                    [-1, 2]             130
================================================================
Total params: 5,002
Trainable params: 5,002
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 2.52
Params size (MB): 0.02
Estimated Total Size (MB): 2.54
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 8, kernel_size: 4, n_block: 8
************************************************************
************************************************************
(2000, 1, 256) Counter({0: 1000, 1: 1000})
(2000, 1, 256) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 8, 256]              40
   MyConv1dPadSame-2               [-1, 8, 256]               0
       BatchNorm1d-3               [-1, 8, 256]              16
              ReLU-4               [-1, 8, 256]               0
            Conv1d-5               [-1, 8, 256]              40
   MyConv1dPadSame-6               [-1, 8, 256]               0
       BatchNorm1d-7               [-1, 8, 256]              16
              ReLU-8               [-1, 8, 256]               0
           Dropout-9               [-1, 8, 256]               0
           Conv1d-10               [-1, 8, 256]              40
  MyConv1dPadSame-11               [-1, 8, 256]               0
       Bottleneck-12               [-1, 8, 256]               0
      BatchNorm1d-13               [-1, 8, 256]              16
             ReLU-14               [-1, 8, 256]               0
          Dropout-15               [-1, 8, 256]               0
           Conv1d-16               [-1, 8, 256]              40
  MyConv1dPadSame-17               [-1, 8, 256]               0
      BatchNorm1d-18               [-1, 8, 256]              16
             ReLU-19               [-1, 8, 256]               0
          Dropout-20               [-1, 8, 256]               0
           Conv1d-21               [-1, 8, 256]              40
  MyConv1dPadSame-22               [-1, 8, 256]               0
       Bottleneck-23               [-1, 8, 256]               0
      BatchNorm1d-24               [-1, 8, 256]              16
             ReLU-25               [-1, 8, 256]               0
          Dropout-26               [-1, 8, 256]               0
           Conv1d-27              [-1, 16, 256]              80
  MyConv1dPadSame-28              [-1, 16, 256]               0
      BatchNorm1d-29              [-1, 16, 256]              32
             ReLU-30              [-1, 16, 256]               0
          Dropout-31              [-1, 16, 256]               0
           Conv1d-32              [-1, 16, 256]             144
  MyConv1dPadSame-33              [-1, 16, 256]               0
       Bottleneck-34              [-1, 16, 256]               0
      BatchNorm1d-35              [-1, 16, 256]              32
             ReLU-36              [-1, 16, 256]               0
          Dropout-37              [-1, 16, 256]               0
           Conv1d-38              [-1, 16, 256]             144
  MyConv1dPadSame-39              [-1, 16, 256]               0
      BatchNorm1d-40              [-1, 16, 256]              32
             ReLU-41              [-1, 16, 256]               0
          Dropout-42              [-1, 16, 256]               0
           Conv1d-43              [-1, 16, 256]             144
  MyConv1dPadSame-44              [-1, 16, 256]               0
       Bottleneck-45              [-1, 16, 256]               0
      BatchNorm1d-46              [-1, 16, 256]              32
             ReLU-47              [-1, 16, 256]               0
          Dropout-48              [-1, 16, 256]               0
           Conv1d-49              [-1, 32, 256]             288
  MyConv1dPadSame-50              [-1, 32, 256]               0
      BatchNorm1d-51              [-1, 32, 256]              64
             ReLU-52              [-1, 32, 256]               0
          Dropout-53              [-1, 32, 256]               0
           Conv1d-54              [-1, 32, 256]             544
  MyConv1dPadSame-55              [-1, 32, 256]               0
       Bottleneck-56              [-1, 32, 256]               0
      BatchNorm1d-57              [-1, 32, 256]              64
             ReLU-58              [-1, 32, 256]               0
          Dropout-59              [-1, 32, 256]               0
           Conv1d-60              [-1, 32, 256]             544
  MyConv1dPadSame-61              [-1, 32, 256]               0
      BatchNorm1d-62              [-1, 32, 256]              64
             ReLU-63              [-1, 32, 256]               0
          Dropout-64              [-1, 32, 256]               0
           Conv1d-65              [-1, 32, 256]             544
  MyConv1dPadSame-66              [-1, 32, 256]               0
       Bottleneck-67              [-1, 32, 256]               0
      BatchNorm1d-68              [-1, 32, 256]              64
             ReLU-69              [-1, 32, 256]               0
          Dropout-70              [-1, 32, 256]               0
           Conv1d-71              [-1, 64, 256]           1,088
  MyConv1dPadSame-72              [-1, 64, 256]               0
      BatchNorm1d-73              [-1, 64, 256]             128
             ReLU-74              [-1, 64, 256]               0
          Dropout-75              [-1, 64, 256]               0
           Conv1d-76              [-1, 64, 256]           2,112
  MyConv1dPadSame-77              [-1, 64, 256]               0
       Bottleneck-78              [-1, 64, 256]               0
      BatchNorm1d-79              [-1, 64, 256]             128
             ReLU-80              [-1, 64, 256]               0
          Dropout-81              [-1, 64, 256]               0
           Conv1d-82              [-1, 64, 256]           2,112
  MyConv1dPadSame-83              [-1, 64, 256]               0
      BatchNorm1d-84              [-1, 64, 256]             128
             ReLU-85              [-1, 64, 256]               0
          Dropout-86              [-1, 64, 256]               0
           Conv1d-87              [-1, 64, 256]           2,112
  MyConv1dPadSame-88              [-1, 64, 256]               0
       Bottleneck-89              [-1, 64, 256]               0
      BatchNorm1d-90              [-1, 64, 256]             128
             ReLU-91              [-1, 64, 256]               0
           Linear-92                    [-1, 2]             130
================================================================
Total params: 11,162
Trainable params: 11,162
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 5.09
Params size (MB): 0.04
Estimated Total Size (MB): 5.14
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 8, kernel_size: 4, n_block: 16
************************************************************
************************************************************
(2000, 1, 256) Counter({0: 1000, 1: 1000})
(2000, 1, 256) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 8, 256]              40
   MyConv1dPadSame-2               [-1, 8, 256]               0
       BatchNorm1d-3               [-1, 8, 256]              16
              ReLU-4               [-1, 8, 256]               0
            Conv1d-5               [-1, 8, 256]              40
   MyConv1dPadSame-6               [-1, 8, 256]               0
       BatchNorm1d-7               [-1, 8, 256]              16
              ReLU-8               [-1, 8, 256]               0
           Dropout-9               [-1, 8, 256]               0
           Conv1d-10               [-1, 8, 256]              40
  MyConv1dPadSame-11               [-1, 8, 256]               0
       Bottleneck-12               [-1, 8, 256]               0
      BatchNorm1d-13               [-1, 8, 256]              16
             ReLU-14               [-1, 8, 256]               0
          Dropout-15               [-1, 8, 256]               0
           Conv1d-16               [-1, 8, 128]              40
  MyConv1dPadSame-17               [-1, 8, 128]               0
      BatchNorm1d-18               [-1, 8, 128]              16
             ReLU-19               [-1, 8, 128]               0
          Dropout-20               [-1, 8, 128]               0
           Conv1d-21               [-1, 8, 128]              40
  MyConv1dPadSame-22               [-1, 8, 128]               0
        MaxPool1d-23               [-1, 8, 128]               0
MyMaxPool1dPadSame-24               [-1, 8, 128]               0
       Bottleneck-25               [-1, 8, 128]               0
      BatchNorm1d-26               [-1, 8, 128]              16
             ReLU-27               [-1, 8, 128]               0
          Dropout-28               [-1, 8, 128]               0
           Conv1d-29               [-1, 8, 128]              40
  MyConv1dPadSame-30               [-1, 8, 128]               0
      BatchNorm1d-31               [-1, 8, 128]              16
             ReLU-32               [-1, 8, 128]               0
          Dropout-33               [-1, 8, 128]               0
           Conv1d-34               [-1, 8, 128]              40
  MyConv1dPadSame-35               [-1, 8, 128]               0
       Bottleneck-36               [-1, 8, 128]               0
      BatchNorm1d-37               [-1, 8, 128]              16
             ReLU-38               [-1, 8, 128]               0
          Dropout-39               [-1, 8, 128]               0
           Conv1d-40                [-1, 8, 64]              40
  MyConv1dPadSame-41                [-1, 8, 64]               0
      BatchNorm1d-42                [-1, 8, 64]              16
             ReLU-43                [-1, 8, 64]               0
          Dropout-44                [-1, 8, 64]               0
           Conv1d-45                [-1, 8, 64]              40
  MyConv1dPadSame-46                [-1, 8, 64]               0
        MaxPool1d-47                [-1, 8, 64]               0
MyMaxPool1dPadSame-48                [-1, 8, 64]               0
       Bottleneck-49                [-1, 8, 64]               0
      BatchNorm1d-50                [-1, 8, 64]              16
             ReLU-51                [-1, 8, 64]               0
          Dropout-52                [-1, 8, 64]               0
           Conv1d-53               [-1, 16, 64]              80
  MyConv1dPadSame-54               [-1, 16, 64]               0
      BatchNorm1d-55               [-1, 16, 64]              32
             ReLU-56               [-1, 16, 64]               0
          Dropout-57               [-1, 16, 64]               0
           Conv1d-58               [-1, 16, 64]             144
  MyConv1dPadSame-59               [-1, 16, 64]               0
       Bottleneck-60               [-1, 16, 64]               0
      BatchNorm1d-61               [-1, 16, 64]              32
             ReLU-62               [-1, 16, 64]               0
          Dropout-63               [-1, 16, 64]               0
           Conv1d-64               [-1, 16, 32]             144
  MyConv1dPadSame-65               [-1, 16, 32]               0
      BatchNorm1d-66               [-1, 16, 32]              32
             ReLU-67               [-1, 16, 32]               0
          Dropout-68               [-1, 16, 32]               0
           Conv1d-69               [-1, 16, 32]             144
  MyConv1dPadSame-70               [-1, 16, 32]               0
        MaxPool1d-71               [-1, 16, 32]               0
MyMaxPool1dPadSame-72               [-1, 16, 32]               0
       Bottleneck-73               [-1, 16, 32]               0
      BatchNorm1d-74               [-1, 16, 32]              32
             ReLU-75               [-1, 16, 32]               0
          Dropout-76               [-1, 16, 32]               0
           Conv1d-77               [-1, 16, 32]             144
  MyConv1dPadSame-78               [-1, 16, 32]               0
      BatchNorm1d-79               [-1, 16, 32]              32
             ReLU-80               [-1, 16, 32]               0
          Dropout-81               [-1, 16, 32]               0
           Conv1d-82               [-1, 16, 32]             144
  MyConv1dPadSame-83               [-1, 16, 32]               0
       Bottleneck-84               [-1, 16, 32]               0
      BatchNorm1d-85               [-1, 16, 32]              32
             ReLU-86               [-1, 16, 32]               0
          Dropout-87               [-1, 16, 32]               0
           Conv1d-88               [-1, 16, 16]             144
  MyConv1dPadSame-89               [-1, 16, 16]               0
      BatchNorm1d-90               [-1, 16, 16]              32
             ReLU-91               [-1, 16, 16]               0
          Dropout-92               [-1, 16, 16]               0
           Conv1d-93               [-1, 16, 16]             144
  MyConv1dPadSame-94               [-1, 16, 16]               0
        MaxPool1d-95               [-1, 16, 16]               0
MyMaxPool1dPadSame-96               [-1, 16, 16]               0
       Bottleneck-97               [-1, 16, 16]               0
      BatchNorm1d-98               [-1, 16, 16]              32
             ReLU-99               [-1, 16, 16]               0
         Dropout-100               [-1, 16, 16]               0
          Conv1d-101               [-1, 32, 16]             288
 MyConv1dPadSame-102               [-1, 32, 16]               0
     BatchNorm1d-103               [-1, 32, 16]              64
            ReLU-104               [-1, 32, 16]               0
         Dropout-105               [-1, 32, 16]               0
          Conv1d-106               [-1, 32, 16]             544
 MyConv1dPadSame-107               [-1, 32, 16]               0
      Bottleneck-108               [-1, 32, 16]               0
     BatchNorm1d-109               [-1, 32, 16]              64
            ReLU-110               [-1, 32, 16]               0
         Dropout-111               [-1, 32, 16]               0
          Conv1d-112                [-1, 32, 8]             544
 MyConv1dPadSame-113                [-1, 32, 8]               0
     BatchNorm1d-114                [-1, 32, 8]              64
            ReLU-115                [-1, 32, 8]               0
         Dropout-116                [-1, 32, 8]               0
          Conv1d-117                [-1, 32, 8]             544
 MyConv1dPadSame-118                [-1, 32, 8]               0
       MaxPool1d-119                [-1, 32, 8]               0
MyMaxPool1dPadSame-120                [-1, 32, 8]               0
      Bottleneck-121                [-1, 32, 8]               0
     BatchNorm1d-122                [-1, 32, 8]              64
            ReLU-123                [-1, 32, 8]               0
         Dropout-124                [-1, 32, 8]               0
          Conv1d-125                [-1, 32, 8]             544
 MyConv1dPadSame-126                [-1, 32, 8]               0
     BatchNorm1d-127                [-1, 32, 8]              64
            ReLU-128                [-1, 32, 8]               0
         Dropout-129                [-1, 32, 8]               0
          Conv1d-130                [-1, 32, 8]             544
 MyConv1dPadSame-131                [-1, 32, 8]               0
      Bottleneck-132                [-1, 32, 8]               0
     BatchNorm1d-133                [-1, 32, 8]              64
            ReLU-134                [-1, 32, 8]               0
         Dropout-135                [-1, 32, 8]               0
          Conv1d-136                [-1, 32, 4]             544
 MyConv1dPadSame-137                [-1, 32, 4]               0
     BatchNorm1d-138                [-1, 32, 4]              64
            ReLU-139                [-1, 32, 4]               0
         Dropout-140                [-1, 32, 4]               0
          Conv1d-141                [-1, 32, 4]             544
 MyConv1dPadSame-142                [-1, 32, 4]               0
       MaxPool1d-143                [-1, 32, 4]               0
MyMaxPool1dPadSame-144                [-1, 32, 4]               0
      Bottleneck-145                [-1, 32, 4]               0
     BatchNorm1d-146                [-1, 32, 4]              64
            ReLU-147                [-1, 32, 4]               0
         Dropout-148                [-1, 32, 4]               0
          Conv1d-149                [-1, 64, 4]           1,088
 MyConv1dPadSame-150                [-1, 64, 4]               0
     BatchNorm1d-151                [-1, 64, 4]             128
            ReLU-152                [-1, 64, 4]               0
         Dropout-153                [-1, 64, 4]               0
          Conv1d-154                [-1, 64, 4]           2,112
 MyConv1dPadSame-155                [-1, 64, 4]               0
      Bottleneck-156                [-1, 64, 4]               0
     BatchNorm1d-157                [-1, 64, 4]             128
            ReLU-158                [-1, 64, 4]               0
         Dropout-159                [-1, 64, 4]               0
          Conv1d-160                [-1, 64, 2]           2,112
 MyConv1dPadSame-161                [-1, 64, 2]               0
     BatchNorm1d-162                [-1, 64, 2]             128
            ReLU-163                [-1, 64, 2]               0
         Dropout-164                [-1, 64, 2]               0
          Conv1d-165                [-1, 64, 2]           2,112
 MyConv1dPadSame-166                [-1, 64, 2]               0
       MaxPool1d-167                [-1, 64, 2]               0
MyMaxPool1dPadSame-168                [-1, 64, 2]               0
      Bottleneck-169                [-1, 64, 2]               0
     BatchNorm1d-170                [-1, 64, 2]             128
            ReLU-171                [-1, 64, 2]               0
         Dropout-172                [-1, 64, 2]               0
          Conv1d-173                [-1, 64, 2]           2,112
 MyConv1dPadSame-174                [-1, 64, 2]               0
     BatchNorm1d-175                [-1, 64, 2]             128
            ReLU-176                [-1, 64, 2]               0
         Dropout-177                [-1, 64, 2]               0
          Conv1d-178                [-1, 64, 2]           2,112
 MyConv1dPadSame-179                [-1, 64, 2]               0
      Bottleneck-180                [-1, 64, 2]               0
     BatchNorm1d-181                [-1, 64, 2]             128
            ReLU-182                [-1, 64, 2]               0
         Dropout-183                [-1, 64, 2]               0
          Conv1d-184                [-1, 64, 1]           2,112
 MyConv1dPadSame-185                [-1, 64, 1]               0
     BatchNorm1d-186                [-1, 64, 1]             128
            ReLU-187                [-1, 64, 1]               0
         Dropout-188                [-1, 64, 1]               0
          Conv1d-189                [-1, 64, 1]           2,112
 MyConv1dPadSame-190                [-1, 64, 1]               0
       MaxPool1d-191                [-1, 64, 1]               0
MyMaxPool1dPadSame-192                [-1, 64, 1]               0
      Bottleneck-193                [-1, 64, 1]               0
     BatchNorm1d-194                [-1, 64, 1]             128
            ReLU-195                [-1, 64, 1]               0
          Linear-196                    [-1, 2]             130
================================================================
Total params: 23,482
Trainable params: 23,482
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.83
Params size (MB): 0.09
Estimated Total Size (MB): 0.92
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 8, kernel_size: 8, n_block: 2
************************************************************
************************************************************
(2000, 1, 256) Counter({0: 1000, 1: 1000})
(2000, 1, 256) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 8, 256]              72
   MyConv1dPadSame-2               [-1, 8, 256]               0
       BatchNorm1d-3               [-1, 8, 256]              16
              ReLU-4               [-1, 8, 256]               0
            Conv1d-5               [-1, 8, 256]              72
   MyConv1dPadSame-6               [-1, 8, 256]               0
       BatchNorm1d-7               [-1, 8, 256]              16
              ReLU-8               [-1, 8, 256]               0
           Dropout-9               [-1, 8, 256]               0
           Conv1d-10               [-1, 8, 256]              72
  MyConv1dPadSame-11               [-1, 8, 256]               0
       Bottleneck-12               [-1, 8, 256]               0
      BatchNorm1d-13               [-1, 8, 256]              16
             ReLU-14               [-1, 8, 256]               0
          Dropout-15               [-1, 8, 256]               0
           Conv1d-16              [-1, 16, 256]             144
  MyConv1dPadSame-17              [-1, 16, 256]               0
      BatchNorm1d-18              [-1, 16, 256]              32
             ReLU-19              [-1, 16, 256]               0
          Dropout-20              [-1, 16, 256]               0
           Conv1d-21              [-1, 16, 256]             272
  MyConv1dPadSame-22              [-1, 16, 256]               0
       Bottleneck-23              [-1, 16, 256]               0
      BatchNorm1d-24              [-1, 16, 256]              32
             ReLU-25              [-1, 16, 256]               0
           Linear-26                    [-1, 2]              34
================================================================
Total params: 778
Trainable params: 778
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.55
Params size (MB): 0.00
Estimated Total Size (MB): 0.55
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 8, kernel_size: 8, n_block: 4
************************************************************
************************************************************
(2000, 1, 256) Counter({0: 1000, 1: 1000})
(2000, 1, 256) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 8, 256]              72
   MyConv1dPadSame-2               [-1, 8, 256]               0
       BatchNorm1d-3               [-1, 8, 256]              16
              ReLU-4               [-1, 8, 256]               0
            Conv1d-5               [-1, 8, 256]              72
   MyConv1dPadSame-6               [-1, 8, 256]               0
       BatchNorm1d-7               [-1, 8, 256]              16
              ReLU-8               [-1, 8, 256]               0
           Dropout-9               [-1, 8, 256]               0
           Conv1d-10               [-1, 8, 256]              72
  MyConv1dPadSame-11               [-1, 8, 256]               0
       Bottleneck-12               [-1, 8, 256]               0
      BatchNorm1d-13               [-1, 8, 256]              16
             ReLU-14               [-1, 8, 256]               0
          Dropout-15               [-1, 8, 256]               0
           Conv1d-16              [-1, 16, 256]             144
  MyConv1dPadSame-17              [-1, 16, 256]               0
      BatchNorm1d-18              [-1, 16, 256]              32
             ReLU-19              [-1, 16, 256]               0
          Dropout-20              [-1, 16, 256]               0
           Conv1d-21              [-1, 16, 256]             272
  MyConv1dPadSame-22              [-1, 16, 256]               0
       Bottleneck-23              [-1, 16, 256]               0
      BatchNorm1d-24              [-1, 16, 256]              32
             ReLU-25              [-1, 16, 256]               0
          Dropout-26              [-1, 16, 256]               0
           Conv1d-27              [-1, 32, 256]             544
  MyConv1dPadSame-28              [-1, 32, 256]               0
      BatchNorm1d-29              [-1, 32, 256]              64
             ReLU-30              [-1, 32, 256]               0
          Dropout-31              [-1, 32, 256]               0
           Conv1d-32              [-1, 32, 256]           1,056
  MyConv1dPadSame-33              [-1, 32, 256]               0
       Bottleneck-34              [-1, 32, 256]               0
      BatchNorm1d-35              [-1, 32, 256]              64
             ReLU-36              [-1, 32, 256]               0
          Dropout-37              [-1, 32, 256]               0
           Conv1d-38              [-1, 64, 256]           2,112
  MyConv1dPadSame-39              [-1, 64, 256]               0
      BatchNorm1d-40              [-1, 64, 256]             128
             ReLU-41              [-1, 64, 256]               0
          Dropout-42              [-1, 64, 256]               0
           Conv1d-43              [-1, 64, 256]           4,160
  MyConv1dPadSame-44              [-1, 64, 256]               0
       Bottleneck-45              [-1, 64, 256]               0
      BatchNorm1d-46              [-1, 64, 256]             128
             ReLU-47              [-1, 64, 256]               0
           Linear-48                    [-1, 2]             130
================================================================
Total params: 9,130
Trainable params: 9,130
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 2.52
Params size (MB): 0.03
Estimated Total Size (MB): 2.55
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 8, kernel_size: 8, n_block: 8
************************************************************
************************************************************
(2000, 1, 256) Counter({1: 1000, 0: 1000})
(2000, 1, 256) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 8, 256]              72
   MyConv1dPadSame-2               [-1, 8, 256]               0
       BatchNorm1d-3               [-1, 8, 256]              16
              ReLU-4               [-1, 8, 256]               0
            Conv1d-5               [-1, 8, 256]              72
   MyConv1dPadSame-6               [-1, 8, 256]               0
       BatchNorm1d-7               [-1, 8, 256]              16
              ReLU-8               [-1, 8, 256]               0
           Dropout-9               [-1, 8, 256]               0
           Conv1d-10               [-1, 8, 256]              72
  MyConv1dPadSame-11               [-1, 8, 256]               0
       Bottleneck-12               [-1, 8, 256]               0
      BatchNorm1d-13               [-1, 8, 256]              16
             ReLU-14               [-1, 8, 256]               0
          Dropout-15               [-1, 8, 256]               0
           Conv1d-16               [-1, 8, 256]              72
  MyConv1dPadSame-17               [-1, 8, 256]               0
      BatchNorm1d-18               [-1, 8, 256]              16
             ReLU-19               [-1, 8, 256]               0
          Dropout-20               [-1, 8, 256]               0
           Conv1d-21               [-1, 8, 256]              72
  MyConv1dPadSame-22               [-1, 8, 256]               0
       Bottleneck-23               [-1, 8, 256]               0
      BatchNorm1d-24               [-1, 8, 256]              16
             ReLU-25               [-1, 8, 256]               0
          Dropout-26               [-1, 8, 256]               0
           Conv1d-27              [-1, 16, 256]             144
  MyConv1dPadSame-28              [-1, 16, 256]               0
      BatchNorm1d-29              [-1, 16, 256]              32
             ReLU-30              [-1, 16, 256]               0
          Dropout-31              [-1, 16, 256]               0
           Conv1d-32              [-1, 16, 256]             272
  MyConv1dPadSame-33              [-1, 16, 256]               0
       Bottleneck-34              [-1, 16, 256]               0
      BatchNorm1d-35              [-1, 16, 256]              32
             ReLU-36              [-1, 16, 256]               0
          Dropout-37              [-1, 16, 256]               0
           Conv1d-38              [-1, 16, 256]             272
  MyConv1dPadSame-39              [-1, 16, 256]               0
      BatchNorm1d-40              [-1, 16, 256]              32
             ReLU-41              [-1, 16, 256]               0
          Dropout-42              [-1, 16, 256]               0
           Conv1d-43              [-1, 16, 256]             272
  MyConv1dPadSame-44              [-1, 16, 256]               0
       Bottleneck-45              [-1, 16, 256]               0
      BatchNorm1d-46              [-1, 16, 256]              32
             ReLU-47              [-1, 16, 256]               0
          Dropout-48              [-1, 16, 256]               0
           Conv1d-49              [-1, 32, 256]             544
  MyConv1dPadSame-50              [-1, 32, 256]               0
      BatchNorm1d-51              [-1, 32, 256]              64
             ReLU-52              [-1, 32, 256]               0
          Dropout-53              [-1, 32, 256]               0
           Conv1d-54              [-1, 32, 256]           1,056
  MyConv1dPadSame-55              [-1, 32, 256]               0
       Bottleneck-56              [-1, 32, 256]               0
      BatchNorm1d-57              [-1, 32, 256]              64
             ReLU-58              [-1, 32, 256]               0
          Dropout-59              [-1, 32, 256]               0
           Conv1d-60              [-1, 32, 256]           1,056
  MyConv1dPadSame-61              [-1, 32, 256]               0
      BatchNorm1d-62              [-1, 32, 256]              64
             ReLU-63              [-1, 32, 256]               0
          Dropout-64              [-1, 32, 256]               0
           Conv1d-65              [-1, 32, 256]           1,056
  MyConv1dPadSame-66              [-1, 32, 256]               0
       Bottleneck-67              [-1, 32, 256]               0
      BatchNorm1d-68              [-1, 32, 256]              64
             ReLU-69              [-1, 32, 256]               0
          Dropout-70              [-1, 32, 256]               0
           Conv1d-71              [-1, 64, 256]           2,112
  MyConv1dPadSame-72              [-1, 64, 256]               0
      BatchNorm1d-73              [-1, 64, 256]             128
             ReLU-74              [-1, 64, 256]               0
          Dropout-75              [-1, 64, 256]               0
           Conv1d-76              [-1, 64, 256]           4,160
  MyConv1dPadSame-77              [-1, 64, 256]               0
       Bottleneck-78              [-1, 64, 256]               0
      BatchNorm1d-79              [-1, 64, 256]             128
             ReLU-80              [-1, 64, 256]               0
          Dropout-81              [-1, 64, 256]               0
           Conv1d-82              [-1, 64, 256]           4,160
  MyConv1dPadSame-83              [-1, 64, 256]               0
      BatchNorm1d-84              [-1, 64, 256]             128
             ReLU-85              [-1, 64, 256]               0
          Dropout-86              [-1, 64, 256]               0
           Conv1d-87              [-1, 64, 256]           4,160
  MyConv1dPadSame-88              [-1, 64, 256]               0
       Bottleneck-89              [-1, 64, 256]               0
      BatchNorm1d-90              [-1, 64, 256]             128
             ReLU-91              [-1, 64, 256]               0
           Linear-92                    [-1, 2]             130
================================================================
Total params: 20,730
Trainable params: 20,730
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 5.09
Params size (MB): 0.08
Estimated Total Size (MB): 5.17
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 8, kernel_size: 8, n_block: 16
************************************************************
************************************************************
(2000, 1, 256) Counter({1: 1000, 0: 1000})
(2000, 1, 256) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 8, 256]              72
   MyConv1dPadSame-2               [-1, 8, 256]               0
       BatchNorm1d-3               [-1, 8, 256]              16
              ReLU-4               [-1, 8, 256]               0
            Conv1d-5               [-1, 8, 256]              72
   MyConv1dPadSame-6               [-1, 8, 256]               0
       BatchNorm1d-7               [-1, 8, 256]              16
              ReLU-8               [-1, 8, 256]               0
           Dropout-9               [-1, 8, 256]               0
           Conv1d-10               [-1, 8, 256]              72
  MyConv1dPadSame-11               [-1, 8, 256]               0
       Bottleneck-12               [-1, 8, 256]               0
      BatchNorm1d-13               [-1, 8, 256]              16
             ReLU-14               [-1, 8, 256]               0
          Dropout-15               [-1, 8, 256]               0
           Conv1d-16               [-1, 8, 128]              72
  MyConv1dPadSame-17               [-1, 8, 128]               0
      BatchNorm1d-18               [-1, 8, 128]              16
             ReLU-19               [-1, 8, 128]               0
          Dropout-20               [-1, 8, 128]               0
           Conv1d-21               [-1, 8, 128]              72
  MyConv1dPadSame-22               [-1, 8, 128]               0
        MaxPool1d-23               [-1, 8, 128]               0
MyMaxPool1dPadSame-24               [-1, 8, 128]               0
       Bottleneck-25               [-1, 8, 128]               0
      BatchNorm1d-26               [-1, 8, 128]              16
             ReLU-27               [-1, 8, 128]               0
          Dropout-28               [-1, 8, 128]               0
           Conv1d-29               [-1, 8, 128]              72
  MyConv1dPadSame-30               [-1, 8, 128]               0
      BatchNorm1d-31               [-1, 8, 128]              16
             ReLU-32               [-1, 8, 128]               0
          Dropout-33               [-1, 8, 128]               0
           Conv1d-34               [-1, 8, 128]              72
  MyConv1dPadSame-35               [-1, 8, 128]               0
       Bottleneck-36               [-1, 8, 128]               0
      BatchNorm1d-37               [-1, 8, 128]              16
             ReLU-38               [-1, 8, 128]               0
          Dropout-39               [-1, 8, 128]               0
           Conv1d-40                [-1, 8, 64]              72
  MyConv1dPadSame-41                [-1, 8, 64]               0
      BatchNorm1d-42                [-1, 8, 64]              16
             ReLU-43                [-1, 8, 64]               0
          Dropout-44                [-1, 8, 64]               0
           Conv1d-45                [-1, 8, 64]              72
  MyConv1dPadSame-46                [-1, 8, 64]               0
        MaxPool1d-47                [-1, 8, 64]               0
MyMaxPool1dPadSame-48                [-1, 8, 64]               0
       Bottleneck-49                [-1, 8, 64]               0
      BatchNorm1d-50                [-1, 8, 64]              16
             ReLU-51                [-1, 8, 64]               0
          Dropout-52                [-1, 8, 64]               0
           Conv1d-53               [-1, 16, 64]             144
  MyConv1dPadSame-54               [-1, 16, 64]               0
      BatchNorm1d-55               [-1, 16, 64]              32
             ReLU-56               [-1, 16, 64]               0
          Dropout-57               [-1, 16, 64]               0
           Conv1d-58               [-1, 16, 64]             272
  MyConv1dPadSame-59               [-1, 16, 64]               0
       Bottleneck-60               [-1, 16, 64]               0
      BatchNorm1d-61               [-1, 16, 64]              32
             ReLU-62               [-1, 16, 64]               0
          Dropout-63               [-1, 16, 64]               0
           Conv1d-64               [-1, 16, 32]             272
  MyConv1dPadSame-65               [-1, 16, 32]               0
      BatchNorm1d-66               [-1, 16, 32]              32
             ReLU-67               [-1, 16, 32]               0
          Dropout-68               [-1, 16, 32]               0
           Conv1d-69               [-1, 16, 32]             272
  MyConv1dPadSame-70               [-1, 16, 32]               0
        MaxPool1d-71               [-1, 16, 32]               0
MyMaxPool1dPadSame-72               [-1, 16, 32]               0
       Bottleneck-73               [-1, 16, 32]               0
      BatchNorm1d-74               [-1, 16, 32]              32
             ReLU-75               [-1, 16, 32]               0
          Dropout-76               [-1, 16, 32]               0
           Conv1d-77               [-1, 16, 32]             272
  MyConv1dPadSame-78               [-1, 16, 32]               0
      BatchNorm1d-79               [-1, 16, 32]              32
             ReLU-80               [-1, 16, 32]               0
          Dropout-81               [-1, 16, 32]               0
           Conv1d-82               [-1, 16, 32]             272
  MyConv1dPadSame-83               [-1, 16, 32]               0
       Bottleneck-84               [-1, 16, 32]               0
      BatchNorm1d-85               [-1, 16, 32]              32
             ReLU-86               [-1, 16, 32]               0
          Dropout-87               [-1, 16, 32]               0
           Conv1d-88               [-1, 16, 16]             272
  MyConv1dPadSame-89               [-1, 16, 16]               0
      BatchNorm1d-90               [-1, 16, 16]              32
             ReLU-91               [-1, 16, 16]               0
          Dropout-92               [-1, 16, 16]               0
           Conv1d-93               [-1, 16, 16]             272
  MyConv1dPadSame-94               [-1, 16, 16]               0
        MaxPool1d-95               [-1, 16, 16]               0
MyMaxPool1dPadSame-96               [-1, 16, 16]               0
       Bottleneck-97               [-1, 16, 16]               0
      BatchNorm1d-98               [-1, 16, 16]              32
             ReLU-99               [-1, 16, 16]               0
         Dropout-100               [-1, 16, 16]               0
          Conv1d-101               [-1, 32, 16]             544
 MyConv1dPadSame-102               [-1, 32, 16]               0
     BatchNorm1d-103               [-1, 32, 16]              64
            ReLU-104               [-1, 32, 16]               0
         Dropout-105               [-1, 32, 16]               0
          Conv1d-106               [-1, 32, 16]           1,056
 MyConv1dPadSame-107               [-1, 32, 16]               0
      Bottleneck-108               [-1, 32, 16]               0
     BatchNorm1d-109               [-1, 32, 16]              64
            ReLU-110               [-1, 32, 16]               0
         Dropout-111               [-1, 32, 16]               0
          Conv1d-112                [-1, 32, 8]           1,056
 MyConv1dPadSame-113                [-1, 32, 8]               0
     BatchNorm1d-114                [-1, 32, 8]              64
            ReLU-115                [-1, 32, 8]               0
         Dropout-116                [-1, 32, 8]               0
          Conv1d-117                [-1, 32, 8]           1,056
 MyConv1dPadSame-118                [-1, 32, 8]               0
       MaxPool1d-119                [-1, 32, 8]               0
MyMaxPool1dPadSame-120                [-1, 32, 8]               0
      Bottleneck-121                [-1, 32, 8]               0
     BatchNorm1d-122                [-1, 32, 8]              64
            ReLU-123                [-1, 32, 8]               0
         Dropout-124                [-1, 32, 8]               0
          Conv1d-125                [-1, 32, 8]           1,056
 MyConv1dPadSame-126                [-1, 32, 8]               0
     BatchNorm1d-127                [-1, 32, 8]              64
            ReLU-128                [-1, 32, 8]               0
         Dropout-129                [-1, 32, 8]               0
          Conv1d-130                [-1, 32, 8]           1,056
 MyConv1dPadSame-131                [-1, 32, 8]               0
      Bottleneck-132                [-1, 32, 8]               0
     BatchNorm1d-133                [-1, 32, 8]              64
            ReLU-134                [-1, 32, 8]               0
         Dropout-135                [-1, 32, 8]               0
          Conv1d-136                [-1, 32, 4]           1,056
 MyConv1dPadSame-137                [-1, 32, 4]               0
     BatchNorm1d-138                [-1, 32, 4]              64
            ReLU-139                [-1, 32, 4]               0
         Dropout-140                [-1, 32, 4]               0
          Conv1d-141                [-1, 32, 4]           1,056
 MyConv1dPadSame-142                [-1, 32, 4]               0
       MaxPool1d-143                [-1, 32, 4]               0
MyMaxPool1dPadSame-144                [-1, 32, 4]               0
      Bottleneck-145                [-1, 32, 4]               0
     BatchNorm1d-146                [-1, 32, 4]              64
            ReLU-147                [-1, 32, 4]               0
         Dropout-148                [-1, 32, 4]               0
          Conv1d-149                [-1, 64, 4]           2,112
 MyConv1dPadSame-150                [-1, 64, 4]               0
     BatchNorm1d-151                [-1, 64, 4]             128
            ReLU-152                [-1, 64, 4]               0
         Dropout-153                [-1, 64, 4]               0
          Conv1d-154                [-1, 64, 4]           4,160
 MyConv1dPadSame-155                [-1, 64, 4]               0
      Bottleneck-156                [-1, 64, 4]               0
     BatchNorm1d-157                [-1, 64, 4]             128
            ReLU-158                [-1, 64, 4]               0
         Dropout-159                [-1, 64, 4]               0
          Conv1d-160                [-1, 64, 2]           4,160
 MyConv1dPadSame-161                [-1, 64, 2]               0
     BatchNorm1d-162                [-1, 64, 2]             128
            ReLU-163                [-1, 64, 2]               0
         Dropout-164                [-1, 64, 2]               0
          Conv1d-165                [-1, 64, 2]           4,160
 MyConv1dPadSame-166                [-1, 64, 2]               0
       MaxPool1d-167                [-1, 64, 2]               0
MyMaxPool1dPadSame-168                [-1, 64, 2]               0
      Bottleneck-169                [-1, 64, 2]               0
     BatchNorm1d-170                [-1, 64, 2]             128
            ReLU-171                [-1, 64, 2]               0
         Dropout-172                [-1, 64, 2]               0
          Conv1d-173                [-1, 64, 2]           4,160
 MyConv1dPadSame-174                [-1, 64, 2]               0
     BatchNorm1d-175                [-1, 64, 2]             128
            ReLU-176                [-1, 64, 2]               0
         Dropout-177                [-1, 64, 2]               0
          Conv1d-178                [-1, 64, 2]           4,160
 MyConv1dPadSame-179                [-1, 64, 2]               0
      Bottleneck-180                [-1, 64, 2]               0
     BatchNorm1d-181                [-1, 64, 2]             128
            ReLU-182                [-1, 64, 2]               0
         Dropout-183                [-1, 64, 2]               0
          Conv1d-184                [-1, 64, 1]           4,160
 MyConv1dPadSame-185                [-1, 64, 1]               0
     BatchNorm1d-186                [-1, 64, 1]             128
            ReLU-187                [-1, 64, 1]               0
         Dropout-188                [-1, 64, 1]               0
          Conv1d-189                [-1, 64, 1]           4,160
 MyConv1dPadSame-190                [-1, 64, 1]               0
       MaxPool1d-191                [-1, 64, 1]               0
MyMaxPool1dPadSame-192                [-1, 64, 1]               0
      Bottleneck-193                [-1, 64, 1]               0
     BatchNorm1d-194                [-1, 64, 1]             128
            ReLU-195                [-1, 64, 1]               0
          Linear-196                    [-1, 2]             130
================================================================
Total params: 43,930
Trainable params: 43,930
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.83
Params size (MB): 0.17
Estimated Total Size (MB): 1.00
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 8, kernel_size: 16, n_block: 2
************************************************************
************************************************************
(2000, 1, 256) Counter({1: 1000, 0: 1000})
(2000, 1, 256) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 8, 256]             136
   MyConv1dPadSame-2               [-1, 8, 256]               0
       BatchNorm1d-3               [-1, 8, 256]              16
              ReLU-4               [-1, 8, 256]               0
            Conv1d-5               [-1, 8, 256]             136
   MyConv1dPadSame-6               [-1, 8, 256]               0
       BatchNorm1d-7               [-1, 8, 256]              16
              ReLU-8               [-1, 8, 256]               0
           Dropout-9               [-1, 8, 256]               0
           Conv1d-10               [-1, 8, 256]             136
  MyConv1dPadSame-11               [-1, 8, 256]               0
       Bottleneck-12               [-1, 8, 256]               0
      BatchNorm1d-13               [-1, 8, 256]              16
             ReLU-14               [-1, 8, 256]               0
          Dropout-15               [-1, 8, 256]               0
           Conv1d-16              [-1, 16, 256]             272
  MyConv1dPadSame-17              [-1, 16, 256]               0
      BatchNorm1d-18              [-1, 16, 256]              32
             ReLU-19              [-1, 16, 256]               0
          Dropout-20              [-1, 16, 256]               0
           Conv1d-21              [-1, 16, 256]             528
  MyConv1dPadSame-22              [-1, 16, 256]               0
       Bottleneck-23              [-1, 16, 256]               0
      BatchNorm1d-24              [-1, 16, 256]              32
             ReLU-25              [-1, 16, 256]               0
           Linear-26                    [-1, 2]              34
================================================================
Total params: 1,354
Trainable params: 1,354
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.55
Params size (MB): 0.01
Estimated Total Size (MB): 0.55
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 8, kernel_size: 16, n_block: 4
************************************************************
************************************************************
(2000, 1, 256) Counter({1: 1000, 0: 1000})
(2000, 1, 256) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 8, 256]             136
   MyConv1dPadSame-2               [-1, 8, 256]               0
       BatchNorm1d-3               [-1, 8, 256]              16
              ReLU-4               [-1, 8, 256]               0
            Conv1d-5               [-1, 8, 256]             136
   MyConv1dPadSame-6               [-1, 8, 256]               0
       BatchNorm1d-7               [-1, 8, 256]              16
              ReLU-8               [-1, 8, 256]               0
           Dropout-9               [-1, 8, 256]               0
           Conv1d-10               [-1, 8, 256]             136
  MyConv1dPadSame-11               [-1, 8, 256]               0
       Bottleneck-12               [-1, 8, 256]               0
      BatchNorm1d-13               [-1, 8, 256]              16
             ReLU-14               [-1, 8, 256]               0
          Dropout-15               [-1, 8, 256]               0
           Conv1d-16              [-1, 16, 256]             272
  MyConv1dPadSame-17              [-1, 16, 256]               0
      BatchNorm1d-18              [-1, 16, 256]              32
             ReLU-19              [-1, 16, 256]               0
          Dropout-20              [-1, 16, 256]               0
           Conv1d-21              [-1, 16, 256]             528
  MyConv1dPadSame-22              [-1, 16, 256]               0
       Bottleneck-23              [-1, 16, 256]               0
      BatchNorm1d-24              [-1, 16, 256]              32
             ReLU-25              [-1, 16, 256]               0
          Dropout-26              [-1, 16, 256]               0
           Conv1d-27              [-1, 32, 256]           1,056
  MyConv1dPadSame-28              [-1, 32, 256]               0
      BatchNorm1d-29              [-1, 32, 256]              64
             ReLU-30              [-1, 32, 256]               0
          Dropout-31              [-1, 32, 256]               0
           Conv1d-32              [-1, 32, 256]           2,080
  MyConv1dPadSame-33              [-1, 32, 256]               0
       Bottleneck-34              [-1, 32, 256]               0
      BatchNorm1d-35              [-1, 32, 256]              64
             ReLU-36              [-1, 32, 256]               0
          Dropout-37              [-1, 32, 256]               0
           Conv1d-38              [-1, 64, 256]           4,160
  MyConv1dPadSame-39              [-1, 64, 256]               0
      BatchNorm1d-40              [-1, 64, 256]             128
             ReLU-41              [-1, 64, 256]               0
          Dropout-42              [-1, 64, 256]               0
           Conv1d-43              [-1, 64, 256]           8,256
  MyConv1dPadSame-44              [-1, 64, 256]               0
       Bottleneck-45              [-1, 64, 256]               0
      BatchNorm1d-46              [-1, 64, 256]             128
             ReLU-47              [-1, 64, 256]               0
           Linear-48                    [-1, 2]             130
================================================================
Total params: 17,386
Trainable params: 17,386
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 2.52
Params size (MB): 0.07
Estimated Total Size (MB): 2.58
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 8, kernel_size: 16, n_block: 8
************************************************************
************************************************************
(2000, 1, 256) Counter({0: 1000, 1: 1000})
(2000, 1, 256) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 8, 256]             136
   MyConv1dPadSame-2               [-1, 8, 256]               0
       BatchNorm1d-3               [-1, 8, 256]              16
              ReLU-4               [-1, 8, 256]               0
            Conv1d-5               [-1, 8, 256]             136
   MyConv1dPadSame-6               [-1, 8, 256]               0
       BatchNorm1d-7               [-1, 8, 256]              16
              ReLU-8               [-1, 8, 256]               0
           Dropout-9               [-1, 8, 256]               0
           Conv1d-10               [-1, 8, 256]             136
  MyConv1dPadSame-11               [-1, 8, 256]               0
       Bottleneck-12               [-1, 8, 256]               0
      BatchNorm1d-13               [-1, 8, 256]              16
             ReLU-14               [-1, 8, 256]               0
          Dropout-15               [-1, 8, 256]               0
           Conv1d-16               [-1, 8, 256]             136
  MyConv1dPadSame-17               [-1, 8, 256]               0
      BatchNorm1d-18               [-1, 8, 256]              16
             ReLU-19               [-1, 8, 256]               0
          Dropout-20               [-1, 8, 256]               0
           Conv1d-21               [-1, 8, 256]             136
  MyConv1dPadSame-22               [-1, 8, 256]               0
       Bottleneck-23               [-1, 8, 256]               0
      BatchNorm1d-24               [-1, 8, 256]              16
             ReLU-25               [-1, 8, 256]               0
          Dropout-26               [-1, 8, 256]               0
           Conv1d-27              [-1, 16, 256]             272
  MyConv1dPadSame-28              [-1, 16, 256]               0
      BatchNorm1d-29              [-1, 16, 256]              32
             ReLU-30              [-1, 16, 256]               0
          Dropout-31              [-1, 16, 256]               0
           Conv1d-32              [-1, 16, 256]             528
  MyConv1dPadSame-33              [-1, 16, 256]               0
       Bottleneck-34              [-1, 16, 256]               0
      BatchNorm1d-35              [-1, 16, 256]              32
             ReLU-36              [-1, 16, 256]               0
          Dropout-37              [-1, 16, 256]               0
           Conv1d-38              [-1, 16, 256]             528
  MyConv1dPadSame-39              [-1, 16, 256]               0
      BatchNorm1d-40              [-1, 16, 256]              32
             ReLU-41              [-1, 16, 256]               0
          Dropout-42              [-1, 16, 256]               0
           Conv1d-43              [-1, 16, 256]             528
  MyConv1dPadSame-44              [-1, 16, 256]               0
       Bottleneck-45              [-1, 16, 256]               0
      BatchNorm1d-46              [-1, 16, 256]              32
             ReLU-47              [-1, 16, 256]               0
          Dropout-48              [-1, 16, 256]               0
           Conv1d-49              [-1, 32, 256]           1,056
  MyConv1dPadSame-50              [-1, 32, 256]               0
      BatchNorm1d-51              [-1, 32, 256]              64
             ReLU-52              [-1, 32, 256]               0
          Dropout-53              [-1, 32, 256]               0
           Conv1d-54              [-1, 32, 256]           2,080
  MyConv1dPadSame-55              [-1, 32, 256]               0
       Bottleneck-56              [-1, 32, 256]               0
      BatchNorm1d-57              [-1, 32, 256]              64
             ReLU-58              [-1, 32, 256]               0
          Dropout-59              [-1, 32, 256]               0
           Conv1d-60              [-1, 32, 256]           2,080
  MyConv1dPadSame-61              [-1, 32, 256]               0
      BatchNorm1d-62              [-1, 32, 256]              64
             ReLU-63              [-1, 32, 256]               0
          Dropout-64              [-1, 32, 256]               0
           Conv1d-65              [-1, 32, 256]           2,080
  MyConv1dPadSame-66              [-1, 32, 256]               0
       Bottleneck-67              [-1, 32, 256]               0
      BatchNorm1d-68              [-1, 32, 256]              64
             ReLU-69              [-1, 32, 256]               0
          Dropout-70              [-1, 32, 256]               0
           Conv1d-71              [-1, 64, 256]           4,160
  MyConv1dPadSame-72              [-1, 64, 256]               0
      BatchNorm1d-73              [-1, 64, 256]             128
             ReLU-74              [-1, 64, 256]               0
          Dropout-75              [-1, 64, 256]               0
           Conv1d-76              [-1, 64, 256]           8,256
  MyConv1dPadSame-77              [-1, 64, 256]               0
       Bottleneck-78              [-1, 64, 256]               0
      BatchNorm1d-79              [-1, 64, 256]             128
             ReLU-80              [-1, 64, 256]               0
          Dropout-81              [-1, 64, 256]               0
           Conv1d-82              [-1, 64, 256]           8,256
  MyConv1dPadSame-83              [-1, 64, 256]               0
      BatchNorm1d-84              [-1, 64, 256]             128
             ReLU-85              [-1, 64, 256]               0
          Dropout-86              [-1, 64, 256]               0
           Conv1d-87              [-1, 64, 256]           8,256
  MyConv1dPadSame-88              [-1, 64, 256]               0
       Bottleneck-89              [-1, 64, 256]               0
      BatchNorm1d-90              [-1, 64, 256]             128
             ReLU-91              [-1, 64, 256]               0
           Linear-92                    [-1, 2]             130
================================================================
Total params: 39,866
Trainable params: 39,866
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 5.09
Params size (MB): 0.15
Estimated Total Size (MB): 5.25
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 8, kernel_size: 16, n_block: 16
************************************************************
************************************************************
(2000, 1, 256) Counter({0: 1000, 1: 1000})
(2000, 1, 256) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1               [-1, 8, 256]             136
   MyConv1dPadSame-2               [-1, 8, 256]               0
       BatchNorm1d-3               [-1, 8, 256]              16
              ReLU-4               [-1, 8, 256]               0
            Conv1d-5               [-1, 8, 256]             136
   MyConv1dPadSame-6               [-1, 8, 256]               0
       BatchNorm1d-7               [-1, 8, 256]              16
              ReLU-8               [-1, 8, 256]               0
           Dropout-9               [-1, 8, 256]               0
           Conv1d-10               [-1, 8, 256]             136
  MyConv1dPadSame-11               [-1, 8, 256]               0
       Bottleneck-12               [-1, 8, 256]               0
      BatchNorm1d-13               [-1, 8, 256]              16
             ReLU-14               [-1, 8, 256]               0
          Dropout-15               [-1, 8, 256]               0
           Conv1d-16               [-1, 8, 128]             136
  MyConv1dPadSame-17               [-1, 8, 128]               0
      BatchNorm1d-18               [-1, 8, 128]              16
             ReLU-19               [-1, 8, 128]               0
          Dropout-20               [-1, 8, 128]               0
           Conv1d-21               [-1, 8, 128]             136
  MyConv1dPadSame-22               [-1, 8, 128]               0
        MaxPool1d-23               [-1, 8, 128]               0
MyMaxPool1dPadSame-24               [-1, 8, 128]               0
       Bottleneck-25               [-1, 8, 128]               0
      BatchNorm1d-26               [-1, 8, 128]              16
             ReLU-27               [-1, 8, 128]               0
          Dropout-28               [-1, 8, 128]               0
           Conv1d-29               [-1, 8, 128]             136
  MyConv1dPadSame-30               [-1, 8, 128]               0
      BatchNorm1d-31               [-1, 8, 128]              16
             ReLU-32               [-1, 8, 128]               0
          Dropout-33               [-1, 8, 128]               0
           Conv1d-34               [-1, 8, 128]             136
  MyConv1dPadSame-35               [-1, 8, 128]               0
       Bottleneck-36               [-1, 8, 128]               0
      BatchNorm1d-37               [-1, 8, 128]              16
             ReLU-38               [-1, 8, 128]               0
          Dropout-39               [-1, 8, 128]               0
           Conv1d-40                [-1, 8, 64]             136
  MyConv1dPadSame-41                [-1, 8, 64]               0
      BatchNorm1d-42                [-1, 8, 64]              16
             ReLU-43                [-1, 8, 64]               0
          Dropout-44                [-1, 8, 64]               0
           Conv1d-45                [-1, 8, 64]             136
  MyConv1dPadSame-46                [-1, 8, 64]               0
        MaxPool1d-47                [-1, 8, 64]               0
MyMaxPool1dPadSame-48                [-1, 8, 64]               0
       Bottleneck-49                [-1, 8, 64]               0
      BatchNorm1d-50                [-1, 8, 64]              16
             ReLU-51                [-1, 8, 64]               0
          Dropout-52                [-1, 8, 64]               0
           Conv1d-53               [-1, 16, 64]             272
  MyConv1dPadSame-54               [-1, 16, 64]               0
      BatchNorm1d-55               [-1, 16, 64]              32
             ReLU-56               [-1, 16, 64]               0
          Dropout-57               [-1, 16, 64]               0
           Conv1d-58               [-1, 16, 64]             528
  MyConv1dPadSame-59               [-1, 16, 64]               0
       Bottleneck-60               [-1, 16, 64]               0
      BatchNorm1d-61               [-1, 16, 64]              32
             ReLU-62               [-1, 16, 64]               0
          Dropout-63               [-1, 16, 64]               0
           Conv1d-64               [-1, 16, 32]             528
  MyConv1dPadSame-65               [-1, 16, 32]               0
      BatchNorm1d-66               [-1, 16, 32]              32
             ReLU-67               [-1, 16, 32]               0
          Dropout-68               [-1, 16, 32]               0
           Conv1d-69               [-1, 16, 32]             528
  MyConv1dPadSame-70               [-1, 16, 32]               0
        MaxPool1d-71               [-1, 16, 32]               0
MyMaxPool1dPadSame-72               [-1, 16, 32]               0
       Bottleneck-73               [-1, 16, 32]               0
      BatchNorm1d-74               [-1, 16, 32]              32
             ReLU-75               [-1, 16, 32]               0
          Dropout-76               [-1, 16, 32]               0
           Conv1d-77               [-1, 16, 32]             528
  MyConv1dPadSame-78               [-1, 16, 32]               0
      BatchNorm1d-79               [-1, 16, 32]              32
             ReLU-80               [-1, 16, 32]               0
          Dropout-81               [-1, 16, 32]               0
           Conv1d-82               [-1, 16, 32]             528
  MyConv1dPadSame-83               [-1, 16, 32]               0
       Bottleneck-84               [-1, 16, 32]               0
      BatchNorm1d-85               [-1, 16, 32]              32
             ReLU-86               [-1, 16, 32]               0
          Dropout-87               [-1, 16, 32]               0
           Conv1d-88               [-1, 16, 16]             528
  MyConv1dPadSame-89               [-1, 16, 16]               0
      BatchNorm1d-90               [-1, 16, 16]              32
             ReLU-91               [-1, 16, 16]               0
          Dropout-92               [-1, 16, 16]               0
           Conv1d-93               [-1, 16, 16]             528
  MyConv1dPadSame-94               [-1, 16, 16]               0
        MaxPool1d-95               [-1, 16, 16]               0
MyMaxPool1dPadSame-96               [-1, 16, 16]               0
       Bottleneck-97               [-1, 16, 16]               0
      BatchNorm1d-98               [-1, 16, 16]              32
             ReLU-99               [-1, 16, 16]               0
         Dropout-100               [-1, 16, 16]               0
          Conv1d-101               [-1, 32, 16]           1,056
 MyConv1dPadSame-102               [-1, 32, 16]               0
     BatchNorm1d-103               [-1, 32, 16]              64
            ReLU-104               [-1, 32, 16]               0
         Dropout-105               [-1, 32, 16]               0
          Conv1d-106               [-1, 32, 16]           2,080
 MyConv1dPadSame-107               [-1, 32, 16]               0
      Bottleneck-108               [-1, 32, 16]               0
     BatchNorm1d-109               [-1, 32, 16]              64
            ReLU-110               [-1, 32, 16]               0
         Dropout-111               [-1, 32, 16]               0
          Conv1d-112                [-1, 32, 8]           2,080
 MyConv1dPadSame-113                [-1, 32, 8]               0
     BatchNorm1d-114                [-1, 32, 8]              64
            ReLU-115                [-1, 32, 8]               0
         Dropout-116                [-1, 32, 8]               0
          Conv1d-117                [-1, 32, 8]           2,080
 MyConv1dPadSame-118                [-1, 32, 8]               0
       MaxPool1d-119                [-1, 32, 8]               0
MyMaxPool1dPadSame-120                [-1, 32, 8]               0
      Bottleneck-121                [-1, 32, 8]               0
     BatchNorm1d-122                [-1, 32, 8]              64
            ReLU-123                [-1, 32, 8]               0
         Dropout-124                [-1, 32, 8]               0
          Conv1d-125                [-1, 32, 8]           2,080
 MyConv1dPadSame-126                [-1, 32, 8]               0
     BatchNorm1d-127                [-1, 32, 8]              64
            ReLU-128                [-1, 32, 8]               0
         Dropout-129                [-1, 32, 8]               0
          Conv1d-130                [-1, 32, 8]           2,080
 MyConv1dPadSame-131                [-1, 32, 8]               0
      Bottleneck-132                [-1, 32, 8]               0
     BatchNorm1d-133                [-1, 32, 8]              64
            ReLU-134                [-1, 32, 8]               0
         Dropout-135                [-1, 32, 8]               0
          Conv1d-136                [-1, 32, 4]           2,080
 MyConv1dPadSame-137                [-1, 32, 4]               0
     BatchNorm1d-138                [-1, 32, 4]              64
            ReLU-139                [-1, 32, 4]               0
         Dropout-140                [-1, 32, 4]               0
          Conv1d-141                [-1, 32, 4]           2,080
 MyConv1dPadSame-142                [-1, 32, 4]               0
       MaxPool1d-143                [-1, 32, 4]               0
MyMaxPool1dPadSame-144                [-1, 32, 4]               0
      Bottleneck-145                [-1, 32, 4]               0
     BatchNorm1d-146                [-1, 32, 4]              64
            ReLU-147                [-1, 32, 4]               0
         Dropout-148                [-1, 32, 4]               0
          Conv1d-149                [-1, 64, 4]           4,160
 MyConv1dPadSame-150                [-1, 64, 4]               0
     BatchNorm1d-151                [-1, 64, 4]             128
            ReLU-152                [-1, 64, 4]               0
         Dropout-153                [-1, 64, 4]               0
          Conv1d-154                [-1, 64, 4]           8,256
 MyConv1dPadSame-155                [-1, 64, 4]               0
      Bottleneck-156                [-1, 64, 4]               0
     BatchNorm1d-157                [-1, 64, 4]             128
            ReLU-158                [-1, 64, 4]               0
         Dropout-159                [-1, 64, 4]               0
          Conv1d-160                [-1, 64, 2]           8,256
 MyConv1dPadSame-161                [-1, 64, 2]               0
     BatchNorm1d-162                [-1, 64, 2]             128
            ReLU-163                [-1, 64, 2]               0
         Dropout-164                [-1, 64, 2]               0
          Conv1d-165                [-1, 64, 2]           8,256
 MyConv1dPadSame-166                [-1, 64, 2]               0
       MaxPool1d-167                [-1, 64, 2]               0
MyMaxPool1dPadSame-168                [-1, 64, 2]               0
      Bottleneck-169                [-1, 64, 2]               0
     BatchNorm1d-170                [-1, 64, 2]             128
            ReLU-171                [-1, 64, 2]               0
         Dropout-172                [-1, 64, 2]               0
          Conv1d-173                [-1, 64, 2]           8,256
 MyConv1dPadSame-174                [-1, 64, 2]               0
     BatchNorm1d-175                [-1, 64, 2]             128
            ReLU-176                [-1, 64, 2]               0
         Dropout-177                [-1, 64, 2]               0
          Conv1d-178                [-1, 64, 2]           8,256
 MyConv1dPadSame-179                [-1, 64, 2]               0
      Bottleneck-180                [-1, 64, 2]               0
     BatchNorm1d-181                [-1, 64, 2]             128
            ReLU-182                [-1, 64, 2]               0
         Dropout-183                [-1, 64, 2]               0
          Conv1d-184                [-1, 64, 1]           8,256
 MyConv1dPadSame-185                [-1, 64, 1]               0
     BatchNorm1d-186                [-1, 64, 1]             128
            ReLU-187                [-1, 64, 1]               0
         Dropout-188                [-1, 64, 1]               0
          Conv1d-189                [-1, 64, 1]           8,256
 MyConv1dPadSame-190                [-1, 64, 1]               0
       MaxPool1d-191                [-1, 64, 1]               0
MyMaxPool1dPadSame-192                [-1, 64, 1]               0
      Bottleneck-193                [-1, 64, 1]               0
     BatchNorm1d-194                [-1, 64, 1]             128
            ReLU-195                [-1, 64, 1]               0
          Linear-196                    [-1, 2]             130
================================================================
Total params: 84,826
Trainable params: 84,826
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.83
Params size (MB): 0.32
Estimated Total Size (MB): 1.16
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 16, kernel_size: 2, n_block: 2
************************************************************
************************************************************
(2000, 1, 256) Counter({1: 1000, 0: 1000})
(2000, 1, 256) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 16, 256]              48
   MyConv1dPadSame-2              [-1, 16, 256]               0
       BatchNorm1d-3              [-1, 16, 256]              32
              ReLU-4              [-1, 16, 256]               0
            Conv1d-5              [-1, 16, 256]              48
   MyConv1dPadSame-6              [-1, 16, 256]               0
       BatchNorm1d-7              [-1, 16, 256]              32
              ReLU-8              [-1, 16, 256]               0
           Dropout-9              [-1, 16, 256]               0
           Conv1d-10              [-1, 16, 256]              48
  MyConv1dPadSame-11              [-1, 16, 256]               0
       Bottleneck-12              [-1, 16, 256]               0
      BatchNorm1d-13              [-1, 16, 256]              32
             ReLU-14              [-1, 16, 256]               0
          Dropout-15              [-1, 16, 256]               0
           Conv1d-16              [-1, 32, 256]              96
  MyConv1dPadSame-17              [-1, 32, 256]               0
      BatchNorm1d-18              [-1, 32, 256]              64
             ReLU-19              [-1, 32, 256]               0
          Dropout-20              [-1, 32, 256]               0
           Conv1d-21              [-1, 32, 256]             160
  MyConv1dPadSame-22              [-1, 32, 256]               0
       Bottleneck-23              [-1, 32, 256]               0
      BatchNorm1d-24              [-1, 32, 256]              64
             ReLU-25              [-1, 32, 256]               0
           Linear-26                    [-1, 2]              66
================================================================
Total params: 690
Trainable params: 690
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 1.09
Params size (MB): 0.00
Estimated Total Size (MB): 1.10
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 16, kernel_size: 2, n_block: 4
************************************************************
************************************************************
(2000, 1, 256) Counter({1: 1000, 0: 1000})
(2000, 1, 256) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 16, 256]              48
   MyConv1dPadSame-2              [-1, 16, 256]               0
       BatchNorm1d-3              [-1, 16, 256]              32
              ReLU-4              [-1, 16, 256]               0
            Conv1d-5              [-1, 16, 256]              48
   MyConv1dPadSame-6              [-1, 16, 256]               0
       BatchNorm1d-7              [-1, 16, 256]              32
              ReLU-8              [-1, 16, 256]               0
           Dropout-9              [-1, 16, 256]               0
           Conv1d-10              [-1, 16, 256]              48
  MyConv1dPadSame-11              [-1, 16, 256]               0
       Bottleneck-12              [-1, 16, 256]               0
      BatchNorm1d-13              [-1, 16, 256]              32
             ReLU-14              [-1, 16, 256]               0
          Dropout-15              [-1, 16, 256]               0
           Conv1d-16              [-1, 32, 256]              96
  MyConv1dPadSame-17              [-1, 32, 256]               0
      BatchNorm1d-18              [-1, 32, 256]              64
             ReLU-19              [-1, 32, 256]               0
          Dropout-20              [-1, 32, 256]               0
           Conv1d-21              [-1, 32, 256]             160
  MyConv1dPadSame-22              [-1, 32, 256]               0
       Bottleneck-23              [-1, 32, 256]               0
      BatchNorm1d-24              [-1, 32, 256]              64
             ReLU-25              [-1, 32, 256]               0
          Dropout-26              [-1, 32, 256]               0
           Conv1d-27              [-1, 64, 256]             320
  MyConv1dPadSame-28              [-1, 64, 256]               0
      BatchNorm1d-29              [-1, 64, 256]             128
             ReLU-30              [-1, 64, 256]               0
          Dropout-31              [-1, 64, 256]               0
           Conv1d-32              [-1, 64, 256]             576
  MyConv1dPadSame-33              [-1, 64, 256]               0
       Bottleneck-34              [-1, 64, 256]               0
      BatchNorm1d-35              [-1, 64, 256]             128
             ReLU-36              [-1, 64, 256]               0
          Dropout-37              [-1, 64, 256]               0
           Conv1d-38             [-1, 128, 256]           1,152
  MyConv1dPadSame-39             [-1, 128, 256]               0
      BatchNorm1d-40             [-1, 128, 256]             256
             ReLU-41             [-1, 128, 256]               0
          Dropout-42             [-1, 128, 256]               0
           Conv1d-43             [-1, 128, 256]           2,176
  MyConv1dPadSame-44             [-1, 128, 256]               0
       Bottleneck-45             [-1, 128, 256]               0
      BatchNorm1d-46             [-1, 128, 256]             256
             ReLU-47             [-1, 128, 256]               0
           Linear-48                    [-1, 2]             258
================================================================
Total params: 5,874
Trainable params: 5,874
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 5.03
Params size (MB): 0.02
Estimated Total Size (MB): 5.05
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 16, kernel_size: 2, n_block: 8
************************************************************
************************************************************
(2000, 1, 256) Counter({1: 1000, 0: 1000})
(2000, 1, 256) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 16, 256]              48
   MyConv1dPadSame-2              [-1, 16, 256]               0
       BatchNorm1d-3              [-1, 16, 256]              32
              ReLU-4              [-1, 16, 256]               0
            Conv1d-5              [-1, 16, 256]              48
   MyConv1dPadSame-6              [-1, 16, 256]               0
       BatchNorm1d-7              [-1, 16, 256]              32
              ReLU-8              [-1, 16, 256]               0
           Dropout-9              [-1, 16, 256]               0
           Conv1d-10              [-1, 16, 256]              48
  MyConv1dPadSame-11              [-1, 16, 256]               0
       Bottleneck-12              [-1, 16, 256]               0
      BatchNorm1d-13              [-1, 16, 256]              32
             ReLU-14              [-1, 16, 256]               0
          Dropout-15              [-1, 16, 256]               0
           Conv1d-16              [-1, 16, 256]              48
  MyConv1dPadSame-17              [-1, 16, 256]               0
      BatchNorm1d-18              [-1, 16, 256]              32
             ReLU-19              [-1, 16, 256]               0
          Dropout-20              [-1, 16, 256]               0
           Conv1d-21              [-1, 16, 256]              48
  MyConv1dPadSame-22              [-1, 16, 256]               0
       Bottleneck-23              [-1, 16, 256]               0
      BatchNorm1d-24              [-1, 16, 256]              32
             ReLU-25              [-1, 16, 256]               0
          Dropout-26              [-1, 16, 256]               0
           Conv1d-27              [-1, 32, 256]              96
  MyConv1dPadSame-28              [-1, 32, 256]               0
      BatchNorm1d-29              [-1, 32, 256]              64
             ReLU-30              [-1, 32, 256]               0
          Dropout-31              [-1, 32, 256]               0
           Conv1d-32              [-1, 32, 256]             160
  MyConv1dPadSame-33              [-1, 32, 256]               0
       Bottleneck-34              [-1, 32, 256]               0
      BatchNorm1d-35              [-1, 32, 256]              64
             ReLU-36              [-1, 32, 256]               0
          Dropout-37              [-1, 32, 256]               0
           Conv1d-38              [-1, 32, 256]             160
  MyConv1dPadSame-39              [-1, 32, 256]               0
      BatchNorm1d-40              [-1, 32, 256]              64
             ReLU-41              [-1, 32, 256]               0
          Dropout-42              [-1, 32, 256]               0
           Conv1d-43              [-1, 32, 256]             160
  MyConv1dPadSame-44              [-1, 32, 256]               0
       Bottleneck-45              [-1, 32, 256]               0
      BatchNorm1d-46              [-1, 32, 256]              64
             ReLU-47              [-1, 32, 256]               0
          Dropout-48              [-1, 32, 256]               0
           Conv1d-49              [-1, 64, 256]             320
  MyConv1dPadSame-50              [-1, 64, 256]               0
      BatchNorm1d-51              [-1, 64, 256]             128
             ReLU-52              [-1, 64, 256]               0
          Dropout-53              [-1, 64, 256]               0
           Conv1d-54              [-1, 64, 256]             576
  MyConv1dPadSame-55              [-1, 64, 256]               0
       Bottleneck-56              [-1, 64, 256]               0
      BatchNorm1d-57              [-1, 64, 256]             128
             ReLU-58              [-1, 64, 256]               0
          Dropout-59              [-1, 64, 256]               0
           Conv1d-60              [-1, 64, 256]             576
  MyConv1dPadSame-61              [-1, 64, 256]               0
      BatchNorm1d-62              [-1, 64, 256]             128
             ReLU-63              [-1, 64, 256]               0
          Dropout-64              [-1, 64, 256]               0
           Conv1d-65              [-1, 64, 256]             576
  MyConv1dPadSame-66              [-1, 64, 256]               0
       Bottleneck-67              [-1, 64, 256]               0
      BatchNorm1d-68              [-1, 64, 256]             128
             ReLU-69              [-1, 64, 256]               0
          Dropout-70              [-1, 64, 256]               0
           Conv1d-71             [-1, 128, 256]           1,152
  MyConv1dPadSame-72             [-1, 128, 256]               0
      BatchNorm1d-73             [-1, 128, 256]             256
             ReLU-74             [-1, 128, 256]               0
          Dropout-75             [-1, 128, 256]               0
           Conv1d-76             [-1, 128, 256]           2,176
  MyConv1dPadSame-77             [-1, 128, 256]               0
       Bottleneck-78             [-1, 128, 256]               0
      BatchNorm1d-79             [-1, 128, 256]             256
             ReLU-80             [-1, 128, 256]               0
          Dropout-81             [-1, 128, 256]               0
           Conv1d-82             [-1, 128, 256]           2,176
  MyConv1dPadSame-83             [-1, 128, 256]               0
      BatchNorm1d-84             [-1, 128, 256]             256
             ReLU-85             [-1, 128, 256]               0
          Dropout-86             [-1, 128, 256]               0
           Conv1d-87             [-1, 128, 256]           2,176
  MyConv1dPadSame-88             [-1, 128, 256]               0
       Bottleneck-89             [-1, 128, 256]               0
      BatchNorm1d-90             [-1, 128, 256]             256
             ReLU-91             [-1, 128, 256]               0
           Linear-92                    [-1, 2]             258
================================================================
Total params: 12,754
Trainable params: 12,754
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 10.19
Params size (MB): 0.05
Estimated Total Size (MB): 10.24
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 16, kernel_size: 2, n_block: 16
************************************************************
************************************************************
(2000, 1, 256) Counter({0: 1000, 1: 1000})
(2000, 1, 256) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 16, 256]              48
   MyConv1dPadSame-2              [-1, 16, 256]               0
       BatchNorm1d-3              [-1, 16, 256]              32
              ReLU-4              [-1, 16, 256]               0
            Conv1d-5              [-1, 16, 256]              48
   MyConv1dPadSame-6              [-1, 16, 256]               0
       BatchNorm1d-7              [-1, 16, 256]              32
              ReLU-8              [-1, 16, 256]               0
           Dropout-9              [-1, 16, 256]               0
           Conv1d-10              [-1, 16, 256]              48
  MyConv1dPadSame-11              [-1, 16, 256]               0
       Bottleneck-12              [-1, 16, 256]               0
      BatchNorm1d-13              [-1, 16, 256]              32
             ReLU-14              [-1, 16, 256]               0
          Dropout-15              [-1, 16, 256]               0
           Conv1d-16              [-1, 16, 128]              48
  MyConv1dPadSame-17              [-1, 16, 128]               0
      BatchNorm1d-18              [-1, 16, 128]              32
             ReLU-19              [-1, 16, 128]               0
          Dropout-20              [-1, 16, 128]               0
           Conv1d-21              [-1, 16, 128]              48
  MyConv1dPadSame-22              [-1, 16, 128]               0
        MaxPool1d-23              [-1, 16, 128]               0
MyMaxPool1dPadSame-24              [-1, 16, 128]               0
       Bottleneck-25              [-1, 16, 128]               0
      BatchNorm1d-26              [-1, 16, 128]              32
             ReLU-27              [-1, 16, 128]               0
          Dropout-28              [-1, 16, 128]               0
           Conv1d-29              [-1, 16, 128]              48
  MyConv1dPadSame-30              [-1, 16, 128]               0
      BatchNorm1d-31              [-1, 16, 128]              32
             ReLU-32              [-1, 16, 128]               0
          Dropout-33              [-1, 16, 128]               0
           Conv1d-34              [-1, 16, 128]              48
  MyConv1dPadSame-35              [-1, 16, 128]               0
       Bottleneck-36              [-1, 16, 128]               0
      BatchNorm1d-37              [-1, 16, 128]              32
             ReLU-38              [-1, 16, 128]               0
          Dropout-39              [-1, 16, 128]               0
           Conv1d-40               [-1, 16, 64]              48
  MyConv1dPadSame-41               [-1, 16, 64]               0
      BatchNorm1d-42               [-1, 16, 64]              32
             ReLU-43               [-1, 16, 64]               0
          Dropout-44               [-1, 16, 64]               0
           Conv1d-45               [-1, 16, 64]              48
  MyConv1dPadSame-46               [-1, 16, 64]               0
        MaxPool1d-47               [-1, 16, 64]               0
MyMaxPool1dPadSame-48               [-1, 16, 64]               0
       Bottleneck-49               [-1, 16, 64]               0
      BatchNorm1d-50               [-1, 16, 64]              32
             ReLU-51               [-1, 16, 64]               0
          Dropout-52               [-1, 16, 64]               0
           Conv1d-53               [-1, 32, 64]              96
  MyConv1dPadSame-54               [-1, 32, 64]               0
      BatchNorm1d-55               [-1, 32, 64]              64
             ReLU-56               [-1, 32, 64]               0
          Dropout-57               [-1, 32, 64]               0
           Conv1d-58               [-1, 32, 64]             160
  MyConv1dPadSame-59               [-1, 32, 64]               0
       Bottleneck-60               [-1, 32, 64]               0
      BatchNorm1d-61               [-1, 32, 64]              64
             ReLU-62               [-1, 32, 64]               0
          Dropout-63               [-1, 32, 64]               0
           Conv1d-64               [-1, 32, 32]             160
  MyConv1dPadSame-65               [-1, 32, 32]               0
      BatchNorm1d-66               [-1, 32, 32]              64
             ReLU-67               [-1, 32, 32]               0
          Dropout-68               [-1, 32, 32]               0
           Conv1d-69               [-1, 32, 32]             160
  MyConv1dPadSame-70               [-1, 32, 32]               0
        MaxPool1d-71               [-1, 32, 32]               0
MyMaxPool1dPadSame-72               [-1, 32, 32]               0
       Bottleneck-73               [-1, 32, 32]               0
      BatchNorm1d-74               [-1, 32, 32]              64
             ReLU-75               [-1, 32, 32]               0
          Dropout-76               [-1, 32, 32]               0
           Conv1d-77               [-1, 32, 32]             160
  MyConv1dPadSame-78               [-1, 32, 32]               0
      BatchNorm1d-79               [-1, 32, 32]              64
             ReLU-80               [-1, 32, 32]               0
          Dropout-81               [-1, 32, 32]               0
           Conv1d-82               [-1, 32, 32]             160
  MyConv1dPadSame-83               [-1, 32, 32]               0
       Bottleneck-84               [-1, 32, 32]               0
      BatchNorm1d-85               [-1, 32, 32]              64
             ReLU-86               [-1, 32, 32]               0
          Dropout-87               [-1, 32, 32]               0
           Conv1d-88               [-1, 32, 16]             160
  MyConv1dPadSame-89               [-1, 32, 16]               0
      BatchNorm1d-90               [-1, 32, 16]              64
             ReLU-91               [-1, 32, 16]               0
          Dropout-92               [-1, 32, 16]               0
           Conv1d-93               [-1, 32, 16]             160
  MyConv1dPadSame-94               [-1, 32, 16]               0
        MaxPool1d-95               [-1, 32, 16]               0
MyMaxPool1dPadSame-96               [-1, 32, 16]               0
       Bottleneck-97               [-1, 32, 16]               0
      BatchNorm1d-98               [-1, 32, 16]              64
             ReLU-99               [-1, 32, 16]               0
         Dropout-100               [-1, 32, 16]               0
          Conv1d-101               [-1, 64, 16]             320
 MyConv1dPadSame-102               [-1, 64, 16]               0
     BatchNorm1d-103               [-1, 64, 16]             128
            ReLU-104               [-1, 64, 16]               0
         Dropout-105               [-1, 64, 16]               0
          Conv1d-106               [-1, 64, 16]             576
 MyConv1dPadSame-107               [-1, 64, 16]               0
      Bottleneck-108               [-1, 64, 16]               0
     BatchNorm1d-109               [-1, 64, 16]             128
            ReLU-110               [-1, 64, 16]               0
         Dropout-111               [-1, 64, 16]               0
          Conv1d-112                [-1, 64, 8]             576
 MyConv1dPadSame-113                [-1, 64, 8]               0
     BatchNorm1d-114                [-1, 64, 8]             128
            ReLU-115                [-1, 64, 8]               0
         Dropout-116                [-1, 64, 8]               0
          Conv1d-117                [-1, 64, 8]             576
 MyConv1dPadSame-118                [-1, 64, 8]               0
       MaxPool1d-119                [-1, 64, 8]               0
MyMaxPool1dPadSame-120                [-1, 64, 8]               0
      Bottleneck-121                [-1, 64, 8]               0
     BatchNorm1d-122                [-1, 64, 8]             128
            ReLU-123                [-1, 64, 8]               0
         Dropout-124                [-1, 64, 8]               0
          Conv1d-125                [-1, 64, 8]             576
 MyConv1dPadSame-126                [-1, 64, 8]               0
     BatchNorm1d-127                [-1, 64, 8]             128
            ReLU-128                [-1, 64, 8]               0
         Dropout-129                [-1, 64, 8]               0
          Conv1d-130                [-1, 64, 8]             576
 MyConv1dPadSame-131                [-1, 64, 8]               0
      Bottleneck-132                [-1, 64, 8]               0
     BatchNorm1d-133                [-1, 64, 8]             128
            ReLU-134                [-1, 64, 8]               0
         Dropout-135                [-1, 64, 8]               0
          Conv1d-136                [-1, 64, 4]             576
 MyConv1dPadSame-137                [-1, 64, 4]               0
     BatchNorm1d-138                [-1, 64, 4]             128
            ReLU-139                [-1, 64, 4]               0
         Dropout-140                [-1, 64, 4]               0
          Conv1d-141                [-1, 64, 4]             576
 MyConv1dPadSame-142                [-1, 64, 4]               0
       MaxPool1d-143                [-1, 64, 4]               0
MyMaxPool1dPadSame-144                [-1, 64, 4]               0
      Bottleneck-145                [-1, 64, 4]               0
     BatchNorm1d-146                [-1, 64, 4]             128
            ReLU-147                [-1, 64, 4]               0
         Dropout-148                [-1, 64, 4]               0
          Conv1d-149               [-1, 128, 4]           1,152
 MyConv1dPadSame-150               [-1, 128, 4]               0
     BatchNorm1d-151               [-1, 128, 4]             256
            ReLU-152               [-1, 128, 4]               0
         Dropout-153               [-1, 128, 4]               0
          Conv1d-154               [-1, 128, 4]           2,176
 MyConv1dPadSame-155               [-1, 128, 4]               0
      Bottleneck-156               [-1, 128, 4]               0
     BatchNorm1d-157               [-1, 128, 4]             256
            ReLU-158               [-1, 128, 4]               0
         Dropout-159               [-1, 128, 4]               0
          Conv1d-160               [-1, 128, 2]           2,176
 MyConv1dPadSame-161               [-1, 128, 2]               0
     BatchNorm1d-162               [-1, 128, 2]             256
            ReLU-163               [-1, 128, 2]               0
         Dropout-164               [-1, 128, 2]               0
          Conv1d-165               [-1, 128, 2]           2,176
 MyConv1dPadSame-166               [-1, 128, 2]               0
       MaxPool1d-167               [-1, 128, 2]               0
MyMaxPool1dPadSame-168               [-1, 128, 2]               0
      Bottleneck-169               [-1, 128, 2]               0
     BatchNorm1d-170               [-1, 128, 2]             256
            ReLU-171               [-1, 128, 2]               0
         Dropout-172               [-1, 128, 2]               0
          Conv1d-173               [-1, 128, 2]           2,176
 MyConv1dPadSame-174               [-1, 128, 2]               0
     BatchNorm1d-175               [-1, 128, 2]             256
            ReLU-176               [-1, 128, 2]               0
         Dropout-177               [-1, 128, 2]               0
          Conv1d-178               [-1, 128, 2]           2,176
 MyConv1dPadSame-179               [-1, 128, 2]               0
      Bottleneck-180               [-1, 128, 2]               0
     BatchNorm1d-181               [-1, 128, 2]             256
            ReLU-182               [-1, 128, 2]               0
         Dropout-183               [-1, 128, 2]               0
          Conv1d-184               [-1, 128, 1]           2,176
 MyConv1dPadSame-185               [-1, 128, 1]               0
     BatchNorm1d-186               [-1, 128, 1]             256
            ReLU-187               [-1, 128, 1]               0
         Dropout-188               [-1, 128, 1]               0
          Conv1d-189               [-1, 128, 1]           2,176
 MyConv1dPadSame-190               [-1, 128, 1]               0
       MaxPool1d-191               [-1, 128, 1]               0
MyMaxPool1dPadSame-192               [-1, 128, 1]               0
      Bottleneck-193               [-1, 128, 1]               0
     BatchNorm1d-194               [-1, 128, 1]             256
            ReLU-195               [-1, 128, 1]               0
          Linear-196                    [-1, 2]             258
================================================================
Total params: 26,514
Trainable params: 26,514
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 1.66
Params size (MB): 0.10
Estimated Total Size (MB): 1.76
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 16, kernel_size: 4, n_block: 2
************************************************************
************************************************************
(2000, 1, 256) Counter({0: 1000, 1: 1000})
(2000, 1, 256) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 16, 256]              80
   MyConv1dPadSame-2              [-1, 16, 256]               0
       BatchNorm1d-3              [-1, 16, 256]              32
              ReLU-4              [-1, 16, 256]               0
            Conv1d-5              [-1, 16, 256]              80
   MyConv1dPadSame-6              [-1, 16, 256]               0
       BatchNorm1d-7              [-1, 16, 256]              32
              ReLU-8              [-1, 16, 256]               0
           Dropout-9              [-1, 16, 256]               0
           Conv1d-10              [-1, 16, 256]              80
  MyConv1dPadSame-11              [-1, 16, 256]               0
       Bottleneck-12              [-1, 16, 256]               0
      BatchNorm1d-13              [-1, 16, 256]              32
             ReLU-14              [-1, 16, 256]               0
          Dropout-15              [-1, 16, 256]               0
           Conv1d-16              [-1, 32, 256]             160
  MyConv1dPadSame-17              [-1, 32, 256]               0
      BatchNorm1d-18              [-1, 32, 256]              64
             ReLU-19              [-1, 32, 256]               0
          Dropout-20              [-1, 32, 256]               0
           Conv1d-21              [-1, 32, 256]             288
  MyConv1dPadSame-22              [-1, 32, 256]               0
       Bottleneck-23              [-1, 32, 256]               0
      BatchNorm1d-24              [-1, 32, 256]              64
             ReLU-25              [-1, 32, 256]               0
           Linear-26                    [-1, 2]              66
================================================================
Total params: 978
Trainable params: 978
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 1.09
Params size (MB): 0.00
Estimated Total Size (MB): 1.10
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 16, kernel_size: 4, n_block: 4
************************************************************
************************************************************
(2000, 1, 256) Counter({1: 1000, 0: 1000})
(2000, 1, 256) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 16, 256]              80
   MyConv1dPadSame-2              [-1, 16, 256]               0
       BatchNorm1d-3              [-1, 16, 256]              32
              ReLU-4              [-1, 16, 256]               0
            Conv1d-5              [-1, 16, 256]              80
   MyConv1dPadSame-6              [-1, 16, 256]               0
       BatchNorm1d-7              [-1, 16, 256]              32
              ReLU-8              [-1, 16, 256]               0
           Dropout-9              [-1, 16, 256]               0
           Conv1d-10              [-1, 16, 256]              80
  MyConv1dPadSame-11              [-1, 16, 256]               0
       Bottleneck-12              [-1, 16, 256]               0
      BatchNorm1d-13              [-1, 16, 256]              32
             ReLU-14              [-1, 16, 256]               0
          Dropout-15              [-1, 16, 256]               0
           Conv1d-16              [-1, 32, 256]             160
  MyConv1dPadSame-17              [-1, 32, 256]               0
      BatchNorm1d-18              [-1, 32, 256]              64
             ReLU-19              [-1, 32, 256]               0
          Dropout-20              [-1, 32, 256]               0
           Conv1d-21              [-1, 32, 256]             288
  MyConv1dPadSame-22              [-1, 32, 256]               0
       Bottleneck-23              [-1, 32, 256]               0
      BatchNorm1d-24              [-1, 32, 256]              64
             ReLU-25              [-1, 32, 256]               0
          Dropout-26              [-1, 32, 256]               0
           Conv1d-27              [-1, 64, 256]             576
  MyConv1dPadSame-28              [-1, 64, 256]               0
      BatchNorm1d-29              [-1, 64, 256]             128
             ReLU-30              [-1, 64, 256]               0
          Dropout-31              [-1, 64, 256]               0
           Conv1d-32              [-1, 64, 256]           1,088
  MyConv1dPadSame-33              [-1, 64, 256]               0
       Bottleneck-34              [-1, 64, 256]               0
      BatchNorm1d-35              [-1, 64, 256]             128
             ReLU-36              [-1, 64, 256]               0
          Dropout-37              [-1, 64, 256]               0
           Conv1d-38             [-1, 128, 256]           2,176
  MyConv1dPadSame-39             [-1, 128, 256]               0
      BatchNorm1d-40             [-1, 128, 256]             256
             ReLU-41             [-1, 128, 256]               0
          Dropout-42             [-1, 128, 256]               0
           Conv1d-43             [-1, 128, 256]           4,224
  MyConv1dPadSame-44             [-1, 128, 256]               0
       Bottleneck-45             [-1, 128, 256]               0
      BatchNorm1d-46             [-1, 128, 256]             256
             ReLU-47             [-1, 128, 256]               0
           Linear-48                    [-1, 2]             258
================================================================
Total params: 10,002
Trainable params: 10,002
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 5.03
Params size (MB): 0.04
Estimated Total Size (MB): 5.07
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 16, kernel_size: 4, n_block: 8
************************************************************
************************************************************
(2000, 1, 256) Counter({1: 1000, 0: 1000})
(2000, 1, 256) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 16, 256]              80
   MyConv1dPadSame-2              [-1, 16, 256]               0
       BatchNorm1d-3              [-1, 16, 256]              32
              ReLU-4              [-1, 16, 256]               0
            Conv1d-5              [-1, 16, 256]              80
   MyConv1dPadSame-6              [-1, 16, 256]               0
       BatchNorm1d-7              [-1, 16, 256]              32
              ReLU-8              [-1, 16, 256]               0
           Dropout-9              [-1, 16, 256]               0
           Conv1d-10              [-1, 16, 256]              80
  MyConv1dPadSame-11              [-1, 16, 256]               0
       Bottleneck-12              [-1, 16, 256]               0
      BatchNorm1d-13              [-1, 16, 256]              32
             ReLU-14              [-1, 16, 256]               0
          Dropout-15              [-1, 16, 256]               0
           Conv1d-16              [-1, 16, 256]              80
  MyConv1dPadSame-17              [-1, 16, 256]               0
      BatchNorm1d-18              [-1, 16, 256]              32
             ReLU-19              [-1, 16, 256]               0
          Dropout-20              [-1, 16, 256]               0
           Conv1d-21              [-1, 16, 256]              80
  MyConv1dPadSame-22              [-1, 16, 256]               0
       Bottleneck-23              [-1, 16, 256]               0
      BatchNorm1d-24              [-1, 16, 256]              32
             ReLU-25              [-1, 16, 256]               0
          Dropout-26              [-1, 16, 256]               0
           Conv1d-27              [-1, 32, 256]             160
  MyConv1dPadSame-28              [-1, 32, 256]               0
      BatchNorm1d-29              [-1, 32, 256]              64
             ReLU-30              [-1, 32, 256]               0
          Dropout-31              [-1, 32, 256]               0
           Conv1d-32              [-1, 32, 256]             288
  MyConv1dPadSame-33              [-1, 32, 256]               0
       Bottleneck-34              [-1, 32, 256]               0
      BatchNorm1d-35              [-1, 32, 256]              64
             ReLU-36              [-1, 32, 256]               0
          Dropout-37              [-1, 32, 256]               0
           Conv1d-38              [-1, 32, 256]             288
  MyConv1dPadSame-39              [-1, 32, 256]               0
      BatchNorm1d-40              [-1, 32, 256]              64
             ReLU-41              [-1, 32, 256]               0
          Dropout-42              [-1, 32, 256]               0
           Conv1d-43              [-1, 32, 256]             288
  MyConv1dPadSame-44              [-1, 32, 256]               0
       Bottleneck-45              [-1, 32, 256]               0
      BatchNorm1d-46              [-1, 32, 256]              64
             ReLU-47              [-1, 32, 256]               0
          Dropout-48              [-1, 32, 256]               0
           Conv1d-49              [-1, 64, 256]             576
  MyConv1dPadSame-50              [-1, 64, 256]               0
      BatchNorm1d-51              [-1, 64, 256]             128
             ReLU-52              [-1, 64, 256]               0
          Dropout-53              [-1, 64, 256]               0
           Conv1d-54              [-1, 64, 256]           1,088
  MyConv1dPadSame-55              [-1, 64, 256]               0
       Bottleneck-56              [-1, 64, 256]               0
      BatchNorm1d-57              [-1, 64, 256]             128
             ReLU-58              [-1, 64, 256]               0
          Dropout-59              [-1, 64, 256]               0
           Conv1d-60              [-1, 64, 256]           1,088
  MyConv1dPadSame-61              [-1, 64, 256]               0
      BatchNorm1d-62              [-1, 64, 256]             128
             ReLU-63              [-1, 64, 256]               0
          Dropout-64              [-1, 64, 256]               0
           Conv1d-65              [-1, 64, 256]           1,088
  MyConv1dPadSame-66              [-1, 64, 256]               0
       Bottleneck-67              [-1, 64, 256]               0
      BatchNorm1d-68              [-1, 64, 256]             128
             ReLU-69              [-1, 64, 256]               0
          Dropout-70              [-1, 64, 256]               0
           Conv1d-71             [-1, 128, 256]           2,176
  MyConv1dPadSame-72             [-1, 128, 256]               0
      BatchNorm1d-73             [-1, 128, 256]             256
             ReLU-74             [-1, 128, 256]               0
          Dropout-75             [-1, 128, 256]               0
           Conv1d-76             [-1, 128, 256]           4,224
  MyConv1dPadSame-77             [-1, 128, 256]               0
       Bottleneck-78             [-1, 128, 256]               0
      BatchNorm1d-79             [-1, 128, 256]             256
             ReLU-80             [-1, 128, 256]               0
          Dropout-81             [-1, 128, 256]               0
           Conv1d-82             [-1, 128, 256]           4,224
  MyConv1dPadSame-83             [-1, 128, 256]               0
      BatchNorm1d-84             [-1, 128, 256]             256
             ReLU-85             [-1, 128, 256]               0
          Dropout-86             [-1, 128, 256]               0
           Conv1d-87             [-1, 128, 256]           4,224
  MyConv1dPadSame-88             [-1, 128, 256]               0
       Bottleneck-89             [-1, 128, 256]               0
      BatchNorm1d-90             [-1, 128, 256]             256
             ReLU-91             [-1, 128, 256]               0
           Linear-92                    [-1, 2]             258
================================================================
Total params: 22,322
Trainable params: 22,322
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 10.19
Params size (MB): 0.09
Estimated Total Size (MB): 10.27
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 16, kernel_size: 4, n_block: 16
************************************************************
************************************************************
(2000, 1, 256) Counter({0: 1000, 1: 1000})
(2000, 1, 256) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 16, 256]              80
   MyConv1dPadSame-2              [-1, 16, 256]               0
       BatchNorm1d-3              [-1, 16, 256]              32
              ReLU-4              [-1, 16, 256]               0
            Conv1d-5              [-1, 16, 256]              80
   MyConv1dPadSame-6              [-1, 16, 256]               0
       BatchNorm1d-7              [-1, 16, 256]              32
              ReLU-8              [-1, 16, 256]               0
           Dropout-9              [-1, 16, 256]               0
           Conv1d-10              [-1, 16, 256]              80
  MyConv1dPadSame-11              [-1, 16, 256]               0
       Bottleneck-12              [-1, 16, 256]               0
      BatchNorm1d-13              [-1, 16, 256]              32
             ReLU-14              [-1, 16, 256]               0
          Dropout-15              [-1, 16, 256]               0
           Conv1d-16              [-1, 16, 128]              80
  MyConv1dPadSame-17              [-1, 16, 128]               0
      BatchNorm1d-18              [-1, 16, 128]              32
             ReLU-19              [-1, 16, 128]               0
          Dropout-20              [-1, 16, 128]               0
           Conv1d-21              [-1, 16, 128]              80
  MyConv1dPadSame-22              [-1, 16, 128]               0
        MaxPool1d-23              [-1, 16, 128]               0
MyMaxPool1dPadSame-24              [-1, 16, 128]               0
       Bottleneck-25              [-1, 16, 128]               0
      BatchNorm1d-26              [-1, 16, 128]              32
             ReLU-27              [-1, 16, 128]               0
          Dropout-28              [-1, 16, 128]               0
           Conv1d-29              [-1, 16, 128]              80
  MyConv1dPadSame-30              [-1, 16, 128]               0
      BatchNorm1d-31              [-1, 16, 128]              32
             ReLU-32              [-1, 16, 128]               0
          Dropout-33              [-1, 16, 128]               0
           Conv1d-34              [-1, 16, 128]              80
  MyConv1dPadSame-35              [-1, 16, 128]               0
       Bottleneck-36              [-1, 16, 128]               0
      BatchNorm1d-37              [-1, 16, 128]              32
             ReLU-38              [-1, 16, 128]               0
          Dropout-39              [-1, 16, 128]               0
           Conv1d-40               [-1, 16, 64]              80
  MyConv1dPadSame-41               [-1, 16, 64]               0
      BatchNorm1d-42               [-1, 16, 64]              32
             ReLU-43               [-1, 16, 64]               0
          Dropout-44               [-1, 16, 64]               0
           Conv1d-45               [-1, 16, 64]              80
  MyConv1dPadSame-46               [-1, 16, 64]               0
        MaxPool1d-47               [-1, 16, 64]               0
MyMaxPool1dPadSame-48               [-1, 16, 64]               0
       Bottleneck-49               [-1, 16, 64]               0
      BatchNorm1d-50               [-1, 16, 64]              32
             ReLU-51               [-1, 16, 64]               0
          Dropout-52               [-1, 16, 64]               0
           Conv1d-53               [-1, 32, 64]             160
  MyConv1dPadSame-54               [-1, 32, 64]               0
      BatchNorm1d-55               [-1, 32, 64]              64
             ReLU-56               [-1, 32, 64]               0
          Dropout-57               [-1, 32, 64]               0
           Conv1d-58               [-1, 32, 64]             288
  MyConv1dPadSame-59               [-1, 32, 64]               0
       Bottleneck-60               [-1, 32, 64]               0
      BatchNorm1d-61               [-1, 32, 64]              64
             ReLU-62               [-1, 32, 64]               0
          Dropout-63               [-1, 32, 64]               0
           Conv1d-64               [-1, 32, 32]             288
  MyConv1dPadSame-65               [-1, 32, 32]               0
      BatchNorm1d-66               [-1, 32, 32]              64
             ReLU-67               [-1, 32, 32]               0
          Dropout-68               [-1, 32, 32]               0
           Conv1d-69               [-1, 32, 32]             288
  MyConv1dPadSame-70               [-1, 32, 32]               0
        MaxPool1d-71               [-1, 32, 32]               0
MyMaxPool1dPadSame-72               [-1, 32, 32]               0
       Bottleneck-73               [-1, 32, 32]               0
      BatchNorm1d-74               [-1, 32, 32]              64
             ReLU-75               [-1, 32, 32]               0
          Dropout-76               [-1, 32, 32]               0
           Conv1d-77               [-1, 32, 32]             288
  MyConv1dPadSame-78               [-1, 32, 32]               0
      BatchNorm1d-79               [-1, 32, 32]              64
             ReLU-80               [-1, 32, 32]               0
          Dropout-81               [-1, 32, 32]               0
           Conv1d-82               [-1, 32, 32]             288
  MyConv1dPadSame-83               [-1, 32, 32]               0
       Bottleneck-84               [-1, 32, 32]               0
      BatchNorm1d-85               [-1, 32, 32]              64
             ReLU-86               [-1, 32, 32]               0
          Dropout-87               [-1, 32, 32]               0
           Conv1d-88               [-1, 32, 16]             288
  MyConv1dPadSame-89               [-1, 32, 16]               0
      BatchNorm1d-90               [-1, 32, 16]              64
             ReLU-91               [-1, 32, 16]               0
          Dropout-92               [-1, 32, 16]               0
           Conv1d-93               [-1, 32, 16]             288
  MyConv1dPadSame-94               [-1, 32, 16]               0
        MaxPool1d-95               [-1, 32, 16]               0
MyMaxPool1dPadSame-96               [-1, 32, 16]               0
       Bottleneck-97               [-1, 32, 16]               0
      BatchNorm1d-98               [-1, 32, 16]              64
             ReLU-99               [-1, 32, 16]               0
         Dropout-100               [-1, 32, 16]               0
          Conv1d-101               [-1, 64, 16]             576
 MyConv1dPadSame-102               [-1, 64, 16]               0
     BatchNorm1d-103               [-1, 64, 16]             128
            ReLU-104               [-1, 64, 16]               0
         Dropout-105               [-1, 64, 16]               0
          Conv1d-106               [-1, 64, 16]           1,088
 MyConv1dPadSame-107               [-1, 64, 16]               0
      Bottleneck-108               [-1, 64, 16]               0
     BatchNorm1d-109               [-1, 64, 16]             128
            ReLU-110               [-1, 64, 16]               0
         Dropout-111               [-1, 64, 16]               0
          Conv1d-112                [-1, 64, 8]           1,088
 MyConv1dPadSame-113                [-1, 64, 8]               0
     BatchNorm1d-114                [-1, 64, 8]             128
            ReLU-115                [-1, 64, 8]               0
         Dropout-116                [-1, 64, 8]               0
          Conv1d-117                [-1, 64, 8]           1,088
 MyConv1dPadSame-118                [-1, 64, 8]               0
       MaxPool1d-119                [-1, 64, 8]               0
MyMaxPool1dPadSame-120                [-1, 64, 8]               0
      Bottleneck-121                [-1, 64, 8]               0
     BatchNorm1d-122                [-1, 64, 8]             128
            ReLU-123                [-1, 64, 8]               0
         Dropout-124                [-1, 64, 8]               0
          Conv1d-125                [-1, 64, 8]           1,088
 MyConv1dPadSame-126                [-1, 64, 8]               0
     BatchNorm1d-127                [-1, 64, 8]             128
            ReLU-128                [-1, 64, 8]               0
         Dropout-129                [-1, 64, 8]               0
          Conv1d-130                [-1, 64, 8]           1,088
 MyConv1dPadSame-131                [-1, 64, 8]               0
      Bottleneck-132                [-1, 64, 8]               0
     BatchNorm1d-133                [-1, 64, 8]             128
            ReLU-134                [-1, 64, 8]               0
         Dropout-135                [-1, 64, 8]               0
          Conv1d-136                [-1, 64, 4]           1,088
 MyConv1dPadSame-137                [-1, 64, 4]               0
     BatchNorm1d-138                [-1, 64, 4]             128
            ReLU-139                [-1, 64, 4]               0
         Dropout-140                [-1, 64, 4]               0
          Conv1d-141                [-1, 64, 4]           1,088
 MyConv1dPadSame-142                [-1, 64, 4]               0
       MaxPool1d-143                [-1, 64, 4]               0
MyMaxPool1dPadSame-144                [-1, 64, 4]               0
      Bottleneck-145                [-1, 64, 4]               0
     BatchNorm1d-146                [-1, 64, 4]             128
            ReLU-147                [-1, 64, 4]               0
         Dropout-148                [-1, 64, 4]               0
          Conv1d-149               [-1, 128, 4]           2,176
 MyConv1dPadSame-150               [-1, 128, 4]               0
     BatchNorm1d-151               [-1, 128, 4]             256
            ReLU-152               [-1, 128, 4]               0
         Dropout-153               [-1, 128, 4]               0
          Conv1d-154               [-1, 128, 4]           4,224
 MyConv1dPadSame-155               [-1, 128, 4]               0
      Bottleneck-156               [-1, 128, 4]               0
     BatchNorm1d-157               [-1, 128, 4]             256
            ReLU-158               [-1, 128, 4]               0
         Dropout-159               [-1, 128, 4]               0
          Conv1d-160               [-1, 128, 2]           4,224
 MyConv1dPadSame-161               [-1, 128, 2]               0
     BatchNorm1d-162               [-1, 128, 2]             256
            ReLU-163               [-1, 128, 2]               0
         Dropout-164               [-1, 128, 2]               0
          Conv1d-165               [-1, 128, 2]           4,224
 MyConv1dPadSame-166               [-1, 128, 2]               0
       MaxPool1d-167               [-1, 128, 2]               0
MyMaxPool1dPadSame-168               [-1, 128, 2]               0
      Bottleneck-169               [-1, 128, 2]               0
     BatchNorm1d-170               [-1, 128, 2]             256
            ReLU-171               [-1, 128, 2]               0
         Dropout-172               [-1, 128, 2]               0
          Conv1d-173               [-1, 128, 2]           4,224
 MyConv1dPadSame-174               [-1, 128, 2]               0
     BatchNorm1d-175               [-1, 128, 2]             256
            ReLU-176               [-1, 128, 2]               0
         Dropout-177               [-1, 128, 2]               0
          Conv1d-178               [-1, 128, 2]           4,224
 MyConv1dPadSame-179               [-1, 128, 2]               0
      Bottleneck-180               [-1, 128, 2]               0
     BatchNorm1d-181               [-1, 128, 2]             256
            ReLU-182               [-1, 128, 2]               0
         Dropout-183               [-1, 128, 2]               0
          Conv1d-184               [-1, 128, 1]           4,224
 MyConv1dPadSame-185               [-1, 128, 1]               0
     BatchNorm1d-186               [-1, 128, 1]             256
            ReLU-187               [-1, 128, 1]               0
         Dropout-188               [-1, 128, 1]               0
          Conv1d-189               [-1, 128, 1]           4,224
 MyConv1dPadSame-190               [-1, 128, 1]               0
       MaxPool1d-191               [-1, 128, 1]               0
MyMaxPool1dPadSame-192               [-1, 128, 1]               0
      Bottleneck-193               [-1, 128, 1]               0
     BatchNorm1d-194               [-1, 128, 1]             256
            ReLU-195               [-1, 128, 1]               0
          Linear-196                    [-1, 2]             258
================================================================
Total params: 46,962
Trainable params: 46,962
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 1.66
Params size (MB): 0.18
Estimated Total Size (MB): 1.84
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 16, kernel_size: 8, n_block: 2
************************************************************
************************************************************
(2000, 1, 256) Counter({0: 1000, 1: 1000})
(2000, 1, 256) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 16, 256]             144
   MyConv1dPadSame-2              [-1, 16, 256]               0
       BatchNorm1d-3              [-1, 16, 256]              32
              ReLU-4              [-1, 16, 256]               0
            Conv1d-5              [-1, 16, 256]             144
   MyConv1dPadSame-6              [-1, 16, 256]               0
       BatchNorm1d-7              [-1, 16, 256]              32
              ReLU-8              [-1, 16, 256]               0
           Dropout-9              [-1, 16, 256]               0
           Conv1d-10              [-1, 16, 256]             144
  MyConv1dPadSame-11              [-1, 16, 256]               0
       Bottleneck-12              [-1, 16, 256]               0
      BatchNorm1d-13              [-1, 16, 256]              32
             ReLU-14              [-1, 16, 256]               0
          Dropout-15              [-1, 16, 256]               0
           Conv1d-16              [-1, 32, 256]             288
  MyConv1dPadSame-17              [-1, 32, 256]               0
      BatchNorm1d-18              [-1, 32, 256]              64
             ReLU-19              [-1, 32, 256]               0
          Dropout-20              [-1, 32, 256]               0
           Conv1d-21              [-1, 32, 256]             544
  MyConv1dPadSame-22              [-1, 32, 256]               0
       Bottleneck-23              [-1, 32, 256]               0
      BatchNorm1d-24              [-1, 32, 256]              64
             ReLU-25              [-1, 32, 256]               0
           Linear-26                    [-1, 2]              66
================================================================
Total params: 1,554
Trainable params: 1,554
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 1.09
Params size (MB): 0.01
Estimated Total Size (MB): 1.10
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 16, kernel_size: 8, n_block: 4
************************************************************
************************************************************
(2000, 1, 256) Counter({0: 1000, 1: 1000})
(2000, 1, 256) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 16, 256]             144
   MyConv1dPadSame-2              [-1, 16, 256]               0
       BatchNorm1d-3              [-1, 16, 256]              32
              ReLU-4              [-1, 16, 256]               0
            Conv1d-5              [-1, 16, 256]             144
   MyConv1dPadSame-6              [-1, 16, 256]               0
       BatchNorm1d-7              [-1, 16, 256]              32
              ReLU-8              [-1, 16, 256]               0
           Dropout-9              [-1, 16, 256]               0
           Conv1d-10              [-1, 16, 256]             144
  MyConv1dPadSame-11              [-1, 16, 256]               0
       Bottleneck-12              [-1, 16, 256]               0
      BatchNorm1d-13              [-1, 16, 256]              32
             ReLU-14              [-1, 16, 256]               0
          Dropout-15              [-1, 16, 256]               0
           Conv1d-16              [-1, 32, 256]             288
  MyConv1dPadSame-17              [-1, 32, 256]               0
      BatchNorm1d-18              [-1, 32, 256]              64
             ReLU-19              [-1, 32, 256]               0
          Dropout-20              [-1, 32, 256]               0
           Conv1d-21              [-1, 32, 256]             544
  MyConv1dPadSame-22              [-1, 32, 256]               0
       Bottleneck-23              [-1, 32, 256]               0
      BatchNorm1d-24              [-1, 32, 256]              64
             ReLU-25              [-1, 32, 256]               0
          Dropout-26              [-1, 32, 256]               0
           Conv1d-27              [-1, 64, 256]           1,088
  MyConv1dPadSame-28              [-1, 64, 256]               0
      BatchNorm1d-29              [-1, 64, 256]             128
             ReLU-30              [-1, 64, 256]               0
          Dropout-31              [-1, 64, 256]               0
           Conv1d-32              [-1, 64, 256]           2,112
  MyConv1dPadSame-33              [-1, 64, 256]               0
       Bottleneck-34              [-1, 64, 256]               0
      BatchNorm1d-35              [-1, 64, 256]             128
             ReLU-36              [-1, 64, 256]               0
          Dropout-37              [-1, 64, 256]               0
           Conv1d-38             [-1, 128, 256]           4,224
  MyConv1dPadSame-39             [-1, 128, 256]               0
      BatchNorm1d-40             [-1, 128, 256]             256
             ReLU-41             [-1, 128, 256]               0
          Dropout-42             [-1, 128, 256]               0
           Conv1d-43             [-1, 128, 256]           8,320
  MyConv1dPadSame-44             [-1, 128, 256]               0
       Bottleneck-45             [-1, 128, 256]               0
      BatchNorm1d-46             [-1, 128, 256]             256
             ReLU-47             [-1, 128, 256]               0
           Linear-48                    [-1, 2]             258
================================================================
Total params: 18,258
Trainable params: 18,258
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 5.03
Params size (MB): 0.07
Estimated Total Size (MB): 5.10
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 16, kernel_size: 8, n_block: 8
************************************************************
************************************************************
(2000, 1, 256) Counter({1: 1000, 0: 1000})
(2000, 1, 256) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 16, 256]             144
   MyConv1dPadSame-2              [-1, 16, 256]               0
       BatchNorm1d-3              [-1, 16, 256]              32
              ReLU-4              [-1, 16, 256]               0
            Conv1d-5              [-1, 16, 256]             144
   MyConv1dPadSame-6              [-1, 16, 256]               0
       BatchNorm1d-7              [-1, 16, 256]              32
              ReLU-8              [-1, 16, 256]               0
           Dropout-9              [-1, 16, 256]               0
           Conv1d-10              [-1, 16, 256]             144
  MyConv1dPadSame-11              [-1, 16, 256]               0
       Bottleneck-12              [-1, 16, 256]               0
      BatchNorm1d-13              [-1, 16, 256]              32
             ReLU-14              [-1, 16, 256]               0
          Dropout-15              [-1, 16, 256]               0
           Conv1d-16              [-1, 16, 256]             144
  MyConv1dPadSame-17              [-1, 16, 256]               0
      BatchNorm1d-18              [-1, 16, 256]              32
             ReLU-19              [-1, 16, 256]               0
          Dropout-20              [-1, 16, 256]               0
           Conv1d-21              [-1, 16, 256]             144
  MyConv1dPadSame-22              [-1, 16, 256]               0
       Bottleneck-23              [-1, 16, 256]               0
      BatchNorm1d-24              [-1, 16, 256]              32
             ReLU-25              [-1, 16, 256]               0
          Dropout-26              [-1, 16, 256]               0
           Conv1d-27              [-1, 32, 256]             288
  MyConv1dPadSame-28              [-1, 32, 256]               0
      BatchNorm1d-29              [-1, 32, 256]              64
             ReLU-30              [-1, 32, 256]               0
          Dropout-31              [-1, 32, 256]               0
           Conv1d-32              [-1, 32, 256]             544
  MyConv1dPadSame-33              [-1, 32, 256]               0
       Bottleneck-34              [-1, 32, 256]               0
      BatchNorm1d-35              [-1, 32, 256]              64
             ReLU-36              [-1, 32, 256]               0
          Dropout-37              [-1, 32, 256]               0
           Conv1d-38              [-1, 32, 256]             544
  MyConv1dPadSame-39              [-1, 32, 256]               0
      BatchNorm1d-40              [-1, 32, 256]              64
             ReLU-41              [-1, 32, 256]               0
          Dropout-42              [-1, 32, 256]               0
           Conv1d-43              [-1, 32, 256]             544
  MyConv1dPadSame-44              [-1, 32, 256]               0
       Bottleneck-45              [-1, 32, 256]               0
      BatchNorm1d-46              [-1, 32, 256]              64
             ReLU-47              [-1, 32, 256]               0
          Dropout-48              [-1, 32, 256]               0
           Conv1d-49              [-1, 64, 256]           1,088
  MyConv1dPadSame-50              [-1, 64, 256]               0
      BatchNorm1d-51              [-1, 64, 256]             128
             ReLU-52              [-1, 64, 256]               0
          Dropout-53              [-1, 64, 256]               0
           Conv1d-54              [-1, 64, 256]           2,112
  MyConv1dPadSame-55              [-1, 64, 256]               0
       Bottleneck-56              [-1, 64, 256]               0
      BatchNorm1d-57              [-1, 64, 256]             128
             ReLU-58              [-1, 64, 256]               0
          Dropout-59              [-1, 64, 256]               0
           Conv1d-60              [-1, 64, 256]           2,112
  MyConv1dPadSame-61              [-1, 64, 256]               0
      BatchNorm1d-62              [-1, 64, 256]             128
             ReLU-63              [-1, 64, 256]               0
          Dropout-64              [-1, 64, 256]               0
           Conv1d-65              [-1, 64, 256]           2,112
  MyConv1dPadSame-66              [-1, 64, 256]               0
       Bottleneck-67              [-1, 64, 256]               0
      BatchNorm1d-68              [-1, 64, 256]             128
             ReLU-69              [-1, 64, 256]               0
          Dropout-70              [-1, 64, 256]               0
           Conv1d-71             [-1, 128, 256]           4,224
  MyConv1dPadSame-72             [-1, 128, 256]               0
      BatchNorm1d-73             [-1, 128, 256]             256
             ReLU-74             [-1, 128, 256]               0
          Dropout-75             [-1, 128, 256]               0
           Conv1d-76             [-1, 128, 256]           8,320
  MyConv1dPadSame-77             [-1, 128, 256]               0
       Bottleneck-78             [-1, 128, 256]               0
      BatchNorm1d-79             [-1, 128, 256]             256
             ReLU-80             [-1, 128, 256]               0
          Dropout-81             [-1, 128, 256]               0
           Conv1d-82             [-1, 128, 256]           8,320
  MyConv1dPadSame-83             [-1, 128, 256]               0
      BatchNorm1d-84             [-1, 128, 256]             256
             ReLU-85             [-1, 128, 256]               0
          Dropout-86             [-1, 128, 256]               0
           Conv1d-87             [-1, 128, 256]           8,320
  MyConv1dPadSame-88             [-1, 128, 256]               0
       Bottleneck-89             [-1, 128, 256]               0
      BatchNorm1d-90             [-1, 128, 256]             256
             ReLU-91             [-1, 128, 256]               0
           Linear-92                    [-1, 2]             258
================================================================
Total params: 41,458
Trainable params: 41,458
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 10.19
Params size (MB): 0.16
Estimated Total Size (MB): 10.35
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 16, kernel_size: 8, n_block: 16
************************************************************
************************************************************
(2000, 1, 256) Counter({1: 1000, 0: 1000})
(2000, 1, 256) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 16, 256]             144
   MyConv1dPadSame-2              [-1, 16, 256]               0
       BatchNorm1d-3              [-1, 16, 256]              32
              ReLU-4              [-1, 16, 256]               0
            Conv1d-5              [-1, 16, 256]             144
   MyConv1dPadSame-6              [-1, 16, 256]               0
       BatchNorm1d-7              [-1, 16, 256]              32
              ReLU-8              [-1, 16, 256]               0
           Dropout-9              [-1, 16, 256]               0
           Conv1d-10              [-1, 16, 256]             144
  MyConv1dPadSame-11              [-1, 16, 256]               0
       Bottleneck-12              [-1, 16, 256]               0
      BatchNorm1d-13              [-1, 16, 256]              32
             ReLU-14              [-1, 16, 256]               0
          Dropout-15              [-1, 16, 256]               0
           Conv1d-16              [-1, 16, 128]             144
  MyConv1dPadSame-17              [-1, 16, 128]               0
      BatchNorm1d-18              [-1, 16, 128]              32
             ReLU-19              [-1, 16, 128]               0
          Dropout-20              [-1, 16, 128]               0
           Conv1d-21              [-1, 16, 128]             144
  MyConv1dPadSame-22              [-1, 16, 128]               0
        MaxPool1d-23              [-1, 16, 128]               0
MyMaxPool1dPadSame-24              [-1, 16, 128]               0
       Bottleneck-25              [-1, 16, 128]               0
      BatchNorm1d-26              [-1, 16, 128]              32
             ReLU-27              [-1, 16, 128]               0
          Dropout-28              [-1, 16, 128]               0
           Conv1d-29              [-1, 16, 128]             144
  MyConv1dPadSame-30              [-1, 16, 128]               0
      BatchNorm1d-31              [-1, 16, 128]              32
             ReLU-32              [-1, 16, 128]               0
          Dropout-33              [-1, 16, 128]               0
           Conv1d-34              [-1, 16, 128]             144
  MyConv1dPadSame-35              [-1, 16, 128]               0
       Bottleneck-36              [-1, 16, 128]               0
      BatchNorm1d-37              [-1, 16, 128]              32
             ReLU-38              [-1, 16, 128]               0
          Dropout-39              [-1, 16, 128]               0
           Conv1d-40               [-1, 16, 64]             144
  MyConv1dPadSame-41               [-1, 16, 64]               0
      BatchNorm1d-42               [-1, 16, 64]              32
             ReLU-43               [-1, 16, 64]               0
          Dropout-44               [-1, 16, 64]               0
           Conv1d-45               [-1, 16, 64]             144
  MyConv1dPadSame-46               [-1, 16, 64]               0
        MaxPool1d-47               [-1, 16, 64]               0
MyMaxPool1dPadSame-48               [-1, 16, 64]               0
       Bottleneck-49               [-1, 16, 64]               0
      BatchNorm1d-50               [-1, 16, 64]              32
             ReLU-51               [-1, 16, 64]               0
          Dropout-52               [-1, 16, 64]               0
           Conv1d-53               [-1, 32, 64]             288
  MyConv1dPadSame-54               [-1, 32, 64]               0
      BatchNorm1d-55               [-1, 32, 64]              64
             ReLU-56               [-1, 32, 64]               0
          Dropout-57               [-1, 32, 64]               0
           Conv1d-58               [-1, 32, 64]             544
  MyConv1dPadSame-59               [-1, 32, 64]               0
       Bottleneck-60               [-1, 32, 64]               0
      BatchNorm1d-61               [-1, 32, 64]              64
             ReLU-62               [-1, 32, 64]               0
          Dropout-63               [-1, 32, 64]               0
           Conv1d-64               [-1, 32, 32]             544
  MyConv1dPadSame-65               [-1, 32, 32]               0
      BatchNorm1d-66               [-1, 32, 32]              64
             ReLU-67               [-1, 32, 32]               0
          Dropout-68               [-1, 32, 32]               0
           Conv1d-69               [-1, 32, 32]             544
  MyConv1dPadSame-70               [-1, 32, 32]               0
        MaxPool1d-71               [-1, 32, 32]               0
MyMaxPool1dPadSame-72               [-1, 32, 32]               0
       Bottleneck-73               [-1, 32, 32]               0
      BatchNorm1d-74               [-1, 32, 32]              64
             ReLU-75               [-1, 32, 32]               0
          Dropout-76               [-1, 32, 32]               0
           Conv1d-77               [-1, 32, 32]             544
  MyConv1dPadSame-78               [-1, 32, 32]               0
      BatchNorm1d-79               [-1, 32, 32]              64
             ReLU-80               [-1, 32, 32]               0
          Dropout-81               [-1, 32, 32]               0
           Conv1d-82               [-1, 32, 32]             544
  MyConv1dPadSame-83               [-1, 32, 32]               0
       Bottleneck-84               [-1, 32, 32]               0
      BatchNorm1d-85               [-1, 32, 32]              64
             ReLU-86               [-1, 32, 32]               0
          Dropout-87               [-1, 32, 32]               0
           Conv1d-88               [-1, 32, 16]             544
  MyConv1dPadSame-89               [-1, 32, 16]               0
      BatchNorm1d-90               [-1, 32, 16]              64
             ReLU-91               [-1, 32, 16]               0
          Dropout-92               [-1, 32, 16]               0
           Conv1d-93               [-1, 32, 16]             544
  MyConv1dPadSame-94               [-1, 32, 16]               0
        MaxPool1d-95               [-1, 32, 16]               0
MyMaxPool1dPadSame-96               [-1, 32, 16]               0
       Bottleneck-97               [-1, 32, 16]               0
      BatchNorm1d-98               [-1, 32, 16]              64
             ReLU-99               [-1, 32, 16]               0
         Dropout-100               [-1, 32, 16]               0
          Conv1d-101               [-1, 64, 16]           1,088
 MyConv1dPadSame-102               [-1, 64, 16]               0
     BatchNorm1d-103               [-1, 64, 16]             128
            ReLU-104               [-1, 64, 16]               0
         Dropout-105               [-1, 64, 16]               0
          Conv1d-106               [-1, 64, 16]           2,112
 MyConv1dPadSame-107               [-1, 64, 16]               0
      Bottleneck-108               [-1, 64, 16]               0
     BatchNorm1d-109               [-1, 64, 16]             128
            ReLU-110               [-1, 64, 16]               0
         Dropout-111               [-1, 64, 16]               0
          Conv1d-112                [-1, 64, 8]           2,112
 MyConv1dPadSame-113                [-1, 64, 8]               0
     BatchNorm1d-114                [-1, 64, 8]             128
            ReLU-115                [-1, 64, 8]               0
         Dropout-116                [-1, 64, 8]               0
          Conv1d-117                [-1, 64, 8]           2,112
 MyConv1dPadSame-118                [-1, 64, 8]               0
       MaxPool1d-119                [-1, 64, 8]               0
MyMaxPool1dPadSame-120                [-1, 64, 8]               0
      Bottleneck-121                [-1, 64, 8]               0
     BatchNorm1d-122                [-1, 64, 8]             128
            ReLU-123                [-1, 64, 8]               0
         Dropout-124                [-1, 64, 8]               0
          Conv1d-125                [-1, 64, 8]           2,112
 MyConv1dPadSame-126                [-1, 64, 8]               0
     BatchNorm1d-127                [-1, 64, 8]             128
            ReLU-128                [-1, 64, 8]               0
         Dropout-129                [-1, 64, 8]               0
          Conv1d-130                [-1, 64, 8]           2,112
 MyConv1dPadSame-131                [-1, 64, 8]               0
      Bottleneck-132                [-1, 64, 8]               0
     BatchNorm1d-133                [-1, 64, 8]             128
            ReLU-134                [-1, 64, 8]               0
         Dropout-135                [-1, 64, 8]               0
          Conv1d-136                [-1, 64, 4]           2,112
 MyConv1dPadSame-137                [-1, 64, 4]               0
     BatchNorm1d-138                [-1, 64, 4]             128
            ReLU-139                [-1, 64, 4]               0
         Dropout-140                [-1, 64, 4]               0
          Conv1d-141                [-1, 64, 4]           2,112
 MyConv1dPadSame-142                [-1, 64, 4]               0
       MaxPool1d-143                [-1, 64, 4]               0
MyMaxPool1dPadSame-144                [-1, 64, 4]               0
      Bottleneck-145                [-1, 64, 4]               0
     BatchNorm1d-146                [-1, 64, 4]             128
            ReLU-147                [-1, 64, 4]               0
         Dropout-148                [-1, 64, 4]               0
          Conv1d-149               [-1, 128, 4]           4,224
 MyConv1dPadSame-150               [-1, 128, 4]               0
     BatchNorm1d-151               [-1, 128, 4]             256
            ReLU-152               [-1, 128, 4]               0
         Dropout-153               [-1, 128, 4]               0
          Conv1d-154               [-1, 128, 4]           8,320
 MyConv1dPadSame-155               [-1, 128, 4]               0
      Bottleneck-156               [-1, 128, 4]               0
     BatchNorm1d-157               [-1, 128, 4]             256
            ReLU-158               [-1, 128, 4]               0
         Dropout-159               [-1, 128, 4]               0
          Conv1d-160               [-1, 128, 2]           8,320
 MyConv1dPadSame-161               [-1, 128, 2]               0
     BatchNorm1d-162               [-1, 128, 2]             256
            ReLU-163               [-1, 128, 2]               0
         Dropout-164               [-1, 128, 2]               0
          Conv1d-165               [-1, 128, 2]           8,320
 MyConv1dPadSame-166               [-1, 128, 2]               0
       MaxPool1d-167               [-1, 128, 2]               0
MyMaxPool1dPadSame-168               [-1, 128, 2]               0
      Bottleneck-169               [-1, 128, 2]               0
     BatchNorm1d-170               [-1, 128, 2]             256
            ReLU-171               [-1, 128, 2]               0
         Dropout-172               [-1, 128, 2]               0
          Conv1d-173               [-1, 128, 2]           8,320
 MyConv1dPadSame-174               [-1, 128, 2]               0
     BatchNorm1d-175               [-1, 128, 2]             256
            ReLU-176               [-1, 128, 2]               0
         Dropout-177               [-1, 128, 2]               0
          Conv1d-178               [-1, 128, 2]           8,320
 MyConv1dPadSame-179               [-1, 128, 2]               0
      Bottleneck-180               [-1, 128, 2]               0
     BatchNorm1d-181               [-1, 128, 2]             256
            ReLU-182               [-1, 128, 2]               0
         Dropout-183               [-1, 128, 2]               0
          Conv1d-184               [-1, 128, 1]           8,320
 MyConv1dPadSame-185               [-1, 128, 1]               0
     BatchNorm1d-186               [-1, 128, 1]             256
            ReLU-187               [-1, 128, 1]               0
         Dropout-188               [-1, 128, 1]               0
          Conv1d-189               [-1, 128, 1]           8,320
 MyConv1dPadSame-190               [-1, 128, 1]               0
       MaxPool1d-191               [-1, 128, 1]               0
MyMaxPool1dPadSame-192               [-1, 128, 1]               0
      Bottleneck-193               [-1, 128, 1]               0
     BatchNorm1d-194               [-1, 128, 1]             256
            ReLU-195               [-1, 128, 1]               0
          Linear-196                    [-1, 2]             258
================================================================
Total params: 87,858
Trainable params: 87,858
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 1.66
Params size (MB): 0.34
Estimated Total Size (MB): 2.00
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 16, kernel_size: 16, n_block: 2
************************************************************
************************************************************
(2000, 1, 256) Counter({1: 1000, 0: 1000})
(2000, 1, 256) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 16, 256]             272
   MyConv1dPadSame-2              [-1, 16, 256]               0
       BatchNorm1d-3              [-1, 16, 256]              32
              ReLU-4              [-1, 16, 256]               0
            Conv1d-5              [-1, 16, 256]             272
   MyConv1dPadSame-6              [-1, 16, 256]               0
       BatchNorm1d-7              [-1, 16, 256]              32
              ReLU-8              [-1, 16, 256]               0
           Dropout-9              [-1, 16, 256]               0
           Conv1d-10              [-1, 16, 256]             272
  MyConv1dPadSame-11              [-1, 16, 256]               0
       Bottleneck-12              [-1, 16, 256]               0
      BatchNorm1d-13              [-1, 16, 256]              32
             ReLU-14              [-1, 16, 256]               0
          Dropout-15              [-1, 16, 256]               0
           Conv1d-16              [-1, 32, 256]             544
  MyConv1dPadSame-17              [-1, 32, 256]               0
      BatchNorm1d-18              [-1, 32, 256]              64
             ReLU-19              [-1, 32, 256]               0
          Dropout-20              [-1, 32, 256]               0
           Conv1d-21              [-1, 32, 256]           1,056
  MyConv1dPadSame-22              [-1, 32, 256]               0
       Bottleneck-23              [-1, 32, 256]               0
      BatchNorm1d-24              [-1, 32, 256]              64
             ReLU-25              [-1, 32, 256]               0
           Linear-26                    [-1, 2]              66
================================================================
Total params: 2,706
Trainable params: 2,706
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 1.09
Params size (MB): 0.01
Estimated Total Size (MB): 1.11
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 16, kernel_size: 16, n_block: 4
************************************************************
************************************************************
(2000, 1, 256) Counter({0: 1000, 1: 1000})
(2000, 1, 256) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 16, 256]             272
   MyConv1dPadSame-2              [-1, 16, 256]               0
       BatchNorm1d-3              [-1, 16, 256]              32
              ReLU-4              [-1, 16, 256]               0
            Conv1d-5              [-1, 16, 256]             272
   MyConv1dPadSame-6              [-1, 16, 256]               0
       BatchNorm1d-7              [-1, 16, 256]              32
              ReLU-8              [-1, 16, 256]               0
           Dropout-9              [-1, 16, 256]               0
           Conv1d-10              [-1, 16, 256]             272
  MyConv1dPadSame-11              [-1, 16, 256]               0
       Bottleneck-12              [-1, 16, 256]               0
      BatchNorm1d-13              [-1, 16, 256]              32
             ReLU-14              [-1, 16, 256]               0
          Dropout-15              [-1, 16, 256]               0
           Conv1d-16              [-1, 32, 256]             544
  MyConv1dPadSame-17              [-1, 32, 256]               0
      BatchNorm1d-18              [-1, 32, 256]              64
             ReLU-19              [-1, 32, 256]               0
          Dropout-20              [-1, 32, 256]               0
           Conv1d-21              [-1, 32, 256]           1,056
  MyConv1dPadSame-22              [-1, 32, 256]               0
       Bottleneck-23              [-1, 32, 256]               0
      BatchNorm1d-24              [-1, 32, 256]              64
             ReLU-25              [-1, 32, 256]               0
          Dropout-26              [-1, 32, 256]               0
           Conv1d-27              [-1, 64, 256]           2,112
  MyConv1dPadSame-28              [-1, 64, 256]               0
      BatchNorm1d-29              [-1, 64, 256]             128
             ReLU-30              [-1, 64, 256]               0
          Dropout-31              [-1, 64, 256]               0
           Conv1d-32              [-1, 64, 256]           4,160
  MyConv1dPadSame-33              [-1, 64, 256]               0
       Bottleneck-34              [-1, 64, 256]               0
      BatchNorm1d-35              [-1, 64, 256]             128
             ReLU-36              [-1, 64, 256]               0
          Dropout-37              [-1, 64, 256]               0
           Conv1d-38             [-1, 128, 256]           8,320
  MyConv1dPadSame-39             [-1, 128, 256]               0
      BatchNorm1d-40             [-1, 128, 256]             256
             ReLU-41             [-1, 128, 256]               0
          Dropout-42             [-1, 128, 256]               0
           Conv1d-43             [-1, 128, 256]          16,512
  MyConv1dPadSame-44             [-1, 128, 256]               0
       Bottleneck-45             [-1, 128, 256]               0
      BatchNorm1d-46             [-1, 128, 256]             256
             ReLU-47             [-1, 128, 256]               0
           Linear-48                    [-1, 2]             258
================================================================
Total params: 34,770
Trainable params: 34,770
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 5.03
Params size (MB): 0.13
Estimated Total Size (MB): 5.16
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 16, kernel_size: 16, n_block: 8
************************************************************
************************************************************
(2000, 1, 256) Counter({1: 1000, 0: 1000})
(2000, 1, 256) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 16, 256]             272
   MyConv1dPadSame-2              [-1, 16, 256]               0
       BatchNorm1d-3              [-1, 16, 256]              32
              ReLU-4              [-1, 16, 256]               0
            Conv1d-5              [-1, 16, 256]             272
   MyConv1dPadSame-6              [-1, 16, 256]               0
       BatchNorm1d-7              [-1, 16, 256]              32
              ReLU-8              [-1, 16, 256]               0
           Dropout-9              [-1, 16, 256]               0
           Conv1d-10              [-1, 16, 256]             272
  MyConv1dPadSame-11              [-1, 16, 256]               0
       Bottleneck-12              [-1, 16, 256]               0
      BatchNorm1d-13              [-1, 16, 256]              32
             ReLU-14              [-1, 16, 256]               0
          Dropout-15              [-1, 16, 256]               0
           Conv1d-16              [-1, 16, 256]             272
  MyConv1dPadSame-17              [-1, 16, 256]               0
      BatchNorm1d-18              [-1, 16, 256]              32
             ReLU-19              [-1, 16, 256]               0
          Dropout-20              [-1, 16, 256]               0
           Conv1d-21              [-1, 16, 256]             272
  MyConv1dPadSame-22              [-1, 16, 256]               0
       Bottleneck-23              [-1, 16, 256]               0
      BatchNorm1d-24              [-1, 16, 256]              32
             ReLU-25              [-1, 16, 256]               0
          Dropout-26              [-1, 16, 256]               0
           Conv1d-27              [-1, 32, 256]             544
  MyConv1dPadSame-28              [-1, 32, 256]               0
      BatchNorm1d-29              [-1, 32, 256]              64
             ReLU-30              [-1, 32, 256]               0
          Dropout-31              [-1, 32, 256]               0
           Conv1d-32              [-1, 32, 256]           1,056
  MyConv1dPadSame-33              [-1, 32, 256]               0
       Bottleneck-34              [-1, 32, 256]               0
      BatchNorm1d-35              [-1, 32, 256]              64
             ReLU-36              [-1, 32, 256]               0
          Dropout-37              [-1, 32, 256]               0
           Conv1d-38              [-1, 32, 256]           1,056
  MyConv1dPadSame-39              [-1, 32, 256]               0
      BatchNorm1d-40              [-1, 32, 256]              64
             ReLU-41              [-1, 32, 256]               0
          Dropout-42              [-1, 32, 256]               0
           Conv1d-43              [-1, 32, 256]           1,056
  MyConv1dPadSame-44              [-1, 32, 256]               0
       Bottleneck-45              [-1, 32, 256]               0
      BatchNorm1d-46              [-1, 32, 256]              64
             ReLU-47              [-1, 32, 256]               0
          Dropout-48              [-1, 32, 256]               0
           Conv1d-49              [-1, 64, 256]           2,112
  MyConv1dPadSame-50              [-1, 64, 256]               0
      BatchNorm1d-51              [-1, 64, 256]             128
             ReLU-52              [-1, 64, 256]               0
          Dropout-53              [-1, 64, 256]               0
           Conv1d-54              [-1, 64, 256]           4,160
  MyConv1dPadSame-55              [-1, 64, 256]               0
       Bottleneck-56              [-1, 64, 256]               0
      BatchNorm1d-57              [-1, 64, 256]             128
             ReLU-58              [-1, 64, 256]               0
          Dropout-59              [-1, 64, 256]               0
           Conv1d-60              [-1, 64, 256]           4,160
  MyConv1dPadSame-61              [-1, 64, 256]               0
      BatchNorm1d-62              [-1, 64, 256]             128
             ReLU-63              [-1, 64, 256]               0
          Dropout-64              [-1, 64, 256]               0
           Conv1d-65              [-1, 64, 256]           4,160
  MyConv1dPadSame-66              [-1, 64, 256]               0
       Bottleneck-67              [-1, 64, 256]               0
      BatchNorm1d-68              [-1, 64, 256]             128
             ReLU-69              [-1, 64, 256]               0
          Dropout-70              [-1, 64, 256]               0
           Conv1d-71             [-1, 128, 256]           8,320
  MyConv1dPadSame-72             [-1, 128, 256]               0
      BatchNorm1d-73             [-1, 128, 256]             256
             ReLU-74             [-1, 128, 256]               0
          Dropout-75             [-1, 128, 256]               0
           Conv1d-76             [-1, 128, 256]          16,512
  MyConv1dPadSame-77             [-1, 128, 256]               0
       Bottleneck-78             [-1, 128, 256]               0
      BatchNorm1d-79             [-1, 128, 256]             256
             ReLU-80             [-1, 128, 256]               0
          Dropout-81             [-1, 128, 256]               0
           Conv1d-82             [-1, 128, 256]          16,512
  MyConv1dPadSame-83             [-1, 128, 256]               0
      BatchNorm1d-84             [-1, 128, 256]             256
             ReLU-85             [-1, 128, 256]               0
          Dropout-86             [-1, 128, 256]               0
           Conv1d-87             [-1, 128, 256]          16,512
  MyConv1dPadSame-88             [-1, 128, 256]               0
       Bottleneck-89             [-1, 128, 256]               0
      BatchNorm1d-90             [-1, 128, 256]             256
             ReLU-91             [-1, 128, 256]               0
           Linear-92                    [-1, 2]             258
================================================================
Total params: 79,730
Trainable params: 79,730
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 10.19
Params size (MB): 0.30
Estimated Total Size (MB): 10.49
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 16, kernel_size: 16, n_block: 16
************************************************************
************************************************************
(2000, 1, 256) Counter({0: 1000, 1: 1000})
(2000, 1, 256) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 16, 256]             272
   MyConv1dPadSame-2              [-1, 16, 256]               0
       BatchNorm1d-3              [-1, 16, 256]              32
              ReLU-4              [-1, 16, 256]               0
            Conv1d-5              [-1, 16, 256]             272
   MyConv1dPadSame-6              [-1, 16, 256]               0
       BatchNorm1d-7              [-1, 16, 256]              32
              ReLU-8              [-1, 16, 256]               0
           Dropout-9              [-1, 16, 256]               0
           Conv1d-10              [-1, 16, 256]             272
  MyConv1dPadSame-11              [-1, 16, 256]               0
       Bottleneck-12              [-1, 16, 256]               0
      BatchNorm1d-13              [-1, 16, 256]              32
             ReLU-14              [-1, 16, 256]               0
          Dropout-15              [-1, 16, 256]               0
           Conv1d-16              [-1, 16, 128]             272
  MyConv1dPadSame-17              [-1, 16, 128]               0
      BatchNorm1d-18              [-1, 16, 128]              32
             ReLU-19              [-1, 16, 128]               0
          Dropout-20              [-1, 16, 128]               0
           Conv1d-21              [-1, 16, 128]             272
  MyConv1dPadSame-22              [-1, 16, 128]               0
        MaxPool1d-23              [-1, 16, 128]               0
MyMaxPool1dPadSame-24              [-1, 16, 128]               0
       Bottleneck-25              [-1, 16, 128]               0
      BatchNorm1d-26              [-1, 16, 128]              32
             ReLU-27              [-1, 16, 128]               0
          Dropout-28              [-1, 16, 128]               0
           Conv1d-29              [-1, 16, 128]             272
  MyConv1dPadSame-30              [-1, 16, 128]               0
      BatchNorm1d-31              [-1, 16, 128]              32
             ReLU-32              [-1, 16, 128]               0
          Dropout-33              [-1, 16, 128]               0
           Conv1d-34              [-1, 16, 128]             272
  MyConv1dPadSame-35              [-1, 16, 128]               0
       Bottleneck-36              [-1, 16, 128]               0
      BatchNorm1d-37              [-1, 16, 128]              32
             ReLU-38              [-1, 16, 128]               0
          Dropout-39              [-1, 16, 128]               0
           Conv1d-40               [-1, 16, 64]             272
  MyConv1dPadSame-41               [-1, 16, 64]               0
      BatchNorm1d-42               [-1, 16, 64]              32
             ReLU-43               [-1, 16, 64]               0
          Dropout-44               [-1, 16, 64]               0
           Conv1d-45               [-1, 16, 64]             272
  MyConv1dPadSame-46               [-1, 16, 64]               0
        MaxPool1d-47               [-1, 16, 64]               0
MyMaxPool1dPadSame-48               [-1, 16, 64]               0
       Bottleneck-49               [-1, 16, 64]               0
      BatchNorm1d-50               [-1, 16, 64]              32
             ReLU-51               [-1, 16, 64]               0
          Dropout-52               [-1, 16, 64]               0
           Conv1d-53               [-1, 32, 64]             544
  MyConv1dPadSame-54               [-1, 32, 64]               0
      BatchNorm1d-55               [-1, 32, 64]              64
             ReLU-56               [-1, 32, 64]               0
          Dropout-57               [-1, 32, 64]               0
           Conv1d-58               [-1, 32, 64]           1,056
  MyConv1dPadSame-59               [-1, 32, 64]               0
       Bottleneck-60               [-1, 32, 64]               0
      BatchNorm1d-61               [-1, 32, 64]              64
             ReLU-62               [-1, 32, 64]               0
          Dropout-63               [-1, 32, 64]               0
           Conv1d-64               [-1, 32, 32]           1,056
  MyConv1dPadSame-65               [-1, 32, 32]               0
      BatchNorm1d-66               [-1, 32, 32]              64
             ReLU-67               [-1, 32, 32]               0
          Dropout-68               [-1, 32, 32]               0
           Conv1d-69               [-1, 32, 32]           1,056
  MyConv1dPadSame-70               [-1, 32, 32]               0
        MaxPool1d-71               [-1, 32, 32]               0
MyMaxPool1dPadSame-72               [-1, 32, 32]               0
       Bottleneck-73               [-1, 32, 32]               0
      BatchNorm1d-74               [-1, 32, 32]              64
             ReLU-75               [-1, 32, 32]               0
          Dropout-76               [-1, 32, 32]               0
           Conv1d-77               [-1, 32, 32]           1,056
  MyConv1dPadSame-78               [-1, 32, 32]               0
      BatchNorm1d-79               [-1, 32, 32]              64
             ReLU-80               [-1, 32, 32]               0
          Dropout-81               [-1, 32, 32]               0
           Conv1d-82               [-1, 32, 32]           1,056
  MyConv1dPadSame-83               [-1, 32, 32]               0
       Bottleneck-84               [-1, 32, 32]               0
      BatchNorm1d-85               [-1, 32, 32]              64
             ReLU-86               [-1, 32, 32]               0
          Dropout-87               [-1, 32, 32]               0
           Conv1d-88               [-1, 32, 16]           1,056
  MyConv1dPadSame-89               [-1, 32, 16]               0
      BatchNorm1d-90               [-1, 32, 16]              64
             ReLU-91               [-1, 32, 16]               0
          Dropout-92               [-1, 32, 16]               0
           Conv1d-93               [-1, 32, 16]           1,056
  MyConv1dPadSame-94               [-1, 32, 16]               0
        MaxPool1d-95               [-1, 32, 16]               0
MyMaxPool1dPadSame-96               [-1, 32, 16]               0
       Bottleneck-97               [-1, 32, 16]               0
      BatchNorm1d-98               [-1, 32, 16]              64
             ReLU-99               [-1, 32, 16]               0
         Dropout-100               [-1, 32, 16]               0
          Conv1d-101               [-1, 64, 16]           2,112
 MyConv1dPadSame-102               [-1, 64, 16]               0
     BatchNorm1d-103               [-1, 64, 16]             128
            ReLU-104               [-1, 64, 16]               0
         Dropout-105               [-1, 64, 16]               0
          Conv1d-106               [-1, 64, 16]           4,160
 MyConv1dPadSame-107               [-1, 64, 16]               0
      Bottleneck-108               [-1, 64, 16]               0
     BatchNorm1d-109               [-1, 64, 16]             128
            ReLU-110               [-1, 64, 16]               0
         Dropout-111               [-1, 64, 16]               0
          Conv1d-112                [-1, 64, 8]           4,160
 MyConv1dPadSame-113                [-1, 64, 8]               0
     BatchNorm1d-114                [-1, 64, 8]             128
            ReLU-115                [-1, 64, 8]               0
         Dropout-116                [-1, 64, 8]               0
          Conv1d-117                [-1, 64, 8]           4,160
 MyConv1dPadSame-118                [-1, 64, 8]               0
       MaxPool1d-119                [-1, 64, 8]               0
MyMaxPool1dPadSame-120                [-1, 64, 8]               0
      Bottleneck-121                [-1, 64, 8]               0
     BatchNorm1d-122                [-1, 64, 8]             128
            ReLU-123                [-1, 64, 8]               0
         Dropout-124                [-1, 64, 8]               0
          Conv1d-125                [-1, 64, 8]           4,160
 MyConv1dPadSame-126                [-1, 64, 8]               0
     BatchNorm1d-127                [-1, 64, 8]             128
            ReLU-128                [-1, 64, 8]               0
         Dropout-129                [-1, 64, 8]               0
          Conv1d-130                [-1, 64, 8]           4,160
 MyConv1dPadSame-131                [-1, 64, 8]               0
      Bottleneck-132                [-1, 64, 8]               0
     BatchNorm1d-133                [-1, 64, 8]             128
            ReLU-134                [-1, 64, 8]               0
         Dropout-135                [-1, 64, 8]               0
          Conv1d-136                [-1, 64, 4]           4,160
 MyConv1dPadSame-137                [-1, 64, 4]               0
     BatchNorm1d-138                [-1, 64, 4]             128
            ReLU-139                [-1, 64, 4]               0
         Dropout-140                [-1, 64, 4]               0
          Conv1d-141                [-1, 64, 4]           4,160
 MyConv1dPadSame-142                [-1, 64, 4]               0
       MaxPool1d-143                [-1, 64, 4]               0
MyMaxPool1dPadSame-144                [-1, 64, 4]               0
      Bottleneck-145                [-1, 64, 4]               0
     BatchNorm1d-146                [-1, 64, 4]             128
            ReLU-147                [-1, 64, 4]               0
         Dropout-148                [-1, 64, 4]               0
          Conv1d-149               [-1, 128, 4]           8,320
 MyConv1dPadSame-150               [-1, 128, 4]               0
     BatchNorm1d-151               [-1, 128, 4]             256
            ReLU-152               [-1, 128, 4]               0
         Dropout-153               [-1, 128, 4]               0
          Conv1d-154               [-1, 128, 4]          16,512
 MyConv1dPadSame-155               [-1, 128, 4]               0
      Bottleneck-156               [-1, 128, 4]               0
     BatchNorm1d-157               [-1, 128, 4]             256
            ReLU-158               [-1, 128, 4]               0
         Dropout-159               [-1, 128, 4]               0
          Conv1d-160               [-1, 128, 2]          16,512
 MyConv1dPadSame-161               [-1, 128, 2]               0
     BatchNorm1d-162               [-1, 128, 2]             256
            ReLU-163               [-1, 128, 2]               0
         Dropout-164               [-1, 128, 2]               0
          Conv1d-165               [-1, 128, 2]          16,512
 MyConv1dPadSame-166               [-1, 128, 2]               0
       MaxPool1d-167               [-1, 128, 2]               0
MyMaxPool1dPadSame-168               [-1, 128, 2]               0
      Bottleneck-169               [-1, 128, 2]               0
     BatchNorm1d-170               [-1, 128, 2]             256
            ReLU-171               [-1, 128, 2]               0
         Dropout-172               [-1, 128, 2]               0
          Conv1d-173               [-1, 128, 2]          16,512
 MyConv1dPadSame-174               [-1, 128, 2]               0
     BatchNorm1d-175               [-1, 128, 2]             256
            ReLU-176               [-1, 128, 2]               0
         Dropout-177               [-1, 128, 2]               0
          Conv1d-178               [-1, 128, 2]          16,512
 MyConv1dPadSame-179               [-1, 128, 2]               0
      Bottleneck-180               [-1, 128, 2]               0
     BatchNorm1d-181               [-1, 128, 2]             256
            ReLU-182               [-1, 128, 2]               0
         Dropout-183               [-1, 128, 2]               0
          Conv1d-184               [-1, 128, 1]          16,512
 MyConv1dPadSame-185               [-1, 128, 1]               0
     BatchNorm1d-186               [-1, 128, 1]             256
            ReLU-187               [-1, 128, 1]               0
         Dropout-188               [-1, 128, 1]               0
          Conv1d-189               [-1, 128, 1]          16,512
 MyConv1dPadSame-190               [-1, 128, 1]               0
       MaxPool1d-191               [-1, 128, 1]               0
MyMaxPool1dPadSame-192               [-1, 128, 1]               0
      Bottleneck-193               [-1, 128, 1]               0
     BatchNorm1d-194               [-1, 128, 1]             256
            ReLU-195               [-1, 128, 1]               0
          Linear-196                    [-1, 2]             258
================================================================
Total params: 169,650
Trainable params: 169,650
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 1.66
Params size (MB): 0.65
Estimated Total Size (MB): 2.31
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 32, kernel_size: 2, n_block: 2
************************************************************
************************************************************
(2000, 1, 256) Counter({0: 1000, 1: 1000})
(2000, 1, 256) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 32, 256]              96
   MyConv1dPadSame-2              [-1, 32, 256]               0
       BatchNorm1d-3              [-1, 32, 256]              64
              ReLU-4              [-1, 32, 256]               0
            Conv1d-5              [-1, 32, 256]              96
   MyConv1dPadSame-6              [-1, 32, 256]               0
       BatchNorm1d-7              [-1, 32, 256]              64
              ReLU-8              [-1, 32, 256]               0
           Dropout-9              [-1, 32, 256]               0
           Conv1d-10              [-1, 32, 256]              96
  MyConv1dPadSame-11              [-1, 32, 256]               0
       Bottleneck-12              [-1, 32, 256]               0
      BatchNorm1d-13              [-1, 32, 256]              64
             ReLU-14              [-1, 32, 256]               0
          Dropout-15              [-1, 32, 256]               0
           Conv1d-16              [-1, 64, 256]             192
  MyConv1dPadSame-17              [-1, 64, 256]               0
      BatchNorm1d-18              [-1, 64, 256]             128
             ReLU-19              [-1, 64, 256]               0
          Dropout-20              [-1, 64, 256]               0
           Conv1d-21              [-1, 64, 256]             320
  MyConv1dPadSame-22              [-1, 64, 256]               0
       Bottleneck-23              [-1, 64, 256]               0
      BatchNorm1d-24              [-1, 64, 256]             128
             ReLU-25              [-1, 64, 256]               0
           Linear-26                    [-1, 2]             130
================================================================
Total params: 1,378
Trainable params: 1,378
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 2.19
Params size (MB): 0.01
Estimated Total Size (MB): 2.19
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 32, kernel_size: 2, n_block: 4
************************************************************
************************************************************
(2000, 1, 256) Counter({1: 1000, 0: 1000})
(2000, 1, 256) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 32, 256]              96
   MyConv1dPadSame-2              [-1, 32, 256]               0
       BatchNorm1d-3              [-1, 32, 256]              64
              ReLU-4              [-1, 32, 256]               0
            Conv1d-5              [-1, 32, 256]              96
   MyConv1dPadSame-6              [-1, 32, 256]               0
       BatchNorm1d-7              [-1, 32, 256]              64
              ReLU-8              [-1, 32, 256]               0
           Dropout-9              [-1, 32, 256]               0
           Conv1d-10              [-1, 32, 256]              96
  MyConv1dPadSame-11              [-1, 32, 256]               0
       Bottleneck-12              [-1, 32, 256]               0
      BatchNorm1d-13              [-1, 32, 256]              64
             ReLU-14              [-1, 32, 256]               0
          Dropout-15              [-1, 32, 256]               0
           Conv1d-16              [-1, 64, 256]             192
  MyConv1dPadSame-17              [-1, 64, 256]               0
      BatchNorm1d-18              [-1, 64, 256]             128
             ReLU-19              [-1, 64, 256]               0
          Dropout-20              [-1, 64, 256]               0
           Conv1d-21              [-1, 64, 256]             320
  MyConv1dPadSame-22              [-1, 64, 256]               0
       Bottleneck-23              [-1, 64, 256]               0
      BatchNorm1d-24              [-1, 64, 256]             128
             ReLU-25              [-1, 64, 256]               0
          Dropout-26              [-1, 64, 256]               0
           Conv1d-27             [-1, 128, 256]             640
  MyConv1dPadSame-28             [-1, 128, 256]               0
      BatchNorm1d-29             [-1, 128, 256]             256
             ReLU-30             [-1, 128, 256]               0
          Dropout-31             [-1, 128, 256]               0
           Conv1d-32             [-1, 128, 256]           1,152
  MyConv1dPadSame-33             [-1, 128, 256]               0
       Bottleneck-34             [-1, 128, 256]               0
      BatchNorm1d-35             [-1, 128, 256]             256
             ReLU-36             [-1, 128, 256]               0
          Dropout-37             [-1, 128, 256]               0
           Conv1d-38             [-1, 256, 256]           2,304
  MyConv1dPadSame-39             [-1, 256, 256]               0
      BatchNorm1d-40             [-1, 256, 256]             512
             ReLU-41             [-1, 256, 256]               0
          Dropout-42             [-1, 256, 256]               0
           Conv1d-43             [-1, 256, 256]           4,352
  MyConv1dPadSame-44             [-1, 256, 256]               0
       Bottleneck-45             [-1, 256, 256]               0
      BatchNorm1d-46             [-1, 256, 256]             512
             ReLU-47             [-1, 256, 256]               0
           Linear-48                    [-1, 2]             514
================================================================
Total params: 11,746
Trainable params: 11,746
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 10.06
Params size (MB): 0.04
Estimated Total Size (MB): 10.11
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 32, kernel_size: 2, n_block: 8
************************************************************
************************************************************
(2000, 1, 256) Counter({0: 1000, 1: 1000})
(2000, 1, 256) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 32, 256]              96
   MyConv1dPadSame-2              [-1, 32, 256]               0
       BatchNorm1d-3              [-1, 32, 256]              64
              ReLU-4              [-1, 32, 256]               0
            Conv1d-5              [-1, 32, 256]              96
   MyConv1dPadSame-6              [-1, 32, 256]               0
       BatchNorm1d-7              [-1, 32, 256]              64
              ReLU-8              [-1, 32, 256]               0
           Dropout-9              [-1, 32, 256]               0
           Conv1d-10              [-1, 32, 256]              96
  MyConv1dPadSame-11              [-1, 32, 256]               0
       Bottleneck-12              [-1, 32, 256]               0
      BatchNorm1d-13              [-1, 32, 256]              64
             ReLU-14              [-1, 32, 256]               0
          Dropout-15              [-1, 32, 256]               0
           Conv1d-16              [-1, 32, 256]              96
  MyConv1dPadSame-17              [-1, 32, 256]               0
      BatchNorm1d-18              [-1, 32, 256]              64
             ReLU-19              [-1, 32, 256]               0
          Dropout-20              [-1, 32, 256]               0
           Conv1d-21              [-1, 32, 256]              96
  MyConv1dPadSame-22              [-1, 32, 256]               0
       Bottleneck-23              [-1, 32, 256]               0
      BatchNorm1d-24              [-1, 32, 256]              64
             ReLU-25              [-1, 32, 256]               0
          Dropout-26              [-1, 32, 256]               0
           Conv1d-27              [-1, 64, 256]             192
  MyConv1dPadSame-28              [-1, 64, 256]               0
      BatchNorm1d-29              [-1, 64, 256]             128
             ReLU-30              [-1, 64, 256]               0
          Dropout-31              [-1, 64, 256]               0
           Conv1d-32              [-1, 64, 256]             320
  MyConv1dPadSame-33              [-1, 64, 256]               0
       Bottleneck-34              [-1, 64, 256]               0
      BatchNorm1d-35              [-1, 64, 256]             128
             ReLU-36              [-1, 64, 256]               0
          Dropout-37              [-1, 64, 256]               0
           Conv1d-38              [-1, 64, 256]             320
  MyConv1dPadSame-39              [-1, 64, 256]               0
      BatchNorm1d-40              [-1, 64, 256]             128
             ReLU-41              [-1, 64, 256]               0
          Dropout-42              [-1, 64, 256]               0
           Conv1d-43              [-1, 64, 256]             320
  MyConv1dPadSame-44              [-1, 64, 256]               0
       Bottleneck-45              [-1, 64, 256]               0
      BatchNorm1d-46              [-1, 64, 256]             128
             ReLU-47              [-1, 64, 256]               0
          Dropout-48              [-1, 64, 256]               0
           Conv1d-49             [-1, 128, 256]             640
  MyConv1dPadSame-50             [-1, 128, 256]               0
      BatchNorm1d-51             [-1, 128, 256]             256
             ReLU-52             [-1, 128, 256]               0
          Dropout-53             [-1, 128, 256]               0
           Conv1d-54             [-1, 128, 256]           1,152
  MyConv1dPadSame-55             [-1, 128, 256]               0
       Bottleneck-56             [-1, 128, 256]               0
      BatchNorm1d-57             [-1, 128, 256]             256
             ReLU-58             [-1, 128, 256]               0
          Dropout-59             [-1, 128, 256]               0
           Conv1d-60             [-1, 128, 256]           1,152
  MyConv1dPadSame-61             [-1, 128, 256]               0
      BatchNorm1d-62             [-1, 128, 256]             256
             ReLU-63             [-1, 128, 256]               0
          Dropout-64             [-1, 128, 256]               0
           Conv1d-65             [-1, 128, 256]           1,152
  MyConv1dPadSame-66             [-1, 128, 256]               0
       Bottleneck-67             [-1, 128, 256]               0
      BatchNorm1d-68             [-1, 128, 256]             256
             ReLU-69             [-1, 128, 256]               0
          Dropout-70             [-1, 128, 256]               0
           Conv1d-71             [-1, 256, 256]           2,304
  MyConv1dPadSame-72             [-1, 256, 256]               0
      BatchNorm1d-73             [-1, 256, 256]             512
             ReLU-74             [-1, 256, 256]               0
          Dropout-75             [-1, 256, 256]               0
           Conv1d-76             [-1, 256, 256]           4,352
  MyConv1dPadSame-77             [-1, 256, 256]               0
       Bottleneck-78             [-1, 256, 256]               0
      BatchNorm1d-79             [-1, 256, 256]             512
             ReLU-80             [-1, 256, 256]               0
          Dropout-81             [-1, 256, 256]               0
           Conv1d-82             [-1, 256, 256]           4,352
  MyConv1dPadSame-83             [-1, 256, 256]               0
      BatchNorm1d-84             [-1, 256, 256]             512
             ReLU-85             [-1, 256, 256]               0
          Dropout-86             [-1, 256, 256]               0
           Conv1d-87             [-1, 256, 256]           4,352
  MyConv1dPadSame-88             [-1, 256, 256]               0
       Bottleneck-89             [-1, 256, 256]               0
      BatchNorm1d-90             [-1, 256, 256]             512
             ReLU-91             [-1, 256, 256]               0
           Linear-92                    [-1, 2]             514
================================================================
Total params: 25,506
Trainable params: 25,506
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 20.38
Params size (MB): 0.10
Estimated Total Size (MB): 20.47
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 32, kernel_size: 2, n_block: 16
************************************************************
************************************************************
(2000, 1, 256) Counter({1: 1000, 0: 1000})
(2000, 1, 256) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 32, 256]              96
   MyConv1dPadSame-2              [-1, 32, 256]               0
       BatchNorm1d-3              [-1, 32, 256]              64
              ReLU-4              [-1, 32, 256]               0
            Conv1d-5              [-1, 32, 256]              96
   MyConv1dPadSame-6              [-1, 32, 256]               0
       BatchNorm1d-7              [-1, 32, 256]              64
              ReLU-8              [-1, 32, 256]               0
           Dropout-9              [-1, 32, 256]               0
           Conv1d-10              [-1, 32, 256]              96
  MyConv1dPadSame-11              [-1, 32, 256]               0
       Bottleneck-12              [-1, 32, 256]               0
      BatchNorm1d-13              [-1, 32, 256]              64
             ReLU-14              [-1, 32, 256]               0
          Dropout-15              [-1, 32, 256]               0
           Conv1d-16              [-1, 32, 128]              96
  MyConv1dPadSame-17              [-1, 32, 128]               0
      BatchNorm1d-18              [-1, 32, 128]              64
             ReLU-19              [-1, 32, 128]               0
          Dropout-20              [-1, 32, 128]               0
           Conv1d-21              [-1, 32, 128]              96
  MyConv1dPadSame-22              [-1, 32, 128]               0
        MaxPool1d-23              [-1, 32, 128]               0
MyMaxPool1dPadSame-24              [-1, 32, 128]               0
       Bottleneck-25              [-1, 32, 128]               0
      BatchNorm1d-26              [-1, 32, 128]              64
             ReLU-27              [-1, 32, 128]               0
          Dropout-28              [-1, 32, 128]               0
           Conv1d-29              [-1, 32, 128]              96
  MyConv1dPadSame-30              [-1, 32, 128]               0
      BatchNorm1d-31              [-1, 32, 128]              64
             ReLU-32              [-1, 32, 128]               0
          Dropout-33              [-1, 32, 128]               0
           Conv1d-34              [-1, 32, 128]              96
  MyConv1dPadSame-35              [-1, 32, 128]               0
       Bottleneck-36              [-1, 32, 128]               0
      BatchNorm1d-37              [-1, 32, 128]              64
             ReLU-38              [-1, 32, 128]               0
          Dropout-39              [-1, 32, 128]               0
           Conv1d-40               [-1, 32, 64]              96
  MyConv1dPadSame-41               [-1, 32, 64]               0
      BatchNorm1d-42               [-1, 32, 64]              64
             ReLU-43               [-1, 32, 64]               0
          Dropout-44               [-1, 32, 64]               0
           Conv1d-45               [-1, 32, 64]              96
  MyConv1dPadSame-46               [-1, 32, 64]               0
        MaxPool1d-47               [-1, 32, 64]               0
MyMaxPool1dPadSame-48               [-1, 32, 64]               0
       Bottleneck-49               [-1, 32, 64]               0
      BatchNorm1d-50               [-1, 32, 64]              64
             ReLU-51               [-1, 32, 64]               0
          Dropout-52               [-1, 32, 64]               0
           Conv1d-53               [-1, 64, 64]             192
  MyConv1dPadSame-54               [-1, 64, 64]               0
      BatchNorm1d-55               [-1, 64, 64]             128
             ReLU-56               [-1, 64, 64]               0
          Dropout-57               [-1, 64, 64]               0
           Conv1d-58               [-1, 64, 64]             320
  MyConv1dPadSame-59               [-1, 64, 64]               0
       Bottleneck-60               [-1, 64, 64]               0
      BatchNorm1d-61               [-1, 64, 64]             128
             ReLU-62               [-1, 64, 64]               0
          Dropout-63               [-1, 64, 64]               0
           Conv1d-64               [-1, 64, 32]             320
  MyConv1dPadSame-65               [-1, 64, 32]               0
      BatchNorm1d-66               [-1, 64, 32]             128
             ReLU-67               [-1, 64, 32]               0
          Dropout-68               [-1, 64, 32]               0
           Conv1d-69               [-1, 64, 32]             320
  MyConv1dPadSame-70               [-1, 64, 32]               0
        MaxPool1d-71               [-1, 64, 32]               0
MyMaxPool1dPadSame-72               [-1, 64, 32]               0
       Bottleneck-73               [-1, 64, 32]               0
      BatchNorm1d-74               [-1, 64, 32]             128
             ReLU-75               [-1, 64, 32]               0
          Dropout-76               [-1, 64, 32]               0
           Conv1d-77               [-1, 64, 32]             320
  MyConv1dPadSame-78               [-1, 64, 32]               0
      BatchNorm1d-79               [-1, 64, 32]             128
             ReLU-80               [-1, 64, 32]               0
          Dropout-81               [-1, 64, 32]               0
           Conv1d-82               [-1, 64, 32]             320
  MyConv1dPadSame-83               [-1, 64, 32]               0
       Bottleneck-84               [-1, 64, 32]               0
      BatchNorm1d-85               [-1, 64, 32]             128
             ReLU-86               [-1, 64, 32]               0
          Dropout-87               [-1, 64, 32]               0
           Conv1d-88               [-1, 64, 16]             320
  MyConv1dPadSame-89               [-1, 64, 16]               0
      BatchNorm1d-90               [-1, 64, 16]             128
             ReLU-91               [-1, 64, 16]               0
          Dropout-92               [-1, 64, 16]               0
           Conv1d-93               [-1, 64, 16]             320
  MyConv1dPadSame-94               [-1, 64, 16]               0
        MaxPool1d-95               [-1, 64, 16]               0
MyMaxPool1dPadSame-96               [-1, 64, 16]               0
       Bottleneck-97               [-1, 64, 16]               0
      BatchNorm1d-98               [-1, 64, 16]             128
             ReLU-99               [-1, 64, 16]               0
         Dropout-100               [-1, 64, 16]               0
          Conv1d-101              [-1, 128, 16]             640
 MyConv1dPadSame-102              [-1, 128, 16]               0
     BatchNorm1d-103              [-1, 128, 16]             256
            ReLU-104              [-1, 128, 16]               0
         Dropout-105              [-1, 128, 16]               0
          Conv1d-106              [-1, 128, 16]           1,152
 MyConv1dPadSame-107              [-1, 128, 16]               0
      Bottleneck-108              [-1, 128, 16]               0
     BatchNorm1d-109              [-1, 128, 16]             256
            ReLU-110              [-1, 128, 16]               0
         Dropout-111              [-1, 128, 16]               0
          Conv1d-112               [-1, 128, 8]           1,152
 MyConv1dPadSame-113               [-1, 128, 8]               0
     BatchNorm1d-114               [-1, 128, 8]             256
            ReLU-115               [-1, 128, 8]               0
         Dropout-116               [-1, 128, 8]               0
          Conv1d-117               [-1, 128, 8]           1,152
 MyConv1dPadSame-118               [-1, 128, 8]               0
       MaxPool1d-119               [-1, 128, 8]               0
MyMaxPool1dPadSame-120               [-1, 128, 8]               0
      Bottleneck-121               [-1, 128, 8]               0
     BatchNorm1d-122               [-1, 128, 8]             256
            ReLU-123               [-1, 128, 8]               0
         Dropout-124               [-1, 128, 8]               0
          Conv1d-125               [-1, 128, 8]           1,152
 MyConv1dPadSame-126               [-1, 128, 8]               0
     BatchNorm1d-127               [-1, 128, 8]             256
            ReLU-128               [-1, 128, 8]               0
         Dropout-129               [-1, 128, 8]               0
          Conv1d-130               [-1, 128, 8]           1,152
 MyConv1dPadSame-131               [-1, 128, 8]               0
      Bottleneck-132               [-1, 128, 8]               0
     BatchNorm1d-133               [-1, 128, 8]             256
            ReLU-134               [-1, 128, 8]               0
         Dropout-135               [-1, 128, 8]               0
          Conv1d-136               [-1, 128, 4]           1,152
 MyConv1dPadSame-137               [-1, 128, 4]               0
     BatchNorm1d-138               [-1, 128, 4]             256
            ReLU-139               [-1, 128, 4]               0
         Dropout-140               [-1, 128, 4]               0
          Conv1d-141               [-1, 128, 4]           1,152
 MyConv1dPadSame-142               [-1, 128, 4]               0
       MaxPool1d-143               [-1, 128, 4]               0
MyMaxPool1dPadSame-144               [-1, 128, 4]               0
      Bottleneck-145               [-1, 128, 4]               0
     BatchNorm1d-146               [-1, 128, 4]             256
            ReLU-147               [-1, 128, 4]               0
         Dropout-148               [-1, 128, 4]               0
          Conv1d-149               [-1, 256, 4]           2,304
 MyConv1dPadSame-150               [-1, 256, 4]               0
     BatchNorm1d-151               [-1, 256, 4]             512
            ReLU-152               [-1, 256, 4]               0
         Dropout-153               [-1, 256, 4]               0
          Conv1d-154               [-1, 256, 4]           4,352
 MyConv1dPadSame-155               [-1, 256, 4]               0
      Bottleneck-156               [-1, 256, 4]               0
     BatchNorm1d-157               [-1, 256, 4]             512
            ReLU-158               [-1, 256, 4]               0
         Dropout-159               [-1, 256, 4]               0
          Conv1d-160               [-1, 256, 2]           4,352
 MyConv1dPadSame-161               [-1, 256, 2]               0
     BatchNorm1d-162               [-1, 256, 2]             512
            ReLU-163               [-1, 256, 2]               0
         Dropout-164               [-1, 256, 2]               0
          Conv1d-165               [-1, 256, 2]           4,352
 MyConv1dPadSame-166               [-1, 256, 2]               0
       MaxPool1d-167               [-1, 256, 2]               0
MyMaxPool1dPadSame-168               [-1, 256, 2]               0
      Bottleneck-169               [-1, 256, 2]               0
     BatchNorm1d-170               [-1, 256, 2]             512
            ReLU-171               [-1, 256, 2]               0
         Dropout-172               [-1, 256, 2]               0
          Conv1d-173               [-1, 256, 2]           4,352
 MyConv1dPadSame-174               [-1, 256, 2]               0
     BatchNorm1d-175               [-1, 256, 2]             512
            ReLU-176               [-1, 256, 2]               0
         Dropout-177               [-1, 256, 2]               0
          Conv1d-178               [-1, 256, 2]           4,352
 MyConv1dPadSame-179               [-1, 256, 2]               0
      Bottleneck-180               [-1, 256, 2]               0
     BatchNorm1d-181               [-1, 256, 2]             512
            ReLU-182               [-1, 256, 2]               0
         Dropout-183               [-1, 256, 2]               0
          Conv1d-184               [-1, 256, 1]           4,352
 MyConv1dPadSame-185               [-1, 256, 1]               0
     BatchNorm1d-186               [-1, 256, 1]             512
            ReLU-187               [-1, 256, 1]               0
         Dropout-188               [-1, 256, 1]               0
          Conv1d-189               [-1, 256, 1]           4,352
 MyConv1dPadSame-190               [-1, 256, 1]               0
       MaxPool1d-191               [-1, 256, 1]               0
MyMaxPool1dPadSame-192               [-1, 256, 1]               0
      Bottleneck-193               [-1, 256, 1]               0
     BatchNorm1d-194               [-1, 256, 1]             512
            ReLU-195               [-1, 256, 1]               0
          Linear-196                    [-1, 2]             514
================================================================
Total params: 53,026
Trainable params: 53,026
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 3.32
Params size (MB): 0.20
Estimated Total Size (MB): 3.53
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 32, kernel_size: 4, n_block: 2
************************************************************
************************************************************
(2000, 1, 256) Counter({0: 1000, 1: 1000})
(2000, 1, 256) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 32, 256]             160
   MyConv1dPadSame-2              [-1, 32, 256]               0
       BatchNorm1d-3              [-1, 32, 256]              64
              ReLU-4              [-1, 32, 256]               0
            Conv1d-5              [-1, 32, 256]             160
   MyConv1dPadSame-6              [-1, 32, 256]               0
       BatchNorm1d-7              [-1, 32, 256]              64
              ReLU-8              [-1, 32, 256]               0
           Dropout-9              [-1, 32, 256]               0
           Conv1d-10              [-1, 32, 256]             160
  MyConv1dPadSame-11              [-1, 32, 256]               0
       Bottleneck-12              [-1, 32, 256]               0
      BatchNorm1d-13              [-1, 32, 256]              64
             ReLU-14              [-1, 32, 256]               0
          Dropout-15              [-1, 32, 256]               0
           Conv1d-16              [-1, 64, 256]             320
  MyConv1dPadSame-17              [-1, 64, 256]               0
      BatchNorm1d-18              [-1, 64, 256]             128
             ReLU-19              [-1, 64, 256]               0
          Dropout-20              [-1, 64, 256]               0
           Conv1d-21              [-1, 64, 256]             576
  MyConv1dPadSame-22              [-1, 64, 256]               0
       Bottleneck-23              [-1, 64, 256]               0
      BatchNorm1d-24              [-1, 64, 256]             128
             ReLU-25              [-1, 64, 256]               0
           Linear-26                    [-1, 2]             130
================================================================
Total params: 1,954
Trainable params: 1,954
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 2.19
Params size (MB): 0.01
Estimated Total Size (MB): 2.20
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 32, kernel_size: 4, n_block: 4
************************************************************
************************************************************
(2000, 1, 256) Counter({0: 1000, 1: 1000})
(2000, 1, 256) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 32, 256]             160
   MyConv1dPadSame-2              [-1, 32, 256]               0
       BatchNorm1d-3              [-1, 32, 256]              64
              ReLU-4              [-1, 32, 256]               0
            Conv1d-5              [-1, 32, 256]             160
   MyConv1dPadSame-6              [-1, 32, 256]               0
       BatchNorm1d-7              [-1, 32, 256]              64
              ReLU-8              [-1, 32, 256]               0
           Dropout-9              [-1, 32, 256]               0
           Conv1d-10              [-1, 32, 256]             160
  MyConv1dPadSame-11              [-1, 32, 256]               0
       Bottleneck-12              [-1, 32, 256]               0
      BatchNorm1d-13              [-1, 32, 256]              64
             ReLU-14              [-1, 32, 256]               0
          Dropout-15              [-1, 32, 256]               0
           Conv1d-16              [-1, 64, 256]             320
  MyConv1dPadSame-17              [-1, 64, 256]               0
      BatchNorm1d-18              [-1, 64, 256]             128
             ReLU-19              [-1, 64, 256]               0
          Dropout-20              [-1, 64, 256]               0
           Conv1d-21              [-1, 64, 256]             576
  MyConv1dPadSame-22              [-1, 64, 256]               0
       Bottleneck-23              [-1, 64, 256]               0
      BatchNorm1d-24              [-1, 64, 256]             128
             ReLU-25              [-1, 64, 256]               0
          Dropout-26              [-1, 64, 256]               0
           Conv1d-27             [-1, 128, 256]           1,152
  MyConv1dPadSame-28             [-1, 128, 256]               0
      BatchNorm1d-29             [-1, 128, 256]             256
             ReLU-30             [-1, 128, 256]               0
          Dropout-31             [-1, 128, 256]               0
           Conv1d-32             [-1, 128, 256]           2,176
  MyConv1dPadSame-33             [-1, 128, 256]               0
       Bottleneck-34             [-1, 128, 256]               0
      BatchNorm1d-35             [-1, 128, 256]             256
             ReLU-36             [-1, 128, 256]               0
          Dropout-37             [-1, 128, 256]               0
           Conv1d-38             [-1, 256, 256]           4,352
  MyConv1dPadSame-39             [-1, 256, 256]               0
      BatchNorm1d-40             [-1, 256, 256]             512
             ReLU-41             [-1, 256, 256]               0
          Dropout-42             [-1, 256, 256]               0
           Conv1d-43             [-1, 256, 256]           8,448
  MyConv1dPadSame-44             [-1, 256, 256]               0
       Bottleneck-45             [-1, 256, 256]               0
      BatchNorm1d-46             [-1, 256, 256]             512
             ReLU-47             [-1, 256, 256]               0
           Linear-48                    [-1, 2]             514
================================================================
Total params: 20,002
Trainable params: 20,002
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 10.06
Params size (MB): 0.08
Estimated Total Size (MB): 10.14
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 32, kernel_size: 4, n_block: 8
************************************************************
************************************************************
(2000, 1, 256) Counter({0: 1000, 1: 1000})
(2000, 1, 256) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 32, 256]             160
   MyConv1dPadSame-2              [-1, 32, 256]               0
       BatchNorm1d-3              [-1, 32, 256]              64
              ReLU-4              [-1, 32, 256]               0
            Conv1d-5              [-1, 32, 256]             160
   MyConv1dPadSame-6              [-1, 32, 256]               0
       BatchNorm1d-7              [-1, 32, 256]              64
              ReLU-8              [-1, 32, 256]               0
           Dropout-9              [-1, 32, 256]               0
           Conv1d-10              [-1, 32, 256]             160
  MyConv1dPadSame-11              [-1, 32, 256]               0
       Bottleneck-12              [-1, 32, 256]               0
      BatchNorm1d-13              [-1, 32, 256]              64
             ReLU-14              [-1, 32, 256]               0
          Dropout-15              [-1, 32, 256]               0
           Conv1d-16              [-1, 32, 256]             160
  MyConv1dPadSame-17              [-1, 32, 256]               0
      BatchNorm1d-18              [-1, 32, 256]              64
             ReLU-19              [-1, 32, 256]               0
          Dropout-20              [-1, 32, 256]               0
           Conv1d-21              [-1, 32, 256]             160
  MyConv1dPadSame-22              [-1, 32, 256]               0
       Bottleneck-23              [-1, 32, 256]               0
      BatchNorm1d-24              [-1, 32, 256]              64
             ReLU-25              [-1, 32, 256]               0
          Dropout-26              [-1, 32, 256]               0
           Conv1d-27              [-1, 64, 256]             320
  MyConv1dPadSame-28              [-1, 64, 256]               0
      BatchNorm1d-29              [-1, 64, 256]             128
             ReLU-30              [-1, 64, 256]               0
          Dropout-31              [-1, 64, 256]               0
           Conv1d-32              [-1, 64, 256]             576
  MyConv1dPadSame-33              [-1, 64, 256]               0
       Bottleneck-34              [-1, 64, 256]               0
      BatchNorm1d-35              [-1, 64, 256]             128
             ReLU-36              [-1, 64, 256]               0
          Dropout-37              [-1, 64, 256]               0
           Conv1d-38              [-1, 64, 256]             576
  MyConv1dPadSame-39              [-1, 64, 256]               0
      BatchNorm1d-40              [-1, 64, 256]             128
             ReLU-41              [-1, 64, 256]               0
          Dropout-42              [-1, 64, 256]               0
           Conv1d-43              [-1, 64, 256]             576
  MyConv1dPadSame-44              [-1, 64, 256]               0
       Bottleneck-45              [-1, 64, 256]               0
      BatchNorm1d-46              [-1, 64, 256]             128
             ReLU-47              [-1, 64, 256]               0
          Dropout-48              [-1, 64, 256]               0
           Conv1d-49             [-1, 128, 256]           1,152
  MyConv1dPadSame-50             [-1, 128, 256]               0
      BatchNorm1d-51             [-1, 128, 256]             256
             ReLU-52             [-1, 128, 256]               0
          Dropout-53             [-1, 128, 256]               0
           Conv1d-54             [-1, 128, 256]           2,176
  MyConv1dPadSame-55             [-1, 128, 256]               0
       Bottleneck-56             [-1, 128, 256]               0
      BatchNorm1d-57             [-1, 128, 256]             256
             ReLU-58             [-1, 128, 256]               0
          Dropout-59             [-1, 128, 256]               0
           Conv1d-60             [-1, 128, 256]           2,176
  MyConv1dPadSame-61             [-1, 128, 256]               0
      BatchNorm1d-62             [-1, 128, 256]             256
             ReLU-63             [-1, 128, 256]               0
          Dropout-64             [-1, 128, 256]               0
           Conv1d-65             [-1, 128, 256]           2,176
  MyConv1dPadSame-66             [-1, 128, 256]               0
       Bottleneck-67             [-1, 128, 256]               0
      BatchNorm1d-68             [-1, 128, 256]             256
             ReLU-69             [-1, 128, 256]               0
          Dropout-70             [-1, 128, 256]               0
           Conv1d-71             [-1, 256, 256]           4,352
  MyConv1dPadSame-72             [-1, 256, 256]               0
      BatchNorm1d-73             [-1, 256, 256]             512
             ReLU-74             [-1, 256, 256]               0
          Dropout-75             [-1, 256, 256]               0
           Conv1d-76             [-1, 256, 256]           8,448
  MyConv1dPadSame-77             [-1, 256, 256]               0
       Bottleneck-78             [-1, 256, 256]               0
      BatchNorm1d-79             [-1, 256, 256]             512
             ReLU-80             [-1, 256, 256]               0
          Dropout-81             [-1, 256, 256]               0
           Conv1d-82             [-1, 256, 256]           8,448
  MyConv1dPadSame-83             [-1, 256, 256]               0
      BatchNorm1d-84             [-1, 256, 256]             512
             ReLU-85             [-1, 256, 256]               0
          Dropout-86             [-1, 256, 256]               0
           Conv1d-87             [-1, 256, 256]           8,448
  MyConv1dPadSame-88             [-1, 256, 256]               0
       Bottleneck-89             [-1, 256, 256]               0
      BatchNorm1d-90             [-1, 256, 256]             512
             ReLU-91             [-1, 256, 256]               0
           Linear-92                    [-1, 2]             514
================================================================
Total params: 44,642
Trainable params: 44,642
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 20.38
Params size (MB): 0.17
Estimated Total Size (MB): 20.55
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 32, kernel_size: 4, n_block: 16
************************************************************
************************************************************
(2000, 1, 256) Counter({0: 1000, 1: 1000})
(2000, 1, 256) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 32, 256]             160
   MyConv1dPadSame-2              [-1, 32, 256]               0
       BatchNorm1d-3              [-1, 32, 256]              64
              ReLU-4              [-1, 32, 256]               0
            Conv1d-5              [-1, 32, 256]             160
   MyConv1dPadSame-6              [-1, 32, 256]               0
       BatchNorm1d-7              [-1, 32, 256]              64
              ReLU-8              [-1, 32, 256]               0
           Dropout-9              [-1, 32, 256]               0
           Conv1d-10              [-1, 32, 256]             160
  MyConv1dPadSame-11              [-1, 32, 256]               0
       Bottleneck-12              [-1, 32, 256]               0
      BatchNorm1d-13              [-1, 32, 256]              64
             ReLU-14              [-1, 32, 256]               0
          Dropout-15              [-1, 32, 256]               0
           Conv1d-16              [-1, 32, 128]             160
  MyConv1dPadSame-17              [-1, 32, 128]               0
      BatchNorm1d-18              [-1, 32, 128]              64
             ReLU-19              [-1, 32, 128]               0
          Dropout-20              [-1, 32, 128]               0
           Conv1d-21              [-1, 32, 128]             160
  MyConv1dPadSame-22              [-1, 32, 128]               0
        MaxPool1d-23              [-1, 32, 128]               0
MyMaxPool1dPadSame-24              [-1, 32, 128]               0
       Bottleneck-25              [-1, 32, 128]               0
      BatchNorm1d-26              [-1, 32, 128]              64
             ReLU-27              [-1, 32, 128]               0
          Dropout-28              [-1, 32, 128]               0
           Conv1d-29              [-1, 32, 128]             160
  MyConv1dPadSame-30              [-1, 32, 128]               0
      BatchNorm1d-31              [-1, 32, 128]              64
             ReLU-32              [-1, 32, 128]               0
          Dropout-33              [-1, 32, 128]               0
           Conv1d-34              [-1, 32, 128]             160
  MyConv1dPadSame-35              [-1, 32, 128]               0
       Bottleneck-36              [-1, 32, 128]               0
      BatchNorm1d-37              [-1, 32, 128]              64
             ReLU-38              [-1, 32, 128]               0
          Dropout-39              [-1, 32, 128]               0
           Conv1d-40               [-1, 32, 64]             160
  MyConv1dPadSame-41               [-1, 32, 64]               0
      BatchNorm1d-42               [-1, 32, 64]              64
             ReLU-43               [-1, 32, 64]               0
          Dropout-44               [-1, 32, 64]               0
           Conv1d-45               [-1, 32, 64]             160
  MyConv1dPadSame-46               [-1, 32, 64]               0
        MaxPool1d-47               [-1, 32, 64]               0
MyMaxPool1dPadSame-48               [-1, 32, 64]               0
       Bottleneck-49               [-1, 32, 64]               0
      BatchNorm1d-50               [-1, 32, 64]              64
             ReLU-51               [-1, 32, 64]               0
          Dropout-52               [-1, 32, 64]               0
           Conv1d-53               [-1, 64, 64]             320
  MyConv1dPadSame-54               [-1, 64, 64]               0
      BatchNorm1d-55               [-1, 64, 64]             128
             ReLU-56               [-1, 64, 64]               0
          Dropout-57               [-1, 64, 64]               0
           Conv1d-58               [-1, 64, 64]             576
  MyConv1dPadSame-59               [-1, 64, 64]               0
       Bottleneck-60               [-1, 64, 64]               0
      BatchNorm1d-61               [-1, 64, 64]             128
             ReLU-62               [-1, 64, 64]               0
          Dropout-63               [-1, 64, 64]               0
           Conv1d-64               [-1, 64, 32]             576
  MyConv1dPadSame-65               [-1, 64, 32]               0
      BatchNorm1d-66               [-1, 64, 32]             128
             ReLU-67               [-1, 64, 32]               0
          Dropout-68               [-1, 64, 32]               0
           Conv1d-69               [-1, 64, 32]             576
  MyConv1dPadSame-70               [-1, 64, 32]               0
        MaxPool1d-71               [-1, 64, 32]               0
MyMaxPool1dPadSame-72               [-1, 64, 32]               0
       Bottleneck-73               [-1, 64, 32]               0
      BatchNorm1d-74               [-1, 64, 32]             128
             ReLU-75               [-1, 64, 32]               0
          Dropout-76               [-1, 64, 32]               0
           Conv1d-77               [-1, 64, 32]             576
  MyConv1dPadSame-78               [-1, 64, 32]               0
      BatchNorm1d-79               [-1, 64, 32]             128
             ReLU-80               [-1, 64, 32]               0
          Dropout-81               [-1, 64, 32]               0
           Conv1d-82               [-1, 64, 32]             576
  MyConv1dPadSame-83               [-1, 64, 32]               0
       Bottleneck-84               [-1, 64, 32]               0
      BatchNorm1d-85               [-1, 64, 32]             128
             ReLU-86               [-1, 64, 32]               0
          Dropout-87               [-1, 64, 32]               0
           Conv1d-88               [-1, 64, 16]             576
  MyConv1dPadSame-89               [-1, 64, 16]               0
      BatchNorm1d-90               [-1, 64, 16]             128
             ReLU-91               [-1, 64, 16]               0
          Dropout-92               [-1, 64, 16]               0
           Conv1d-93               [-1, 64, 16]             576
  MyConv1dPadSame-94               [-1, 64, 16]               0
        MaxPool1d-95               [-1, 64, 16]               0
MyMaxPool1dPadSame-96               [-1, 64, 16]               0
       Bottleneck-97               [-1, 64, 16]               0
      BatchNorm1d-98               [-1, 64, 16]             128
             ReLU-99               [-1, 64, 16]               0
         Dropout-100               [-1, 64, 16]               0
          Conv1d-101              [-1, 128, 16]           1,152
 MyConv1dPadSame-102              [-1, 128, 16]               0
     BatchNorm1d-103              [-1, 128, 16]             256
            ReLU-104              [-1, 128, 16]               0
         Dropout-105              [-1, 128, 16]               0
          Conv1d-106              [-1, 128, 16]           2,176
 MyConv1dPadSame-107              [-1, 128, 16]               0
      Bottleneck-108              [-1, 128, 16]               0
     BatchNorm1d-109              [-1, 128, 16]             256
            ReLU-110              [-1, 128, 16]               0
         Dropout-111              [-1, 128, 16]               0
          Conv1d-112               [-1, 128, 8]           2,176
 MyConv1dPadSame-113               [-1, 128, 8]               0
     BatchNorm1d-114               [-1, 128, 8]             256
            ReLU-115               [-1, 128, 8]               0
         Dropout-116               [-1, 128, 8]               0
          Conv1d-117               [-1, 128, 8]           2,176
 MyConv1dPadSame-118               [-1, 128, 8]               0
       MaxPool1d-119               [-1, 128, 8]               0
MyMaxPool1dPadSame-120               [-1, 128, 8]               0
      Bottleneck-121               [-1, 128, 8]               0
     BatchNorm1d-122               [-1, 128, 8]             256
            ReLU-123               [-1, 128, 8]               0
         Dropout-124               [-1, 128, 8]               0
          Conv1d-125               [-1, 128, 8]           2,176
 MyConv1dPadSame-126               [-1, 128, 8]               0
     BatchNorm1d-127               [-1, 128, 8]             256
            ReLU-128               [-1, 128, 8]               0
         Dropout-129               [-1, 128, 8]               0
          Conv1d-130               [-1, 128, 8]           2,176
 MyConv1dPadSame-131               [-1, 128, 8]               0
      Bottleneck-132               [-1, 128, 8]               0
     BatchNorm1d-133               [-1, 128, 8]             256
            ReLU-134               [-1, 128, 8]               0
         Dropout-135               [-1, 128, 8]               0
          Conv1d-136               [-1, 128, 4]           2,176
 MyConv1dPadSame-137               [-1, 128, 4]               0
     BatchNorm1d-138               [-1, 128, 4]             256
            ReLU-139               [-1, 128, 4]               0
         Dropout-140               [-1, 128, 4]               0
          Conv1d-141               [-1, 128, 4]           2,176
 MyConv1dPadSame-142               [-1, 128, 4]               0
       MaxPool1d-143               [-1, 128, 4]               0
MyMaxPool1dPadSame-144               [-1, 128, 4]               0
      Bottleneck-145               [-1, 128, 4]               0
     BatchNorm1d-146               [-1, 128, 4]             256
            ReLU-147               [-1, 128, 4]               0
         Dropout-148               [-1, 128, 4]               0
          Conv1d-149               [-1, 256, 4]           4,352
 MyConv1dPadSame-150               [-1, 256, 4]               0
     BatchNorm1d-151               [-1, 256, 4]             512
            ReLU-152               [-1, 256, 4]               0
         Dropout-153               [-1, 256, 4]               0
          Conv1d-154               [-1, 256, 4]           8,448
 MyConv1dPadSame-155               [-1, 256, 4]               0
      Bottleneck-156               [-1, 256, 4]               0
     BatchNorm1d-157               [-1, 256, 4]             512
            ReLU-158               [-1, 256, 4]               0
         Dropout-159               [-1, 256, 4]               0
          Conv1d-160               [-1, 256, 2]           8,448
 MyConv1dPadSame-161               [-1, 256, 2]               0
     BatchNorm1d-162               [-1, 256, 2]             512
            ReLU-163               [-1, 256, 2]               0
         Dropout-164               [-1, 256, 2]               0
          Conv1d-165               [-1, 256, 2]           8,448
 MyConv1dPadSame-166               [-1, 256, 2]               0
       MaxPool1d-167               [-1, 256, 2]               0
MyMaxPool1dPadSame-168               [-1, 256, 2]               0
      Bottleneck-169               [-1, 256, 2]               0
     BatchNorm1d-170               [-1, 256, 2]             512
            ReLU-171               [-1, 256, 2]               0
         Dropout-172               [-1, 256, 2]               0
          Conv1d-173               [-1, 256, 2]           8,448
 MyConv1dPadSame-174               [-1, 256, 2]               0
     BatchNorm1d-175               [-1, 256, 2]             512
            ReLU-176               [-1, 256, 2]               0
         Dropout-177               [-1, 256, 2]               0
          Conv1d-178               [-1, 256, 2]           8,448
 MyConv1dPadSame-179               [-1, 256, 2]               0
      Bottleneck-180               [-1, 256, 2]               0
     BatchNorm1d-181               [-1, 256, 2]             512
            ReLU-182               [-1, 256, 2]               0
         Dropout-183               [-1, 256, 2]               0
          Conv1d-184               [-1, 256, 1]           8,448
 MyConv1dPadSame-185               [-1, 256, 1]               0
     BatchNorm1d-186               [-1, 256, 1]             512
            ReLU-187               [-1, 256, 1]               0
         Dropout-188               [-1, 256, 1]               0
          Conv1d-189               [-1, 256, 1]           8,448
 MyConv1dPadSame-190               [-1, 256, 1]               0
       MaxPool1d-191               [-1, 256, 1]               0
MyMaxPool1dPadSame-192               [-1, 256, 1]               0
      Bottleneck-193               [-1, 256, 1]               0
     BatchNorm1d-194               [-1, 256, 1]             512
            ReLU-195               [-1, 256, 1]               0
          Linear-196                    [-1, 2]             514
================================================================
Total params: 93,922
Trainable params: 93,922
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 3.32
Params size (MB): 0.36
Estimated Total Size (MB): 3.68
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 32, kernel_size: 8, n_block: 2
************************************************************
************************************************************
(2000, 1, 256) Counter({0: 1000, 1: 1000})
(2000, 1, 256) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 32, 256]             288
   MyConv1dPadSame-2              [-1, 32, 256]               0
       BatchNorm1d-3              [-1, 32, 256]              64
              ReLU-4              [-1, 32, 256]               0
            Conv1d-5              [-1, 32, 256]             288
   MyConv1dPadSame-6              [-1, 32, 256]               0
       BatchNorm1d-7              [-1, 32, 256]              64
              ReLU-8              [-1, 32, 256]               0
           Dropout-9              [-1, 32, 256]               0
           Conv1d-10              [-1, 32, 256]             288
  MyConv1dPadSame-11              [-1, 32, 256]               0
       Bottleneck-12              [-1, 32, 256]               0
      BatchNorm1d-13              [-1, 32, 256]              64
             ReLU-14              [-1, 32, 256]               0
          Dropout-15              [-1, 32, 256]               0
           Conv1d-16              [-1, 64, 256]             576
  MyConv1dPadSame-17              [-1, 64, 256]               0
      BatchNorm1d-18              [-1, 64, 256]             128
             ReLU-19              [-1, 64, 256]               0
          Dropout-20              [-1, 64, 256]               0
           Conv1d-21              [-1, 64, 256]           1,088
  MyConv1dPadSame-22              [-1, 64, 256]               0
       Bottleneck-23              [-1, 64, 256]               0
      BatchNorm1d-24              [-1, 64, 256]             128
             ReLU-25              [-1, 64, 256]               0
           Linear-26                    [-1, 2]             130
================================================================
Total params: 3,106
Trainable params: 3,106
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 2.19
Params size (MB): 0.01
Estimated Total Size (MB): 2.20
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 32, kernel_size: 8, n_block: 4
************************************************************
************************************************************
(2000, 1, 256) Counter({1: 1000, 0: 1000})
(2000, 1, 256) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 32, 256]             288
   MyConv1dPadSame-2              [-1, 32, 256]               0
       BatchNorm1d-3              [-1, 32, 256]              64
              ReLU-4              [-1, 32, 256]               0
            Conv1d-5              [-1, 32, 256]             288
   MyConv1dPadSame-6              [-1, 32, 256]               0
       BatchNorm1d-7              [-1, 32, 256]              64
              ReLU-8              [-1, 32, 256]               0
           Dropout-9              [-1, 32, 256]               0
           Conv1d-10              [-1, 32, 256]             288
  MyConv1dPadSame-11              [-1, 32, 256]               0
       Bottleneck-12              [-1, 32, 256]               0
      BatchNorm1d-13              [-1, 32, 256]              64
             ReLU-14              [-1, 32, 256]               0
          Dropout-15              [-1, 32, 256]               0
           Conv1d-16              [-1, 64, 256]             576
  MyConv1dPadSame-17              [-1, 64, 256]               0
      BatchNorm1d-18              [-1, 64, 256]             128
             ReLU-19              [-1, 64, 256]               0
          Dropout-20              [-1, 64, 256]               0
           Conv1d-21              [-1, 64, 256]           1,088
  MyConv1dPadSame-22              [-1, 64, 256]               0
       Bottleneck-23              [-1, 64, 256]               0
      BatchNorm1d-24              [-1, 64, 256]             128
             ReLU-25              [-1, 64, 256]               0
          Dropout-26              [-1, 64, 256]               0
           Conv1d-27             [-1, 128, 256]           2,176
  MyConv1dPadSame-28             [-1, 128, 256]               0
      BatchNorm1d-29             [-1, 128, 256]             256
             ReLU-30             [-1, 128, 256]               0
          Dropout-31             [-1, 128, 256]               0
           Conv1d-32             [-1, 128, 256]           4,224
  MyConv1dPadSame-33             [-1, 128, 256]               0
       Bottleneck-34             [-1, 128, 256]               0
      BatchNorm1d-35             [-1, 128, 256]             256
             ReLU-36             [-1, 128, 256]               0
          Dropout-37             [-1, 128, 256]               0
           Conv1d-38             [-1, 256, 256]           8,448
  MyConv1dPadSame-39             [-1, 256, 256]               0
      BatchNorm1d-40             [-1, 256, 256]             512
             ReLU-41             [-1, 256, 256]               0
          Dropout-42             [-1, 256, 256]               0
           Conv1d-43             [-1, 256, 256]          16,640
  MyConv1dPadSame-44             [-1, 256, 256]               0
       Bottleneck-45             [-1, 256, 256]               0
      BatchNorm1d-46             [-1, 256, 256]             512
             ReLU-47             [-1, 256, 256]               0
           Linear-48                    [-1, 2]             514
================================================================
Total params: 36,514
Trainable params: 36,514
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 10.06
Params size (MB): 0.14
Estimated Total Size (MB): 10.20
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 32, kernel_size: 8, n_block: 8
************************************************************
************************************************************
(2000, 1, 256) Counter({1: 1000, 0: 1000})
(2000, 1, 256) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 32, 256]             288
   MyConv1dPadSame-2              [-1, 32, 256]               0
       BatchNorm1d-3              [-1, 32, 256]              64
              ReLU-4              [-1, 32, 256]               0
            Conv1d-5              [-1, 32, 256]             288
   MyConv1dPadSame-6              [-1, 32, 256]               0
       BatchNorm1d-7              [-1, 32, 256]              64
              ReLU-8              [-1, 32, 256]               0
           Dropout-9              [-1, 32, 256]               0
           Conv1d-10              [-1, 32, 256]             288
  MyConv1dPadSame-11              [-1, 32, 256]               0
       Bottleneck-12              [-1, 32, 256]               0
      BatchNorm1d-13              [-1, 32, 256]              64
             ReLU-14              [-1, 32, 256]               0
          Dropout-15              [-1, 32, 256]               0
           Conv1d-16              [-1, 32, 256]             288
  MyConv1dPadSame-17              [-1, 32, 256]               0
      BatchNorm1d-18              [-1, 32, 256]              64
             ReLU-19              [-1, 32, 256]               0
          Dropout-20              [-1, 32, 256]               0
           Conv1d-21              [-1, 32, 256]             288
  MyConv1dPadSame-22              [-1, 32, 256]               0
       Bottleneck-23              [-1, 32, 256]               0
      BatchNorm1d-24              [-1, 32, 256]              64
             ReLU-25              [-1, 32, 256]               0
          Dropout-26              [-1, 32, 256]               0
           Conv1d-27              [-1, 64, 256]             576
  MyConv1dPadSame-28              [-1, 64, 256]               0
      BatchNorm1d-29              [-1, 64, 256]             128
             ReLU-30              [-1, 64, 256]               0
          Dropout-31              [-1, 64, 256]               0
           Conv1d-32              [-1, 64, 256]           1,088
  MyConv1dPadSame-33              [-1, 64, 256]               0
       Bottleneck-34              [-1, 64, 256]               0
      BatchNorm1d-35              [-1, 64, 256]             128
             ReLU-36              [-1, 64, 256]               0
          Dropout-37              [-1, 64, 256]               0
           Conv1d-38              [-1, 64, 256]           1,088
  MyConv1dPadSame-39              [-1, 64, 256]               0
      BatchNorm1d-40              [-1, 64, 256]             128
             ReLU-41              [-1, 64, 256]               0
          Dropout-42              [-1, 64, 256]               0
           Conv1d-43              [-1, 64, 256]           1,088
  MyConv1dPadSame-44              [-1, 64, 256]               0
       Bottleneck-45              [-1, 64, 256]               0
      BatchNorm1d-46              [-1, 64, 256]             128
             ReLU-47              [-1, 64, 256]               0
          Dropout-48              [-1, 64, 256]               0
           Conv1d-49             [-1, 128, 256]           2,176
  MyConv1dPadSame-50             [-1, 128, 256]               0
      BatchNorm1d-51             [-1, 128, 256]             256
             ReLU-52             [-1, 128, 256]               0
          Dropout-53             [-1, 128, 256]               0
           Conv1d-54             [-1, 128, 256]           4,224
  MyConv1dPadSame-55             [-1, 128, 256]               0
       Bottleneck-56             [-1, 128, 256]               0
      BatchNorm1d-57             [-1, 128, 256]             256
             ReLU-58             [-1, 128, 256]               0
          Dropout-59             [-1, 128, 256]               0
           Conv1d-60             [-1, 128, 256]           4,224
  MyConv1dPadSame-61             [-1, 128, 256]               0
      BatchNorm1d-62             [-1, 128, 256]             256
             ReLU-63             [-1, 128, 256]               0
          Dropout-64             [-1, 128, 256]               0
           Conv1d-65             [-1, 128, 256]           4,224
  MyConv1dPadSame-66             [-1, 128, 256]               0
       Bottleneck-67             [-1, 128, 256]               0
      BatchNorm1d-68             [-1, 128, 256]             256
             ReLU-69             [-1, 128, 256]               0
          Dropout-70             [-1, 128, 256]               0
           Conv1d-71             [-1, 256, 256]           8,448
  MyConv1dPadSame-72             [-1, 256, 256]               0
      BatchNorm1d-73             [-1, 256, 256]             512
             ReLU-74             [-1, 256, 256]               0
          Dropout-75             [-1, 256, 256]               0
           Conv1d-76             [-1, 256, 256]          16,640
  MyConv1dPadSame-77             [-1, 256, 256]               0
       Bottleneck-78             [-1, 256, 256]               0
      BatchNorm1d-79             [-1, 256, 256]             512
             ReLU-80             [-1, 256, 256]               0
          Dropout-81             [-1, 256, 256]               0
           Conv1d-82             [-1, 256, 256]          16,640
  MyConv1dPadSame-83             [-1, 256, 256]               0
      BatchNorm1d-84             [-1, 256, 256]             512
             ReLU-85             [-1, 256, 256]               0
          Dropout-86             [-1, 256, 256]               0
           Conv1d-87             [-1, 256, 256]          16,640
  MyConv1dPadSame-88             [-1, 256, 256]               0
       Bottleneck-89             [-1, 256, 256]               0
      BatchNorm1d-90             [-1, 256, 256]             512
             ReLU-91             [-1, 256, 256]               0
           Linear-92                    [-1, 2]             514
================================================================
Total params: 82,914
Trainable params: 82,914
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 20.38
Params size (MB): 0.32
Estimated Total Size (MB): 20.69
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 32, kernel_size: 8, n_block: 16
************************************************************
************************************************************
(2000, 1, 256) Counter({0: 1000, 1: 1000})
(2000, 1, 256) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 32, 256]             288
   MyConv1dPadSame-2              [-1, 32, 256]               0
       BatchNorm1d-3              [-1, 32, 256]              64
              ReLU-4              [-1, 32, 256]               0
            Conv1d-5              [-1, 32, 256]             288
   MyConv1dPadSame-6              [-1, 32, 256]               0
       BatchNorm1d-7              [-1, 32, 256]              64
              ReLU-8              [-1, 32, 256]               0
           Dropout-9              [-1, 32, 256]               0
           Conv1d-10              [-1, 32, 256]             288
  MyConv1dPadSame-11              [-1, 32, 256]               0
       Bottleneck-12              [-1, 32, 256]               0
      BatchNorm1d-13              [-1, 32, 256]              64
             ReLU-14              [-1, 32, 256]               0
          Dropout-15              [-1, 32, 256]               0
           Conv1d-16              [-1, 32, 128]             288
  MyConv1dPadSame-17              [-1, 32, 128]               0
      BatchNorm1d-18              [-1, 32, 128]              64
             ReLU-19              [-1, 32, 128]               0
          Dropout-20              [-1, 32, 128]               0
           Conv1d-21              [-1, 32, 128]             288
  MyConv1dPadSame-22              [-1, 32, 128]               0
        MaxPool1d-23              [-1, 32, 128]               0
MyMaxPool1dPadSame-24              [-1, 32, 128]               0
       Bottleneck-25              [-1, 32, 128]               0
      BatchNorm1d-26              [-1, 32, 128]              64
             ReLU-27              [-1, 32, 128]               0
          Dropout-28              [-1, 32, 128]               0
           Conv1d-29              [-1, 32, 128]             288
  MyConv1dPadSame-30              [-1, 32, 128]               0
      BatchNorm1d-31              [-1, 32, 128]              64
             ReLU-32              [-1, 32, 128]               0
          Dropout-33              [-1, 32, 128]               0
           Conv1d-34              [-1, 32, 128]             288
  MyConv1dPadSame-35              [-1, 32, 128]               0
       Bottleneck-36              [-1, 32, 128]               0
      BatchNorm1d-37              [-1, 32, 128]              64
             ReLU-38              [-1, 32, 128]               0
          Dropout-39              [-1, 32, 128]               0
           Conv1d-40               [-1, 32, 64]             288
  MyConv1dPadSame-41               [-1, 32, 64]               0
      BatchNorm1d-42               [-1, 32, 64]              64
             ReLU-43               [-1, 32, 64]               0
          Dropout-44               [-1, 32, 64]               0
           Conv1d-45               [-1, 32, 64]             288
  MyConv1dPadSame-46               [-1, 32, 64]               0
        MaxPool1d-47               [-1, 32, 64]               0
MyMaxPool1dPadSame-48               [-1, 32, 64]               0
       Bottleneck-49               [-1, 32, 64]               0
      BatchNorm1d-50               [-1, 32, 64]              64
             ReLU-51               [-1, 32, 64]               0
          Dropout-52               [-1, 32, 64]               0
           Conv1d-53               [-1, 64, 64]             576
  MyConv1dPadSame-54               [-1, 64, 64]               0
      BatchNorm1d-55               [-1, 64, 64]             128
             ReLU-56               [-1, 64, 64]               0
          Dropout-57               [-1, 64, 64]               0
           Conv1d-58               [-1, 64, 64]           1,088
  MyConv1dPadSame-59               [-1, 64, 64]               0
       Bottleneck-60               [-1, 64, 64]               0
      BatchNorm1d-61               [-1, 64, 64]             128
             ReLU-62               [-1, 64, 64]               0
          Dropout-63               [-1, 64, 64]               0
           Conv1d-64               [-1, 64, 32]           1,088
  MyConv1dPadSame-65               [-1, 64, 32]               0
      BatchNorm1d-66               [-1, 64, 32]             128
             ReLU-67               [-1, 64, 32]               0
          Dropout-68               [-1, 64, 32]               0
           Conv1d-69               [-1, 64, 32]           1,088
  MyConv1dPadSame-70               [-1, 64, 32]               0
        MaxPool1d-71               [-1, 64, 32]               0
MyMaxPool1dPadSame-72               [-1, 64, 32]               0
       Bottleneck-73               [-1, 64, 32]               0
      BatchNorm1d-74               [-1, 64, 32]             128
             ReLU-75               [-1, 64, 32]               0
          Dropout-76               [-1, 64, 32]               0
           Conv1d-77               [-1, 64, 32]           1,088
  MyConv1dPadSame-78               [-1, 64, 32]               0
      BatchNorm1d-79               [-1, 64, 32]             128
             ReLU-80               [-1, 64, 32]               0
          Dropout-81               [-1, 64, 32]               0
           Conv1d-82               [-1, 64, 32]           1,088
  MyConv1dPadSame-83               [-1, 64, 32]               0
       Bottleneck-84               [-1, 64, 32]               0
      BatchNorm1d-85               [-1, 64, 32]             128
             ReLU-86               [-1, 64, 32]               0
          Dropout-87               [-1, 64, 32]               0
           Conv1d-88               [-1, 64, 16]           1,088
  MyConv1dPadSame-89               [-1, 64, 16]               0
      BatchNorm1d-90               [-1, 64, 16]             128
             ReLU-91               [-1, 64, 16]               0
          Dropout-92               [-1, 64, 16]               0
           Conv1d-93               [-1, 64, 16]           1,088
  MyConv1dPadSame-94               [-1, 64, 16]               0
        MaxPool1d-95               [-1, 64, 16]               0
MyMaxPool1dPadSame-96               [-1, 64, 16]               0
       Bottleneck-97               [-1, 64, 16]               0
      BatchNorm1d-98               [-1, 64, 16]             128
             ReLU-99               [-1, 64, 16]               0
         Dropout-100               [-1, 64, 16]               0
          Conv1d-101              [-1, 128, 16]           2,176
 MyConv1dPadSame-102              [-1, 128, 16]               0
     BatchNorm1d-103              [-1, 128, 16]             256
            ReLU-104              [-1, 128, 16]               0
         Dropout-105              [-1, 128, 16]               0
          Conv1d-106              [-1, 128, 16]           4,224
 MyConv1dPadSame-107              [-1, 128, 16]               0
      Bottleneck-108              [-1, 128, 16]               0
     BatchNorm1d-109              [-1, 128, 16]             256
            ReLU-110              [-1, 128, 16]               0
         Dropout-111              [-1, 128, 16]               0
          Conv1d-112               [-1, 128, 8]           4,224
 MyConv1dPadSame-113               [-1, 128, 8]               0
     BatchNorm1d-114               [-1, 128, 8]             256
            ReLU-115               [-1, 128, 8]               0
         Dropout-116               [-1, 128, 8]               0
          Conv1d-117               [-1, 128, 8]           4,224
 MyConv1dPadSame-118               [-1, 128, 8]               0
       MaxPool1d-119               [-1, 128, 8]               0
MyMaxPool1dPadSame-120               [-1, 128, 8]               0
      Bottleneck-121               [-1, 128, 8]               0
     BatchNorm1d-122               [-1, 128, 8]             256
            ReLU-123               [-1, 128, 8]               0
         Dropout-124               [-1, 128, 8]               0
          Conv1d-125               [-1, 128, 8]           4,224
 MyConv1dPadSame-126               [-1, 128, 8]               0
     BatchNorm1d-127               [-1, 128, 8]             256
            ReLU-128               [-1, 128, 8]               0
         Dropout-129               [-1, 128, 8]               0
          Conv1d-130               [-1, 128, 8]           4,224
 MyConv1dPadSame-131               [-1, 128, 8]               0
      Bottleneck-132               [-1, 128, 8]               0
     BatchNorm1d-133               [-1, 128, 8]             256
            ReLU-134               [-1, 128, 8]               0
         Dropout-135               [-1, 128, 8]               0
          Conv1d-136               [-1, 128, 4]           4,224
 MyConv1dPadSame-137               [-1, 128, 4]               0
     BatchNorm1d-138               [-1, 128, 4]             256
            ReLU-139               [-1, 128, 4]               0
         Dropout-140               [-1, 128, 4]               0
          Conv1d-141               [-1, 128, 4]           4,224
 MyConv1dPadSame-142               [-1, 128, 4]               0
       MaxPool1d-143               [-1, 128, 4]               0
MyMaxPool1dPadSame-144               [-1, 128, 4]               0
      Bottleneck-145               [-1, 128, 4]               0
     BatchNorm1d-146               [-1, 128, 4]             256
            ReLU-147               [-1, 128, 4]               0
         Dropout-148               [-1, 128, 4]               0
          Conv1d-149               [-1, 256, 4]           8,448
 MyConv1dPadSame-150               [-1, 256, 4]               0
     BatchNorm1d-151               [-1, 256, 4]             512
            ReLU-152               [-1, 256, 4]               0
         Dropout-153               [-1, 256, 4]               0
          Conv1d-154               [-1, 256, 4]          16,640
 MyConv1dPadSame-155               [-1, 256, 4]               0
      Bottleneck-156               [-1, 256, 4]               0
     BatchNorm1d-157               [-1, 256, 4]             512
            ReLU-158               [-1, 256, 4]               0
         Dropout-159               [-1, 256, 4]               0
          Conv1d-160               [-1, 256, 2]          16,640
 MyConv1dPadSame-161               [-1, 256, 2]               0
     BatchNorm1d-162               [-1, 256, 2]             512
            ReLU-163               [-1, 256, 2]               0
         Dropout-164               [-1, 256, 2]               0
          Conv1d-165               [-1, 256, 2]          16,640
 MyConv1dPadSame-166               [-1, 256, 2]               0
       MaxPool1d-167               [-1, 256, 2]               0
MyMaxPool1dPadSame-168               [-1, 256, 2]               0
      Bottleneck-169               [-1, 256, 2]               0
     BatchNorm1d-170               [-1, 256, 2]             512
            ReLU-171               [-1, 256, 2]               0
         Dropout-172               [-1, 256, 2]               0
          Conv1d-173               [-1, 256, 2]          16,640
 MyConv1dPadSame-174               [-1, 256, 2]               0
     BatchNorm1d-175               [-1, 256, 2]             512
            ReLU-176               [-1, 256, 2]               0
         Dropout-177               [-1, 256, 2]               0
          Conv1d-178               [-1, 256, 2]          16,640
 MyConv1dPadSame-179               [-1, 256, 2]               0
      Bottleneck-180               [-1, 256, 2]               0
     BatchNorm1d-181               [-1, 256, 2]             512
            ReLU-182               [-1, 256, 2]               0
         Dropout-183               [-1, 256, 2]               0
          Conv1d-184               [-1, 256, 1]          16,640
 MyConv1dPadSame-185               [-1, 256, 1]               0
     BatchNorm1d-186               [-1, 256, 1]             512
            ReLU-187               [-1, 256, 1]               0
         Dropout-188               [-1, 256, 1]               0
          Conv1d-189               [-1, 256, 1]          16,640
 MyConv1dPadSame-190               [-1, 256, 1]               0
       MaxPool1d-191               [-1, 256, 1]               0
MyMaxPool1dPadSame-192               [-1, 256, 1]               0
      Bottleneck-193               [-1, 256, 1]               0
     BatchNorm1d-194               [-1, 256, 1]             512
            ReLU-195               [-1, 256, 1]               0
          Linear-196                    [-1, 2]             514
================================================================
Total params: 175,714
Trainable params: 175,714
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 3.32
Params size (MB): 0.67
Estimated Total Size (MB): 4.00
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 32, kernel_size: 16, n_block: 2
************************************************************
************************************************************
(2000, 1, 256) Counter({1: 1000, 0: 1000})
(2000, 1, 256) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 32, 256]             544
   MyConv1dPadSame-2              [-1, 32, 256]               0
       BatchNorm1d-3              [-1, 32, 256]              64
              ReLU-4              [-1, 32, 256]               0
            Conv1d-5              [-1, 32, 256]             544
   MyConv1dPadSame-6              [-1, 32, 256]               0
       BatchNorm1d-7              [-1, 32, 256]              64
              ReLU-8              [-1, 32, 256]               0
           Dropout-9              [-1, 32, 256]               0
           Conv1d-10              [-1, 32, 256]             544
  MyConv1dPadSame-11              [-1, 32, 256]               0
       Bottleneck-12              [-1, 32, 256]               0
      BatchNorm1d-13              [-1, 32, 256]              64
             ReLU-14              [-1, 32, 256]               0
          Dropout-15              [-1, 32, 256]               0
           Conv1d-16              [-1, 64, 256]           1,088
  MyConv1dPadSame-17              [-1, 64, 256]               0
      BatchNorm1d-18              [-1, 64, 256]             128
             ReLU-19              [-1, 64, 256]               0
          Dropout-20              [-1, 64, 256]               0
           Conv1d-21              [-1, 64, 256]           2,112
  MyConv1dPadSame-22              [-1, 64, 256]               0
       Bottleneck-23              [-1, 64, 256]               0
      BatchNorm1d-24              [-1, 64, 256]             128
             ReLU-25              [-1, 64, 256]               0
           Linear-26                    [-1, 2]             130
================================================================
Total params: 5,410
Trainable params: 5,410
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 2.19
Params size (MB): 0.02
Estimated Total Size (MB): 2.21
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 32, kernel_size: 16, n_block: 4
************************************************************
************************************************************
(2000, 1, 256) Counter({1: 1000, 0: 1000})
(2000, 1, 256) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 32, 256]             544
   MyConv1dPadSame-2              [-1, 32, 256]               0
       BatchNorm1d-3              [-1, 32, 256]              64
              ReLU-4              [-1, 32, 256]               0
            Conv1d-5              [-1, 32, 256]             544
   MyConv1dPadSame-6              [-1, 32, 256]               0
       BatchNorm1d-7              [-1, 32, 256]              64
              ReLU-8              [-1, 32, 256]               0
           Dropout-9              [-1, 32, 256]               0
           Conv1d-10              [-1, 32, 256]             544
  MyConv1dPadSame-11              [-1, 32, 256]               0
       Bottleneck-12              [-1, 32, 256]               0
      BatchNorm1d-13              [-1, 32, 256]              64
             ReLU-14              [-1, 32, 256]               0
          Dropout-15              [-1, 32, 256]               0
           Conv1d-16              [-1, 64, 256]           1,088
  MyConv1dPadSame-17              [-1, 64, 256]               0
      BatchNorm1d-18              [-1, 64, 256]             128
             ReLU-19              [-1, 64, 256]               0
          Dropout-20              [-1, 64, 256]               0
           Conv1d-21              [-1, 64, 256]           2,112
  MyConv1dPadSame-22              [-1, 64, 256]               0
       Bottleneck-23              [-1, 64, 256]               0
      BatchNorm1d-24              [-1, 64, 256]             128
             ReLU-25              [-1, 64, 256]               0
          Dropout-26              [-1, 64, 256]               0
           Conv1d-27             [-1, 128, 256]           4,224
  MyConv1dPadSame-28             [-1, 128, 256]               0
      BatchNorm1d-29             [-1, 128, 256]             256
             ReLU-30             [-1, 128, 256]               0
          Dropout-31             [-1, 128, 256]               0
           Conv1d-32             [-1, 128, 256]           8,320
  MyConv1dPadSame-33             [-1, 128, 256]               0
       Bottleneck-34             [-1, 128, 256]               0
      BatchNorm1d-35             [-1, 128, 256]             256
             ReLU-36             [-1, 128, 256]               0
          Dropout-37             [-1, 128, 256]               0
           Conv1d-38             [-1, 256, 256]          16,640
  MyConv1dPadSame-39             [-1, 256, 256]               0
      BatchNorm1d-40             [-1, 256, 256]             512
             ReLU-41             [-1, 256, 256]               0
          Dropout-42             [-1, 256, 256]               0
           Conv1d-43             [-1, 256, 256]          33,024
  MyConv1dPadSame-44             [-1, 256, 256]               0
       Bottleneck-45             [-1, 256, 256]               0
      BatchNorm1d-46             [-1, 256, 256]             512
             ReLU-47             [-1, 256, 256]               0
           Linear-48                    [-1, 2]             514
================================================================
Total params: 69,538
Trainable params: 69,538
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 10.06
Params size (MB): 0.27
Estimated Total Size (MB): 10.33
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 32, kernel_size: 16, n_block: 8
************************************************************
************************************************************
(2000, 1, 256) Counter({1: 1000, 0: 1000})
(2000, 1, 256) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 32, 256]             544
   MyConv1dPadSame-2              [-1, 32, 256]               0
       BatchNorm1d-3              [-1, 32, 256]              64
              ReLU-4              [-1, 32, 256]               0
            Conv1d-5              [-1, 32, 256]             544
   MyConv1dPadSame-6              [-1, 32, 256]               0
       BatchNorm1d-7              [-1, 32, 256]              64
              ReLU-8              [-1, 32, 256]               0
           Dropout-9              [-1, 32, 256]               0
           Conv1d-10              [-1, 32, 256]             544
  MyConv1dPadSame-11              [-1, 32, 256]               0
       Bottleneck-12              [-1, 32, 256]               0
      BatchNorm1d-13              [-1, 32, 256]              64
             ReLU-14              [-1, 32, 256]               0
          Dropout-15              [-1, 32, 256]               0
           Conv1d-16              [-1, 32, 256]             544
  MyConv1dPadSame-17              [-1, 32, 256]               0
      BatchNorm1d-18              [-1, 32, 256]              64
             ReLU-19              [-1, 32, 256]               0
          Dropout-20              [-1, 32, 256]               0
           Conv1d-21              [-1, 32, 256]             544
  MyConv1dPadSame-22              [-1, 32, 256]               0
       Bottleneck-23              [-1, 32, 256]               0
      BatchNorm1d-24              [-1, 32, 256]              64
             ReLU-25              [-1, 32, 256]               0
          Dropout-26              [-1, 32, 256]               0
           Conv1d-27              [-1, 64, 256]           1,088
  MyConv1dPadSame-28              [-1, 64, 256]               0
      BatchNorm1d-29              [-1, 64, 256]             128
             ReLU-30              [-1, 64, 256]               0
          Dropout-31              [-1, 64, 256]               0
           Conv1d-32              [-1, 64, 256]           2,112
  MyConv1dPadSame-33              [-1, 64, 256]               0
       Bottleneck-34              [-1, 64, 256]               0
      BatchNorm1d-35              [-1, 64, 256]             128
             ReLU-36              [-1, 64, 256]               0
          Dropout-37              [-1, 64, 256]               0
           Conv1d-38              [-1, 64, 256]           2,112
  MyConv1dPadSame-39              [-1, 64, 256]               0
      BatchNorm1d-40              [-1, 64, 256]             128
             ReLU-41              [-1, 64, 256]               0
          Dropout-42              [-1, 64, 256]               0
           Conv1d-43              [-1, 64, 256]           2,112
  MyConv1dPadSame-44              [-1, 64, 256]               0
       Bottleneck-45              [-1, 64, 256]               0
      BatchNorm1d-46              [-1, 64, 256]             128
             ReLU-47              [-1, 64, 256]               0
          Dropout-48              [-1, 64, 256]               0
           Conv1d-49             [-1, 128, 256]           4,224
  MyConv1dPadSame-50             [-1, 128, 256]               0
      BatchNorm1d-51             [-1, 128, 256]             256
             ReLU-52             [-1, 128, 256]               0
          Dropout-53             [-1, 128, 256]               0
           Conv1d-54             [-1, 128, 256]           8,320
  MyConv1dPadSame-55             [-1, 128, 256]               0
       Bottleneck-56             [-1, 128, 256]               0
      BatchNorm1d-57             [-1, 128, 256]             256
             ReLU-58             [-1, 128, 256]               0
          Dropout-59             [-1, 128, 256]               0
           Conv1d-60             [-1, 128, 256]           8,320
  MyConv1dPadSame-61             [-1, 128, 256]               0
      BatchNorm1d-62             [-1, 128, 256]             256
             ReLU-63             [-1, 128, 256]               0
          Dropout-64             [-1, 128, 256]               0
           Conv1d-65             [-1, 128, 256]           8,320
  MyConv1dPadSame-66             [-1, 128, 256]               0
       Bottleneck-67             [-1, 128, 256]               0
      BatchNorm1d-68             [-1, 128, 256]             256
             ReLU-69             [-1, 128, 256]               0
          Dropout-70             [-1, 128, 256]               0
           Conv1d-71             [-1, 256, 256]          16,640
  MyConv1dPadSame-72             [-1, 256, 256]               0
      BatchNorm1d-73             [-1, 256, 256]             512
             ReLU-74             [-1, 256, 256]               0
          Dropout-75             [-1, 256, 256]               0
           Conv1d-76             [-1, 256, 256]          33,024
  MyConv1dPadSame-77             [-1, 256, 256]               0
       Bottleneck-78             [-1, 256, 256]               0
      BatchNorm1d-79             [-1, 256, 256]             512
             ReLU-80             [-1, 256, 256]               0
          Dropout-81             [-1, 256, 256]               0
           Conv1d-82             [-1, 256, 256]          33,024
  MyConv1dPadSame-83             [-1, 256, 256]               0
      BatchNorm1d-84             [-1, 256, 256]             512
             ReLU-85             [-1, 256, 256]               0
          Dropout-86             [-1, 256, 256]               0
           Conv1d-87             [-1, 256, 256]          33,024
  MyConv1dPadSame-88             [-1, 256, 256]               0
       Bottleneck-89             [-1, 256, 256]               0
      BatchNorm1d-90             [-1, 256, 256]             512
             ReLU-91             [-1, 256, 256]               0
           Linear-92                    [-1, 2]             514
================================================================
Total params: 159,458
Trainable params: 159,458
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 20.38
Params size (MB): 0.61
Estimated Total Size (MB): 20.98
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 32, kernel_size: 16, n_block: 16
************************************************************
************************************************************
(2000, 1, 256) Counter({0: 1000, 1: 1000})
(2000, 1, 256) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 32, 256]             544
   MyConv1dPadSame-2              [-1, 32, 256]               0
       BatchNorm1d-3              [-1, 32, 256]              64
              ReLU-4              [-1, 32, 256]               0
            Conv1d-5              [-1, 32, 256]             544
   MyConv1dPadSame-6              [-1, 32, 256]               0
       BatchNorm1d-7              [-1, 32, 256]              64
              ReLU-8              [-1, 32, 256]               0
           Dropout-9              [-1, 32, 256]               0
           Conv1d-10              [-1, 32, 256]             544
  MyConv1dPadSame-11              [-1, 32, 256]               0
       Bottleneck-12              [-1, 32, 256]               0
      BatchNorm1d-13              [-1, 32, 256]              64
             ReLU-14              [-1, 32, 256]               0
          Dropout-15              [-1, 32, 256]               0
           Conv1d-16              [-1, 32, 128]             544
  MyConv1dPadSame-17              [-1, 32, 128]               0
      BatchNorm1d-18              [-1, 32, 128]              64
             ReLU-19              [-1, 32, 128]               0
          Dropout-20              [-1, 32, 128]               0
           Conv1d-21              [-1, 32, 128]             544
  MyConv1dPadSame-22              [-1, 32, 128]               0
        MaxPool1d-23              [-1, 32, 128]               0
MyMaxPool1dPadSame-24              [-1, 32, 128]               0
       Bottleneck-25              [-1, 32, 128]               0
      BatchNorm1d-26              [-1, 32, 128]              64
             ReLU-27              [-1, 32, 128]               0
          Dropout-28              [-1, 32, 128]               0
           Conv1d-29              [-1, 32, 128]             544
  MyConv1dPadSame-30              [-1, 32, 128]               0
      BatchNorm1d-31              [-1, 32, 128]              64
             ReLU-32              [-1, 32, 128]               0
          Dropout-33              [-1, 32, 128]               0
           Conv1d-34              [-1, 32, 128]             544
  MyConv1dPadSame-35              [-1, 32, 128]               0
       Bottleneck-36              [-1, 32, 128]               0
      BatchNorm1d-37              [-1, 32, 128]              64
             ReLU-38              [-1, 32, 128]               0
          Dropout-39              [-1, 32, 128]               0
           Conv1d-40               [-1, 32, 64]             544
  MyConv1dPadSame-41               [-1, 32, 64]               0
      BatchNorm1d-42               [-1, 32, 64]              64
             ReLU-43               [-1, 32, 64]               0
          Dropout-44               [-1, 32, 64]               0
           Conv1d-45               [-1, 32, 64]             544
  MyConv1dPadSame-46               [-1, 32, 64]               0
        MaxPool1d-47               [-1, 32, 64]               0
MyMaxPool1dPadSame-48               [-1, 32, 64]               0
       Bottleneck-49               [-1, 32, 64]               0
      BatchNorm1d-50               [-1, 32, 64]              64
             ReLU-51               [-1, 32, 64]               0
          Dropout-52               [-1, 32, 64]               0
           Conv1d-53               [-1, 64, 64]           1,088
  MyConv1dPadSame-54               [-1, 64, 64]               0
      BatchNorm1d-55               [-1, 64, 64]             128
             ReLU-56               [-1, 64, 64]               0
          Dropout-57               [-1, 64, 64]               0
           Conv1d-58               [-1, 64, 64]           2,112
  MyConv1dPadSame-59               [-1, 64, 64]               0
       Bottleneck-60               [-1, 64, 64]               0
      BatchNorm1d-61               [-1, 64, 64]             128
             ReLU-62               [-1, 64, 64]               0
          Dropout-63               [-1, 64, 64]               0
           Conv1d-64               [-1, 64, 32]           2,112
  MyConv1dPadSame-65               [-1, 64, 32]               0
      BatchNorm1d-66               [-1, 64, 32]             128
             ReLU-67               [-1, 64, 32]               0
          Dropout-68               [-1, 64, 32]               0
           Conv1d-69               [-1, 64, 32]           2,112
  MyConv1dPadSame-70               [-1, 64, 32]               0
        MaxPool1d-71               [-1, 64, 32]               0
MyMaxPool1dPadSame-72               [-1, 64, 32]               0
       Bottleneck-73               [-1, 64, 32]               0
      BatchNorm1d-74               [-1, 64, 32]             128
             ReLU-75               [-1, 64, 32]               0
          Dropout-76               [-1, 64, 32]               0
           Conv1d-77               [-1, 64, 32]           2,112
  MyConv1dPadSame-78               [-1, 64, 32]               0
      BatchNorm1d-79               [-1, 64, 32]             128
             ReLU-80               [-1, 64, 32]               0
          Dropout-81               [-1, 64, 32]               0
           Conv1d-82               [-1, 64, 32]           2,112
  MyConv1dPadSame-83               [-1, 64, 32]               0
       Bottleneck-84               [-1, 64, 32]               0
      BatchNorm1d-85               [-1, 64, 32]             128
             ReLU-86               [-1, 64, 32]               0
          Dropout-87               [-1, 64, 32]               0
           Conv1d-88               [-1, 64, 16]           2,112
  MyConv1dPadSame-89               [-1, 64, 16]               0
      BatchNorm1d-90               [-1, 64, 16]             128
             ReLU-91               [-1, 64, 16]               0
          Dropout-92               [-1, 64, 16]               0
           Conv1d-93               [-1, 64, 16]           2,112
  MyConv1dPadSame-94               [-1, 64, 16]               0
        MaxPool1d-95               [-1, 64, 16]               0
MyMaxPool1dPadSame-96               [-1, 64, 16]               0
       Bottleneck-97               [-1, 64, 16]               0
      BatchNorm1d-98               [-1, 64, 16]             128
             ReLU-99               [-1, 64, 16]               0
         Dropout-100               [-1, 64, 16]               0
          Conv1d-101              [-1, 128, 16]           4,224
 MyConv1dPadSame-102              [-1, 128, 16]               0
     BatchNorm1d-103              [-1, 128, 16]             256
            ReLU-104              [-1, 128, 16]               0
         Dropout-105              [-1, 128, 16]               0
          Conv1d-106              [-1, 128, 16]           8,320
 MyConv1dPadSame-107              [-1, 128, 16]               0
      Bottleneck-108              [-1, 128, 16]               0
     BatchNorm1d-109              [-1, 128, 16]             256
            ReLU-110              [-1, 128, 16]               0
         Dropout-111              [-1, 128, 16]               0
          Conv1d-112               [-1, 128, 8]           8,320
 MyConv1dPadSame-113               [-1, 128, 8]               0
     BatchNorm1d-114               [-1, 128, 8]             256
            ReLU-115               [-1, 128, 8]               0
         Dropout-116               [-1, 128, 8]               0
          Conv1d-117               [-1, 128, 8]           8,320
 MyConv1dPadSame-118               [-1, 128, 8]               0
       MaxPool1d-119               [-1, 128, 8]               0
MyMaxPool1dPadSame-120               [-1, 128, 8]               0
      Bottleneck-121               [-1, 128, 8]               0
     BatchNorm1d-122               [-1, 128, 8]             256
            ReLU-123               [-1, 128, 8]               0
         Dropout-124               [-1, 128, 8]               0
          Conv1d-125               [-1, 128, 8]           8,320
 MyConv1dPadSame-126               [-1, 128, 8]               0
     BatchNorm1d-127               [-1, 128, 8]             256
            ReLU-128               [-1, 128, 8]               0
         Dropout-129               [-1, 128, 8]               0
          Conv1d-130               [-1, 128, 8]           8,320
 MyConv1dPadSame-131               [-1, 128, 8]               0
      Bottleneck-132               [-1, 128, 8]               0
     BatchNorm1d-133               [-1, 128, 8]             256
            ReLU-134               [-1, 128, 8]               0
         Dropout-135               [-1, 128, 8]               0
          Conv1d-136               [-1, 128, 4]           8,320
 MyConv1dPadSame-137               [-1, 128, 4]               0
     BatchNorm1d-138               [-1, 128, 4]             256
            ReLU-139               [-1, 128, 4]               0
         Dropout-140               [-1, 128, 4]               0
          Conv1d-141               [-1, 128, 4]           8,320
 MyConv1dPadSame-142               [-1, 128, 4]               0
       MaxPool1d-143               [-1, 128, 4]               0
MyMaxPool1dPadSame-144               [-1, 128, 4]               0
      Bottleneck-145               [-1, 128, 4]               0
     BatchNorm1d-146               [-1, 128, 4]             256
            ReLU-147               [-1, 128, 4]               0
         Dropout-148               [-1, 128, 4]               0
          Conv1d-149               [-1, 256, 4]          16,640
 MyConv1dPadSame-150               [-1, 256, 4]               0
     BatchNorm1d-151               [-1, 256, 4]             512
            ReLU-152               [-1, 256, 4]               0
         Dropout-153               [-1, 256, 4]               0
          Conv1d-154               [-1, 256, 4]          33,024
 MyConv1dPadSame-155               [-1, 256, 4]               0
      Bottleneck-156               [-1, 256, 4]               0
     BatchNorm1d-157               [-1, 256, 4]             512
            ReLU-158               [-1, 256, 4]               0
         Dropout-159               [-1, 256, 4]               0
          Conv1d-160               [-1, 256, 2]          33,024
 MyConv1dPadSame-161               [-1, 256, 2]               0
     BatchNorm1d-162               [-1, 256, 2]             512
            ReLU-163               [-1, 256, 2]               0
         Dropout-164               [-1, 256, 2]               0
          Conv1d-165               [-1, 256, 2]          33,024
 MyConv1dPadSame-166               [-1, 256, 2]               0
       MaxPool1d-167               [-1, 256, 2]               0
MyMaxPool1dPadSame-168               [-1, 256, 2]               0
      Bottleneck-169               [-1, 256, 2]               0
     BatchNorm1d-170               [-1, 256, 2]             512
            ReLU-171               [-1, 256, 2]               0
         Dropout-172               [-1, 256, 2]               0
          Conv1d-173               [-1, 256, 2]          33,024
 MyConv1dPadSame-174               [-1, 256, 2]               0
     BatchNorm1d-175               [-1, 256, 2]             512
            ReLU-176               [-1, 256, 2]               0
         Dropout-177               [-1, 256, 2]               0
          Conv1d-178               [-1, 256, 2]          33,024
 MyConv1dPadSame-179               [-1, 256, 2]               0
      Bottleneck-180               [-1, 256, 2]               0
     BatchNorm1d-181               [-1, 256, 2]             512
            ReLU-182               [-1, 256, 2]               0
         Dropout-183               [-1, 256, 2]               0
          Conv1d-184               [-1, 256, 1]          33,024
 MyConv1dPadSame-185               [-1, 256, 1]               0
     BatchNorm1d-186               [-1, 256, 1]             512
            ReLU-187               [-1, 256, 1]               0
         Dropout-188               [-1, 256, 1]               0
          Conv1d-189               [-1, 256, 1]          33,024
 MyConv1dPadSame-190               [-1, 256, 1]               0
       MaxPool1d-191               [-1, 256, 1]               0
MyMaxPool1dPadSame-192               [-1, 256, 1]               0
      Bottleneck-193               [-1, 256, 1]               0
     BatchNorm1d-194               [-1, 256, 1]             512
            ReLU-195               [-1, 256, 1]               0
          Linear-196                    [-1, 2]             514
================================================================
Total params: 339,298
Trainable params: 339,298
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 3.32
Params size (MB): 1.29
Estimated Total Size (MB): 4.62
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 64, kernel_size: 2, n_block: 2
************************************************************
************************************************************
(2000, 1, 256) Counter({0: 1000, 1: 1000})
(2000, 1, 256) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 64, 256]             192
   MyConv1dPadSame-2              [-1, 64, 256]               0
       BatchNorm1d-3              [-1, 64, 256]             128
              ReLU-4              [-1, 64, 256]               0
            Conv1d-5              [-1, 64, 256]             192
   MyConv1dPadSame-6              [-1, 64, 256]               0
       BatchNorm1d-7              [-1, 64, 256]             128
              ReLU-8              [-1, 64, 256]               0
           Dropout-9              [-1, 64, 256]               0
           Conv1d-10              [-1, 64, 256]             192
  MyConv1dPadSame-11              [-1, 64, 256]               0
       Bottleneck-12              [-1, 64, 256]               0
      BatchNorm1d-13              [-1, 64, 256]             128
             ReLU-14              [-1, 64, 256]               0
          Dropout-15              [-1, 64, 256]               0
           Conv1d-16             [-1, 128, 256]             384
  MyConv1dPadSame-17             [-1, 128, 256]               0
      BatchNorm1d-18             [-1, 128, 256]             256
             ReLU-19             [-1, 128, 256]               0
          Dropout-20             [-1, 128, 256]               0
           Conv1d-21             [-1, 128, 256]             640
  MyConv1dPadSame-22             [-1, 128, 256]               0
       Bottleneck-23             [-1, 128, 256]               0
      BatchNorm1d-24             [-1, 128, 256]             256
             ReLU-25             [-1, 128, 256]               0
           Linear-26                    [-1, 2]             258
================================================================
Total params: 2,754
Trainable params: 2,754
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 4.38
Params size (MB): 0.01
Estimated Total Size (MB): 4.39
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 64, kernel_size: 2, n_block: 4
************************************************************
************************************************************
(2000, 1, 256) Counter({1: 1000, 0: 1000})
(2000, 1, 256) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 64, 256]             192
   MyConv1dPadSame-2              [-1, 64, 256]               0
       BatchNorm1d-3              [-1, 64, 256]             128
              ReLU-4              [-1, 64, 256]               0
            Conv1d-5              [-1, 64, 256]             192
   MyConv1dPadSame-6              [-1, 64, 256]               0
       BatchNorm1d-7              [-1, 64, 256]             128
              ReLU-8              [-1, 64, 256]               0
           Dropout-9              [-1, 64, 256]               0
           Conv1d-10              [-1, 64, 256]             192
  MyConv1dPadSame-11              [-1, 64, 256]               0
       Bottleneck-12              [-1, 64, 256]               0
      BatchNorm1d-13              [-1, 64, 256]             128
             ReLU-14              [-1, 64, 256]               0
          Dropout-15              [-1, 64, 256]               0
           Conv1d-16             [-1, 128, 256]             384
  MyConv1dPadSame-17             [-1, 128, 256]               0
      BatchNorm1d-18             [-1, 128, 256]             256
             ReLU-19             [-1, 128, 256]               0
          Dropout-20             [-1, 128, 256]               0
           Conv1d-21             [-1, 128, 256]             640
  MyConv1dPadSame-22             [-1, 128, 256]               0
       Bottleneck-23             [-1, 128, 256]               0
      BatchNorm1d-24             [-1, 128, 256]             256
             ReLU-25             [-1, 128, 256]               0
          Dropout-26             [-1, 128, 256]               0
           Conv1d-27             [-1, 256, 256]           1,280
  MyConv1dPadSame-28             [-1, 256, 256]               0
      BatchNorm1d-29             [-1, 256, 256]             512
             ReLU-30             [-1, 256, 256]               0
          Dropout-31             [-1, 256, 256]               0
           Conv1d-32             [-1, 256, 256]           2,304
  MyConv1dPadSame-33             [-1, 256, 256]               0
       Bottleneck-34             [-1, 256, 256]               0
      BatchNorm1d-35             [-1, 256, 256]             512
             ReLU-36             [-1, 256, 256]               0
          Dropout-37             [-1, 256, 256]               0
           Conv1d-38             [-1, 512, 256]           4,608
  MyConv1dPadSame-39             [-1, 512, 256]               0
      BatchNorm1d-40             [-1, 512, 256]           1,024
             ReLU-41             [-1, 512, 256]               0
          Dropout-42             [-1, 512, 256]               0
           Conv1d-43             [-1, 512, 256]           8,704
  MyConv1dPadSame-44             [-1, 512, 256]               0
       Bottleneck-45             [-1, 512, 256]               0
      BatchNorm1d-46             [-1, 512, 256]           1,024
             ReLU-47             [-1, 512, 256]               0
           Linear-48                    [-1, 2]           1,026
================================================================
Total params: 23,490
Trainable params: 23,490
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 20.13
Params size (MB): 0.09
Estimated Total Size (MB): 20.22
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 64, kernel_size: 2, n_block: 8
************************************************************
************************************************************
(2000, 1, 256) Counter({1: 1000, 0: 1000})
(2000, 1, 256) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 64, 256]             192
   MyConv1dPadSame-2              [-1, 64, 256]               0
       BatchNorm1d-3              [-1, 64, 256]             128
              ReLU-4              [-1, 64, 256]               0
            Conv1d-5              [-1, 64, 256]             192
   MyConv1dPadSame-6              [-1, 64, 256]               0
       BatchNorm1d-7              [-1, 64, 256]             128
              ReLU-8              [-1, 64, 256]               0
           Dropout-9              [-1, 64, 256]               0
           Conv1d-10              [-1, 64, 256]             192
  MyConv1dPadSame-11              [-1, 64, 256]               0
       Bottleneck-12              [-1, 64, 256]               0
      BatchNorm1d-13              [-1, 64, 256]             128
             ReLU-14              [-1, 64, 256]               0
          Dropout-15              [-1, 64, 256]               0
           Conv1d-16              [-1, 64, 256]             192
  MyConv1dPadSame-17              [-1, 64, 256]               0
      BatchNorm1d-18              [-1, 64, 256]             128
             ReLU-19              [-1, 64, 256]               0
          Dropout-20              [-1, 64, 256]               0
           Conv1d-21              [-1, 64, 256]             192
  MyConv1dPadSame-22              [-1, 64, 256]               0
       Bottleneck-23              [-1, 64, 256]               0
      BatchNorm1d-24              [-1, 64, 256]             128
             ReLU-25              [-1, 64, 256]               0
          Dropout-26              [-1, 64, 256]               0
           Conv1d-27             [-1, 128, 256]             384
  MyConv1dPadSame-28             [-1, 128, 256]               0
      BatchNorm1d-29             [-1, 128, 256]             256
             ReLU-30             [-1, 128, 256]               0
          Dropout-31             [-1, 128, 256]               0
           Conv1d-32             [-1, 128, 256]             640
  MyConv1dPadSame-33             [-1, 128, 256]               0
       Bottleneck-34             [-1, 128, 256]               0
      BatchNorm1d-35             [-1, 128, 256]             256
             ReLU-36             [-1, 128, 256]               0
          Dropout-37             [-1, 128, 256]               0
           Conv1d-38             [-1, 128, 256]             640
  MyConv1dPadSame-39             [-1, 128, 256]               0
      BatchNorm1d-40             [-1, 128, 256]             256
             ReLU-41             [-1, 128, 256]               0
          Dropout-42             [-1, 128, 256]               0
           Conv1d-43             [-1, 128, 256]             640
  MyConv1dPadSame-44             [-1, 128, 256]               0
       Bottleneck-45             [-1, 128, 256]               0
      BatchNorm1d-46             [-1, 128, 256]             256
             ReLU-47             [-1, 128, 256]               0
          Dropout-48             [-1, 128, 256]               0
           Conv1d-49             [-1, 256, 256]           1,280
  MyConv1dPadSame-50             [-1, 256, 256]               0
      BatchNorm1d-51             [-1, 256, 256]             512
             ReLU-52             [-1, 256, 256]               0
          Dropout-53             [-1, 256, 256]               0
           Conv1d-54             [-1, 256, 256]           2,304
  MyConv1dPadSame-55             [-1, 256, 256]               0
       Bottleneck-56             [-1, 256, 256]               0
      BatchNorm1d-57             [-1, 256, 256]             512
             ReLU-58             [-1, 256, 256]               0
          Dropout-59             [-1, 256, 256]               0
           Conv1d-60             [-1, 256, 256]           2,304
  MyConv1dPadSame-61             [-1, 256, 256]               0
      BatchNorm1d-62             [-1, 256, 256]             512
             ReLU-63             [-1, 256, 256]               0
          Dropout-64             [-1, 256, 256]               0
           Conv1d-65             [-1, 256, 256]           2,304
  MyConv1dPadSame-66             [-1, 256, 256]               0
       Bottleneck-67             [-1, 256, 256]               0
      BatchNorm1d-68             [-1, 256, 256]             512
             ReLU-69             [-1, 256, 256]               0
          Dropout-70             [-1, 256, 256]               0
           Conv1d-71             [-1, 512, 256]           4,608
  MyConv1dPadSame-72             [-1, 512, 256]               0
      BatchNorm1d-73             [-1, 512, 256]           1,024
             ReLU-74             [-1, 512, 256]               0
          Dropout-75             [-1, 512, 256]               0
           Conv1d-76             [-1, 512, 256]           8,704
  MyConv1dPadSame-77             [-1, 512, 256]               0
       Bottleneck-78             [-1, 512, 256]               0
      BatchNorm1d-79             [-1, 512, 256]           1,024
             ReLU-80             [-1, 512, 256]               0
          Dropout-81             [-1, 512, 256]               0
           Conv1d-82             [-1, 512, 256]           8,704
  MyConv1dPadSame-83             [-1, 512, 256]               0
      BatchNorm1d-84             [-1, 512, 256]           1,024
             ReLU-85             [-1, 512, 256]               0
          Dropout-86             [-1, 512, 256]               0
           Conv1d-87             [-1, 512, 256]           8,704
  MyConv1dPadSame-88             [-1, 512, 256]               0
       Bottleneck-89             [-1, 512, 256]               0
      BatchNorm1d-90             [-1, 512, 256]           1,024
             ReLU-91             [-1, 512, 256]               0
           Linear-92                    [-1, 2]           1,026
================================================================
Total params: 51,010
Trainable params: 51,010
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 40.75
Params size (MB): 0.19
Estimated Total Size (MB): 40.95
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 64, kernel_size: 2, n_block: 16
************************************************************
************************************************************
(2000, 1, 256) Counter({1: 1000, 0: 1000})
(2000, 1, 256) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 64, 256]             192
   MyConv1dPadSame-2              [-1, 64, 256]               0
       BatchNorm1d-3              [-1, 64, 256]             128
              ReLU-4              [-1, 64, 256]               0
            Conv1d-5              [-1, 64, 256]             192
   MyConv1dPadSame-6              [-1, 64, 256]               0
       BatchNorm1d-7              [-1, 64, 256]             128
              ReLU-8              [-1, 64, 256]               0
           Dropout-9              [-1, 64, 256]               0
           Conv1d-10              [-1, 64, 256]             192
  MyConv1dPadSame-11              [-1, 64, 256]               0
       Bottleneck-12              [-1, 64, 256]               0
      BatchNorm1d-13              [-1, 64, 256]             128
             ReLU-14              [-1, 64, 256]               0
          Dropout-15              [-1, 64, 256]               0
           Conv1d-16              [-1, 64, 128]             192
  MyConv1dPadSame-17              [-1, 64, 128]               0
      BatchNorm1d-18              [-1, 64, 128]             128
             ReLU-19              [-1, 64, 128]               0
          Dropout-20              [-1, 64, 128]               0
           Conv1d-21              [-1, 64, 128]             192
  MyConv1dPadSame-22              [-1, 64, 128]               0
        MaxPool1d-23              [-1, 64, 128]               0
MyMaxPool1dPadSame-24              [-1, 64, 128]               0
       Bottleneck-25              [-1, 64, 128]               0
      BatchNorm1d-26              [-1, 64, 128]             128
             ReLU-27              [-1, 64, 128]               0
          Dropout-28              [-1, 64, 128]               0
           Conv1d-29              [-1, 64, 128]             192
  MyConv1dPadSame-30              [-1, 64, 128]               0
      BatchNorm1d-31              [-1, 64, 128]             128
             ReLU-32              [-1, 64, 128]               0
          Dropout-33              [-1, 64, 128]               0
           Conv1d-34              [-1, 64, 128]             192
  MyConv1dPadSame-35              [-1, 64, 128]               0
       Bottleneck-36              [-1, 64, 128]               0
      BatchNorm1d-37              [-1, 64, 128]             128
             ReLU-38              [-1, 64, 128]               0
          Dropout-39              [-1, 64, 128]               0
           Conv1d-40               [-1, 64, 64]             192
  MyConv1dPadSame-41               [-1, 64, 64]               0
      BatchNorm1d-42               [-1, 64, 64]             128
             ReLU-43               [-1, 64, 64]               0
          Dropout-44               [-1, 64, 64]               0
           Conv1d-45               [-1, 64, 64]             192
  MyConv1dPadSame-46               [-1, 64, 64]               0
        MaxPool1d-47               [-1, 64, 64]               0
MyMaxPool1dPadSame-48               [-1, 64, 64]               0
       Bottleneck-49               [-1, 64, 64]               0
      BatchNorm1d-50               [-1, 64, 64]             128
             ReLU-51               [-1, 64, 64]               0
          Dropout-52               [-1, 64, 64]               0
           Conv1d-53              [-1, 128, 64]             384
  MyConv1dPadSame-54              [-1, 128, 64]               0
      BatchNorm1d-55              [-1, 128, 64]             256
             ReLU-56              [-1, 128, 64]               0
          Dropout-57              [-1, 128, 64]               0
           Conv1d-58              [-1, 128, 64]             640
  MyConv1dPadSame-59              [-1, 128, 64]               0
       Bottleneck-60              [-1, 128, 64]               0
      BatchNorm1d-61              [-1, 128, 64]             256
             ReLU-62              [-1, 128, 64]               0
          Dropout-63              [-1, 128, 64]               0
           Conv1d-64              [-1, 128, 32]             640
  MyConv1dPadSame-65              [-1, 128, 32]               0
      BatchNorm1d-66              [-1, 128, 32]             256
             ReLU-67              [-1, 128, 32]               0
          Dropout-68              [-1, 128, 32]               0
           Conv1d-69              [-1, 128, 32]             640
  MyConv1dPadSame-70              [-1, 128, 32]               0
        MaxPool1d-71              [-1, 128, 32]               0
MyMaxPool1dPadSame-72              [-1, 128, 32]               0
       Bottleneck-73              [-1, 128, 32]               0
      BatchNorm1d-74              [-1, 128, 32]             256
             ReLU-75              [-1, 128, 32]               0
          Dropout-76              [-1, 128, 32]               0
           Conv1d-77              [-1, 128, 32]             640
  MyConv1dPadSame-78              [-1, 128, 32]               0
      BatchNorm1d-79              [-1, 128, 32]             256
             ReLU-80              [-1, 128, 32]               0
          Dropout-81              [-1, 128, 32]               0
           Conv1d-82              [-1, 128, 32]             640
  MyConv1dPadSame-83              [-1, 128, 32]               0
       Bottleneck-84              [-1, 128, 32]               0
      BatchNorm1d-85              [-1, 128, 32]             256
             ReLU-86              [-1, 128, 32]               0
          Dropout-87              [-1, 128, 32]               0
           Conv1d-88              [-1, 128, 16]             640
  MyConv1dPadSame-89              [-1, 128, 16]               0
      BatchNorm1d-90              [-1, 128, 16]             256
             ReLU-91              [-1, 128, 16]               0
          Dropout-92              [-1, 128, 16]               0
           Conv1d-93              [-1, 128, 16]             640
  MyConv1dPadSame-94              [-1, 128, 16]               0
        MaxPool1d-95              [-1, 128, 16]               0
MyMaxPool1dPadSame-96              [-1, 128, 16]               0
       Bottleneck-97              [-1, 128, 16]               0
      BatchNorm1d-98              [-1, 128, 16]             256
             ReLU-99              [-1, 128, 16]               0
         Dropout-100              [-1, 128, 16]               0
          Conv1d-101              [-1, 256, 16]           1,280
 MyConv1dPadSame-102              [-1, 256, 16]               0
     BatchNorm1d-103              [-1, 256, 16]             512
            ReLU-104              [-1, 256, 16]               0
         Dropout-105              [-1, 256, 16]               0
          Conv1d-106              [-1, 256, 16]           2,304
 MyConv1dPadSame-107              [-1, 256, 16]               0
      Bottleneck-108              [-1, 256, 16]               0
     BatchNorm1d-109              [-1, 256, 16]             512
            ReLU-110              [-1, 256, 16]               0
         Dropout-111              [-1, 256, 16]               0
          Conv1d-112               [-1, 256, 8]           2,304
 MyConv1dPadSame-113               [-1, 256, 8]               0
     BatchNorm1d-114               [-1, 256, 8]             512
            ReLU-115               [-1, 256, 8]               0
         Dropout-116               [-1, 256, 8]               0
          Conv1d-117               [-1, 256, 8]           2,304
 MyConv1dPadSame-118               [-1, 256, 8]               0
       MaxPool1d-119               [-1, 256, 8]               0
MyMaxPool1dPadSame-120               [-1, 256, 8]               0
      Bottleneck-121               [-1, 256, 8]               0
     BatchNorm1d-122               [-1, 256, 8]             512
            ReLU-123               [-1, 256, 8]               0
         Dropout-124               [-1, 256, 8]               0
          Conv1d-125               [-1, 256, 8]           2,304
 MyConv1dPadSame-126               [-1, 256, 8]               0
     BatchNorm1d-127               [-1, 256, 8]             512
            ReLU-128               [-1, 256, 8]               0
         Dropout-129               [-1, 256, 8]               0
          Conv1d-130               [-1, 256, 8]           2,304
 MyConv1dPadSame-131               [-1, 256, 8]               0
      Bottleneck-132               [-1, 256, 8]               0
     BatchNorm1d-133               [-1, 256, 8]             512
            ReLU-134               [-1, 256, 8]               0
         Dropout-135               [-1, 256, 8]               0
          Conv1d-136               [-1, 256, 4]           2,304
 MyConv1dPadSame-137               [-1, 256, 4]               0
     BatchNorm1d-138               [-1, 256, 4]             512
            ReLU-139               [-1, 256, 4]               0
         Dropout-140               [-1, 256, 4]               0
          Conv1d-141               [-1, 256, 4]           2,304
 MyConv1dPadSame-142               [-1, 256, 4]               0
       MaxPool1d-143               [-1, 256, 4]               0
MyMaxPool1dPadSame-144               [-1, 256, 4]               0
      Bottleneck-145               [-1, 256, 4]               0
     BatchNorm1d-146               [-1, 256, 4]             512
            ReLU-147               [-1, 256, 4]               0
         Dropout-148               [-1, 256, 4]               0
          Conv1d-149               [-1, 512, 4]           4,608
 MyConv1dPadSame-150               [-1, 512, 4]               0
     BatchNorm1d-151               [-1, 512, 4]           1,024
            ReLU-152               [-1, 512, 4]               0
         Dropout-153               [-1, 512, 4]               0
          Conv1d-154               [-1, 512, 4]           8,704
 MyConv1dPadSame-155               [-1, 512, 4]               0
      Bottleneck-156               [-1, 512, 4]               0
     BatchNorm1d-157               [-1, 512, 4]           1,024
            ReLU-158               [-1, 512, 4]               0
         Dropout-159               [-1, 512, 4]               0
          Conv1d-160               [-1, 512, 2]           8,704
 MyConv1dPadSame-161               [-1, 512, 2]               0
     BatchNorm1d-162               [-1, 512, 2]           1,024
            ReLU-163               [-1, 512, 2]               0
         Dropout-164               [-1, 512, 2]               0
          Conv1d-165               [-1, 512, 2]           8,704
 MyConv1dPadSame-166               [-1, 512, 2]               0
       MaxPool1d-167               [-1, 512, 2]               0
MyMaxPool1dPadSame-168               [-1, 512, 2]               0
      Bottleneck-169               [-1, 512, 2]               0
     BatchNorm1d-170               [-1, 512, 2]           1,024
            ReLU-171               [-1, 512, 2]               0
         Dropout-172               [-1, 512, 2]               0
          Conv1d-173               [-1, 512, 2]           8,704
 MyConv1dPadSame-174               [-1, 512, 2]               0
     BatchNorm1d-175               [-1, 512, 2]           1,024
            ReLU-176               [-1, 512, 2]               0
         Dropout-177               [-1, 512, 2]               0
          Conv1d-178               [-1, 512, 2]           8,704
 MyConv1dPadSame-179               [-1, 512, 2]               0
      Bottleneck-180               [-1, 512, 2]               0
     BatchNorm1d-181               [-1, 512, 2]           1,024
            ReLU-182               [-1, 512, 2]               0
         Dropout-183               [-1, 512, 2]               0
          Conv1d-184               [-1, 512, 1]           8,704
 MyConv1dPadSame-185               [-1, 512, 1]               0
     BatchNorm1d-186               [-1, 512, 1]           1,024
            ReLU-187               [-1, 512, 1]               0
         Dropout-188               [-1, 512, 1]               0
          Conv1d-189               [-1, 512, 1]           8,704
 MyConv1dPadSame-190               [-1, 512, 1]               0
       MaxPool1d-191               [-1, 512, 1]               0
MyMaxPool1dPadSame-192               [-1, 512, 1]               0
      Bottleneck-193               [-1, 512, 1]               0
     BatchNorm1d-194               [-1, 512, 1]           1,024
            ReLU-195               [-1, 512, 1]               0
          Linear-196                    [-1, 2]           1,026
================================================================
Total params: 106,050
Trainable params: 106,050
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 6.65
Params size (MB): 0.40
Estimated Total Size (MB): 7.05
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 64, kernel_size: 4, n_block: 2
************************************************************
************************************************************
(2000, 1, 256) Counter({0: 1000, 1: 1000})
(2000, 1, 256) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 64, 256]             320
   MyConv1dPadSame-2              [-1, 64, 256]               0
       BatchNorm1d-3              [-1, 64, 256]             128
              ReLU-4              [-1, 64, 256]               0
            Conv1d-5              [-1, 64, 256]             320
   MyConv1dPadSame-6              [-1, 64, 256]               0
       BatchNorm1d-7              [-1, 64, 256]             128
              ReLU-8              [-1, 64, 256]               0
           Dropout-9              [-1, 64, 256]               0
           Conv1d-10              [-1, 64, 256]             320
  MyConv1dPadSame-11              [-1, 64, 256]               0
       Bottleneck-12              [-1, 64, 256]               0
      BatchNorm1d-13              [-1, 64, 256]             128
             ReLU-14              [-1, 64, 256]               0
          Dropout-15              [-1, 64, 256]               0
           Conv1d-16             [-1, 128, 256]             640
  MyConv1dPadSame-17             [-1, 128, 256]               0
      BatchNorm1d-18             [-1, 128, 256]             256
             ReLU-19             [-1, 128, 256]               0
          Dropout-20             [-1, 128, 256]               0
           Conv1d-21             [-1, 128, 256]           1,152
  MyConv1dPadSame-22             [-1, 128, 256]               0
       Bottleneck-23             [-1, 128, 256]               0
      BatchNorm1d-24             [-1, 128, 256]             256
             ReLU-25             [-1, 128, 256]               0
           Linear-26                    [-1, 2]             258
================================================================
Total params: 3,906
Trainable params: 3,906
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 4.38
Params size (MB): 0.01
Estimated Total Size (MB): 4.39
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 64, kernel_size: 4, n_block: 4
************************************************************
************************************************************
(2000, 1, 256) Counter({0: 1000, 1: 1000})
(2000, 1, 256) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 64, 256]             320
   MyConv1dPadSame-2              [-1, 64, 256]               0
       BatchNorm1d-3              [-1, 64, 256]             128
              ReLU-4              [-1, 64, 256]               0
            Conv1d-5              [-1, 64, 256]             320
   MyConv1dPadSame-6              [-1, 64, 256]               0
       BatchNorm1d-7              [-1, 64, 256]             128
              ReLU-8              [-1, 64, 256]               0
           Dropout-9              [-1, 64, 256]               0
           Conv1d-10              [-1, 64, 256]             320
  MyConv1dPadSame-11              [-1, 64, 256]               0
       Bottleneck-12              [-1, 64, 256]               0
      BatchNorm1d-13              [-1, 64, 256]             128
             ReLU-14              [-1, 64, 256]               0
          Dropout-15              [-1, 64, 256]               0
           Conv1d-16             [-1, 128, 256]             640
  MyConv1dPadSame-17             [-1, 128, 256]               0
      BatchNorm1d-18             [-1, 128, 256]             256
             ReLU-19             [-1, 128, 256]               0
          Dropout-20             [-1, 128, 256]               0
           Conv1d-21             [-1, 128, 256]           1,152
  MyConv1dPadSame-22             [-1, 128, 256]               0
       Bottleneck-23             [-1, 128, 256]               0
      BatchNorm1d-24             [-1, 128, 256]             256
             ReLU-25             [-1, 128, 256]               0
          Dropout-26             [-1, 128, 256]               0
           Conv1d-27             [-1, 256, 256]           2,304
  MyConv1dPadSame-28             [-1, 256, 256]               0
      BatchNorm1d-29             [-1, 256, 256]             512
             ReLU-30             [-1, 256, 256]               0
          Dropout-31             [-1, 256, 256]               0
           Conv1d-32             [-1, 256, 256]           4,352
  MyConv1dPadSame-33             [-1, 256, 256]               0
       Bottleneck-34             [-1, 256, 256]               0
      BatchNorm1d-35             [-1, 256, 256]             512
             ReLU-36             [-1, 256, 256]               0
          Dropout-37             [-1, 256, 256]               0
           Conv1d-38             [-1, 512, 256]           8,704
  MyConv1dPadSame-39             [-1, 512, 256]               0
      BatchNorm1d-40             [-1, 512, 256]           1,024
             ReLU-41             [-1, 512, 256]               0
          Dropout-42             [-1, 512, 256]               0
           Conv1d-43             [-1, 512, 256]          16,896
  MyConv1dPadSame-44             [-1, 512, 256]               0
       Bottleneck-45             [-1, 512, 256]               0
      BatchNorm1d-46             [-1, 512, 256]           1,024
             ReLU-47             [-1, 512, 256]               0
           Linear-48                    [-1, 2]           1,026
================================================================
Total params: 40,002
Trainable params: 40,002
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 20.13
Params size (MB): 0.15
Estimated Total Size (MB): 20.28
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 64, kernel_size: 4, n_block: 8
************************************************************
************************************************************
(2000, 1, 256) Counter({0: 1000, 1: 1000})
(2000, 1, 256) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 64, 256]             320
   MyConv1dPadSame-2              [-1, 64, 256]               0
       BatchNorm1d-3              [-1, 64, 256]             128
              ReLU-4              [-1, 64, 256]               0
            Conv1d-5              [-1, 64, 256]             320
   MyConv1dPadSame-6              [-1, 64, 256]               0
       BatchNorm1d-7              [-1, 64, 256]             128
              ReLU-8              [-1, 64, 256]               0
           Dropout-9              [-1, 64, 256]               0
           Conv1d-10              [-1, 64, 256]             320
  MyConv1dPadSame-11              [-1, 64, 256]               0
       Bottleneck-12              [-1, 64, 256]               0
      BatchNorm1d-13              [-1, 64, 256]             128
             ReLU-14              [-1, 64, 256]               0
          Dropout-15              [-1, 64, 256]               0
           Conv1d-16              [-1, 64, 256]             320
  MyConv1dPadSame-17              [-1, 64, 256]               0
      BatchNorm1d-18              [-1, 64, 256]             128
             ReLU-19              [-1, 64, 256]               0
          Dropout-20              [-1, 64, 256]               0
           Conv1d-21              [-1, 64, 256]             320
  MyConv1dPadSame-22              [-1, 64, 256]               0
       Bottleneck-23              [-1, 64, 256]               0
      BatchNorm1d-24              [-1, 64, 256]             128
             ReLU-25              [-1, 64, 256]               0
          Dropout-26              [-1, 64, 256]               0
           Conv1d-27             [-1, 128, 256]             640
  MyConv1dPadSame-28             [-1, 128, 256]               0
      BatchNorm1d-29             [-1, 128, 256]             256
             ReLU-30             [-1, 128, 256]               0
          Dropout-31             [-1, 128, 256]               0
           Conv1d-32             [-1, 128, 256]           1,152
  MyConv1dPadSame-33             [-1, 128, 256]               0
       Bottleneck-34             [-1, 128, 256]               0
      BatchNorm1d-35             [-1, 128, 256]             256
             ReLU-36             [-1, 128, 256]               0
          Dropout-37             [-1, 128, 256]               0
           Conv1d-38             [-1, 128, 256]           1,152
  MyConv1dPadSame-39             [-1, 128, 256]               0
      BatchNorm1d-40             [-1, 128, 256]             256
             ReLU-41             [-1, 128, 256]               0
          Dropout-42             [-1, 128, 256]               0
           Conv1d-43             [-1, 128, 256]           1,152
  MyConv1dPadSame-44             [-1, 128, 256]               0
       Bottleneck-45             [-1, 128, 256]               0
      BatchNorm1d-46             [-1, 128, 256]             256
             ReLU-47             [-1, 128, 256]               0
          Dropout-48             [-1, 128, 256]               0
           Conv1d-49             [-1, 256, 256]           2,304
  MyConv1dPadSame-50             [-1, 256, 256]               0
      BatchNorm1d-51             [-1, 256, 256]             512
             ReLU-52             [-1, 256, 256]               0
          Dropout-53             [-1, 256, 256]               0
           Conv1d-54             [-1, 256, 256]           4,352
  MyConv1dPadSame-55             [-1, 256, 256]               0
       Bottleneck-56             [-1, 256, 256]               0
      BatchNorm1d-57             [-1, 256, 256]             512
             ReLU-58             [-1, 256, 256]               0
          Dropout-59             [-1, 256, 256]               0
           Conv1d-60             [-1, 256, 256]           4,352
  MyConv1dPadSame-61             [-1, 256, 256]               0
      BatchNorm1d-62             [-1, 256, 256]             512
             ReLU-63             [-1, 256, 256]               0
          Dropout-64             [-1, 256, 256]               0
           Conv1d-65             [-1, 256, 256]           4,352
  MyConv1dPadSame-66             [-1, 256, 256]               0
       Bottleneck-67             [-1, 256, 256]               0
      BatchNorm1d-68             [-1, 256, 256]             512
             ReLU-69             [-1, 256, 256]               0
          Dropout-70             [-1, 256, 256]               0
           Conv1d-71             [-1, 512, 256]           8,704
  MyConv1dPadSame-72             [-1, 512, 256]               0
      BatchNorm1d-73             [-1, 512, 256]           1,024
             ReLU-74             [-1, 512, 256]               0
          Dropout-75             [-1, 512, 256]               0
           Conv1d-76             [-1, 512, 256]          16,896
  MyConv1dPadSame-77             [-1, 512, 256]               0
       Bottleneck-78             [-1, 512, 256]               0
      BatchNorm1d-79             [-1, 512, 256]           1,024
             ReLU-80             [-1, 512, 256]               0
          Dropout-81             [-1, 512, 256]               0
           Conv1d-82             [-1, 512, 256]          16,896
  MyConv1dPadSame-83             [-1, 512, 256]               0
      BatchNorm1d-84             [-1, 512, 256]           1,024
             ReLU-85             [-1, 512, 256]               0
          Dropout-86             [-1, 512, 256]               0
           Conv1d-87             [-1, 512, 256]          16,896
  MyConv1dPadSame-88             [-1, 512, 256]               0
       Bottleneck-89             [-1, 512, 256]               0
      BatchNorm1d-90             [-1, 512, 256]           1,024
             ReLU-91             [-1, 512, 256]               0
           Linear-92                    [-1, 2]           1,026
================================================================
Total params: 89,282
Trainable params: 89,282
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 40.75
Params size (MB): 0.34
Estimated Total Size (MB): 41.09
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 64, kernel_size: 4, n_block: 16
************************************************************
************************************************************
(2000, 1, 256) Counter({0: 1000, 1: 1000})
(2000, 1, 256) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 64, 256]             320
   MyConv1dPadSame-2              [-1, 64, 256]               0
       BatchNorm1d-3              [-1, 64, 256]             128
              ReLU-4              [-1, 64, 256]               0
            Conv1d-5              [-1, 64, 256]             320
   MyConv1dPadSame-6              [-1, 64, 256]               0
       BatchNorm1d-7              [-1, 64, 256]             128
              ReLU-8              [-1, 64, 256]               0
           Dropout-9              [-1, 64, 256]               0
           Conv1d-10              [-1, 64, 256]             320
  MyConv1dPadSame-11              [-1, 64, 256]               0
       Bottleneck-12              [-1, 64, 256]               0
      BatchNorm1d-13              [-1, 64, 256]             128
             ReLU-14              [-1, 64, 256]               0
          Dropout-15              [-1, 64, 256]               0
           Conv1d-16              [-1, 64, 128]             320
  MyConv1dPadSame-17              [-1, 64, 128]               0
      BatchNorm1d-18              [-1, 64, 128]             128
             ReLU-19              [-1, 64, 128]               0
          Dropout-20              [-1, 64, 128]               0
           Conv1d-21              [-1, 64, 128]             320
  MyConv1dPadSame-22              [-1, 64, 128]               0
        MaxPool1d-23              [-1, 64, 128]               0
MyMaxPool1dPadSame-24              [-1, 64, 128]               0
       Bottleneck-25              [-1, 64, 128]               0
      BatchNorm1d-26              [-1, 64, 128]             128
             ReLU-27              [-1, 64, 128]               0
          Dropout-28              [-1, 64, 128]               0
           Conv1d-29              [-1, 64, 128]             320
  MyConv1dPadSame-30              [-1, 64, 128]               0
      BatchNorm1d-31              [-1, 64, 128]             128
             ReLU-32              [-1, 64, 128]               0
          Dropout-33              [-1, 64, 128]               0
           Conv1d-34              [-1, 64, 128]             320
  MyConv1dPadSame-35              [-1, 64, 128]               0
       Bottleneck-36              [-1, 64, 128]               0
      BatchNorm1d-37              [-1, 64, 128]             128
             ReLU-38              [-1, 64, 128]               0
          Dropout-39              [-1, 64, 128]               0
           Conv1d-40               [-1, 64, 64]             320
  MyConv1dPadSame-41               [-1, 64, 64]               0
      BatchNorm1d-42               [-1, 64, 64]             128
             ReLU-43               [-1, 64, 64]               0
          Dropout-44               [-1, 64, 64]               0
           Conv1d-45               [-1, 64, 64]             320
  MyConv1dPadSame-46               [-1, 64, 64]               0
        MaxPool1d-47               [-1, 64, 64]               0
MyMaxPool1dPadSame-48               [-1, 64, 64]               0
       Bottleneck-49               [-1, 64, 64]               0
      BatchNorm1d-50               [-1, 64, 64]             128
             ReLU-51               [-1, 64, 64]               0
          Dropout-52               [-1, 64, 64]               0
           Conv1d-53              [-1, 128, 64]             640
  MyConv1dPadSame-54              [-1, 128, 64]               0
      BatchNorm1d-55              [-1, 128, 64]             256
             ReLU-56              [-1, 128, 64]               0
          Dropout-57              [-1, 128, 64]               0
           Conv1d-58              [-1, 128, 64]           1,152
  MyConv1dPadSame-59              [-1, 128, 64]               0
       Bottleneck-60              [-1, 128, 64]               0
      BatchNorm1d-61              [-1, 128, 64]             256
             ReLU-62              [-1, 128, 64]               0
          Dropout-63              [-1, 128, 64]               0
           Conv1d-64              [-1, 128, 32]           1,152
  MyConv1dPadSame-65              [-1, 128, 32]               0
      BatchNorm1d-66              [-1, 128, 32]             256
             ReLU-67              [-1, 128, 32]               0
          Dropout-68              [-1, 128, 32]               0
           Conv1d-69              [-1, 128, 32]           1,152
  MyConv1dPadSame-70              [-1, 128, 32]               0
        MaxPool1d-71              [-1, 128, 32]               0
MyMaxPool1dPadSame-72              [-1, 128, 32]               0
       Bottleneck-73              [-1, 128, 32]               0
      BatchNorm1d-74              [-1, 128, 32]             256
             ReLU-75              [-1, 128, 32]               0
          Dropout-76              [-1, 128, 32]               0
           Conv1d-77              [-1, 128, 32]           1,152
  MyConv1dPadSame-78              [-1, 128, 32]               0
      BatchNorm1d-79              [-1, 128, 32]             256
             ReLU-80              [-1, 128, 32]               0
          Dropout-81              [-1, 128, 32]               0
           Conv1d-82              [-1, 128, 32]           1,152
  MyConv1dPadSame-83              [-1, 128, 32]               0
       Bottleneck-84              [-1, 128, 32]               0
      BatchNorm1d-85              [-1, 128, 32]             256
             ReLU-86              [-1, 128, 32]               0
          Dropout-87              [-1, 128, 32]               0
           Conv1d-88              [-1, 128, 16]           1,152
  MyConv1dPadSame-89              [-1, 128, 16]               0
      BatchNorm1d-90              [-1, 128, 16]             256
             ReLU-91              [-1, 128, 16]               0
          Dropout-92              [-1, 128, 16]               0
           Conv1d-93              [-1, 128, 16]           1,152
  MyConv1dPadSame-94              [-1, 128, 16]               0
        MaxPool1d-95              [-1, 128, 16]               0
MyMaxPool1dPadSame-96              [-1, 128, 16]               0
       Bottleneck-97              [-1, 128, 16]               0
      BatchNorm1d-98              [-1, 128, 16]             256
             ReLU-99              [-1, 128, 16]               0
         Dropout-100              [-1, 128, 16]               0
          Conv1d-101              [-1, 256, 16]           2,304
 MyConv1dPadSame-102              [-1, 256, 16]               0
     BatchNorm1d-103              [-1, 256, 16]             512
            ReLU-104              [-1, 256, 16]               0
         Dropout-105              [-1, 256, 16]               0
          Conv1d-106              [-1, 256, 16]           4,352
 MyConv1dPadSame-107              [-1, 256, 16]               0
      Bottleneck-108              [-1, 256, 16]               0
     BatchNorm1d-109              [-1, 256, 16]             512
            ReLU-110              [-1, 256, 16]               0
         Dropout-111              [-1, 256, 16]               0
          Conv1d-112               [-1, 256, 8]           4,352
 MyConv1dPadSame-113               [-1, 256, 8]               0
     BatchNorm1d-114               [-1, 256, 8]             512
            ReLU-115               [-1, 256, 8]               0
         Dropout-116               [-1, 256, 8]               0
          Conv1d-117               [-1, 256, 8]           4,352
 MyConv1dPadSame-118               [-1, 256, 8]               0
       MaxPool1d-119               [-1, 256, 8]               0
MyMaxPool1dPadSame-120               [-1, 256, 8]               0
      Bottleneck-121               [-1, 256, 8]               0
     BatchNorm1d-122               [-1, 256, 8]             512
            ReLU-123               [-1, 256, 8]               0
         Dropout-124               [-1, 256, 8]               0
          Conv1d-125               [-1, 256, 8]           4,352
 MyConv1dPadSame-126               [-1, 256, 8]               0
     BatchNorm1d-127               [-1, 256, 8]             512
            ReLU-128               [-1, 256, 8]               0
         Dropout-129               [-1, 256, 8]               0
          Conv1d-130               [-1, 256, 8]           4,352
 MyConv1dPadSame-131               [-1, 256, 8]               0
      Bottleneck-132               [-1, 256, 8]               0
     BatchNorm1d-133               [-1, 256, 8]             512
            ReLU-134               [-1, 256, 8]               0
         Dropout-135               [-1, 256, 8]               0
          Conv1d-136               [-1, 256, 4]           4,352
 MyConv1dPadSame-137               [-1, 256, 4]               0
     BatchNorm1d-138               [-1, 256, 4]             512
            ReLU-139               [-1, 256, 4]               0
         Dropout-140               [-1, 256, 4]               0
          Conv1d-141               [-1, 256, 4]           4,352
 MyConv1dPadSame-142               [-1, 256, 4]               0
       MaxPool1d-143               [-1, 256, 4]               0
MyMaxPool1dPadSame-144               [-1, 256, 4]               0
      Bottleneck-145               [-1, 256, 4]               0
     BatchNorm1d-146               [-1, 256, 4]             512
            ReLU-147               [-1, 256, 4]               0
         Dropout-148               [-1, 256, 4]               0
          Conv1d-149               [-1, 512, 4]           8,704
 MyConv1dPadSame-150               [-1, 512, 4]               0
     BatchNorm1d-151               [-1, 512, 4]           1,024
            ReLU-152               [-1, 512, 4]               0
         Dropout-153               [-1, 512, 4]               0
          Conv1d-154               [-1, 512, 4]          16,896
 MyConv1dPadSame-155               [-1, 512, 4]               0
      Bottleneck-156               [-1, 512, 4]               0
     BatchNorm1d-157               [-1, 512, 4]           1,024
            ReLU-158               [-1, 512, 4]               0
         Dropout-159               [-1, 512, 4]               0
          Conv1d-160               [-1, 512, 2]          16,896
 MyConv1dPadSame-161               [-1, 512, 2]               0
     BatchNorm1d-162               [-1, 512, 2]           1,024
            ReLU-163               [-1, 512, 2]               0
         Dropout-164               [-1, 512, 2]               0
          Conv1d-165               [-1, 512, 2]          16,896
 MyConv1dPadSame-166               [-1, 512, 2]               0
       MaxPool1d-167               [-1, 512, 2]               0
MyMaxPool1dPadSame-168               [-1, 512, 2]               0
      Bottleneck-169               [-1, 512, 2]               0
     BatchNorm1d-170               [-1, 512, 2]           1,024
            ReLU-171               [-1, 512, 2]               0
         Dropout-172               [-1, 512, 2]               0
          Conv1d-173               [-1, 512, 2]          16,896
 MyConv1dPadSame-174               [-1, 512, 2]               0
     BatchNorm1d-175               [-1, 512, 2]           1,024
            ReLU-176               [-1, 512, 2]               0
         Dropout-177               [-1, 512, 2]               0
          Conv1d-178               [-1, 512, 2]          16,896
 MyConv1dPadSame-179               [-1, 512, 2]               0
      Bottleneck-180               [-1, 512, 2]               0
     BatchNorm1d-181               [-1, 512, 2]           1,024
            ReLU-182               [-1, 512, 2]               0
         Dropout-183               [-1, 512, 2]               0
          Conv1d-184               [-1, 512, 1]          16,896
 MyConv1dPadSame-185               [-1, 512, 1]               0
     BatchNorm1d-186               [-1, 512, 1]           1,024
            ReLU-187               [-1, 512, 1]               0
         Dropout-188               [-1, 512, 1]               0
          Conv1d-189               [-1, 512, 1]          16,896
 MyConv1dPadSame-190               [-1, 512, 1]               0
       MaxPool1d-191               [-1, 512, 1]               0
MyMaxPool1dPadSame-192               [-1, 512, 1]               0
      Bottleneck-193               [-1, 512, 1]               0
     BatchNorm1d-194               [-1, 512, 1]           1,024
            ReLU-195               [-1, 512, 1]               0
          Linear-196                    [-1, 2]           1,026
================================================================
Total params: 187,842
Trainable params: 187,842
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 6.65
Params size (MB): 0.72
Estimated Total Size (MB): 7.37
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 64, kernel_size: 8, n_block: 2
************************************************************
************************************************************
(2000, 1, 256) Counter({1: 1000, 0: 1000})
(2000, 1, 256) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 64, 256]             576
   MyConv1dPadSame-2              [-1, 64, 256]               0
       BatchNorm1d-3              [-1, 64, 256]             128
              ReLU-4              [-1, 64, 256]               0
            Conv1d-5              [-1, 64, 256]             576
   MyConv1dPadSame-6              [-1, 64, 256]               0
       BatchNorm1d-7              [-1, 64, 256]             128
              ReLU-8              [-1, 64, 256]               0
           Dropout-9              [-1, 64, 256]               0
           Conv1d-10              [-1, 64, 256]             576
  MyConv1dPadSame-11              [-1, 64, 256]               0
       Bottleneck-12              [-1, 64, 256]               0
      BatchNorm1d-13              [-1, 64, 256]             128
             ReLU-14              [-1, 64, 256]               0
          Dropout-15              [-1, 64, 256]               0
           Conv1d-16             [-1, 128, 256]           1,152
  MyConv1dPadSame-17             [-1, 128, 256]               0
      BatchNorm1d-18             [-1, 128, 256]             256
             ReLU-19             [-1, 128, 256]               0
          Dropout-20             [-1, 128, 256]               0
           Conv1d-21             [-1, 128, 256]           2,176
  MyConv1dPadSame-22             [-1, 128, 256]               0
       Bottleneck-23             [-1, 128, 256]               0
      BatchNorm1d-24             [-1, 128, 256]             256
             ReLU-25             [-1, 128, 256]               0
           Linear-26                    [-1, 2]             258
================================================================
Total params: 6,210
Trainable params: 6,210
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 4.38
Params size (MB): 0.02
Estimated Total Size (MB): 4.40
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 64, kernel_size: 8, n_block: 4
************************************************************
************************************************************
(2000, 1, 256) Counter({0: 1000, 1: 1000})
(2000, 1, 256) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 64, 256]             576
   MyConv1dPadSame-2              [-1, 64, 256]               0
       BatchNorm1d-3              [-1, 64, 256]             128
              ReLU-4              [-1, 64, 256]               0
            Conv1d-5              [-1, 64, 256]             576
   MyConv1dPadSame-6              [-1, 64, 256]               0
       BatchNorm1d-7              [-1, 64, 256]             128
              ReLU-8              [-1, 64, 256]               0
           Dropout-9              [-1, 64, 256]               0
           Conv1d-10              [-1, 64, 256]             576
  MyConv1dPadSame-11              [-1, 64, 256]               0
       Bottleneck-12              [-1, 64, 256]               0
      BatchNorm1d-13              [-1, 64, 256]             128
             ReLU-14              [-1, 64, 256]               0
          Dropout-15              [-1, 64, 256]               0
           Conv1d-16             [-1, 128, 256]           1,152
  MyConv1dPadSame-17             [-1, 128, 256]               0
      BatchNorm1d-18             [-1, 128, 256]             256
             ReLU-19             [-1, 128, 256]               0
          Dropout-20             [-1, 128, 256]               0
           Conv1d-21             [-1, 128, 256]           2,176
  MyConv1dPadSame-22             [-1, 128, 256]               0
       Bottleneck-23             [-1, 128, 256]               0
      BatchNorm1d-24             [-1, 128, 256]             256
             ReLU-25             [-1, 128, 256]               0
          Dropout-26             [-1, 128, 256]               0
           Conv1d-27             [-1, 256, 256]           4,352
  MyConv1dPadSame-28             [-1, 256, 256]               0
      BatchNorm1d-29             [-1, 256, 256]             512
             ReLU-30             [-1, 256, 256]               0
          Dropout-31             [-1, 256, 256]               0
           Conv1d-32             [-1, 256, 256]           8,448
  MyConv1dPadSame-33             [-1, 256, 256]               0
       Bottleneck-34             [-1, 256, 256]               0
      BatchNorm1d-35             [-1, 256, 256]             512
             ReLU-36             [-1, 256, 256]               0
          Dropout-37             [-1, 256, 256]               0
           Conv1d-38             [-1, 512, 256]          16,896
  MyConv1dPadSame-39             [-1, 512, 256]               0
      BatchNorm1d-40             [-1, 512, 256]           1,024
             ReLU-41             [-1, 512, 256]               0
          Dropout-42             [-1, 512, 256]               0
           Conv1d-43             [-1, 512, 256]          33,280
  MyConv1dPadSame-44             [-1, 512, 256]               0
       Bottleneck-45             [-1, 512, 256]               0
      BatchNorm1d-46             [-1, 512, 256]           1,024
             ReLU-47             [-1, 512, 256]               0
           Linear-48                    [-1, 2]           1,026
================================================================
Total params: 73,026
Trainable params: 73,026
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 20.13
Params size (MB): 0.28
Estimated Total Size (MB): 20.40
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 64, kernel_size: 8, n_block: 8
************************************************************
************************************************************
(2000, 1, 256) Counter({1: 1000, 0: 1000})
(2000, 1, 256) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 64, 256]             576
   MyConv1dPadSame-2              [-1, 64, 256]               0
       BatchNorm1d-3              [-1, 64, 256]             128
              ReLU-4              [-1, 64, 256]               0
            Conv1d-5              [-1, 64, 256]             576
   MyConv1dPadSame-6              [-1, 64, 256]               0
       BatchNorm1d-7              [-1, 64, 256]             128
              ReLU-8              [-1, 64, 256]               0
           Dropout-9              [-1, 64, 256]               0
           Conv1d-10              [-1, 64, 256]             576
  MyConv1dPadSame-11              [-1, 64, 256]               0
       Bottleneck-12              [-1, 64, 256]               0
      BatchNorm1d-13              [-1, 64, 256]             128
             ReLU-14              [-1, 64, 256]               0
          Dropout-15              [-1, 64, 256]               0
           Conv1d-16              [-1, 64, 256]             576
  MyConv1dPadSame-17              [-1, 64, 256]               0
      BatchNorm1d-18              [-1, 64, 256]             128
             ReLU-19              [-1, 64, 256]               0
          Dropout-20              [-1, 64, 256]               0
           Conv1d-21              [-1, 64, 256]             576
  MyConv1dPadSame-22              [-1, 64, 256]               0
       Bottleneck-23              [-1, 64, 256]               0
      BatchNorm1d-24              [-1, 64, 256]             128
             ReLU-25              [-1, 64, 256]               0
          Dropout-26              [-1, 64, 256]               0
           Conv1d-27             [-1, 128, 256]           1,152
  MyConv1dPadSame-28             [-1, 128, 256]               0
      BatchNorm1d-29             [-1, 128, 256]             256
             ReLU-30             [-1, 128, 256]               0
          Dropout-31             [-1, 128, 256]               0
           Conv1d-32             [-1, 128, 256]           2,176
  MyConv1dPadSame-33             [-1, 128, 256]               0
       Bottleneck-34             [-1, 128, 256]               0
      BatchNorm1d-35             [-1, 128, 256]             256
             ReLU-36             [-1, 128, 256]               0
          Dropout-37             [-1, 128, 256]               0
           Conv1d-38             [-1, 128, 256]           2,176
  MyConv1dPadSame-39             [-1, 128, 256]               0
      BatchNorm1d-40             [-1, 128, 256]             256
             ReLU-41             [-1, 128, 256]               0
          Dropout-42             [-1, 128, 256]               0
           Conv1d-43             [-1, 128, 256]           2,176
  MyConv1dPadSame-44             [-1, 128, 256]               0
       Bottleneck-45             [-1, 128, 256]               0
      BatchNorm1d-46             [-1, 128, 256]             256
             ReLU-47             [-1, 128, 256]               0
          Dropout-48             [-1, 128, 256]               0
           Conv1d-49             [-1, 256, 256]           4,352
  MyConv1dPadSame-50             [-1, 256, 256]               0
      BatchNorm1d-51             [-1, 256, 256]             512
             ReLU-52             [-1, 256, 256]               0
          Dropout-53             [-1, 256, 256]               0
           Conv1d-54             [-1, 256, 256]           8,448
  MyConv1dPadSame-55             [-1, 256, 256]               0
       Bottleneck-56             [-1, 256, 256]               0
      BatchNorm1d-57             [-1, 256, 256]             512
             ReLU-58             [-1, 256, 256]               0
          Dropout-59             [-1, 256, 256]               0
           Conv1d-60             [-1, 256, 256]           8,448
  MyConv1dPadSame-61             [-1, 256, 256]               0
      BatchNorm1d-62             [-1, 256, 256]             512
             ReLU-63             [-1, 256, 256]               0
          Dropout-64             [-1, 256, 256]               0
           Conv1d-65             [-1, 256, 256]           8,448
  MyConv1dPadSame-66             [-1, 256, 256]               0
       Bottleneck-67             [-1, 256, 256]               0
      BatchNorm1d-68             [-1, 256, 256]             512
             ReLU-69             [-1, 256, 256]               0
          Dropout-70             [-1, 256, 256]               0
           Conv1d-71             [-1, 512, 256]          16,896
  MyConv1dPadSame-72             [-1, 512, 256]               0
      BatchNorm1d-73             [-1, 512, 256]           1,024
             ReLU-74             [-1, 512, 256]               0
          Dropout-75             [-1, 512, 256]               0
           Conv1d-76             [-1, 512, 256]          33,280
  MyConv1dPadSame-77             [-1, 512, 256]               0
       Bottleneck-78             [-1, 512, 256]               0
      BatchNorm1d-79             [-1, 512, 256]           1,024
             ReLU-80             [-1, 512, 256]               0
          Dropout-81             [-1, 512, 256]               0
           Conv1d-82             [-1, 512, 256]          33,280
  MyConv1dPadSame-83             [-1, 512, 256]               0
      BatchNorm1d-84             [-1, 512, 256]           1,024
             ReLU-85             [-1, 512, 256]               0
          Dropout-86             [-1, 512, 256]               0
           Conv1d-87             [-1, 512, 256]          33,280
  MyConv1dPadSame-88             [-1, 512, 256]               0
       Bottleneck-89             [-1, 512, 256]               0
      BatchNorm1d-90             [-1, 512, 256]           1,024
             ReLU-91             [-1, 512, 256]               0
           Linear-92                    [-1, 2]           1,026
================================================================
Total params: 165,826
Trainable params: 165,826
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 40.75
Params size (MB): 0.63
Estimated Total Size (MB): 41.38
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 64, kernel_size: 8, n_block: 16
************************************************************
************************************************************
(2000, 1, 256) Counter({0: 1000, 1: 1000})
(2000, 1, 256) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 64, 256]             576
   MyConv1dPadSame-2              [-1, 64, 256]               0
       BatchNorm1d-3              [-1, 64, 256]             128
              ReLU-4              [-1, 64, 256]               0
            Conv1d-5              [-1, 64, 256]             576
   MyConv1dPadSame-6              [-1, 64, 256]               0
       BatchNorm1d-7              [-1, 64, 256]             128
              ReLU-8              [-1, 64, 256]               0
           Dropout-9              [-1, 64, 256]               0
           Conv1d-10              [-1, 64, 256]             576
  MyConv1dPadSame-11              [-1, 64, 256]               0
       Bottleneck-12              [-1, 64, 256]               0
      BatchNorm1d-13              [-1, 64, 256]             128
             ReLU-14              [-1, 64, 256]               0
          Dropout-15              [-1, 64, 256]               0
           Conv1d-16              [-1, 64, 128]             576
  MyConv1dPadSame-17              [-1, 64, 128]               0
      BatchNorm1d-18              [-1, 64, 128]             128
             ReLU-19              [-1, 64, 128]               0
          Dropout-20              [-1, 64, 128]               0
           Conv1d-21              [-1, 64, 128]             576
  MyConv1dPadSame-22              [-1, 64, 128]               0
        MaxPool1d-23              [-1, 64, 128]               0
MyMaxPool1dPadSame-24              [-1, 64, 128]               0
       Bottleneck-25              [-1, 64, 128]               0
      BatchNorm1d-26              [-1, 64, 128]             128
             ReLU-27              [-1, 64, 128]               0
          Dropout-28              [-1, 64, 128]               0
           Conv1d-29              [-1, 64, 128]             576
  MyConv1dPadSame-30              [-1, 64, 128]               0
      BatchNorm1d-31              [-1, 64, 128]             128
             ReLU-32              [-1, 64, 128]               0
          Dropout-33              [-1, 64, 128]               0
           Conv1d-34              [-1, 64, 128]             576
  MyConv1dPadSame-35              [-1, 64, 128]               0
       Bottleneck-36              [-1, 64, 128]               0
      BatchNorm1d-37              [-1, 64, 128]             128
             ReLU-38              [-1, 64, 128]               0
          Dropout-39              [-1, 64, 128]               0
           Conv1d-40               [-1, 64, 64]             576
  MyConv1dPadSame-41               [-1, 64, 64]               0
      BatchNorm1d-42               [-1, 64, 64]             128
             ReLU-43               [-1, 64, 64]               0
          Dropout-44               [-1, 64, 64]               0
           Conv1d-45               [-1, 64, 64]             576
  MyConv1dPadSame-46               [-1, 64, 64]               0
        MaxPool1d-47               [-1, 64, 64]               0
MyMaxPool1dPadSame-48               [-1, 64, 64]               0
       Bottleneck-49               [-1, 64, 64]               0
      BatchNorm1d-50               [-1, 64, 64]             128
             ReLU-51               [-1, 64, 64]               0
          Dropout-52               [-1, 64, 64]               0
           Conv1d-53              [-1, 128, 64]           1,152
  MyConv1dPadSame-54              [-1, 128, 64]               0
      BatchNorm1d-55              [-1, 128, 64]             256
             ReLU-56              [-1, 128, 64]               0
          Dropout-57              [-1, 128, 64]               0
           Conv1d-58              [-1, 128, 64]           2,176
  MyConv1dPadSame-59              [-1, 128, 64]               0
       Bottleneck-60              [-1, 128, 64]               0
      BatchNorm1d-61              [-1, 128, 64]             256
             ReLU-62              [-1, 128, 64]               0
          Dropout-63              [-1, 128, 64]               0
           Conv1d-64              [-1, 128, 32]           2,176
  MyConv1dPadSame-65              [-1, 128, 32]               0
      BatchNorm1d-66              [-1, 128, 32]             256
             ReLU-67              [-1, 128, 32]               0
          Dropout-68              [-1, 128, 32]               0
           Conv1d-69              [-1, 128, 32]           2,176
  MyConv1dPadSame-70              [-1, 128, 32]               0
        MaxPool1d-71              [-1, 128, 32]               0
MyMaxPool1dPadSame-72              [-1, 128, 32]               0
       Bottleneck-73              [-1, 128, 32]               0
      BatchNorm1d-74              [-1, 128, 32]             256
             ReLU-75              [-1, 128, 32]               0
          Dropout-76              [-1, 128, 32]               0
           Conv1d-77              [-1, 128, 32]           2,176
  MyConv1dPadSame-78              [-1, 128, 32]               0
      BatchNorm1d-79              [-1, 128, 32]             256
             ReLU-80              [-1, 128, 32]               0
          Dropout-81              [-1, 128, 32]               0
           Conv1d-82              [-1, 128, 32]           2,176
  MyConv1dPadSame-83              [-1, 128, 32]               0
       Bottleneck-84              [-1, 128, 32]               0
      BatchNorm1d-85              [-1, 128, 32]             256
             ReLU-86              [-1, 128, 32]               0
          Dropout-87              [-1, 128, 32]               0
           Conv1d-88              [-1, 128, 16]           2,176
  MyConv1dPadSame-89              [-1, 128, 16]               0
      BatchNorm1d-90              [-1, 128, 16]             256
             ReLU-91              [-1, 128, 16]               0
          Dropout-92              [-1, 128, 16]               0
           Conv1d-93              [-1, 128, 16]           2,176
  MyConv1dPadSame-94              [-1, 128, 16]               0
        MaxPool1d-95              [-1, 128, 16]               0
MyMaxPool1dPadSame-96              [-1, 128, 16]               0
       Bottleneck-97              [-1, 128, 16]               0
      BatchNorm1d-98              [-1, 128, 16]             256
             ReLU-99              [-1, 128, 16]               0
         Dropout-100              [-1, 128, 16]               0
          Conv1d-101              [-1, 256, 16]           4,352
 MyConv1dPadSame-102              [-1, 256, 16]               0
     BatchNorm1d-103              [-1, 256, 16]             512
            ReLU-104              [-1, 256, 16]               0
         Dropout-105              [-1, 256, 16]               0
          Conv1d-106              [-1, 256, 16]           8,448
 MyConv1dPadSame-107              [-1, 256, 16]               0
      Bottleneck-108              [-1, 256, 16]               0
     BatchNorm1d-109              [-1, 256, 16]             512
            ReLU-110              [-1, 256, 16]               0
         Dropout-111              [-1, 256, 16]               0
          Conv1d-112               [-1, 256, 8]           8,448
 MyConv1dPadSame-113               [-1, 256, 8]               0
     BatchNorm1d-114               [-1, 256, 8]             512
            ReLU-115               [-1, 256, 8]               0
         Dropout-116               [-1, 256, 8]               0
          Conv1d-117               [-1, 256, 8]           8,448
 MyConv1dPadSame-118               [-1, 256, 8]               0
       MaxPool1d-119               [-1, 256, 8]               0
MyMaxPool1dPadSame-120               [-1, 256, 8]               0
      Bottleneck-121               [-1, 256, 8]               0
     BatchNorm1d-122               [-1, 256, 8]             512
            ReLU-123               [-1, 256, 8]               0
         Dropout-124               [-1, 256, 8]               0
          Conv1d-125               [-1, 256, 8]           8,448
 MyConv1dPadSame-126               [-1, 256, 8]               0
     BatchNorm1d-127               [-1, 256, 8]             512
            ReLU-128               [-1, 256, 8]               0
         Dropout-129               [-1, 256, 8]               0
          Conv1d-130               [-1, 256, 8]           8,448
 MyConv1dPadSame-131               [-1, 256, 8]               0
      Bottleneck-132               [-1, 256, 8]               0
     BatchNorm1d-133               [-1, 256, 8]             512
            ReLU-134               [-1, 256, 8]               0
         Dropout-135               [-1, 256, 8]               0
          Conv1d-136               [-1, 256, 4]           8,448
 MyConv1dPadSame-137               [-1, 256, 4]               0
     BatchNorm1d-138               [-1, 256, 4]             512
            ReLU-139               [-1, 256, 4]               0
         Dropout-140               [-1, 256, 4]               0
          Conv1d-141               [-1, 256, 4]           8,448
 MyConv1dPadSame-142               [-1, 256, 4]               0
       MaxPool1d-143               [-1, 256, 4]               0
MyMaxPool1dPadSame-144               [-1, 256, 4]               0
      Bottleneck-145               [-1, 256, 4]               0
     BatchNorm1d-146               [-1, 256, 4]             512
            ReLU-147               [-1, 256, 4]               0
         Dropout-148               [-1, 256, 4]               0
          Conv1d-149               [-1, 512, 4]          16,896
 MyConv1dPadSame-150               [-1, 512, 4]               0
     BatchNorm1d-151               [-1, 512, 4]           1,024
            ReLU-152               [-1, 512, 4]               0
         Dropout-153               [-1, 512, 4]               0
          Conv1d-154               [-1, 512, 4]          33,280
 MyConv1dPadSame-155               [-1, 512, 4]               0
      Bottleneck-156               [-1, 512, 4]               0
     BatchNorm1d-157               [-1, 512, 4]           1,024
            ReLU-158               [-1, 512, 4]               0
         Dropout-159               [-1, 512, 4]               0
          Conv1d-160               [-1, 512, 2]          33,280
 MyConv1dPadSame-161               [-1, 512, 2]               0
     BatchNorm1d-162               [-1, 512, 2]           1,024
            ReLU-163               [-1, 512, 2]               0
         Dropout-164               [-1, 512, 2]               0
          Conv1d-165               [-1, 512, 2]          33,280
 MyConv1dPadSame-166               [-1, 512, 2]               0
       MaxPool1d-167               [-1, 512, 2]               0
MyMaxPool1dPadSame-168               [-1, 512, 2]               0
      Bottleneck-169               [-1, 512, 2]               0
     BatchNorm1d-170               [-1, 512, 2]           1,024
            ReLU-171               [-1, 512, 2]               0
         Dropout-172               [-1, 512, 2]               0
          Conv1d-173               [-1, 512, 2]          33,280
 MyConv1dPadSame-174               [-1, 512, 2]               0
     BatchNorm1d-175               [-1, 512, 2]           1,024
            ReLU-176               [-1, 512, 2]               0
         Dropout-177               [-1, 512, 2]               0
          Conv1d-178               [-1, 512, 2]          33,280
 MyConv1dPadSame-179               [-1, 512, 2]               0
      Bottleneck-180               [-1, 512, 2]               0
     BatchNorm1d-181               [-1, 512, 2]           1,024
            ReLU-182               [-1, 512, 2]               0
         Dropout-183               [-1, 512, 2]               0
          Conv1d-184               [-1, 512, 1]          33,280
 MyConv1dPadSame-185               [-1, 512, 1]               0
     BatchNorm1d-186               [-1, 512, 1]           1,024
            ReLU-187               [-1, 512, 1]               0
         Dropout-188               [-1, 512, 1]               0
          Conv1d-189               [-1, 512, 1]          33,280
 MyConv1dPadSame-190               [-1, 512, 1]               0
       MaxPool1d-191               [-1, 512, 1]               0
MyMaxPool1dPadSame-192               [-1, 512, 1]               0
      Bottleneck-193               [-1, 512, 1]               0
     BatchNorm1d-194               [-1, 512, 1]           1,024
            ReLU-195               [-1, 512, 1]               0
          Linear-196                    [-1, 2]           1,026
================================================================
Total params: 351,426
Trainable params: 351,426
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 6.65
Params size (MB): 1.34
Estimated Total Size (MB): 7.99
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 64, kernel_size: 16, n_block: 2
************************************************************
************************************************************
(2000, 1, 256) Counter({0: 1000, 1: 1000})
(2000, 1, 256) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 64, 256]           1,088
   MyConv1dPadSame-2              [-1, 64, 256]               0
       BatchNorm1d-3              [-1, 64, 256]             128
              ReLU-4              [-1, 64, 256]               0
            Conv1d-5              [-1, 64, 256]           1,088
   MyConv1dPadSame-6              [-1, 64, 256]               0
       BatchNorm1d-7              [-1, 64, 256]             128
              ReLU-8              [-1, 64, 256]               0
           Dropout-9              [-1, 64, 256]               0
           Conv1d-10              [-1, 64, 256]           1,088
  MyConv1dPadSame-11              [-1, 64, 256]               0
       Bottleneck-12              [-1, 64, 256]               0
      BatchNorm1d-13              [-1, 64, 256]             128
             ReLU-14              [-1, 64, 256]               0
          Dropout-15              [-1, 64, 256]               0
           Conv1d-16             [-1, 128, 256]           2,176
  MyConv1dPadSame-17             [-1, 128, 256]               0
      BatchNorm1d-18             [-1, 128, 256]             256
             ReLU-19             [-1, 128, 256]               0
          Dropout-20             [-1, 128, 256]               0
           Conv1d-21             [-1, 128, 256]           4,224
  MyConv1dPadSame-22             [-1, 128, 256]               0
       Bottleneck-23             [-1, 128, 256]               0
      BatchNorm1d-24             [-1, 128, 256]             256
             ReLU-25             [-1, 128, 256]               0
           Linear-26                    [-1, 2]             258
================================================================
Total params: 10,818
Trainable params: 10,818
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 4.38
Params size (MB): 0.04
Estimated Total Size (MB): 4.42
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 64, kernel_size: 16, n_block: 4
************************************************************
************************************************************
(2000, 1, 256) Counter({1: 1000, 0: 1000})
(2000, 1, 256) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 64, 256]           1,088
   MyConv1dPadSame-2              [-1, 64, 256]               0
       BatchNorm1d-3              [-1, 64, 256]             128
              ReLU-4              [-1, 64, 256]               0
            Conv1d-5              [-1, 64, 256]           1,088
   MyConv1dPadSame-6              [-1, 64, 256]               0
       BatchNorm1d-7              [-1, 64, 256]             128
              ReLU-8              [-1, 64, 256]               0
           Dropout-9              [-1, 64, 256]               0
           Conv1d-10              [-1, 64, 256]           1,088
  MyConv1dPadSame-11              [-1, 64, 256]               0
       Bottleneck-12              [-1, 64, 256]               0
      BatchNorm1d-13              [-1, 64, 256]             128
             ReLU-14              [-1, 64, 256]               0
          Dropout-15              [-1, 64, 256]               0
           Conv1d-16             [-1, 128, 256]           2,176
  MyConv1dPadSame-17             [-1, 128, 256]               0
      BatchNorm1d-18             [-1, 128, 256]             256
             ReLU-19             [-1, 128, 256]               0
          Dropout-20             [-1, 128, 256]               0
           Conv1d-21             [-1, 128, 256]           4,224
  MyConv1dPadSame-22             [-1, 128, 256]               0
       Bottleneck-23             [-1, 128, 256]               0
      BatchNorm1d-24             [-1, 128, 256]             256
             ReLU-25             [-1, 128, 256]               0
          Dropout-26             [-1, 128, 256]               0
           Conv1d-27             [-1, 256, 256]           8,448
  MyConv1dPadSame-28             [-1, 256, 256]               0
      BatchNorm1d-29             [-1, 256, 256]             512
             ReLU-30             [-1, 256, 256]               0
          Dropout-31             [-1, 256, 256]               0
           Conv1d-32             [-1, 256, 256]          16,640
  MyConv1dPadSame-33             [-1, 256, 256]               0
       Bottleneck-34             [-1, 256, 256]               0
      BatchNorm1d-35             [-1, 256, 256]             512
             ReLU-36             [-1, 256, 256]               0
          Dropout-37             [-1, 256, 256]               0
           Conv1d-38             [-1, 512, 256]          33,280
  MyConv1dPadSame-39             [-1, 512, 256]               0
      BatchNorm1d-40             [-1, 512, 256]           1,024
             ReLU-41             [-1, 512, 256]               0
          Dropout-42             [-1, 512, 256]               0
           Conv1d-43             [-1, 512, 256]          66,048
  MyConv1dPadSame-44             [-1, 512, 256]               0
       Bottleneck-45             [-1, 512, 256]               0
      BatchNorm1d-46             [-1, 512, 256]           1,024
             ReLU-47             [-1, 512, 256]               0
           Linear-48                    [-1, 2]           1,026
================================================================
Total params: 139,074
Trainable params: 139,074
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 20.13
Params size (MB): 0.53
Estimated Total Size (MB): 20.66
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 64, kernel_size: 16, n_block: 8
************************************************************
************************************************************
(2000, 1, 256) Counter({0: 1000, 1: 1000})
(2000, 1, 256) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 64, 256]           1,088
   MyConv1dPadSame-2              [-1, 64, 256]               0
       BatchNorm1d-3              [-1, 64, 256]             128
              ReLU-4              [-1, 64, 256]               0
            Conv1d-5              [-1, 64, 256]           1,088
   MyConv1dPadSame-6              [-1, 64, 256]               0
       BatchNorm1d-7              [-1, 64, 256]             128
              ReLU-8              [-1, 64, 256]               0
           Dropout-9              [-1, 64, 256]               0
           Conv1d-10              [-1, 64, 256]           1,088
  MyConv1dPadSame-11              [-1, 64, 256]               0
       Bottleneck-12              [-1, 64, 256]               0
      BatchNorm1d-13              [-1, 64, 256]             128
             ReLU-14              [-1, 64, 256]               0
          Dropout-15              [-1, 64, 256]               0
           Conv1d-16              [-1, 64, 256]           1,088
  MyConv1dPadSame-17              [-1, 64, 256]               0
      BatchNorm1d-18              [-1, 64, 256]             128
             ReLU-19              [-1, 64, 256]               0
          Dropout-20              [-1, 64, 256]               0
           Conv1d-21              [-1, 64, 256]           1,088
  MyConv1dPadSame-22              [-1, 64, 256]               0
       Bottleneck-23              [-1, 64, 256]               0
      BatchNorm1d-24              [-1, 64, 256]             128
             ReLU-25              [-1, 64, 256]               0
          Dropout-26              [-1, 64, 256]               0
           Conv1d-27             [-1, 128, 256]           2,176
  MyConv1dPadSame-28             [-1, 128, 256]               0
      BatchNorm1d-29             [-1, 128, 256]             256
             ReLU-30             [-1, 128, 256]               0
          Dropout-31             [-1, 128, 256]               0
           Conv1d-32             [-1, 128, 256]           4,224
  MyConv1dPadSame-33             [-1, 128, 256]               0
       Bottleneck-34             [-1, 128, 256]               0
      BatchNorm1d-35             [-1, 128, 256]             256
             ReLU-36             [-1, 128, 256]               0
          Dropout-37             [-1, 128, 256]               0
           Conv1d-38             [-1, 128, 256]           4,224
  MyConv1dPadSame-39             [-1, 128, 256]               0
      BatchNorm1d-40             [-1, 128, 256]             256
             ReLU-41             [-1, 128, 256]               0
          Dropout-42             [-1, 128, 256]               0
           Conv1d-43             [-1, 128, 256]           4,224
  MyConv1dPadSame-44             [-1, 128, 256]               0
       Bottleneck-45             [-1, 128, 256]               0
      BatchNorm1d-46             [-1, 128, 256]             256
             ReLU-47             [-1, 128, 256]               0
          Dropout-48             [-1, 128, 256]               0
           Conv1d-49             [-1, 256, 256]           8,448
  MyConv1dPadSame-50             [-1, 256, 256]               0
      BatchNorm1d-51             [-1, 256, 256]             512
             ReLU-52             [-1, 256, 256]               0
          Dropout-53             [-1, 256, 256]               0
           Conv1d-54             [-1, 256, 256]          16,640
  MyConv1dPadSame-55             [-1, 256, 256]               0
       Bottleneck-56             [-1, 256, 256]               0
      BatchNorm1d-57             [-1, 256, 256]             512
             ReLU-58             [-1, 256, 256]               0
          Dropout-59             [-1, 256, 256]               0
           Conv1d-60             [-1, 256, 256]          16,640
  MyConv1dPadSame-61             [-1, 256, 256]               0
      BatchNorm1d-62             [-1, 256, 256]             512
             ReLU-63             [-1, 256, 256]               0
          Dropout-64             [-1, 256, 256]               0
           Conv1d-65             [-1, 256, 256]          16,640
  MyConv1dPadSame-66             [-1, 256, 256]               0
       Bottleneck-67             [-1, 256, 256]               0
      BatchNorm1d-68             [-1, 256, 256]             512
             ReLU-69             [-1, 256, 256]               0
          Dropout-70             [-1, 256, 256]               0
           Conv1d-71             [-1, 512, 256]          33,280
  MyConv1dPadSame-72             [-1, 512, 256]               0
      BatchNorm1d-73             [-1, 512, 256]           1,024
             ReLU-74             [-1, 512, 256]               0
          Dropout-75             [-1, 512, 256]               0
           Conv1d-76             [-1, 512, 256]          66,048
  MyConv1dPadSame-77             [-1, 512, 256]               0
       Bottleneck-78             [-1, 512, 256]               0
      BatchNorm1d-79             [-1, 512, 256]           1,024
             ReLU-80             [-1, 512, 256]               0
          Dropout-81             [-1, 512, 256]               0
           Conv1d-82             [-1, 512, 256]          66,048
  MyConv1dPadSame-83             [-1, 512, 256]               0
      BatchNorm1d-84             [-1, 512, 256]           1,024
             ReLU-85             [-1, 512, 256]               0
          Dropout-86             [-1, 512, 256]               0
           Conv1d-87             [-1, 512, 256]          66,048
  MyConv1dPadSame-88             [-1, 512, 256]               0
       Bottleneck-89             [-1, 512, 256]               0
      BatchNorm1d-90             [-1, 512, 256]           1,024
             ReLU-91             [-1, 512, 256]               0
           Linear-92                    [-1, 2]           1,026
================================================================
Total params: 318,914
Trainable params: 318,914
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 40.75
Params size (MB): 1.22
Estimated Total Size (MB): 41.97
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 64, kernel_size: 16, n_block: 16
************************************************************
************************************************************
(2000, 1, 256) Counter({0: 1000, 1: 1000})
(2000, 1, 256) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 64, 256]           1,088
   MyConv1dPadSame-2              [-1, 64, 256]               0
       BatchNorm1d-3              [-1, 64, 256]             128
              ReLU-4              [-1, 64, 256]               0
            Conv1d-5              [-1, 64, 256]           1,088
   MyConv1dPadSame-6              [-1, 64, 256]               0
       BatchNorm1d-7              [-1, 64, 256]             128
              ReLU-8              [-1, 64, 256]               0
           Dropout-9              [-1, 64, 256]               0
           Conv1d-10              [-1, 64, 256]           1,088
  MyConv1dPadSame-11              [-1, 64, 256]               0
       Bottleneck-12              [-1, 64, 256]               0
      BatchNorm1d-13              [-1, 64, 256]             128
             ReLU-14              [-1, 64, 256]               0
          Dropout-15              [-1, 64, 256]               0
           Conv1d-16              [-1, 64, 128]           1,088
  MyConv1dPadSame-17              [-1, 64, 128]               0
      BatchNorm1d-18              [-1, 64, 128]             128
             ReLU-19              [-1, 64, 128]               0
          Dropout-20              [-1, 64, 128]               0
           Conv1d-21              [-1, 64, 128]           1,088
  MyConv1dPadSame-22              [-1, 64, 128]               0
        MaxPool1d-23              [-1, 64, 128]               0
MyMaxPool1dPadSame-24              [-1, 64, 128]               0
       Bottleneck-25              [-1, 64, 128]               0
      BatchNorm1d-26              [-1, 64, 128]             128
             ReLU-27              [-1, 64, 128]               0
          Dropout-28              [-1, 64, 128]               0
           Conv1d-29              [-1, 64, 128]           1,088
  MyConv1dPadSame-30              [-1, 64, 128]               0
      BatchNorm1d-31              [-1, 64, 128]             128
             ReLU-32              [-1, 64, 128]               0
          Dropout-33              [-1, 64, 128]               0
           Conv1d-34              [-1, 64, 128]           1,088
  MyConv1dPadSame-35              [-1, 64, 128]               0
       Bottleneck-36              [-1, 64, 128]               0
      BatchNorm1d-37              [-1, 64, 128]             128
             ReLU-38              [-1, 64, 128]               0
          Dropout-39              [-1, 64, 128]               0
           Conv1d-40               [-1, 64, 64]           1,088
  MyConv1dPadSame-41               [-1, 64, 64]               0
      BatchNorm1d-42               [-1, 64, 64]             128
             ReLU-43               [-1, 64, 64]               0
          Dropout-44               [-1, 64, 64]               0
           Conv1d-45               [-1, 64, 64]           1,088
  MyConv1dPadSame-46               [-1, 64, 64]               0
        MaxPool1d-47               [-1, 64, 64]               0
MyMaxPool1dPadSame-48               [-1, 64, 64]               0
       Bottleneck-49               [-1, 64, 64]               0
      BatchNorm1d-50               [-1, 64, 64]             128
             ReLU-51               [-1, 64, 64]               0
          Dropout-52               [-1, 64, 64]               0
           Conv1d-53              [-1, 128, 64]           2,176
  MyConv1dPadSame-54              [-1, 128, 64]               0
      BatchNorm1d-55              [-1, 128, 64]             256
             ReLU-56              [-1, 128, 64]               0
          Dropout-57              [-1, 128, 64]               0
           Conv1d-58              [-1, 128, 64]           4,224
  MyConv1dPadSame-59              [-1, 128, 64]               0
       Bottleneck-60              [-1, 128, 64]               0
      BatchNorm1d-61              [-1, 128, 64]             256
             ReLU-62              [-1, 128, 64]               0
          Dropout-63              [-1, 128, 64]               0
           Conv1d-64              [-1, 128, 32]           4,224
  MyConv1dPadSame-65              [-1, 128, 32]               0
      BatchNorm1d-66              [-1, 128, 32]             256
             ReLU-67              [-1, 128, 32]               0
          Dropout-68              [-1, 128, 32]               0
           Conv1d-69              [-1, 128, 32]           4,224
  MyConv1dPadSame-70              [-1, 128, 32]               0
        MaxPool1d-71              [-1, 128, 32]               0
MyMaxPool1dPadSame-72              [-1, 128, 32]               0
       Bottleneck-73              [-1, 128, 32]               0
      BatchNorm1d-74              [-1, 128, 32]             256
             ReLU-75              [-1, 128, 32]               0
          Dropout-76              [-1, 128, 32]               0
           Conv1d-77              [-1, 128, 32]           4,224
  MyConv1dPadSame-78              [-1, 128, 32]               0
      BatchNorm1d-79              [-1, 128, 32]             256
             ReLU-80              [-1, 128, 32]               0
          Dropout-81              [-1, 128, 32]               0
           Conv1d-82              [-1, 128, 32]           4,224
  MyConv1dPadSame-83              [-1, 128, 32]               0
       Bottleneck-84              [-1, 128, 32]               0
      BatchNorm1d-85              [-1, 128, 32]             256
             ReLU-86              [-1, 128, 32]               0
          Dropout-87              [-1, 128, 32]               0
           Conv1d-88              [-1, 128, 16]           4,224
  MyConv1dPadSame-89              [-1, 128, 16]               0
      BatchNorm1d-90              [-1, 128, 16]             256
             ReLU-91              [-1, 128, 16]               0
          Dropout-92              [-1, 128, 16]               0
           Conv1d-93              [-1, 128, 16]           4,224
  MyConv1dPadSame-94              [-1, 128, 16]               0
        MaxPool1d-95              [-1, 128, 16]               0
MyMaxPool1dPadSame-96              [-1, 128, 16]               0
       Bottleneck-97              [-1, 128, 16]               0
      BatchNorm1d-98              [-1, 128, 16]             256
             ReLU-99              [-1, 128, 16]               0
         Dropout-100              [-1, 128, 16]               0
          Conv1d-101              [-1, 256, 16]           8,448
 MyConv1dPadSame-102              [-1, 256, 16]               0
     BatchNorm1d-103              [-1, 256, 16]             512
            ReLU-104              [-1, 256, 16]               0
         Dropout-105              [-1, 256, 16]               0
          Conv1d-106              [-1, 256, 16]          16,640
 MyConv1dPadSame-107              [-1, 256, 16]               0
      Bottleneck-108              [-1, 256, 16]               0
     BatchNorm1d-109              [-1, 256, 16]             512
            ReLU-110              [-1, 256, 16]               0
         Dropout-111              [-1, 256, 16]               0
          Conv1d-112               [-1, 256, 8]          16,640
 MyConv1dPadSame-113               [-1, 256, 8]               0
     BatchNorm1d-114               [-1, 256, 8]             512
            ReLU-115               [-1, 256, 8]               0
         Dropout-116               [-1, 256, 8]               0
          Conv1d-117               [-1, 256, 8]          16,640
 MyConv1dPadSame-118               [-1, 256, 8]               0
       MaxPool1d-119               [-1, 256, 8]               0
MyMaxPool1dPadSame-120               [-1, 256, 8]               0
      Bottleneck-121               [-1, 256, 8]               0
     BatchNorm1d-122               [-1, 256, 8]             512
            ReLU-123               [-1, 256, 8]               0
         Dropout-124               [-1, 256, 8]               0
          Conv1d-125               [-1, 256, 8]          16,640
 MyConv1dPadSame-126               [-1, 256, 8]               0
     BatchNorm1d-127               [-1, 256, 8]             512
            ReLU-128               [-1, 256, 8]               0
         Dropout-129               [-1, 256, 8]               0
          Conv1d-130               [-1, 256, 8]          16,640
 MyConv1dPadSame-131               [-1, 256, 8]               0
      Bottleneck-132               [-1, 256, 8]               0
     BatchNorm1d-133               [-1, 256, 8]             512
            ReLU-134               [-1, 256, 8]               0
         Dropout-135               [-1, 256, 8]               0
          Conv1d-136               [-1, 256, 4]          16,640
 MyConv1dPadSame-137               [-1, 256, 4]               0
     BatchNorm1d-138               [-1, 256, 4]             512
            ReLU-139               [-1, 256, 4]               0
         Dropout-140               [-1, 256, 4]               0
          Conv1d-141               [-1, 256, 4]          16,640
 MyConv1dPadSame-142               [-1, 256, 4]               0
       MaxPool1d-143               [-1, 256, 4]               0
MyMaxPool1dPadSame-144               [-1, 256, 4]               0
      Bottleneck-145               [-1, 256, 4]               0
     BatchNorm1d-146               [-1, 256, 4]             512
            ReLU-147               [-1, 256, 4]               0
         Dropout-148               [-1, 256, 4]               0
          Conv1d-149               [-1, 512, 4]          33,280
 MyConv1dPadSame-150               [-1, 512, 4]               0
     BatchNorm1d-151               [-1, 512, 4]           1,024
            ReLU-152               [-1, 512, 4]               0
         Dropout-153               [-1, 512, 4]               0
          Conv1d-154               [-1, 512, 4]          66,048
 MyConv1dPadSame-155               [-1, 512, 4]               0
      Bottleneck-156               [-1, 512, 4]               0
     BatchNorm1d-157               [-1, 512, 4]           1,024
            ReLU-158               [-1, 512, 4]               0
         Dropout-159               [-1, 512, 4]               0
          Conv1d-160               [-1, 512, 2]          66,048
 MyConv1dPadSame-161               [-1, 512, 2]               0
     BatchNorm1d-162               [-1, 512, 2]           1,024
            ReLU-163               [-1, 512, 2]               0
         Dropout-164               [-1, 512, 2]               0
          Conv1d-165               [-1, 512, 2]          66,048
 MyConv1dPadSame-166               [-1, 512, 2]               0
       MaxPool1d-167               [-1, 512, 2]               0
MyMaxPool1dPadSame-168               [-1, 512, 2]               0
      Bottleneck-169               [-1, 512, 2]               0
     BatchNorm1d-170               [-1, 512, 2]           1,024
            ReLU-171               [-1, 512, 2]               0
         Dropout-172               [-1, 512, 2]               0
          Conv1d-173               [-1, 512, 2]          66,048
 MyConv1dPadSame-174               [-1, 512, 2]               0
     BatchNorm1d-175               [-1, 512, 2]           1,024
            ReLU-176               [-1, 512, 2]               0
         Dropout-177               [-1, 512, 2]               0
          Conv1d-178               [-1, 512, 2]          66,048
 MyConv1dPadSame-179               [-1, 512, 2]               0
      Bottleneck-180               [-1, 512, 2]               0
     BatchNorm1d-181               [-1, 512, 2]           1,024
            ReLU-182               [-1, 512, 2]               0
         Dropout-183               [-1, 512, 2]               0
          Conv1d-184               [-1, 512, 1]          66,048
 MyConv1dPadSame-185               [-1, 512, 1]               0
     BatchNorm1d-186               [-1, 512, 1]           1,024
            ReLU-187               [-1, 512, 1]               0
         Dropout-188               [-1, 512, 1]               0
          Conv1d-189               [-1, 512, 1]          66,048
 MyConv1dPadSame-190               [-1, 512, 1]               0
       MaxPool1d-191               [-1, 512, 1]               0
MyMaxPool1dPadSame-192               [-1, 512, 1]               0
      Bottleneck-193               [-1, 512, 1]               0
     BatchNorm1d-194               [-1, 512, 1]           1,024
            ReLU-195               [-1, 512, 1]               0
          Linear-196                    [-1, 2]           1,026
================================================================
Total params: 678,594
Trainable params: 678,594
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 6.65
Params size (MB): 2.59
Estimated Total Size (MB): 9.24
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 128, kernel_size: 2, n_block: 2
************************************************************
************************************************************
(2000, 1, 256) Counter({0: 1000, 1: 1000})
(2000, 1, 256) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 128, 256]             384
   MyConv1dPadSame-2             [-1, 128, 256]               0
       BatchNorm1d-3             [-1, 128, 256]             256
              ReLU-4             [-1, 128, 256]               0
            Conv1d-5             [-1, 128, 256]             384
   MyConv1dPadSame-6             [-1, 128, 256]               0
       BatchNorm1d-7             [-1, 128, 256]             256
              ReLU-8             [-1, 128, 256]               0
           Dropout-9             [-1, 128, 256]               0
           Conv1d-10             [-1, 128, 256]             384
  MyConv1dPadSame-11             [-1, 128, 256]               0
       Bottleneck-12             [-1, 128, 256]               0
      BatchNorm1d-13             [-1, 128, 256]             256
             ReLU-14             [-1, 128, 256]               0
          Dropout-15             [-1, 128, 256]               0
           Conv1d-16             [-1, 256, 256]             768
  MyConv1dPadSame-17             [-1, 256, 256]               0
      BatchNorm1d-18             [-1, 256, 256]             512
             ReLU-19             [-1, 256, 256]               0
          Dropout-20             [-1, 256, 256]               0
           Conv1d-21             [-1, 256, 256]           1,280
  MyConv1dPadSame-22             [-1, 256, 256]               0
       Bottleneck-23             [-1, 256, 256]               0
      BatchNorm1d-24             [-1, 256, 256]             512
             ReLU-25             [-1, 256, 256]               0
           Linear-26                    [-1, 2]             514
================================================================
Total params: 5,506
Trainable params: 5,506
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 8.75
Params size (MB): 0.02
Estimated Total Size (MB): 8.77
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 128, kernel_size: 2, n_block: 4
************************************************************
************************************************************
(2000, 1, 256) Counter({1: 1000, 0: 1000})
(2000, 1, 256) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 128, 256]             384
   MyConv1dPadSame-2             [-1, 128, 256]               0
       BatchNorm1d-3             [-1, 128, 256]             256
              ReLU-4             [-1, 128, 256]               0
            Conv1d-5             [-1, 128, 256]             384
   MyConv1dPadSame-6             [-1, 128, 256]               0
       BatchNorm1d-7             [-1, 128, 256]             256
              ReLU-8             [-1, 128, 256]               0
           Dropout-9             [-1, 128, 256]               0
           Conv1d-10             [-1, 128, 256]             384
  MyConv1dPadSame-11             [-1, 128, 256]               0
       Bottleneck-12             [-1, 128, 256]               0
      BatchNorm1d-13             [-1, 128, 256]             256
             ReLU-14             [-1, 128, 256]               0
          Dropout-15             [-1, 128, 256]               0
           Conv1d-16             [-1, 256, 256]             768
  MyConv1dPadSame-17             [-1, 256, 256]               0
      BatchNorm1d-18             [-1, 256, 256]             512
             ReLU-19             [-1, 256, 256]               0
          Dropout-20             [-1, 256, 256]               0
           Conv1d-21             [-1, 256, 256]           1,280
  MyConv1dPadSame-22             [-1, 256, 256]               0
       Bottleneck-23             [-1, 256, 256]               0
      BatchNorm1d-24             [-1, 256, 256]             512
             ReLU-25             [-1, 256, 256]               0
          Dropout-26             [-1, 256, 256]               0
           Conv1d-27             [-1, 512, 256]           2,560
  MyConv1dPadSame-28             [-1, 512, 256]               0
      BatchNorm1d-29             [-1, 512, 256]           1,024
             ReLU-30             [-1, 512, 256]               0
          Dropout-31             [-1, 512, 256]               0
           Conv1d-32             [-1, 512, 256]           4,608
  MyConv1dPadSame-33             [-1, 512, 256]               0
       Bottleneck-34             [-1, 512, 256]               0
      BatchNorm1d-35             [-1, 512, 256]           1,024
             ReLU-36             [-1, 512, 256]               0
          Dropout-37             [-1, 512, 256]               0
           Conv1d-38            [-1, 1024, 256]           9,216
  MyConv1dPadSame-39            [-1, 1024, 256]               0
      BatchNorm1d-40            [-1, 1024, 256]           2,048
             ReLU-41            [-1, 1024, 256]               0
          Dropout-42            [-1, 1024, 256]               0
           Conv1d-43            [-1, 1024, 256]          17,408
  MyConv1dPadSame-44            [-1, 1024, 256]               0
       Bottleneck-45            [-1, 1024, 256]               0
      BatchNorm1d-46            [-1, 1024, 256]           2,048
             ReLU-47            [-1, 1024, 256]               0
           Linear-48                    [-1, 2]           2,050
================================================================
Total params: 46,978
Trainable params: 46,978
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 40.25
Params size (MB): 0.18
Estimated Total Size (MB): 40.43
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 128, kernel_size: 2, n_block: 8
************************************************************
************************************************************
(2000, 1, 256) Counter({0: 1000, 1: 1000})
(2000, 1, 256) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 128, 256]             384
   MyConv1dPadSame-2             [-1, 128, 256]               0
       BatchNorm1d-3             [-1, 128, 256]             256
              ReLU-4             [-1, 128, 256]               0
            Conv1d-5             [-1, 128, 256]             384
   MyConv1dPadSame-6             [-1, 128, 256]               0
       BatchNorm1d-7             [-1, 128, 256]             256
              ReLU-8             [-1, 128, 256]               0
           Dropout-9             [-1, 128, 256]               0
           Conv1d-10             [-1, 128, 256]             384
  MyConv1dPadSame-11             [-1, 128, 256]               0
       Bottleneck-12             [-1, 128, 256]               0
      BatchNorm1d-13             [-1, 128, 256]             256
             ReLU-14             [-1, 128, 256]               0
          Dropout-15             [-1, 128, 256]               0
           Conv1d-16             [-1, 128, 256]             384
  MyConv1dPadSame-17             [-1, 128, 256]               0
      BatchNorm1d-18             [-1, 128, 256]             256
             ReLU-19             [-1, 128, 256]               0
          Dropout-20             [-1, 128, 256]               0
           Conv1d-21             [-1, 128, 256]             384
  MyConv1dPadSame-22             [-1, 128, 256]               0
       Bottleneck-23             [-1, 128, 256]               0
      BatchNorm1d-24             [-1, 128, 256]             256
             ReLU-25             [-1, 128, 256]               0
          Dropout-26             [-1, 128, 256]               0
           Conv1d-27             [-1, 256, 256]             768
  MyConv1dPadSame-28             [-1, 256, 256]               0
      BatchNorm1d-29             [-1, 256, 256]             512
             ReLU-30             [-1, 256, 256]               0
          Dropout-31             [-1, 256, 256]               0
           Conv1d-32             [-1, 256, 256]           1,280
  MyConv1dPadSame-33             [-1, 256, 256]               0
       Bottleneck-34             [-1, 256, 256]               0
      BatchNorm1d-35             [-1, 256, 256]             512
             ReLU-36             [-1, 256, 256]               0
          Dropout-37             [-1, 256, 256]               0
           Conv1d-38             [-1, 256, 256]           1,280
  MyConv1dPadSame-39             [-1, 256, 256]               0
      BatchNorm1d-40             [-1, 256, 256]             512
             ReLU-41             [-1, 256, 256]               0
          Dropout-42             [-1, 256, 256]               0
           Conv1d-43             [-1, 256, 256]           1,280
  MyConv1dPadSame-44             [-1, 256, 256]               0
       Bottleneck-45             [-1, 256, 256]               0
      BatchNorm1d-46             [-1, 256, 256]             512
             ReLU-47             [-1, 256, 256]               0
          Dropout-48             [-1, 256, 256]               0
           Conv1d-49             [-1, 512, 256]           2,560
  MyConv1dPadSame-50             [-1, 512, 256]               0
      BatchNorm1d-51             [-1, 512, 256]           1,024
             ReLU-52             [-1, 512, 256]               0
          Dropout-53             [-1, 512, 256]               0
           Conv1d-54             [-1, 512, 256]           4,608
  MyConv1dPadSame-55             [-1, 512, 256]               0
       Bottleneck-56             [-1, 512, 256]               0
      BatchNorm1d-57             [-1, 512, 256]           1,024
             ReLU-58             [-1, 512, 256]               0
          Dropout-59             [-1, 512, 256]               0
           Conv1d-60             [-1, 512, 256]           4,608
  MyConv1dPadSame-61             [-1, 512, 256]               0
      BatchNorm1d-62             [-1, 512, 256]           1,024
             ReLU-63             [-1, 512, 256]               0
          Dropout-64             [-1, 512, 256]               0
           Conv1d-65             [-1, 512, 256]           4,608
  MyConv1dPadSame-66             [-1, 512, 256]               0
       Bottleneck-67             [-1, 512, 256]               0
      BatchNorm1d-68             [-1, 512, 256]           1,024
             ReLU-69             [-1, 512, 256]               0
          Dropout-70             [-1, 512, 256]               0
           Conv1d-71            [-1, 1024, 256]           9,216
  MyConv1dPadSame-72            [-1, 1024, 256]               0
      BatchNorm1d-73            [-1, 1024, 256]           2,048
             ReLU-74            [-1, 1024, 256]               0
          Dropout-75            [-1, 1024, 256]               0
           Conv1d-76            [-1, 1024, 256]          17,408
  MyConv1dPadSame-77            [-1, 1024, 256]               0
       Bottleneck-78            [-1, 1024, 256]               0
      BatchNorm1d-79            [-1, 1024, 256]           2,048
             ReLU-80            [-1, 1024, 256]               0
          Dropout-81            [-1, 1024, 256]               0
           Conv1d-82            [-1, 1024, 256]          17,408
  MyConv1dPadSame-83            [-1, 1024, 256]               0
      BatchNorm1d-84            [-1, 1024, 256]           2,048
             ReLU-85            [-1, 1024, 256]               0
          Dropout-86            [-1, 1024, 256]               0
           Conv1d-87            [-1, 1024, 256]          17,408
  MyConv1dPadSame-88            [-1, 1024, 256]               0
       Bottleneck-89            [-1, 1024, 256]               0
      BatchNorm1d-90            [-1, 1024, 256]           2,048
             ReLU-91            [-1, 1024, 256]               0
           Linear-92                    [-1, 2]           2,050
================================================================
Total params: 102,018
Trainable params: 102,018
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 81.50
Params size (MB): 0.39
Estimated Total Size (MB): 81.89
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 128, kernel_size: 2, n_block: 16
************************************************************
************************************************************
(2000, 1, 256) Counter({1: 1000, 0: 1000})
(2000, 1, 256) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 128, 256]             384
   MyConv1dPadSame-2             [-1, 128, 256]               0
       BatchNorm1d-3             [-1, 128, 256]             256
              ReLU-4             [-1, 128, 256]               0
            Conv1d-5             [-1, 128, 256]             384
   MyConv1dPadSame-6             [-1, 128, 256]               0
       BatchNorm1d-7             [-1, 128, 256]             256
              ReLU-8             [-1, 128, 256]               0
           Dropout-9             [-1, 128, 256]               0
           Conv1d-10             [-1, 128, 256]             384
  MyConv1dPadSame-11             [-1, 128, 256]               0
       Bottleneck-12             [-1, 128, 256]               0
      BatchNorm1d-13             [-1, 128, 256]             256
             ReLU-14             [-1, 128, 256]               0
          Dropout-15             [-1, 128, 256]               0
           Conv1d-16             [-1, 128, 128]             384
  MyConv1dPadSame-17             [-1, 128, 128]               0
      BatchNorm1d-18             [-1, 128, 128]             256
             ReLU-19             [-1, 128, 128]               0
          Dropout-20             [-1, 128, 128]               0
           Conv1d-21             [-1, 128, 128]             384
  MyConv1dPadSame-22             [-1, 128, 128]               0
        MaxPool1d-23             [-1, 128, 128]               0
MyMaxPool1dPadSame-24             [-1, 128, 128]               0
       Bottleneck-25             [-1, 128, 128]               0
      BatchNorm1d-26             [-1, 128, 128]             256
             ReLU-27             [-1, 128, 128]               0
          Dropout-28             [-1, 128, 128]               0
           Conv1d-29             [-1, 128, 128]             384
  MyConv1dPadSame-30             [-1, 128, 128]               0
      BatchNorm1d-31             [-1, 128, 128]             256
             ReLU-32             [-1, 128, 128]               0
          Dropout-33             [-1, 128, 128]               0
           Conv1d-34             [-1, 128, 128]             384
  MyConv1dPadSame-35             [-1, 128, 128]               0
       Bottleneck-36             [-1, 128, 128]               0
      BatchNorm1d-37             [-1, 128, 128]             256
             ReLU-38             [-1, 128, 128]               0
          Dropout-39             [-1, 128, 128]               0
           Conv1d-40              [-1, 128, 64]             384
  MyConv1dPadSame-41              [-1, 128, 64]               0
      BatchNorm1d-42              [-1, 128, 64]             256
             ReLU-43              [-1, 128, 64]               0
          Dropout-44              [-1, 128, 64]               0
           Conv1d-45              [-1, 128, 64]             384
  MyConv1dPadSame-46              [-1, 128, 64]               0
        MaxPool1d-47              [-1, 128, 64]               0
MyMaxPool1dPadSame-48              [-1, 128, 64]               0
       Bottleneck-49              [-1, 128, 64]               0
      BatchNorm1d-50              [-1, 128, 64]             256
             ReLU-51              [-1, 128, 64]               0
          Dropout-52              [-1, 128, 64]               0
           Conv1d-53              [-1, 256, 64]             768
  MyConv1dPadSame-54              [-1, 256, 64]               0
      BatchNorm1d-55              [-1, 256, 64]             512
             ReLU-56              [-1, 256, 64]               0
          Dropout-57              [-1, 256, 64]               0
           Conv1d-58              [-1, 256, 64]           1,280
  MyConv1dPadSame-59              [-1, 256, 64]               0
       Bottleneck-60              [-1, 256, 64]               0
      BatchNorm1d-61              [-1, 256, 64]             512
             ReLU-62              [-1, 256, 64]               0
          Dropout-63              [-1, 256, 64]               0
           Conv1d-64              [-1, 256, 32]           1,280
  MyConv1dPadSame-65              [-1, 256, 32]               0
      BatchNorm1d-66              [-1, 256, 32]             512
             ReLU-67              [-1, 256, 32]               0
          Dropout-68              [-1, 256, 32]               0
           Conv1d-69              [-1, 256, 32]           1,280
  MyConv1dPadSame-70              [-1, 256, 32]               0
        MaxPool1d-71              [-1, 256, 32]               0
MyMaxPool1dPadSame-72              [-1, 256, 32]               0
       Bottleneck-73              [-1, 256, 32]               0
      BatchNorm1d-74              [-1, 256, 32]             512
             ReLU-75              [-1, 256, 32]               0
          Dropout-76              [-1, 256, 32]               0
           Conv1d-77              [-1, 256, 32]           1,280
  MyConv1dPadSame-78              [-1, 256, 32]               0
      BatchNorm1d-79              [-1, 256, 32]             512
             ReLU-80              [-1, 256, 32]               0
          Dropout-81              [-1, 256, 32]               0
           Conv1d-82              [-1, 256, 32]           1,280
  MyConv1dPadSame-83              [-1, 256, 32]               0
       Bottleneck-84              [-1, 256, 32]               0
      BatchNorm1d-85              [-1, 256, 32]             512
             ReLU-86              [-1, 256, 32]               0
          Dropout-87              [-1, 256, 32]               0
           Conv1d-88              [-1, 256, 16]           1,280
  MyConv1dPadSame-89              [-1, 256, 16]               0
      BatchNorm1d-90              [-1, 256, 16]             512
             ReLU-91              [-1, 256, 16]               0
          Dropout-92              [-1, 256, 16]               0
           Conv1d-93              [-1, 256, 16]           1,280
  MyConv1dPadSame-94              [-1, 256, 16]               0
        MaxPool1d-95              [-1, 256, 16]               0
MyMaxPool1dPadSame-96              [-1, 256, 16]               0
       Bottleneck-97              [-1, 256, 16]               0
      BatchNorm1d-98              [-1, 256, 16]             512
             ReLU-99              [-1, 256, 16]               0
         Dropout-100              [-1, 256, 16]               0
          Conv1d-101              [-1, 512, 16]           2,560
 MyConv1dPadSame-102              [-1, 512, 16]               0
     BatchNorm1d-103              [-1, 512, 16]           1,024
            ReLU-104              [-1, 512, 16]               0
         Dropout-105              [-1, 512, 16]               0
          Conv1d-106              [-1, 512, 16]           4,608
 MyConv1dPadSame-107              [-1, 512, 16]               0
      Bottleneck-108              [-1, 512, 16]               0
     BatchNorm1d-109              [-1, 512, 16]           1,024
            ReLU-110              [-1, 512, 16]               0
         Dropout-111              [-1, 512, 16]               0
          Conv1d-112               [-1, 512, 8]           4,608
 MyConv1dPadSame-113               [-1, 512, 8]               0
     BatchNorm1d-114               [-1, 512, 8]           1,024
            ReLU-115               [-1, 512, 8]               0
         Dropout-116               [-1, 512, 8]               0
          Conv1d-117               [-1, 512, 8]           4,608
 MyConv1dPadSame-118               [-1, 512, 8]               0
       MaxPool1d-119               [-1, 512, 8]               0
MyMaxPool1dPadSame-120               [-1, 512, 8]               0
      Bottleneck-121               [-1, 512, 8]               0
     BatchNorm1d-122               [-1, 512, 8]           1,024
            ReLU-123               [-1, 512, 8]               0
         Dropout-124               [-1, 512, 8]               0
          Conv1d-125               [-1, 512, 8]           4,608
 MyConv1dPadSame-126               [-1, 512, 8]               0
     BatchNorm1d-127               [-1, 512, 8]           1,024
            ReLU-128               [-1, 512, 8]               0
         Dropout-129               [-1, 512, 8]               0
          Conv1d-130               [-1, 512, 8]           4,608
 MyConv1dPadSame-131               [-1, 512, 8]               0
      Bottleneck-132               [-1, 512, 8]               0
     BatchNorm1d-133               [-1, 512, 8]           1,024
            ReLU-134               [-1, 512, 8]               0
         Dropout-135               [-1, 512, 8]               0
          Conv1d-136               [-1, 512, 4]           4,608
 MyConv1dPadSame-137               [-1, 512, 4]               0
     BatchNorm1d-138               [-1, 512, 4]           1,024
            ReLU-139               [-1, 512, 4]               0
         Dropout-140               [-1, 512, 4]               0
          Conv1d-141               [-1, 512, 4]           4,608
 MyConv1dPadSame-142               [-1, 512, 4]               0
       MaxPool1d-143               [-1, 512, 4]               0
MyMaxPool1dPadSame-144               [-1, 512, 4]               0
      Bottleneck-145               [-1, 512, 4]               0
     BatchNorm1d-146               [-1, 512, 4]           1,024
            ReLU-147               [-1, 512, 4]               0
         Dropout-148               [-1, 512, 4]               0
          Conv1d-149              [-1, 1024, 4]           9,216
 MyConv1dPadSame-150              [-1, 1024, 4]               0
     BatchNorm1d-151              [-1, 1024, 4]           2,048
            ReLU-152              [-1, 1024, 4]               0
         Dropout-153              [-1, 1024, 4]               0
          Conv1d-154              [-1, 1024, 4]          17,408
 MyConv1dPadSame-155              [-1, 1024, 4]               0
      Bottleneck-156              [-1, 1024, 4]               0
     BatchNorm1d-157              [-1, 1024, 4]           2,048
            ReLU-158              [-1, 1024, 4]               0
         Dropout-159              [-1, 1024, 4]               0
          Conv1d-160              [-1, 1024, 2]          17,408
 MyConv1dPadSame-161              [-1, 1024, 2]               0
     BatchNorm1d-162              [-1, 1024, 2]           2,048
            ReLU-163              [-1, 1024, 2]               0
         Dropout-164              [-1, 1024, 2]               0
          Conv1d-165              [-1, 1024, 2]          17,408
 MyConv1dPadSame-166              [-1, 1024, 2]               0
       MaxPool1d-167              [-1, 1024, 2]               0
MyMaxPool1dPadSame-168              [-1, 1024, 2]               0
      Bottleneck-169              [-1, 1024, 2]               0
     BatchNorm1d-170              [-1, 1024, 2]           2,048
            ReLU-171              [-1, 1024, 2]               0
         Dropout-172              [-1, 1024, 2]               0
          Conv1d-173              [-1, 1024, 2]          17,408
 MyConv1dPadSame-174              [-1, 1024, 2]               0
     BatchNorm1d-175              [-1, 1024, 2]           2,048
            ReLU-176              [-1, 1024, 2]               0
         Dropout-177              [-1, 1024, 2]               0
          Conv1d-178              [-1, 1024, 2]          17,408
 MyConv1dPadSame-179              [-1, 1024, 2]               0
      Bottleneck-180              [-1, 1024, 2]               0
     BatchNorm1d-181              [-1, 1024, 2]           2,048
            ReLU-182              [-1, 1024, 2]               0
         Dropout-183              [-1, 1024, 2]               0
          Conv1d-184              [-1, 1024, 1]          17,408
 MyConv1dPadSame-185              [-1, 1024, 1]               0
     BatchNorm1d-186              [-1, 1024, 1]           2,048
            ReLU-187              [-1, 1024, 1]               0
         Dropout-188              [-1, 1024, 1]               0
          Conv1d-189              [-1, 1024, 1]          17,408
 MyConv1dPadSame-190              [-1, 1024, 1]               0
       MaxPool1d-191              [-1, 1024, 1]               0
MyMaxPool1dPadSame-192              [-1, 1024, 1]               0
      Bottleneck-193              [-1, 1024, 1]               0
     BatchNorm1d-194              [-1, 1024, 1]           2,048
            ReLU-195              [-1, 1024, 1]               0
          Linear-196                    [-1, 2]           2,050
================================================================
Total params: 212,098
Trainable params: 212,098
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 13.30
Params size (MB): 0.81
Estimated Total Size (MB): 14.11
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 128, kernel_size: 4, n_block: 2
************************************************************
************************************************************
(2000, 1, 256) Counter({0: 1000, 1: 1000})
(2000, 1, 256) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 128, 256]             640
   MyConv1dPadSame-2             [-1, 128, 256]               0
       BatchNorm1d-3             [-1, 128, 256]             256
              ReLU-4             [-1, 128, 256]               0
            Conv1d-5             [-1, 128, 256]             640
   MyConv1dPadSame-6             [-1, 128, 256]               0
       BatchNorm1d-7             [-1, 128, 256]             256
              ReLU-8             [-1, 128, 256]               0
           Dropout-9             [-1, 128, 256]               0
           Conv1d-10             [-1, 128, 256]             640
  MyConv1dPadSame-11             [-1, 128, 256]               0
       Bottleneck-12             [-1, 128, 256]               0
      BatchNorm1d-13             [-1, 128, 256]             256
             ReLU-14             [-1, 128, 256]               0
          Dropout-15             [-1, 128, 256]               0
           Conv1d-16             [-1, 256, 256]           1,280
  MyConv1dPadSame-17             [-1, 256, 256]               0
      BatchNorm1d-18             [-1, 256, 256]             512
             ReLU-19             [-1, 256, 256]               0
          Dropout-20             [-1, 256, 256]               0
           Conv1d-21             [-1, 256, 256]           2,304
  MyConv1dPadSame-22             [-1, 256, 256]               0
       Bottleneck-23             [-1, 256, 256]               0
      BatchNorm1d-24             [-1, 256, 256]             512
             ReLU-25             [-1, 256, 256]               0
           Linear-26                    [-1, 2]             514
================================================================
Total params: 7,810
Trainable params: 7,810
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 8.75
Params size (MB): 0.03
Estimated Total Size (MB): 8.78
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 128, kernel_size: 4, n_block: 4
************************************************************
************************************************************
(2000, 1, 256) Counter({1: 1000, 0: 1000})
(2000, 1, 256) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 128, 256]             640
   MyConv1dPadSame-2             [-1, 128, 256]               0
       BatchNorm1d-3             [-1, 128, 256]             256
              ReLU-4             [-1, 128, 256]               0
            Conv1d-5             [-1, 128, 256]             640
   MyConv1dPadSame-6             [-1, 128, 256]               0
       BatchNorm1d-7             [-1, 128, 256]             256
              ReLU-8             [-1, 128, 256]               0
           Dropout-9             [-1, 128, 256]               0
           Conv1d-10             [-1, 128, 256]             640
  MyConv1dPadSame-11             [-1, 128, 256]               0
       Bottleneck-12             [-1, 128, 256]               0
      BatchNorm1d-13             [-1, 128, 256]             256
             ReLU-14             [-1, 128, 256]               0
          Dropout-15             [-1, 128, 256]               0
           Conv1d-16             [-1, 256, 256]           1,280
  MyConv1dPadSame-17             [-1, 256, 256]               0
      BatchNorm1d-18             [-1, 256, 256]             512
             ReLU-19             [-1, 256, 256]               0
          Dropout-20             [-1, 256, 256]               0
           Conv1d-21             [-1, 256, 256]           2,304
  MyConv1dPadSame-22             [-1, 256, 256]               0
       Bottleneck-23             [-1, 256, 256]               0
      BatchNorm1d-24             [-1, 256, 256]             512
             ReLU-25             [-1, 256, 256]               0
          Dropout-26             [-1, 256, 256]               0
           Conv1d-27             [-1, 512, 256]           4,608
  MyConv1dPadSame-28             [-1, 512, 256]               0
      BatchNorm1d-29             [-1, 512, 256]           1,024
             ReLU-30             [-1, 512, 256]               0
          Dropout-31             [-1, 512, 256]               0
           Conv1d-32             [-1, 512, 256]           8,704
  MyConv1dPadSame-33             [-1, 512, 256]               0
       Bottleneck-34             [-1, 512, 256]               0
      BatchNorm1d-35             [-1, 512, 256]           1,024
             ReLU-36             [-1, 512, 256]               0
          Dropout-37             [-1, 512, 256]               0
           Conv1d-38            [-1, 1024, 256]          17,408
  MyConv1dPadSame-39            [-1, 1024, 256]               0
      BatchNorm1d-40            [-1, 1024, 256]           2,048
             ReLU-41            [-1, 1024, 256]               0
          Dropout-42            [-1, 1024, 256]               0
           Conv1d-43            [-1, 1024, 256]          33,792
  MyConv1dPadSame-44            [-1, 1024, 256]               0
       Bottleneck-45            [-1, 1024, 256]               0
      BatchNorm1d-46            [-1, 1024, 256]           2,048
             ReLU-47            [-1, 1024, 256]               0
           Linear-48                    [-1, 2]           2,050
================================================================
Total params: 80,002
Trainable params: 80,002
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 40.25
Params size (MB): 0.31
Estimated Total Size (MB): 40.56
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 128, kernel_size: 4, n_block: 8
************************************************************
************************************************************
(2000, 1, 256) Counter({0: 1000, 1: 1000})
(2000, 1, 256) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 128, 256]             640
   MyConv1dPadSame-2             [-1, 128, 256]               0
       BatchNorm1d-3             [-1, 128, 256]             256
              ReLU-4             [-1, 128, 256]               0
            Conv1d-5             [-1, 128, 256]             640
   MyConv1dPadSame-6             [-1, 128, 256]               0
       BatchNorm1d-7             [-1, 128, 256]             256
              ReLU-8             [-1, 128, 256]               0
           Dropout-9             [-1, 128, 256]               0
           Conv1d-10             [-1, 128, 256]             640
  MyConv1dPadSame-11             [-1, 128, 256]               0
       Bottleneck-12             [-1, 128, 256]               0
      BatchNorm1d-13             [-1, 128, 256]             256
             ReLU-14             [-1, 128, 256]               0
          Dropout-15             [-1, 128, 256]               0
           Conv1d-16             [-1, 128, 256]             640
  MyConv1dPadSame-17             [-1, 128, 256]               0
      BatchNorm1d-18             [-1, 128, 256]             256
             ReLU-19             [-1, 128, 256]               0
          Dropout-20             [-1, 128, 256]               0
           Conv1d-21             [-1, 128, 256]             640
  MyConv1dPadSame-22             [-1, 128, 256]               0
       Bottleneck-23             [-1, 128, 256]               0
      BatchNorm1d-24             [-1, 128, 256]             256
             ReLU-25             [-1, 128, 256]               0
          Dropout-26             [-1, 128, 256]               0
           Conv1d-27             [-1, 256, 256]           1,280
  MyConv1dPadSame-28             [-1, 256, 256]               0
      BatchNorm1d-29             [-1, 256, 256]             512
             ReLU-30             [-1, 256, 256]               0
          Dropout-31             [-1, 256, 256]               0
           Conv1d-32             [-1, 256, 256]           2,304
  MyConv1dPadSame-33             [-1, 256, 256]               0
       Bottleneck-34             [-1, 256, 256]               0
      BatchNorm1d-35             [-1, 256, 256]             512
             ReLU-36             [-1, 256, 256]               0
          Dropout-37             [-1, 256, 256]               0
           Conv1d-38             [-1, 256, 256]           2,304
  MyConv1dPadSame-39             [-1, 256, 256]               0
      BatchNorm1d-40             [-1, 256, 256]             512
             ReLU-41             [-1, 256, 256]               0
          Dropout-42             [-1, 256, 256]               0
           Conv1d-43             [-1, 256, 256]           2,304
  MyConv1dPadSame-44             [-1, 256, 256]               0
       Bottleneck-45             [-1, 256, 256]               0
      BatchNorm1d-46             [-1, 256, 256]             512
             ReLU-47             [-1, 256, 256]               0
          Dropout-48             [-1, 256, 256]               0
           Conv1d-49             [-1, 512, 256]           4,608
  MyConv1dPadSame-50             [-1, 512, 256]               0
      BatchNorm1d-51             [-1, 512, 256]           1,024
             ReLU-52             [-1, 512, 256]               0
          Dropout-53             [-1, 512, 256]               0
           Conv1d-54             [-1, 512, 256]           8,704
  MyConv1dPadSame-55             [-1, 512, 256]               0
       Bottleneck-56             [-1, 512, 256]               0
      BatchNorm1d-57             [-1, 512, 256]           1,024
             ReLU-58             [-1, 512, 256]               0
          Dropout-59             [-1, 512, 256]               0
           Conv1d-60             [-1, 512, 256]           8,704
  MyConv1dPadSame-61             [-1, 512, 256]               0
      BatchNorm1d-62             [-1, 512, 256]           1,024
             ReLU-63             [-1, 512, 256]               0
          Dropout-64             [-1, 512, 256]               0
           Conv1d-65             [-1, 512, 256]           8,704
  MyConv1dPadSame-66             [-1, 512, 256]               0
       Bottleneck-67             [-1, 512, 256]               0
      BatchNorm1d-68             [-1, 512, 256]           1,024
             ReLU-69             [-1, 512, 256]               0
          Dropout-70             [-1, 512, 256]               0
           Conv1d-71            [-1, 1024, 256]          17,408
  MyConv1dPadSame-72            [-1, 1024, 256]               0
      BatchNorm1d-73            [-1, 1024, 256]           2,048
             ReLU-74            [-1, 1024, 256]               0
          Dropout-75            [-1, 1024, 256]               0
           Conv1d-76            [-1, 1024, 256]          33,792
  MyConv1dPadSame-77            [-1, 1024, 256]               0
       Bottleneck-78            [-1, 1024, 256]               0
      BatchNorm1d-79            [-1, 1024, 256]           2,048
             ReLU-80            [-1, 1024, 256]               0
          Dropout-81            [-1, 1024, 256]               0
           Conv1d-82            [-1, 1024, 256]          33,792
  MyConv1dPadSame-83            [-1, 1024, 256]               0
      BatchNorm1d-84            [-1, 1024, 256]           2,048
             ReLU-85            [-1, 1024, 256]               0
          Dropout-86            [-1, 1024, 256]               0
           Conv1d-87            [-1, 1024, 256]          33,792
  MyConv1dPadSame-88            [-1, 1024, 256]               0
       Bottleneck-89            [-1, 1024, 256]               0
      BatchNorm1d-90            [-1, 1024, 256]           2,048
             ReLU-91            [-1, 1024, 256]               0
           Linear-92                    [-1, 2]           2,050
================================================================
Total params: 178,562
Trainable params: 178,562
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 81.50
Params size (MB): 0.68
Estimated Total Size (MB): 82.18
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 128, kernel_size: 4, n_block: 16
************************************************************
************************************************************
(2000, 1, 256) Counter({0: 1000, 1: 1000})
(2000, 1, 256) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 128, 256]             640
   MyConv1dPadSame-2             [-1, 128, 256]               0
       BatchNorm1d-3             [-1, 128, 256]             256
              ReLU-4             [-1, 128, 256]               0
            Conv1d-5             [-1, 128, 256]             640
   MyConv1dPadSame-6             [-1, 128, 256]               0
       BatchNorm1d-7             [-1, 128, 256]             256
              ReLU-8             [-1, 128, 256]               0
           Dropout-9             [-1, 128, 256]               0
           Conv1d-10             [-1, 128, 256]             640
  MyConv1dPadSame-11             [-1, 128, 256]               0
       Bottleneck-12             [-1, 128, 256]               0
      BatchNorm1d-13             [-1, 128, 256]             256
             ReLU-14             [-1, 128, 256]               0
          Dropout-15             [-1, 128, 256]               0
           Conv1d-16             [-1, 128, 128]             640
  MyConv1dPadSame-17             [-1, 128, 128]               0
      BatchNorm1d-18             [-1, 128, 128]             256
             ReLU-19             [-1, 128, 128]               0
          Dropout-20             [-1, 128, 128]               0
           Conv1d-21             [-1, 128, 128]             640
  MyConv1dPadSame-22             [-1, 128, 128]               0
        MaxPool1d-23             [-1, 128, 128]               0
MyMaxPool1dPadSame-24             [-1, 128, 128]               0
       Bottleneck-25             [-1, 128, 128]               0
      BatchNorm1d-26             [-1, 128, 128]             256
             ReLU-27             [-1, 128, 128]               0
          Dropout-28             [-1, 128, 128]               0
           Conv1d-29             [-1, 128, 128]             640
  MyConv1dPadSame-30             [-1, 128, 128]               0
      BatchNorm1d-31             [-1, 128, 128]             256
             ReLU-32             [-1, 128, 128]               0
          Dropout-33             [-1, 128, 128]               0
           Conv1d-34             [-1, 128, 128]             640
  MyConv1dPadSame-35             [-1, 128, 128]               0
       Bottleneck-36             [-1, 128, 128]               0
      BatchNorm1d-37             [-1, 128, 128]             256
             ReLU-38             [-1, 128, 128]               0
          Dropout-39             [-1, 128, 128]               0
           Conv1d-40              [-1, 128, 64]             640
  MyConv1dPadSame-41              [-1, 128, 64]               0
      BatchNorm1d-42              [-1, 128, 64]             256
             ReLU-43              [-1, 128, 64]               0
          Dropout-44              [-1, 128, 64]               0
           Conv1d-45              [-1, 128, 64]             640
  MyConv1dPadSame-46              [-1, 128, 64]               0
        MaxPool1d-47              [-1, 128, 64]               0
MyMaxPool1dPadSame-48              [-1, 128, 64]               0
       Bottleneck-49              [-1, 128, 64]               0
      BatchNorm1d-50              [-1, 128, 64]             256
             ReLU-51              [-1, 128, 64]               0
          Dropout-52              [-1, 128, 64]               0
           Conv1d-53              [-1, 256, 64]           1,280
  MyConv1dPadSame-54              [-1, 256, 64]               0
      BatchNorm1d-55              [-1, 256, 64]             512
             ReLU-56              [-1, 256, 64]               0
          Dropout-57              [-1, 256, 64]               0
           Conv1d-58              [-1, 256, 64]           2,304
  MyConv1dPadSame-59              [-1, 256, 64]               0
       Bottleneck-60              [-1, 256, 64]               0
      BatchNorm1d-61              [-1, 256, 64]             512
             ReLU-62              [-1, 256, 64]               0
          Dropout-63              [-1, 256, 64]               0
           Conv1d-64              [-1, 256, 32]           2,304
  MyConv1dPadSame-65              [-1, 256, 32]               0
      BatchNorm1d-66              [-1, 256, 32]             512
             ReLU-67              [-1, 256, 32]               0
          Dropout-68              [-1, 256, 32]               0
           Conv1d-69              [-1, 256, 32]           2,304
  MyConv1dPadSame-70              [-1, 256, 32]               0
        MaxPool1d-71              [-1, 256, 32]               0
MyMaxPool1dPadSame-72              [-1, 256, 32]               0
       Bottleneck-73              [-1, 256, 32]               0
      BatchNorm1d-74              [-1, 256, 32]             512
             ReLU-75              [-1, 256, 32]               0
          Dropout-76              [-1, 256, 32]               0
           Conv1d-77              [-1, 256, 32]           2,304
  MyConv1dPadSame-78              [-1, 256, 32]               0
      BatchNorm1d-79              [-1, 256, 32]             512
             ReLU-80              [-1, 256, 32]               0
          Dropout-81              [-1, 256, 32]               0
           Conv1d-82              [-1, 256, 32]           2,304
  MyConv1dPadSame-83              [-1, 256, 32]               0
       Bottleneck-84              [-1, 256, 32]               0
      BatchNorm1d-85              [-1, 256, 32]             512
             ReLU-86              [-1, 256, 32]               0
          Dropout-87              [-1, 256, 32]               0
           Conv1d-88              [-1, 256, 16]           2,304
  MyConv1dPadSame-89              [-1, 256, 16]               0
      BatchNorm1d-90              [-1, 256, 16]             512
             ReLU-91              [-1, 256, 16]               0
          Dropout-92              [-1, 256, 16]               0
           Conv1d-93              [-1, 256, 16]           2,304
  MyConv1dPadSame-94              [-1, 256, 16]               0
        MaxPool1d-95              [-1, 256, 16]               0
MyMaxPool1dPadSame-96              [-1, 256, 16]               0
       Bottleneck-97              [-1, 256, 16]               0
      BatchNorm1d-98              [-1, 256, 16]             512
             ReLU-99              [-1, 256, 16]               0
         Dropout-100              [-1, 256, 16]               0
          Conv1d-101              [-1, 512, 16]           4,608
 MyConv1dPadSame-102              [-1, 512, 16]               0
     BatchNorm1d-103              [-1, 512, 16]           1,024
            ReLU-104              [-1, 512, 16]               0
         Dropout-105              [-1, 512, 16]               0
          Conv1d-106              [-1, 512, 16]           8,704
 MyConv1dPadSame-107              [-1, 512, 16]               0
      Bottleneck-108              [-1, 512, 16]               0
     BatchNorm1d-109              [-1, 512, 16]           1,024
            ReLU-110              [-1, 512, 16]               0
         Dropout-111              [-1, 512, 16]               0
          Conv1d-112               [-1, 512, 8]           8,704
 MyConv1dPadSame-113               [-1, 512, 8]               0
     BatchNorm1d-114               [-1, 512, 8]           1,024
            ReLU-115               [-1, 512, 8]               0
         Dropout-116               [-1, 512, 8]               0
          Conv1d-117               [-1, 512, 8]           8,704
 MyConv1dPadSame-118               [-1, 512, 8]               0
       MaxPool1d-119               [-1, 512, 8]               0
MyMaxPool1dPadSame-120               [-1, 512, 8]               0
      Bottleneck-121               [-1, 512, 8]               0
     BatchNorm1d-122               [-1, 512, 8]           1,024
            ReLU-123               [-1, 512, 8]               0
         Dropout-124               [-1, 512, 8]               0
          Conv1d-125               [-1, 512, 8]           8,704
 MyConv1dPadSame-126               [-1, 512, 8]               0
     BatchNorm1d-127               [-1, 512, 8]           1,024
            ReLU-128               [-1, 512, 8]               0
         Dropout-129               [-1, 512, 8]               0
          Conv1d-130               [-1, 512, 8]           8,704
 MyConv1dPadSame-131               [-1, 512, 8]               0
      Bottleneck-132               [-1, 512, 8]               0
     BatchNorm1d-133               [-1, 512, 8]           1,024
            ReLU-134               [-1, 512, 8]               0
         Dropout-135               [-1, 512, 8]               0
          Conv1d-136               [-1, 512, 4]           8,704
 MyConv1dPadSame-137               [-1, 512, 4]               0
     BatchNorm1d-138               [-1, 512, 4]           1,024
            ReLU-139               [-1, 512, 4]               0
         Dropout-140               [-1, 512, 4]               0
          Conv1d-141               [-1, 512, 4]           8,704
 MyConv1dPadSame-142               [-1, 512, 4]               0
       MaxPool1d-143               [-1, 512, 4]               0
MyMaxPool1dPadSame-144               [-1, 512, 4]               0
      Bottleneck-145               [-1, 512, 4]               0
     BatchNorm1d-146               [-1, 512, 4]           1,024
            ReLU-147               [-1, 512, 4]               0
         Dropout-148               [-1, 512, 4]               0
          Conv1d-149              [-1, 1024, 4]          17,408
 MyConv1dPadSame-150              [-1, 1024, 4]               0
     BatchNorm1d-151              [-1, 1024, 4]           2,048
            ReLU-152              [-1, 1024, 4]               0
         Dropout-153              [-1, 1024, 4]               0
          Conv1d-154              [-1, 1024, 4]          33,792
 MyConv1dPadSame-155              [-1, 1024, 4]               0
      Bottleneck-156              [-1, 1024, 4]               0
     BatchNorm1d-157              [-1, 1024, 4]           2,048
            ReLU-158              [-1, 1024, 4]               0
         Dropout-159              [-1, 1024, 4]               0
          Conv1d-160              [-1, 1024, 2]          33,792
 MyConv1dPadSame-161              [-1, 1024, 2]               0
     BatchNorm1d-162              [-1, 1024, 2]           2,048
            ReLU-163              [-1, 1024, 2]               0
         Dropout-164              [-1, 1024, 2]               0
          Conv1d-165              [-1, 1024, 2]          33,792
 MyConv1dPadSame-166              [-1, 1024, 2]               0
       MaxPool1d-167              [-1, 1024, 2]               0
MyMaxPool1dPadSame-168              [-1, 1024, 2]               0
      Bottleneck-169              [-1, 1024, 2]               0
     BatchNorm1d-170              [-1, 1024, 2]           2,048
            ReLU-171              [-1, 1024, 2]               0
         Dropout-172              [-1, 1024, 2]               0
          Conv1d-173              [-1, 1024, 2]          33,792
 MyConv1dPadSame-174              [-1, 1024, 2]               0
     BatchNorm1d-175              [-1, 1024, 2]           2,048
            ReLU-176              [-1, 1024, 2]               0
         Dropout-177              [-1, 1024, 2]               0
          Conv1d-178              [-1, 1024, 2]          33,792
 MyConv1dPadSame-179              [-1, 1024, 2]               0
      Bottleneck-180              [-1, 1024, 2]               0
     BatchNorm1d-181              [-1, 1024, 2]           2,048
            ReLU-182              [-1, 1024, 2]               0
         Dropout-183              [-1, 1024, 2]               0
          Conv1d-184              [-1, 1024, 1]          33,792
 MyConv1dPadSame-185              [-1, 1024, 1]               0
     BatchNorm1d-186              [-1, 1024, 1]           2,048
            ReLU-187              [-1, 1024, 1]               0
         Dropout-188              [-1, 1024, 1]               0
          Conv1d-189              [-1, 1024, 1]          33,792
 MyConv1dPadSame-190              [-1, 1024, 1]               0
       MaxPool1d-191              [-1, 1024, 1]               0
MyMaxPool1dPadSame-192              [-1, 1024, 1]               0
      Bottleneck-193              [-1, 1024, 1]               0
     BatchNorm1d-194              [-1, 1024, 1]           2,048
            ReLU-195              [-1, 1024, 1]               0
          Linear-196                    [-1, 2]           2,050
================================================================
Total params: 375,682
Trainable params: 375,682
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 13.30
Params size (MB): 1.43
Estimated Total Size (MB): 14.73
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 128, kernel_size: 8, n_block: 2
************************************************************
************************************************************
(2000, 1, 256) Counter({0: 1000, 1: 1000})
(2000, 1, 256) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 128, 256]           1,152
   MyConv1dPadSame-2             [-1, 128, 256]               0
       BatchNorm1d-3             [-1, 128, 256]             256
              ReLU-4             [-1, 128, 256]               0
            Conv1d-5             [-1, 128, 256]           1,152
   MyConv1dPadSame-6             [-1, 128, 256]               0
       BatchNorm1d-7             [-1, 128, 256]             256
              ReLU-8             [-1, 128, 256]               0
           Dropout-9             [-1, 128, 256]               0
           Conv1d-10             [-1, 128, 256]           1,152
  MyConv1dPadSame-11             [-1, 128, 256]               0
       Bottleneck-12             [-1, 128, 256]               0
      BatchNorm1d-13             [-1, 128, 256]             256
             ReLU-14             [-1, 128, 256]               0
          Dropout-15             [-1, 128, 256]               0
           Conv1d-16             [-1, 256, 256]           2,304
  MyConv1dPadSame-17             [-1, 256, 256]               0
      BatchNorm1d-18             [-1, 256, 256]             512
             ReLU-19             [-1, 256, 256]               0
          Dropout-20             [-1, 256, 256]               0
           Conv1d-21             [-1, 256, 256]           4,352
  MyConv1dPadSame-22             [-1, 256, 256]               0
       Bottleneck-23             [-1, 256, 256]               0
      BatchNorm1d-24             [-1, 256, 256]             512
             ReLU-25             [-1, 256, 256]               0
           Linear-26                    [-1, 2]             514
================================================================
Total params: 12,418
Trainable params: 12,418
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 8.75
Params size (MB): 0.05
Estimated Total Size (MB): 8.80
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 128, kernel_size: 8, n_block: 4
************************************************************
************************************************************
(2000, 1, 256) Counter({0: 1000, 1: 1000})
(2000, 1, 256) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 128, 256]           1,152
   MyConv1dPadSame-2             [-1, 128, 256]               0
       BatchNorm1d-3             [-1, 128, 256]             256
              ReLU-4             [-1, 128, 256]               0
            Conv1d-5             [-1, 128, 256]           1,152
   MyConv1dPadSame-6             [-1, 128, 256]               0
       BatchNorm1d-7             [-1, 128, 256]             256
              ReLU-8             [-1, 128, 256]               0
           Dropout-9             [-1, 128, 256]               0
           Conv1d-10             [-1, 128, 256]           1,152
  MyConv1dPadSame-11             [-1, 128, 256]               0
       Bottleneck-12             [-1, 128, 256]               0
      BatchNorm1d-13             [-1, 128, 256]             256
             ReLU-14             [-1, 128, 256]               0
          Dropout-15             [-1, 128, 256]               0
           Conv1d-16             [-1, 256, 256]           2,304
  MyConv1dPadSame-17             [-1, 256, 256]               0
      BatchNorm1d-18             [-1, 256, 256]             512
             ReLU-19             [-1, 256, 256]               0
          Dropout-20             [-1, 256, 256]               0
           Conv1d-21             [-1, 256, 256]           4,352
  MyConv1dPadSame-22             [-1, 256, 256]               0
       Bottleneck-23             [-1, 256, 256]               0
      BatchNorm1d-24             [-1, 256, 256]             512
             ReLU-25             [-1, 256, 256]               0
          Dropout-26             [-1, 256, 256]               0
           Conv1d-27             [-1, 512, 256]           8,704
  MyConv1dPadSame-28             [-1, 512, 256]               0
      BatchNorm1d-29             [-1, 512, 256]           1,024
             ReLU-30             [-1, 512, 256]               0
          Dropout-31             [-1, 512, 256]               0
           Conv1d-32             [-1, 512, 256]          16,896
  MyConv1dPadSame-33             [-1, 512, 256]               0
       Bottleneck-34             [-1, 512, 256]               0
      BatchNorm1d-35             [-1, 512, 256]           1,024
             ReLU-36             [-1, 512, 256]               0
          Dropout-37             [-1, 512, 256]               0
           Conv1d-38            [-1, 1024, 256]          33,792
  MyConv1dPadSame-39            [-1, 1024, 256]               0
      BatchNorm1d-40            [-1, 1024, 256]           2,048
             ReLU-41            [-1, 1024, 256]               0
          Dropout-42            [-1, 1024, 256]               0
           Conv1d-43            [-1, 1024, 256]          66,560
  MyConv1dPadSame-44            [-1, 1024, 256]               0
       Bottleneck-45            [-1, 1024, 256]               0
      BatchNorm1d-46            [-1, 1024, 256]           2,048
             ReLU-47            [-1, 1024, 256]               0
           Linear-48                    [-1, 2]           2,050
================================================================
Total params: 146,050
Trainable params: 146,050
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 40.25
Params size (MB): 0.56
Estimated Total Size (MB): 40.81
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 128, kernel_size: 8, n_block: 8
************************************************************
************************************************************
(2000, 1, 256) Counter({0: 1000, 1: 1000})
(2000, 1, 256) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 128, 256]           1,152
   MyConv1dPadSame-2             [-1, 128, 256]               0
       BatchNorm1d-3             [-1, 128, 256]             256
              ReLU-4             [-1, 128, 256]               0
            Conv1d-5             [-1, 128, 256]           1,152
   MyConv1dPadSame-6             [-1, 128, 256]               0
       BatchNorm1d-7             [-1, 128, 256]             256
              ReLU-8             [-1, 128, 256]               0
           Dropout-9             [-1, 128, 256]               0
           Conv1d-10             [-1, 128, 256]           1,152
  MyConv1dPadSame-11             [-1, 128, 256]               0
       Bottleneck-12             [-1, 128, 256]               0
      BatchNorm1d-13             [-1, 128, 256]             256
             ReLU-14             [-1, 128, 256]               0
          Dropout-15             [-1, 128, 256]               0
           Conv1d-16             [-1, 128, 256]           1,152
  MyConv1dPadSame-17             [-1, 128, 256]               0
      BatchNorm1d-18             [-1, 128, 256]             256
             ReLU-19             [-1, 128, 256]               0
          Dropout-20             [-1, 128, 256]               0
           Conv1d-21             [-1, 128, 256]           1,152
  MyConv1dPadSame-22             [-1, 128, 256]               0
       Bottleneck-23             [-1, 128, 256]               0
      BatchNorm1d-24             [-1, 128, 256]             256
             ReLU-25             [-1, 128, 256]               0
          Dropout-26             [-1, 128, 256]               0
           Conv1d-27             [-1, 256, 256]           2,304
  MyConv1dPadSame-28             [-1, 256, 256]               0
      BatchNorm1d-29             [-1, 256, 256]             512
             ReLU-30             [-1, 256, 256]               0
          Dropout-31             [-1, 256, 256]               0
           Conv1d-32             [-1, 256, 256]           4,352
  MyConv1dPadSame-33             [-1, 256, 256]               0
       Bottleneck-34             [-1, 256, 256]               0
      BatchNorm1d-35             [-1, 256, 256]             512
             ReLU-36             [-1, 256, 256]               0
          Dropout-37             [-1, 256, 256]               0
           Conv1d-38             [-1, 256, 256]           4,352
  MyConv1dPadSame-39             [-1, 256, 256]               0
      BatchNorm1d-40             [-1, 256, 256]             512
             ReLU-41             [-1, 256, 256]               0
          Dropout-42             [-1, 256, 256]               0
           Conv1d-43             [-1, 256, 256]           4,352
  MyConv1dPadSame-44             [-1, 256, 256]               0
       Bottleneck-45             [-1, 256, 256]               0
      BatchNorm1d-46             [-1, 256, 256]             512
             ReLU-47             [-1, 256, 256]               0
          Dropout-48             [-1, 256, 256]               0
           Conv1d-49             [-1, 512, 256]           8,704
  MyConv1dPadSame-50             [-1, 512, 256]               0
      BatchNorm1d-51             [-1, 512, 256]           1,024
             ReLU-52             [-1, 512, 256]               0
          Dropout-53             [-1, 512, 256]               0
           Conv1d-54             [-1, 512, 256]          16,896
  MyConv1dPadSame-55             [-1, 512, 256]               0
       Bottleneck-56             [-1, 512, 256]               0
      BatchNorm1d-57             [-1, 512, 256]           1,024
             ReLU-58             [-1, 512, 256]               0
          Dropout-59             [-1, 512, 256]               0
           Conv1d-60             [-1, 512, 256]          16,896
  MyConv1dPadSame-61             [-1, 512, 256]               0
      BatchNorm1d-62             [-1, 512, 256]           1,024
             ReLU-63             [-1, 512, 256]               0
          Dropout-64             [-1, 512, 256]               0
           Conv1d-65             [-1, 512, 256]          16,896
  MyConv1dPadSame-66             [-1, 512, 256]               0
       Bottleneck-67             [-1, 512, 256]               0
      BatchNorm1d-68             [-1, 512, 256]           1,024
             ReLU-69             [-1, 512, 256]               0
          Dropout-70             [-1, 512, 256]               0
           Conv1d-71            [-1, 1024, 256]          33,792
  MyConv1dPadSame-72            [-1, 1024, 256]               0
      BatchNorm1d-73            [-1, 1024, 256]           2,048
             ReLU-74            [-1, 1024, 256]               0
          Dropout-75            [-1, 1024, 256]               0
           Conv1d-76            [-1, 1024, 256]          66,560
  MyConv1dPadSame-77            [-1, 1024, 256]               0
       Bottleneck-78            [-1, 1024, 256]               0
      BatchNorm1d-79            [-1, 1024, 256]           2,048
             ReLU-80            [-1, 1024, 256]               0
          Dropout-81            [-1, 1024, 256]               0
           Conv1d-82            [-1, 1024, 256]          66,560
  MyConv1dPadSame-83            [-1, 1024, 256]               0
      BatchNorm1d-84            [-1, 1024, 256]           2,048
             ReLU-85            [-1, 1024, 256]               0
          Dropout-86            [-1, 1024, 256]               0
           Conv1d-87            [-1, 1024, 256]          66,560
  MyConv1dPadSame-88            [-1, 1024, 256]               0
       Bottleneck-89            [-1, 1024, 256]               0
      BatchNorm1d-90            [-1, 1024, 256]           2,048
             ReLU-91            [-1, 1024, 256]               0
           Linear-92                    [-1, 2]           2,050
================================================================
Total params: 331,650
Trainable params: 331,650
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 81.50
Params size (MB): 1.27
Estimated Total Size (MB): 82.77
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 128, kernel_size: 8, n_block: 16
************************************************************
************************************************************
(2000, 1, 256) Counter({1: 1000, 0: 1000})
(2000, 1, 256) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 128, 256]           1,152
   MyConv1dPadSame-2             [-1, 128, 256]               0
       BatchNorm1d-3             [-1, 128, 256]             256
              ReLU-4             [-1, 128, 256]               0
            Conv1d-5             [-1, 128, 256]           1,152
   MyConv1dPadSame-6             [-1, 128, 256]               0
       BatchNorm1d-7             [-1, 128, 256]             256
              ReLU-8             [-1, 128, 256]               0
           Dropout-9             [-1, 128, 256]               0
           Conv1d-10             [-1, 128, 256]           1,152
  MyConv1dPadSame-11             [-1, 128, 256]               0
       Bottleneck-12             [-1, 128, 256]               0
      BatchNorm1d-13             [-1, 128, 256]             256
             ReLU-14             [-1, 128, 256]               0
          Dropout-15             [-1, 128, 256]               0
           Conv1d-16             [-1, 128, 128]           1,152
  MyConv1dPadSame-17             [-1, 128, 128]               0
      BatchNorm1d-18             [-1, 128, 128]             256
             ReLU-19             [-1, 128, 128]               0
          Dropout-20             [-1, 128, 128]               0
           Conv1d-21             [-1, 128, 128]           1,152
  MyConv1dPadSame-22             [-1, 128, 128]               0
        MaxPool1d-23             [-1, 128, 128]               0
MyMaxPool1dPadSame-24             [-1, 128, 128]               0
       Bottleneck-25             [-1, 128, 128]               0
      BatchNorm1d-26             [-1, 128, 128]             256
             ReLU-27             [-1, 128, 128]               0
          Dropout-28             [-1, 128, 128]               0
           Conv1d-29             [-1, 128, 128]           1,152
  MyConv1dPadSame-30             [-1, 128, 128]               0
      BatchNorm1d-31             [-1, 128, 128]             256
             ReLU-32             [-1, 128, 128]               0
          Dropout-33             [-1, 128, 128]               0
           Conv1d-34             [-1, 128, 128]           1,152
  MyConv1dPadSame-35             [-1, 128, 128]               0
       Bottleneck-36             [-1, 128, 128]               0
      BatchNorm1d-37             [-1, 128, 128]             256
             ReLU-38             [-1, 128, 128]               0
          Dropout-39             [-1, 128, 128]               0
           Conv1d-40              [-1, 128, 64]           1,152
  MyConv1dPadSame-41              [-1, 128, 64]               0
      BatchNorm1d-42              [-1, 128, 64]             256
             ReLU-43              [-1, 128, 64]               0
          Dropout-44              [-1, 128, 64]               0
           Conv1d-45              [-1, 128, 64]           1,152
  MyConv1dPadSame-46              [-1, 128, 64]               0
        MaxPool1d-47              [-1, 128, 64]               0
MyMaxPool1dPadSame-48              [-1, 128, 64]               0
       Bottleneck-49              [-1, 128, 64]               0
      BatchNorm1d-50              [-1, 128, 64]             256
             ReLU-51              [-1, 128, 64]               0
          Dropout-52              [-1, 128, 64]               0
           Conv1d-53              [-1, 256, 64]           2,304
  MyConv1dPadSame-54              [-1, 256, 64]               0
      BatchNorm1d-55              [-1, 256, 64]             512
             ReLU-56              [-1, 256, 64]               0
          Dropout-57              [-1, 256, 64]               0
           Conv1d-58              [-1, 256, 64]           4,352
  MyConv1dPadSame-59              [-1, 256, 64]               0
       Bottleneck-60              [-1, 256, 64]               0
      BatchNorm1d-61              [-1, 256, 64]             512
             ReLU-62              [-1, 256, 64]               0
          Dropout-63              [-1, 256, 64]               0
           Conv1d-64              [-1, 256, 32]           4,352
  MyConv1dPadSame-65              [-1, 256, 32]               0
      BatchNorm1d-66              [-1, 256, 32]             512
             ReLU-67              [-1, 256, 32]               0
          Dropout-68              [-1, 256, 32]               0
           Conv1d-69              [-1, 256, 32]           4,352
  MyConv1dPadSame-70              [-1, 256, 32]               0
        MaxPool1d-71              [-1, 256, 32]               0
MyMaxPool1dPadSame-72              [-1, 256, 32]               0
       Bottleneck-73              [-1, 256, 32]               0
      BatchNorm1d-74              [-1, 256, 32]             512
             ReLU-75              [-1, 256, 32]               0
          Dropout-76              [-1, 256, 32]               0
           Conv1d-77              [-1, 256, 32]           4,352
  MyConv1dPadSame-78              [-1, 256, 32]               0
      BatchNorm1d-79              [-1, 256, 32]             512
             ReLU-80              [-1, 256, 32]               0
          Dropout-81              [-1, 256, 32]               0
           Conv1d-82              [-1, 256, 32]           4,352
  MyConv1dPadSame-83              [-1, 256, 32]               0
       Bottleneck-84              [-1, 256, 32]               0
      BatchNorm1d-85              [-1, 256, 32]             512
             ReLU-86              [-1, 256, 32]               0
          Dropout-87              [-1, 256, 32]               0
           Conv1d-88              [-1, 256, 16]           4,352
  MyConv1dPadSame-89              [-1, 256, 16]               0
      BatchNorm1d-90              [-1, 256, 16]             512
             ReLU-91              [-1, 256, 16]               0
          Dropout-92              [-1, 256, 16]               0
           Conv1d-93              [-1, 256, 16]           4,352
  MyConv1dPadSame-94              [-1, 256, 16]               0
        MaxPool1d-95              [-1, 256, 16]               0
MyMaxPool1dPadSame-96              [-1, 256, 16]               0
       Bottleneck-97              [-1, 256, 16]               0
      BatchNorm1d-98              [-1, 256, 16]             512
             ReLU-99              [-1, 256, 16]               0
         Dropout-100              [-1, 256, 16]               0
          Conv1d-101              [-1, 512, 16]           8,704
 MyConv1dPadSame-102              [-1, 512, 16]               0
     BatchNorm1d-103              [-1, 512, 16]           1,024
            ReLU-104              [-1, 512, 16]               0
         Dropout-105              [-1, 512, 16]               0
          Conv1d-106              [-1, 512, 16]          16,896
 MyConv1dPadSame-107              [-1, 512, 16]               0
      Bottleneck-108              [-1, 512, 16]               0
     BatchNorm1d-109              [-1, 512, 16]           1,024
            ReLU-110              [-1, 512, 16]               0
         Dropout-111              [-1, 512, 16]               0
          Conv1d-112               [-1, 512, 8]          16,896
 MyConv1dPadSame-113               [-1, 512, 8]               0
     BatchNorm1d-114               [-1, 512, 8]           1,024
            ReLU-115               [-1, 512, 8]               0
         Dropout-116               [-1, 512, 8]               0
          Conv1d-117               [-1, 512, 8]          16,896
 MyConv1dPadSame-118               [-1, 512, 8]               0
       MaxPool1d-119               [-1, 512, 8]               0
MyMaxPool1dPadSame-120               [-1, 512, 8]               0
      Bottleneck-121               [-1, 512, 8]               0
     BatchNorm1d-122               [-1, 512, 8]           1,024
            ReLU-123               [-1, 512, 8]               0
         Dropout-124               [-1, 512, 8]               0
          Conv1d-125               [-1, 512, 8]          16,896
 MyConv1dPadSame-126               [-1, 512, 8]               0
     BatchNorm1d-127               [-1, 512, 8]           1,024
            ReLU-128               [-1, 512, 8]               0
         Dropout-129               [-1, 512, 8]               0
          Conv1d-130               [-1, 512, 8]          16,896
 MyConv1dPadSame-131               [-1, 512, 8]               0
      Bottleneck-132               [-1, 512, 8]               0
     BatchNorm1d-133               [-1, 512, 8]           1,024
            ReLU-134               [-1, 512, 8]               0
         Dropout-135               [-1, 512, 8]               0
          Conv1d-136               [-1, 512, 4]          16,896
 MyConv1dPadSame-137               [-1, 512, 4]               0
     BatchNorm1d-138               [-1, 512, 4]           1,024
            ReLU-139               [-1, 512, 4]               0
         Dropout-140               [-1, 512, 4]               0
          Conv1d-141               [-1, 512, 4]          16,896
 MyConv1dPadSame-142               [-1, 512, 4]               0
       MaxPool1d-143               [-1, 512, 4]               0
MyMaxPool1dPadSame-144               [-1, 512, 4]               0
      Bottleneck-145               [-1, 512, 4]               0
     BatchNorm1d-146               [-1, 512, 4]           1,024
            ReLU-147               [-1, 512, 4]               0
         Dropout-148               [-1, 512, 4]               0
          Conv1d-149              [-1, 1024, 4]          33,792
 MyConv1dPadSame-150              [-1, 1024, 4]               0
     BatchNorm1d-151              [-1, 1024, 4]           2,048
            ReLU-152              [-1, 1024, 4]               0
         Dropout-153              [-1, 1024, 4]               0
          Conv1d-154              [-1, 1024, 4]          66,560
 MyConv1dPadSame-155              [-1, 1024, 4]               0
      Bottleneck-156              [-1, 1024, 4]               0
     BatchNorm1d-157              [-1, 1024, 4]           2,048
            ReLU-158              [-1, 1024, 4]               0
         Dropout-159              [-1, 1024, 4]               0
          Conv1d-160              [-1, 1024, 2]          66,560
 MyConv1dPadSame-161              [-1, 1024, 2]               0
     BatchNorm1d-162              [-1, 1024, 2]           2,048
            ReLU-163              [-1, 1024, 2]               0
         Dropout-164              [-1, 1024, 2]               0
          Conv1d-165              [-1, 1024, 2]          66,560
 MyConv1dPadSame-166              [-1, 1024, 2]               0
       MaxPool1d-167              [-1, 1024, 2]               0
MyMaxPool1dPadSame-168              [-1, 1024, 2]               0
      Bottleneck-169              [-1, 1024, 2]               0
     BatchNorm1d-170              [-1, 1024, 2]           2,048
            ReLU-171              [-1, 1024, 2]               0
         Dropout-172              [-1, 1024, 2]               0
          Conv1d-173              [-1, 1024, 2]          66,560
 MyConv1dPadSame-174              [-1, 1024, 2]               0
     BatchNorm1d-175              [-1, 1024, 2]           2,048
            ReLU-176              [-1, 1024, 2]               0
         Dropout-177              [-1, 1024, 2]               0
          Conv1d-178              [-1, 1024, 2]          66,560
 MyConv1dPadSame-179              [-1, 1024, 2]               0
      Bottleneck-180              [-1, 1024, 2]               0
     BatchNorm1d-181              [-1, 1024, 2]           2,048
            ReLU-182              [-1, 1024, 2]               0
         Dropout-183              [-1, 1024, 2]               0
          Conv1d-184              [-1, 1024, 1]          66,560
 MyConv1dPadSame-185              [-1, 1024, 1]               0
     BatchNorm1d-186              [-1, 1024, 1]           2,048
            ReLU-187              [-1, 1024, 1]               0
         Dropout-188              [-1, 1024, 1]               0
          Conv1d-189              [-1, 1024, 1]          66,560
 MyConv1dPadSame-190              [-1, 1024, 1]               0
       MaxPool1d-191              [-1, 1024, 1]               0
MyMaxPool1dPadSame-192              [-1, 1024, 1]               0
      Bottleneck-193              [-1, 1024, 1]               0
     BatchNorm1d-194              [-1, 1024, 1]           2,048
            ReLU-195              [-1, 1024, 1]               0
          Linear-196                    [-1, 2]           2,050
================================================================
Total params: 702,850
Trainable params: 702,850
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 13.30
Params size (MB): 2.68
Estimated Total Size (MB): 15.98
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 128, kernel_size: 16, n_block: 2
************************************************************
************************************************************
(2000, 1, 256) Counter({1: 1000, 0: 1000})
(2000, 1, 256) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 128, 256]           2,176
   MyConv1dPadSame-2             [-1, 128, 256]               0
       BatchNorm1d-3             [-1, 128, 256]             256
              ReLU-4             [-1, 128, 256]               0
            Conv1d-5             [-1, 128, 256]           2,176
   MyConv1dPadSame-6             [-1, 128, 256]               0
       BatchNorm1d-7             [-1, 128, 256]             256
              ReLU-8             [-1, 128, 256]               0
           Dropout-9             [-1, 128, 256]               0
           Conv1d-10             [-1, 128, 256]           2,176
  MyConv1dPadSame-11             [-1, 128, 256]               0
       Bottleneck-12             [-1, 128, 256]               0
      BatchNorm1d-13             [-1, 128, 256]             256
             ReLU-14             [-1, 128, 256]               0
          Dropout-15             [-1, 128, 256]               0
           Conv1d-16             [-1, 256, 256]           4,352
  MyConv1dPadSame-17             [-1, 256, 256]               0
      BatchNorm1d-18             [-1, 256, 256]             512
             ReLU-19             [-1, 256, 256]               0
          Dropout-20             [-1, 256, 256]               0
           Conv1d-21             [-1, 256, 256]           8,448
  MyConv1dPadSame-22             [-1, 256, 256]               0
       Bottleneck-23             [-1, 256, 256]               0
      BatchNorm1d-24             [-1, 256, 256]             512
             ReLU-25             [-1, 256, 256]               0
           Linear-26                    [-1, 2]             514
================================================================
Total params: 21,634
Trainable params: 21,634
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 8.75
Params size (MB): 0.08
Estimated Total Size (MB): 8.83
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 128, kernel_size: 16, n_block: 4
************************************************************
************************************************************
(2000, 1, 256) Counter({1: 1000, 0: 1000})
(2000, 1, 256) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 128, 256]           2,176
   MyConv1dPadSame-2             [-1, 128, 256]               0
       BatchNorm1d-3             [-1, 128, 256]             256
              ReLU-4             [-1, 128, 256]               0
            Conv1d-5             [-1, 128, 256]           2,176
   MyConv1dPadSame-6             [-1, 128, 256]               0
       BatchNorm1d-7             [-1, 128, 256]             256
              ReLU-8             [-1, 128, 256]               0
           Dropout-9             [-1, 128, 256]               0
           Conv1d-10             [-1, 128, 256]           2,176
  MyConv1dPadSame-11             [-1, 128, 256]               0
       Bottleneck-12             [-1, 128, 256]               0
      BatchNorm1d-13             [-1, 128, 256]             256
             ReLU-14             [-1, 128, 256]               0
          Dropout-15             [-1, 128, 256]               0
           Conv1d-16             [-1, 256, 256]           4,352
  MyConv1dPadSame-17             [-1, 256, 256]               0
      BatchNorm1d-18             [-1, 256, 256]             512
             ReLU-19             [-1, 256, 256]               0
          Dropout-20             [-1, 256, 256]               0
           Conv1d-21             [-1, 256, 256]           8,448
  MyConv1dPadSame-22             [-1, 256, 256]               0
       Bottleneck-23             [-1, 256, 256]               0
      BatchNorm1d-24             [-1, 256, 256]             512
             ReLU-25             [-1, 256, 256]               0
          Dropout-26             [-1, 256, 256]               0
           Conv1d-27             [-1, 512, 256]          16,896
  MyConv1dPadSame-28             [-1, 512, 256]               0
      BatchNorm1d-29             [-1, 512, 256]           1,024
             ReLU-30             [-1, 512, 256]               0
          Dropout-31             [-1, 512, 256]               0
           Conv1d-32             [-1, 512, 256]          33,280
  MyConv1dPadSame-33             [-1, 512, 256]               0
       Bottleneck-34             [-1, 512, 256]               0
      BatchNorm1d-35             [-1, 512, 256]           1,024
             ReLU-36             [-1, 512, 256]               0
          Dropout-37             [-1, 512, 256]               0
           Conv1d-38            [-1, 1024, 256]          66,560
  MyConv1dPadSame-39            [-1, 1024, 256]               0
      BatchNorm1d-40            [-1, 1024, 256]           2,048
             ReLU-41            [-1, 1024, 256]               0
          Dropout-42            [-1, 1024, 256]               0
           Conv1d-43            [-1, 1024, 256]         132,096
  MyConv1dPadSame-44            [-1, 1024, 256]               0
       Bottleneck-45            [-1, 1024, 256]               0
      BatchNorm1d-46            [-1, 1024, 256]           2,048
             ReLU-47            [-1, 1024, 256]               0
           Linear-48                    [-1, 2]           2,050
================================================================
Total params: 278,146
Trainable params: 278,146
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 40.25
Params size (MB): 1.06
Estimated Total Size (MB): 41.31
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 128, kernel_size: 16, n_block: 8
************************************************************
************************************************************
(2000, 1, 256) Counter({0: 1000, 1: 1000})
(2000, 1, 256) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 128, 256]           2,176
   MyConv1dPadSame-2             [-1, 128, 256]               0
       BatchNorm1d-3             [-1, 128, 256]             256
              ReLU-4             [-1, 128, 256]               0
            Conv1d-5             [-1, 128, 256]           2,176
   MyConv1dPadSame-6             [-1, 128, 256]               0
       BatchNorm1d-7             [-1, 128, 256]             256
              ReLU-8             [-1, 128, 256]               0
           Dropout-9             [-1, 128, 256]               0
           Conv1d-10             [-1, 128, 256]           2,176
  MyConv1dPadSame-11             [-1, 128, 256]               0
       Bottleneck-12             [-1, 128, 256]               0
      BatchNorm1d-13             [-1, 128, 256]             256
             ReLU-14             [-1, 128, 256]               0
          Dropout-15             [-1, 128, 256]               0
           Conv1d-16             [-1, 128, 256]           2,176
  MyConv1dPadSame-17             [-1, 128, 256]               0
      BatchNorm1d-18             [-1, 128, 256]             256
             ReLU-19             [-1, 128, 256]               0
          Dropout-20             [-1, 128, 256]               0
           Conv1d-21             [-1, 128, 256]           2,176
  MyConv1dPadSame-22             [-1, 128, 256]               0
       Bottleneck-23             [-1, 128, 256]               0
      BatchNorm1d-24             [-1, 128, 256]             256
             ReLU-25             [-1, 128, 256]               0
          Dropout-26             [-1, 128, 256]               0
           Conv1d-27             [-1, 256, 256]           4,352
  MyConv1dPadSame-28             [-1, 256, 256]               0
      BatchNorm1d-29             [-1, 256, 256]             512
             ReLU-30             [-1, 256, 256]               0
          Dropout-31             [-1, 256, 256]               0
           Conv1d-32             [-1, 256, 256]           8,448
  MyConv1dPadSame-33             [-1, 256, 256]               0
       Bottleneck-34             [-1, 256, 256]               0
      BatchNorm1d-35             [-1, 256, 256]             512
             ReLU-36             [-1, 256, 256]               0
          Dropout-37             [-1, 256, 256]               0
           Conv1d-38             [-1, 256, 256]           8,448
  MyConv1dPadSame-39             [-1, 256, 256]               0
      BatchNorm1d-40             [-1, 256, 256]             512
             ReLU-41             [-1, 256, 256]               0
          Dropout-42             [-1, 256, 256]               0
           Conv1d-43             [-1, 256, 256]           8,448
  MyConv1dPadSame-44             [-1, 256, 256]               0
       Bottleneck-45             [-1, 256, 256]               0
      BatchNorm1d-46             [-1, 256, 256]             512
             ReLU-47             [-1, 256, 256]               0
          Dropout-48             [-1, 256, 256]               0
           Conv1d-49             [-1, 512, 256]          16,896
  MyConv1dPadSame-50             [-1, 512, 256]               0
      BatchNorm1d-51             [-1, 512, 256]           1,024
             ReLU-52             [-1, 512, 256]               0
          Dropout-53             [-1, 512, 256]               0
           Conv1d-54             [-1, 512, 256]          33,280
  MyConv1dPadSame-55             [-1, 512, 256]               0
       Bottleneck-56             [-1, 512, 256]               0
      BatchNorm1d-57             [-1, 512, 256]           1,024
             ReLU-58             [-1, 512, 256]               0
          Dropout-59             [-1, 512, 256]               0
           Conv1d-60             [-1, 512, 256]          33,280
  MyConv1dPadSame-61             [-1, 512, 256]               0
      BatchNorm1d-62             [-1, 512, 256]           1,024
             ReLU-63             [-1, 512, 256]               0
          Dropout-64             [-1, 512, 256]               0
           Conv1d-65             [-1, 512, 256]          33,280
  MyConv1dPadSame-66             [-1, 512, 256]               0
       Bottleneck-67             [-1, 512, 256]               0
      BatchNorm1d-68             [-1, 512, 256]           1,024
             ReLU-69             [-1, 512, 256]               0
          Dropout-70             [-1, 512, 256]               0
           Conv1d-71            [-1, 1024, 256]          66,560
  MyConv1dPadSame-72            [-1, 1024, 256]               0
      BatchNorm1d-73            [-1, 1024, 256]           2,048
             ReLU-74            [-1, 1024, 256]               0
          Dropout-75            [-1, 1024, 256]               0
           Conv1d-76            [-1, 1024, 256]         132,096
  MyConv1dPadSame-77            [-1, 1024, 256]               0
       Bottleneck-78            [-1, 1024, 256]               0
      BatchNorm1d-79            [-1, 1024, 256]           2,048
             ReLU-80            [-1, 1024, 256]               0
          Dropout-81            [-1, 1024, 256]               0
           Conv1d-82            [-1, 1024, 256]         132,096
  MyConv1dPadSame-83            [-1, 1024, 256]               0
      BatchNorm1d-84            [-1, 1024, 256]           2,048
             ReLU-85            [-1, 1024, 256]               0
          Dropout-86            [-1, 1024, 256]               0
           Conv1d-87            [-1, 1024, 256]         132,096
  MyConv1dPadSame-88            [-1, 1024, 256]               0
       Bottleneck-89            [-1, 1024, 256]               0
      BatchNorm1d-90            [-1, 1024, 256]           2,048
             ReLU-91            [-1, 1024, 256]               0
           Linear-92                    [-1, 2]           2,050
================================================================
Total params: 637,826
Trainable params: 637,826
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 81.50
Params size (MB): 2.43
Estimated Total Size (MB): 83.93
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 256, base_filters: 128, kernel_size: 16, n_block: 16
************************************************************
************************************************************
(2000, 1, 256) Counter({1: 1000, 0: 1000})
(2000, 1, 256) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 128, 256]           2,176
   MyConv1dPadSame-2             [-1, 128, 256]               0
       BatchNorm1d-3             [-1, 128, 256]             256
              ReLU-4             [-1, 128, 256]               0
            Conv1d-5             [-1, 128, 256]           2,176
   MyConv1dPadSame-6             [-1, 128, 256]               0
       BatchNorm1d-7             [-1, 128, 256]             256
              ReLU-8             [-1, 128, 256]               0
           Dropout-9             [-1, 128, 256]               0
           Conv1d-10             [-1, 128, 256]           2,176
  MyConv1dPadSame-11             [-1, 128, 256]               0
       Bottleneck-12             [-1, 128, 256]               0
      BatchNorm1d-13             [-1, 128, 256]             256
             ReLU-14             [-1, 128, 256]               0
          Dropout-15             [-1, 128, 256]               0
           Conv1d-16             [-1, 128, 128]           2,176
  MyConv1dPadSame-17             [-1, 128, 128]               0
      BatchNorm1d-18             [-1, 128, 128]             256
             ReLU-19             [-1, 128, 128]               0
          Dropout-20             [-1, 128, 128]               0
           Conv1d-21             [-1, 128, 128]           2,176
  MyConv1dPadSame-22             [-1, 128, 128]               0
        MaxPool1d-23             [-1, 128, 128]               0
MyMaxPool1dPadSame-24             [-1, 128, 128]               0
       Bottleneck-25             [-1, 128, 128]               0
      BatchNorm1d-26             [-1, 128, 128]             256
             ReLU-27             [-1, 128, 128]               0
          Dropout-28             [-1, 128, 128]               0
           Conv1d-29             [-1, 128, 128]           2,176
  MyConv1dPadSame-30             [-1, 128, 128]               0
      BatchNorm1d-31             [-1, 128, 128]             256
             ReLU-32             [-1, 128, 128]               0
          Dropout-33             [-1, 128, 128]               0
           Conv1d-34             [-1, 128, 128]           2,176
  MyConv1dPadSame-35             [-1, 128, 128]               0
       Bottleneck-36             [-1, 128, 128]               0
      BatchNorm1d-37             [-1, 128, 128]             256
             ReLU-38             [-1, 128, 128]               0
          Dropout-39             [-1, 128, 128]               0
           Conv1d-40              [-1, 128, 64]           2,176
  MyConv1dPadSame-41              [-1, 128, 64]               0
      BatchNorm1d-42              [-1, 128, 64]             256
             ReLU-43              [-1, 128, 64]               0
          Dropout-44              [-1, 128, 64]               0
           Conv1d-45              [-1, 128, 64]           2,176
  MyConv1dPadSame-46              [-1, 128, 64]               0
        MaxPool1d-47              [-1, 128, 64]               0
MyMaxPool1dPadSame-48              [-1, 128, 64]               0
       Bottleneck-49              [-1, 128, 64]               0
      BatchNorm1d-50              [-1, 128, 64]             256
             ReLU-51              [-1, 128, 64]               0
          Dropout-52              [-1, 128, 64]               0
           Conv1d-53              [-1, 256, 64]           4,352
  MyConv1dPadSame-54              [-1, 256, 64]               0
      BatchNorm1d-55              [-1, 256, 64]             512
             ReLU-56              [-1, 256, 64]               0
          Dropout-57              [-1, 256, 64]               0
           Conv1d-58              [-1, 256, 64]           8,448
  MyConv1dPadSame-59              [-1, 256, 64]               0
       Bottleneck-60              [-1, 256, 64]               0
      BatchNorm1d-61              [-1, 256, 64]             512
             ReLU-62              [-1, 256, 64]               0
          Dropout-63              [-1, 256, 64]               0
           Conv1d-64              [-1, 256, 32]           8,448
  MyConv1dPadSame-65              [-1, 256, 32]               0
      BatchNorm1d-66              [-1, 256, 32]             512
             ReLU-67              [-1, 256, 32]               0
          Dropout-68              [-1, 256, 32]               0
           Conv1d-69              [-1, 256, 32]           8,448
  MyConv1dPadSame-70              [-1, 256, 32]               0
        MaxPool1d-71              [-1, 256, 32]               0
MyMaxPool1dPadSame-72              [-1, 256, 32]               0
       Bottleneck-73              [-1, 256, 32]               0
      BatchNorm1d-74              [-1, 256, 32]             512
             ReLU-75              [-1, 256, 32]               0
          Dropout-76              [-1, 256, 32]               0
           Conv1d-77              [-1, 256, 32]           8,448
  MyConv1dPadSame-78              [-1, 256, 32]               0
      BatchNorm1d-79              [-1, 256, 32]             512
             ReLU-80              [-1, 256, 32]               0
          Dropout-81              [-1, 256, 32]               0
           Conv1d-82              [-1, 256, 32]           8,448
  MyConv1dPadSame-83              [-1, 256, 32]               0
       Bottleneck-84              [-1, 256, 32]               0
      BatchNorm1d-85              [-1, 256, 32]             512
             ReLU-86              [-1, 256, 32]               0
          Dropout-87              [-1, 256, 32]               0
           Conv1d-88              [-1, 256, 16]           8,448
  MyConv1dPadSame-89              [-1, 256, 16]               0
      BatchNorm1d-90              [-1, 256, 16]             512
             ReLU-91              [-1, 256, 16]               0
          Dropout-92              [-1, 256, 16]               0
           Conv1d-93              [-1, 256, 16]           8,448
  MyConv1dPadSame-94              [-1, 256, 16]               0
        MaxPool1d-95              [-1, 256, 16]               0
MyMaxPool1dPadSame-96              [-1, 256, 16]               0
       Bottleneck-97              [-1, 256, 16]               0
      BatchNorm1d-98              [-1, 256, 16]             512
             ReLU-99              [-1, 256, 16]               0
         Dropout-100              [-1, 256, 16]               0
          Conv1d-101              [-1, 512, 16]          16,896
 MyConv1dPadSame-102              [-1, 512, 16]               0
     BatchNorm1d-103              [-1, 512, 16]           1,024
            ReLU-104              [-1, 512, 16]               0
         Dropout-105              [-1, 512, 16]               0
          Conv1d-106              [-1, 512, 16]          33,280
 MyConv1dPadSame-107              [-1, 512, 16]               0
      Bottleneck-108              [-1, 512, 16]               0
     BatchNorm1d-109              [-1, 512, 16]           1,024
            ReLU-110              [-1, 512, 16]               0
         Dropout-111              [-1, 512, 16]               0
          Conv1d-112               [-1, 512, 8]          33,280
 MyConv1dPadSame-113               [-1, 512, 8]               0
     BatchNorm1d-114               [-1, 512, 8]           1,024
            ReLU-115               [-1, 512, 8]               0
         Dropout-116               [-1, 512, 8]               0
          Conv1d-117               [-1, 512, 8]          33,280
 MyConv1dPadSame-118               [-1, 512, 8]               0
       MaxPool1d-119               [-1, 512, 8]               0
MyMaxPool1dPadSame-120               [-1, 512, 8]               0
      Bottleneck-121               [-1, 512, 8]               0
     BatchNorm1d-122               [-1, 512, 8]           1,024
            ReLU-123               [-1, 512, 8]               0
         Dropout-124               [-1, 512, 8]               0
          Conv1d-125               [-1, 512, 8]          33,280
 MyConv1dPadSame-126               [-1, 512, 8]               0
     BatchNorm1d-127               [-1, 512, 8]           1,024
            ReLU-128               [-1, 512, 8]               0
         Dropout-129               [-1, 512, 8]               0
          Conv1d-130               [-1, 512, 8]          33,280
 MyConv1dPadSame-131               [-1, 512, 8]               0
      Bottleneck-132               [-1, 512, 8]               0
     BatchNorm1d-133               [-1, 512, 8]           1,024
            ReLU-134               [-1, 512, 8]               0
         Dropout-135               [-1, 512, 8]               0
          Conv1d-136               [-1, 512, 4]          33,280
 MyConv1dPadSame-137               [-1, 512, 4]               0
     BatchNorm1d-138               [-1, 512, 4]           1,024
            ReLU-139               [-1, 512, 4]               0
         Dropout-140               [-1, 512, 4]               0
          Conv1d-141               [-1, 512, 4]          33,280
 MyConv1dPadSame-142               [-1, 512, 4]               0
       MaxPool1d-143               [-1, 512, 4]               0
MyMaxPool1dPadSame-144               [-1, 512, 4]               0
      Bottleneck-145               [-1, 512, 4]               0
     BatchNorm1d-146               [-1, 512, 4]           1,024
            ReLU-147               [-1, 512, 4]               0
         Dropout-148               [-1, 512, 4]               0
          Conv1d-149              [-1, 1024, 4]          66,560
 MyConv1dPadSame-150              [-1, 1024, 4]               0
     BatchNorm1d-151              [-1, 1024, 4]           2,048
            ReLU-152              [-1, 1024, 4]               0
         Dropout-153              [-1, 1024, 4]               0
          Conv1d-154              [-1, 1024, 4]         132,096
 MyConv1dPadSame-155              [-1, 1024, 4]               0
      Bottleneck-156              [-1, 1024, 4]               0
     BatchNorm1d-157              [-1, 1024, 4]           2,048
            ReLU-158              [-1, 1024, 4]               0
         Dropout-159              [-1, 1024, 4]               0
          Conv1d-160              [-1, 1024, 2]         132,096
 MyConv1dPadSame-161              [-1, 1024, 2]               0
     BatchNorm1d-162              [-1, 1024, 2]           2,048
            ReLU-163              [-1, 1024, 2]               0
         Dropout-164              [-1, 1024, 2]               0
          Conv1d-165              [-1, 1024, 2]         132,096
 MyConv1dPadSame-166              [-1, 1024, 2]               0
       MaxPool1d-167              [-1, 1024, 2]               0
MyMaxPool1dPadSame-168              [-1, 1024, 2]               0
      Bottleneck-169              [-1, 1024, 2]               0
     BatchNorm1d-170              [-1, 1024, 2]           2,048
            ReLU-171              [-1, 1024, 2]               0
         Dropout-172              [-1, 1024, 2]               0
          Conv1d-173              [-1, 1024, 2]         132,096
 MyConv1dPadSame-174              [-1, 1024, 2]               0
     BatchNorm1d-175              [-1, 1024, 2]           2,048
            ReLU-176              [-1, 1024, 2]               0
         Dropout-177              [-1, 1024, 2]               0
          Conv1d-178              [-1, 1024, 2]         132,096
 MyConv1dPadSame-179              [-1, 1024, 2]               0
      Bottleneck-180              [-1, 1024, 2]               0
     BatchNorm1d-181              [-1, 1024, 2]           2,048
            ReLU-182              [-1, 1024, 2]               0
         Dropout-183              [-1, 1024, 2]               0
          Conv1d-184              [-1, 1024, 1]         132,096
 MyConv1dPadSame-185              [-1, 1024, 1]               0
     BatchNorm1d-186              [-1, 1024, 1]           2,048
            ReLU-187              [-1, 1024, 1]               0
         Dropout-188              [-1, 1024, 1]               0
          Conv1d-189              [-1, 1024, 1]         132,096
 MyConv1dPadSame-190              [-1, 1024, 1]               0
       MaxPool1d-191              [-1, 1024, 1]               0
MyMaxPool1dPadSame-192              [-1, 1024, 1]               0
      Bottleneck-193              [-1, 1024, 1]               0
     BatchNorm1d-194              [-1, 1024, 1]           2,048
            ReLU-195              [-1, 1024, 1]               0
          Linear-196                    [-1, 2]           2,050
================================================================
Total params: 1,357,186
Trainable params: 1,357,186
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 13.30
Params size (MB): 5.18
Estimated Total Size (MB): 18.48
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 8, kernel_size: 2, n_block: 2
************************************************************
************************************************************
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 8, 1024]              24
   MyConv1dPadSame-2              [-1, 8, 1024]               0
       BatchNorm1d-3              [-1, 8, 1024]              16
              ReLU-4              [-1, 8, 1024]               0
            Conv1d-5              [-1, 8, 1024]              24
   MyConv1dPadSame-6              [-1, 8, 1024]               0
       BatchNorm1d-7              [-1, 8, 1024]              16
              ReLU-8              [-1, 8, 1024]               0
           Dropout-9              [-1, 8, 1024]               0
           Conv1d-10              [-1, 8, 1024]              24
  MyConv1dPadSame-11              [-1, 8, 1024]               0
       Bottleneck-12              [-1, 8, 1024]               0
      BatchNorm1d-13              [-1, 8, 1024]              16
             ReLU-14              [-1, 8, 1024]               0
          Dropout-15              [-1, 8, 1024]               0
           Conv1d-16             [-1, 16, 1024]              48
  MyConv1dPadSame-17             [-1, 16, 1024]               0
      BatchNorm1d-18             [-1, 16, 1024]              32
             ReLU-19             [-1, 16, 1024]               0
          Dropout-20             [-1, 16, 1024]               0
           Conv1d-21             [-1, 16, 1024]              80
  MyConv1dPadSame-22             [-1, 16, 1024]               0
       Bottleneck-23             [-1, 16, 1024]               0
      BatchNorm1d-24             [-1, 16, 1024]              32
             ReLU-25             [-1, 16, 1024]               0
           Linear-26                    [-1, 2]              34
================================================================
Total params: 346
Trainable params: 346
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 2.19
Params size (MB): 0.00
Estimated Total Size (MB): 2.19
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 8, kernel_size: 2, n_block: 4
************************************************************
************************************************************
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 8, 1024]              24
   MyConv1dPadSame-2              [-1, 8, 1024]               0
       BatchNorm1d-3              [-1, 8, 1024]              16
              ReLU-4              [-1, 8, 1024]               0
            Conv1d-5              [-1, 8, 1024]              24
   MyConv1dPadSame-6              [-1, 8, 1024]               0
       BatchNorm1d-7              [-1, 8, 1024]              16
              ReLU-8              [-1, 8, 1024]               0
           Dropout-9              [-1, 8, 1024]               0
           Conv1d-10              [-1, 8, 1024]              24
  MyConv1dPadSame-11              [-1, 8, 1024]               0
       Bottleneck-12              [-1, 8, 1024]               0
      BatchNorm1d-13              [-1, 8, 1024]              16
             ReLU-14              [-1, 8, 1024]               0
          Dropout-15              [-1, 8, 1024]               0
           Conv1d-16             [-1, 16, 1024]              48
  MyConv1dPadSame-17             [-1, 16, 1024]               0
      BatchNorm1d-18             [-1, 16, 1024]              32
             ReLU-19             [-1, 16, 1024]               0
          Dropout-20             [-1, 16, 1024]               0
           Conv1d-21             [-1, 16, 1024]              80
  MyConv1dPadSame-22             [-1, 16, 1024]               0
       Bottleneck-23             [-1, 16, 1024]               0
      BatchNorm1d-24             [-1, 16, 1024]              32
             ReLU-25             [-1, 16, 1024]               0
          Dropout-26             [-1, 16, 1024]               0
           Conv1d-27             [-1, 32, 1024]             160
  MyConv1dPadSame-28             [-1, 32, 1024]               0
      BatchNorm1d-29             [-1, 32, 1024]              64
             ReLU-30             [-1, 32, 1024]               0
          Dropout-31             [-1, 32, 1024]               0
           Conv1d-32             [-1, 32, 1024]             288
  MyConv1dPadSame-33             [-1, 32, 1024]               0
       Bottleneck-34             [-1, 32, 1024]               0
      BatchNorm1d-35             [-1, 32, 1024]              64
             ReLU-36             [-1, 32, 1024]               0
          Dropout-37             [-1, 32, 1024]               0
           Conv1d-38             [-1, 64, 1024]             576
  MyConv1dPadSame-39             [-1, 64, 1024]               0
      BatchNorm1d-40             [-1, 64, 1024]             128
             ReLU-41             [-1, 64, 1024]               0
          Dropout-42             [-1, 64, 1024]               0
           Conv1d-43             [-1, 64, 1024]           1,088
  MyConv1dPadSame-44             [-1, 64, 1024]               0
       Bottleneck-45             [-1, 64, 1024]               0
      BatchNorm1d-46             [-1, 64, 1024]             128
             ReLU-47             [-1, 64, 1024]               0
           Linear-48                    [-1, 2]             130
================================================================
Total params: 2,938
Trainable params: 2,938
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 10.06
Params size (MB): 0.01
Estimated Total Size (MB): 10.08
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 8, kernel_size: 2, n_block: 8
************************************************************
************************************************************
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 8, 1024]              24
   MyConv1dPadSame-2              [-1, 8, 1024]               0
       BatchNorm1d-3              [-1, 8, 1024]              16
              ReLU-4              [-1, 8, 1024]               0
            Conv1d-5              [-1, 8, 1024]              24
   MyConv1dPadSame-6              [-1, 8, 1024]               0
       BatchNorm1d-7              [-1, 8, 1024]              16
              ReLU-8              [-1, 8, 1024]               0
           Dropout-9              [-1, 8, 1024]               0
           Conv1d-10              [-1, 8, 1024]              24
  MyConv1dPadSame-11              [-1, 8, 1024]               0
       Bottleneck-12              [-1, 8, 1024]               0
      BatchNorm1d-13              [-1, 8, 1024]              16
             ReLU-14              [-1, 8, 1024]               0
          Dropout-15              [-1, 8, 1024]               0
           Conv1d-16              [-1, 8, 1024]              24
  MyConv1dPadSame-17              [-1, 8, 1024]               0
      BatchNorm1d-18              [-1, 8, 1024]              16
             ReLU-19              [-1, 8, 1024]               0
          Dropout-20              [-1, 8, 1024]               0
           Conv1d-21              [-1, 8, 1024]              24
  MyConv1dPadSame-22              [-1, 8, 1024]               0
       Bottleneck-23              [-1, 8, 1024]               0
      BatchNorm1d-24              [-1, 8, 1024]              16
             ReLU-25              [-1, 8, 1024]               0
          Dropout-26              [-1, 8, 1024]               0
           Conv1d-27             [-1, 16, 1024]              48
  MyConv1dPadSame-28             [-1, 16, 1024]               0
      BatchNorm1d-29             [-1, 16, 1024]              32
             ReLU-30             [-1, 16, 1024]               0
          Dropout-31             [-1, 16, 1024]               0
           Conv1d-32             [-1, 16, 1024]              80
  MyConv1dPadSame-33             [-1, 16, 1024]               0
       Bottleneck-34             [-1, 16, 1024]               0
      BatchNorm1d-35             [-1, 16, 1024]              32
             ReLU-36             [-1, 16, 1024]               0
          Dropout-37             [-1, 16, 1024]               0
           Conv1d-38             [-1, 16, 1024]              80
  MyConv1dPadSame-39             [-1, 16, 1024]               0
      BatchNorm1d-40             [-1, 16, 1024]              32
             ReLU-41             [-1, 16, 1024]               0
          Dropout-42             [-1, 16, 1024]               0
           Conv1d-43             [-1, 16, 1024]              80
  MyConv1dPadSame-44             [-1, 16, 1024]               0
       Bottleneck-45             [-1, 16, 1024]               0
      BatchNorm1d-46             [-1, 16, 1024]              32
             ReLU-47             [-1, 16, 1024]               0
          Dropout-48             [-1, 16, 1024]               0
           Conv1d-49             [-1, 32, 1024]             160
  MyConv1dPadSame-50             [-1, 32, 1024]               0
      BatchNorm1d-51             [-1, 32, 1024]              64
             ReLU-52             [-1, 32, 1024]               0
          Dropout-53             [-1, 32, 1024]               0
           Conv1d-54             [-1, 32, 1024]             288
  MyConv1dPadSame-55             [-1, 32, 1024]               0
       Bottleneck-56             [-1, 32, 1024]               0
      BatchNorm1d-57             [-1, 32, 1024]              64
             ReLU-58             [-1, 32, 1024]               0
          Dropout-59             [-1, 32, 1024]               0
           Conv1d-60             [-1, 32, 1024]             288
  MyConv1dPadSame-61             [-1, 32, 1024]               0
      BatchNorm1d-62             [-1, 32, 1024]              64
             ReLU-63             [-1, 32, 1024]               0
          Dropout-64             [-1, 32, 1024]               0
           Conv1d-65             [-1, 32, 1024]             288
  MyConv1dPadSame-66             [-1, 32, 1024]               0
       Bottleneck-67             [-1, 32, 1024]               0
      BatchNorm1d-68             [-1, 32, 1024]              64
             ReLU-69             [-1, 32, 1024]               0
          Dropout-70             [-1, 32, 1024]               0
           Conv1d-71             [-1, 64, 1024]             576
  MyConv1dPadSame-72             [-1, 64, 1024]               0
      BatchNorm1d-73             [-1, 64, 1024]             128
             ReLU-74             [-1, 64, 1024]               0
          Dropout-75             [-1, 64, 1024]               0
           Conv1d-76             [-1, 64, 1024]           1,088
  MyConv1dPadSame-77             [-1, 64, 1024]               0
       Bottleneck-78             [-1, 64, 1024]               0
      BatchNorm1d-79             [-1, 64, 1024]             128
             ReLU-80             [-1, 64, 1024]               0
          Dropout-81             [-1, 64, 1024]               0
           Conv1d-82             [-1, 64, 1024]           1,088
  MyConv1dPadSame-83             [-1, 64, 1024]               0
      BatchNorm1d-84             [-1, 64, 1024]             128
             ReLU-85             [-1, 64, 1024]               0
          Dropout-86             [-1, 64, 1024]               0
           Conv1d-87             [-1, 64, 1024]           1,088
  MyConv1dPadSame-88             [-1, 64, 1024]               0
       Bottleneck-89             [-1, 64, 1024]               0
      BatchNorm1d-90             [-1, 64, 1024]             128
             ReLU-91             [-1, 64, 1024]               0
           Linear-92                    [-1, 2]             130
================================================================
Total params: 6,378
Trainable params: 6,378
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 20.38
Params size (MB): 0.02
Estimated Total Size (MB): 20.40
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 8, kernel_size: 2, n_block: 16
************************************************************
************************************************************
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 8, 1024]              24
   MyConv1dPadSame-2              [-1, 8, 1024]               0
       BatchNorm1d-3              [-1, 8, 1024]              16
              ReLU-4              [-1, 8, 1024]               0
            Conv1d-5              [-1, 8, 1024]              24
   MyConv1dPadSame-6              [-1, 8, 1024]               0
       BatchNorm1d-7              [-1, 8, 1024]              16
              ReLU-8              [-1, 8, 1024]               0
           Dropout-9              [-1, 8, 1024]               0
           Conv1d-10              [-1, 8, 1024]              24
  MyConv1dPadSame-11              [-1, 8, 1024]               0
       Bottleneck-12              [-1, 8, 1024]               0
      BatchNorm1d-13              [-1, 8, 1024]              16
             ReLU-14              [-1, 8, 1024]               0
          Dropout-15              [-1, 8, 1024]               0
           Conv1d-16               [-1, 8, 512]              24
  MyConv1dPadSame-17               [-1, 8, 512]               0
      BatchNorm1d-18               [-1, 8, 512]              16
             ReLU-19               [-1, 8, 512]               0
          Dropout-20               [-1, 8, 512]               0
           Conv1d-21               [-1, 8, 512]              24
  MyConv1dPadSame-22               [-1, 8, 512]               0
        MaxPool1d-23               [-1, 8, 512]               0
MyMaxPool1dPadSame-24               [-1, 8, 512]               0
       Bottleneck-25               [-1, 8, 512]               0
      BatchNorm1d-26               [-1, 8, 512]              16
             ReLU-27               [-1, 8, 512]               0
          Dropout-28               [-1, 8, 512]               0
           Conv1d-29               [-1, 8, 512]              24
  MyConv1dPadSame-30               [-1, 8, 512]               0
      BatchNorm1d-31               [-1, 8, 512]              16
             ReLU-32               [-1, 8, 512]               0
          Dropout-33               [-1, 8, 512]               0
           Conv1d-34               [-1, 8, 512]              24
  MyConv1dPadSame-35               [-1, 8, 512]               0
       Bottleneck-36               [-1, 8, 512]               0
      BatchNorm1d-37               [-1, 8, 512]              16
             ReLU-38               [-1, 8, 512]               0
          Dropout-39               [-1, 8, 512]               0
           Conv1d-40               [-1, 8, 256]              24
  MyConv1dPadSame-41               [-1, 8, 256]               0
      BatchNorm1d-42               [-1, 8, 256]              16
             ReLU-43               [-1, 8, 256]               0
          Dropout-44               [-1, 8, 256]               0
           Conv1d-45               [-1, 8, 256]              24
  MyConv1dPadSame-46               [-1, 8, 256]               0
        MaxPool1d-47               [-1, 8, 256]               0
MyMaxPool1dPadSame-48               [-1, 8, 256]               0
       Bottleneck-49               [-1, 8, 256]               0
      BatchNorm1d-50               [-1, 8, 256]              16
             ReLU-51               [-1, 8, 256]               0
          Dropout-52               [-1, 8, 256]               0
           Conv1d-53              [-1, 16, 256]              48
  MyConv1dPadSame-54              [-1, 16, 256]               0
      BatchNorm1d-55              [-1, 16, 256]              32
             ReLU-56              [-1, 16, 256]               0
          Dropout-57              [-1, 16, 256]               0
           Conv1d-58              [-1, 16, 256]              80
  MyConv1dPadSame-59              [-1, 16, 256]               0
       Bottleneck-60              [-1, 16, 256]               0
      BatchNorm1d-61              [-1, 16, 256]              32
             ReLU-62              [-1, 16, 256]               0
          Dropout-63              [-1, 16, 256]               0
           Conv1d-64              [-1, 16, 128]              80
  MyConv1dPadSame-65              [-1, 16, 128]               0
      BatchNorm1d-66              [-1, 16, 128]              32
             ReLU-67              [-1, 16, 128]               0
          Dropout-68              [-1, 16, 128]               0
           Conv1d-69              [-1, 16, 128]              80
  MyConv1dPadSame-70              [-1, 16, 128]               0
        MaxPool1d-71              [-1, 16, 128]               0
MyMaxPool1dPadSame-72              [-1, 16, 128]               0
       Bottleneck-73              [-1, 16, 128]               0
      BatchNorm1d-74              [-1, 16, 128]              32
             ReLU-75              [-1, 16, 128]               0
          Dropout-76              [-1, 16, 128]               0
           Conv1d-77              [-1, 16, 128]              80
  MyConv1dPadSame-78              [-1, 16, 128]               0
      BatchNorm1d-79              [-1, 16, 128]              32
             ReLU-80              [-1, 16, 128]               0
          Dropout-81              [-1, 16, 128]               0
           Conv1d-82              [-1, 16, 128]              80
  MyConv1dPadSame-83              [-1, 16, 128]               0
       Bottleneck-84              [-1, 16, 128]               0
      BatchNorm1d-85              [-1, 16, 128]              32
             ReLU-86              [-1, 16, 128]               0
          Dropout-87              [-1, 16, 128]               0
           Conv1d-88               [-1, 16, 64]              80
  MyConv1dPadSame-89               [-1, 16, 64]               0
      BatchNorm1d-90               [-1, 16, 64]              32
             ReLU-91               [-1, 16, 64]               0
          Dropout-92               [-1, 16, 64]               0
           Conv1d-93               [-1, 16, 64]              80
  MyConv1dPadSame-94               [-1, 16, 64]               0
        MaxPool1d-95               [-1, 16, 64]               0
MyMaxPool1dPadSame-96               [-1, 16, 64]               0
       Bottleneck-97               [-1, 16, 64]               0
      BatchNorm1d-98               [-1, 16, 64]              32
             ReLU-99               [-1, 16, 64]               0
         Dropout-100               [-1, 16, 64]               0
          Conv1d-101               [-1, 32, 64]             160
 MyConv1dPadSame-102               [-1, 32, 64]               0
     BatchNorm1d-103               [-1, 32, 64]              64
            ReLU-104               [-1, 32, 64]               0
         Dropout-105               [-1, 32, 64]               0
          Conv1d-106               [-1, 32, 64]             288
 MyConv1dPadSame-107               [-1, 32, 64]               0
      Bottleneck-108               [-1, 32, 64]               0
     BatchNorm1d-109               [-1, 32, 64]              64
            ReLU-110               [-1, 32, 64]               0
         Dropout-111               [-1, 32, 64]               0
          Conv1d-112               [-1, 32, 32]             288
 MyConv1dPadSame-113               [-1, 32, 32]               0
     BatchNorm1d-114               [-1, 32, 32]              64
            ReLU-115               [-1, 32, 32]               0
         Dropout-116               [-1, 32, 32]               0
          Conv1d-117               [-1, 32, 32]             288
 MyConv1dPadSame-118               [-1, 32, 32]               0
       MaxPool1d-119               [-1, 32, 32]               0
MyMaxPool1dPadSame-120               [-1, 32, 32]               0
      Bottleneck-121               [-1, 32, 32]               0
     BatchNorm1d-122               [-1, 32, 32]              64
            ReLU-123               [-1, 32, 32]               0
         Dropout-124               [-1, 32, 32]               0
          Conv1d-125               [-1, 32, 32]             288
 MyConv1dPadSame-126               [-1, 32, 32]               0
     BatchNorm1d-127               [-1, 32, 32]              64
            ReLU-128               [-1, 32, 32]               0
         Dropout-129               [-1, 32, 32]               0
          Conv1d-130               [-1, 32, 32]             288
 MyConv1dPadSame-131               [-1, 32, 32]               0
      Bottleneck-132               [-1, 32, 32]               0
     BatchNorm1d-133               [-1, 32, 32]              64
            ReLU-134               [-1, 32, 32]               0
         Dropout-135               [-1, 32, 32]               0
          Conv1d-136               [-1, 32, 16]             288
 MyConv1dPadSame-137               [-1, 32, 16]               0
     BatchNorm1d-138               [-1, 32, 16]              64
            ReLU-139               [-1, 32, 16]               0
         Dropout-140               [-1, 32, 16]               0
          Conv1d-141               [-1, 32, 16]             288
 MyConv1dPadSame-142               [-1, 32, 16]               0
       MaxPool1d-143               [-1, 32, 16]               0
MyMaxPool1dPadSame-144               [-1, 32, 16]               0
      Bottleneck-145               [-1, 32, 16]               0
     BatchNorm1d-146               [-1, 32, 16]              64
            ReLU-147               [-1, 32, 16]               0
         Dropout-148               [-1, 32, 16]               0
          Conv1d-149               [-1, 64, 16]             576
 MyConv1dPadSame-150               [-1, 64, 16]               0
     BatchNorm1d-151               [-1, 64, 16]             128
            ReLU-152               [-1, 64, 16]               0
         Dropout-153               [-1, 64, 16]               0
          Conv1d-154               [-1, 64, 16]           1,088
 MyConv1dPadSame-155               [-1, 64, 16]               0
      Bottleneck-156               [-1, 64, 16]               0
     BatchNorm1d-157               [-1, 64, 16]             128
            ReLU-158               [-1, 64, 16]               0
         Dropout-159               [-1, 64, 16]               0
          Conv1d-160                [-1, 64, 8]           1,088
 MyConv1dPadSame-161                [-1, 64, 8]               0
     BatchNorm1d-162                [-1, 64, 8]             128
            ReLU-163                [-1, 64, 8]               0
         Dropout-164                [-1, 64, 8]               0
          Conv1d-165                [-1, 64, 8]           1,088
 MyConv1dPadSame-166                [-1, 64, 8]               0
       MaxPool1d-167                [-1, 64, 8]               0
MyMaxPool1dPadSame-168                [-1, 64, 8]               0
      Bottleneck-169                [-1, 64, 8]               0
     BatchNorm1d-170                [-1, 64, 8]             128
            ReLU-171                [-1, 64, 8]               0
         Dropout-172                [-1, 64, 8]               0
          Conv1d-173                [-1, 64, 8]           1,088
 MyConv1dPadSame-174                [-1, 64, 8]               0
     BatchNorm1d-175                [-1, 64, 8]             128
            ReLU-176                [-1, 64, 8]               0
         Dropout-177                [-1, 64, 8]               0
          Conv1d-178                [-1, 64, 8]           1,088
 MyConv1dPadSame-179                [-1, 64, 8]               0
      Bottleneck-180                [-1, 64, 8]               0
     BatchNorm1d-181                [-1, 64, 8]             128
            ReLU-182                [-1, 64, 8]               0
         Dropout-183                [-1, 64, 8]               0
          Conv1d-184                [-1, 64, 4]           1,088
 MyConv1dPadSame-185                [-1, 64, 4]               0
     BatchNorm1d-186                [-1, 64, 4]             128
            ReLU-187                [-1, 64, 4]               0
         Dropout-188                [-1, 64, 4]               0
          Conv1d-189                [-1, 64, 4]           1,088
 MyConv1dPadSame-190                [-1, 64, 4]               0
       MaxPool1d-191                [-1, 64, 4]               0
MyMaxPool1dPadSame-192                [-1, 64, 4]               0
      Bottleneck-193                [-1, 64, 4]               0
     BatchNorm1d-194                [-1, 64, 4]             128
            ReLU-195                [-1, 64, 4]               0
          Linear-196                    [-1, 2]             130
================================================================
Total params: 13,258
Trainable params: 13,258
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 3.32
Params size (MB): 0.05
Estimated Total Size (MB): 3.38
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 8, kernel_size: 4, n_block: 2
************************************************************
************************************************************
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 8, 1024]              40
   MyConv1dPadSame-2              [-1, 8, 1024]               0
       BatchNorm1d-3              [-1, 8, 1024]              16
              ReLU-4              [-1, 8, 1024]               0
            Conv1d-5              [-1, 8, 1024]              40
   MyConv1dPadSame-6              [-1, 8, 1024]               0
       BatchNorm1d-7              [-1, 8, 1024]              16
              ReLU-8              [-1, 8, 1024]               0
           Dropout-9              [-1, 8, 1024]               0
           Conv1d-10              [-1, 8, 1024]              40
  MyConv1dPadSame-11              [-1, 8, 1024]               0
       Bottleneck-12              [-1, 8, 1024]               0
      BatchNorm1d-13              [-1, 8, 1024]              16
             ReLU-14              [-1, 8, 1024]               0
          Dropout-15              [-1, 8, 1024]               0
           Conv1d-16             [-1, 16, 1024]              80
  MyConv1dPadSame-17             [-1, 16, 1024]               0
      BatchNorm1d-18             [-1, 16, 1024]              32
             ReLU-19             [-1, 16, 1024]               0
          Dropout-20             [-1, 16, 1024]               0
           Conv1d-21             [-1, 16, 1024]             144
  MyConv1dPadSame-22             [-1, 16, 1024]               0
       Bottleneck-23             [-1, 16, 1024]               0
      BatchNorm1d-24             [-1, 16, 1024]              32
             ReLU-25             [-1, 16, 1024]               0
           Linear-26                    [-1, 2]              34
================================================================
Total params: 490
Trainable params: 490
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 2.19
Params size (MB): 0.00
Estimated Total Size (MB): 2.19
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 8, kernel_size: 4, n_block: 4
************************************************************
************************************************************
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 8, 1024]              40
   MyConv1dPadSame-2              [-1, 8, 1024]               0
       BatchNorm1d-3              [-1, 8, 1024]              16
              ReLU-4              [-1, 8, 1024]               0
            Conv1d-5              [-1, 8, 1024]              40
   MyConv1dPadSame-6              [-1, 8, 1024]               0
       BatchNorm1d-7              [-1, 8, 1024]              16
              ReLU-8              [-1, 8, 1024]               0
           Dropout-9              [-1, 8, 1024]               0
           Conv1d-10              [-1, 8, 1024]              40
  MyConv1dPadSame-11              [-1, 8, 1024]               0
       Bottleneck-12              [-1, 8, 1024]               0
      BatchNorm1d-13              [-1, 8, 1024]              16
             ReLU-14              [-1, 8, 1024]               0
          Dropout-15              [-1, 8, 1024]               0
           Conv1d-16             [-1, 16, 1024]              80
  MyConv1dPadSame-17             [-1, 16, 1024]               0
      BatchNorm1d-18             [-1, 16, 1024]              32
             ReLU-19             [-1, 16, 1024]               0
          Dropout-20             [-1, 16, 1024]               0
           Conv1d-21             [-1, 16, 1024]             144
  MyConv1dPadSame-22             [-1, 16, 1024]               0
       Bottleneck-23             [-1, 16, 1024]               0
      BatchNorm1d-24             [-1, 16, 1024]              32
             ReLU-25             [-1, 16, 1024]               0
          Dropout-26             [-1, 16, 1024]               0
           Conv1d-27             [-1, 32, 1024]             288
  MyConv1dPadSame-28             [-1, 32, 1024]               0
      BatchNorm1d-29             [-1, 32, 1024]              64
             ReLU-30             [-1, 32, 1024]               0
          Dropout-31             [-1, 32, 1024]               0
           Conv1d-32             [-1, 32, 1024]             544
  MyConv1dPadSame-33             [-1, 32, 1024]               0
       Bottleneck-34             [-1, 32, 1024]               0
      BatchNorm1d-35             [-1, 32, 1024]              64
             ReLU-36             [-1, 32, 1024]               0
          Dropout-37             [-1, 32, 1024]               0
           Conv1d-38             [-1, 64, 1024]           1,088
  MyConv1dPadSame-39             [-1, 64, 1024]               0
      BatchNorm1d-40             [-1, 64, 1024]             128
             ReLU-41             [-1, 64, 1024]               0
          Dropout-42             [-1, 64, 1024]               0
           Conv1d-43             [-1, 64, 1024]           2,112
  MyConv1dPadSame-44             [-1, 64, 1024]               0
       Bottleneck-45             [-1, 64, 1024]               0
      BatchNorm1d-46             [-1, 64, 1024]             128
             ReLU-47             [-1, 64, 1024]               0
           Linear-48                    [-1, 2]             130
================================================================
Total params: 5,002
Trainable params: 5,002
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 10.06
Params size (MB): 0.02
Estimated Total Size (MB): 10.09
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 8, kernel_size: 4, n_block: 8
************************************************************
************************************************************
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 8, 1024]              40
   MyConv1dPadSame-2              [-1, 8, 1024]               0
       BatchNorm1d-3              [-1, 8, 1024]              16
              ReLU-4              [-1, 8, 1024]               0
            Conv1d-5              [-1, 8, 1024]              40
   MyConv1dPadSame-6              [-1, 8, 1024]               0
       BatchNorm1d-7              [-1, 8, 1024]              16
              ReLU-8              [-1, 8, 1024]               0
           Dropout-9              [-1, 8, 1024]               0
           Conv1d-10              [-1, 8, 1024]              40
  MyConv1dPadSame-11              [-1, 8, 1024]               0
       Bottleneck-12              [-1, 8, 1024]               0
      BatchNorm1d-13              [-1, 8, 1024]              16
             ReLU-14              [-1, 8, 1024]               0
          Dropout-15              [-1, 8, 1024]               0
           Conv1d-16              [-1, 8, 1024]              40
  MyConv1dPadSame-17              [-1, 8, 1024]               0
      BatchNorm1d-18              [-1, 8, 1024]              16
             ReLU-19              [-1, 8, 1024]               0
          Dropout-20              [-1, 8, 1024]               0
           Conv1d-21              [-1, 8, 1024]              40
  MyConv1dPadSame-22              [-1, 8, 1024]               0
       Bottleneck-23              [-1, 8, 1024]               0
      BatchNorm1d-24              [-1, 8, 1024]              16
             ReLU-25              [-1, 8, 1024]               0
          Dropout-26              [-1, 8, 1024]               0
           Conv1d-27             [-1, 16, 1024]              80
  MyConv1dPadSame-28             [-1, 16, 1024]               0
      BatchNorm1d-29             [-1, 16, 1024]              32
             ReLU-30             [-1, 16, 1024]               0
          Dropout-31             [-1, 16, 1024]               0
           Conv1d-32             [-1, 16, 1024]             144
  MyConv1dPadSame-33             [-1, 16, 1024]               0
       Bottleneck-34             [-1, 16, 1024]               0
      BatchNorm1d-35             [-1, 16, 1024]              32
             ReLU-36             [-1, 16, 1024]               0
          Dropout-37             [-1, 16, 1024]               0
           Conv1d-38             [-1, 16, 1024]             144
  MyConv1dPadSame-39             [-1, 16, 1024]               0
      BatchNorm1d-40             [-1, 16, 1024]              32
             ReLU-41             [-1, 16, 1024]               0
          Dropout-42             [-1, 16, 1024]               0
           Conv1d-43             [-1, 16, 1024]             144
  MyConv1dPadSame-44             [-1, 16, 1024]               0
       Bottleneck-45             [-1, 16, 1024]               0
      BatchNorm1d-46             [-1, 16, 1024]              32
             ReLU-47             [-1, 16, 1024]               0
          Dropout-48             [-1, 16, 1024]               0
           Conv1d-49             [-1, 32, 1024]             288
  MyConv1dPadSame-50             [-1, 32, 1024]               0
      BatchNorm1d-51             [-1, 32, 1024]              64
             ReLU-52             [-1, 32, 1024]               0
          Dropout-53             [-1, 32, 1024]               0
           Conv1d-54             [-1, 32, 1024]             544
  MyConv1dPadSame-55             [-1, 32, 1024]               0
       Bottleneck-56             [-1, 32, 1024]               0
      BatchNorm1d-57             [-1, 32, 1024]              64
             ReLU-58             [-1, 32, 1024]               0
          Dropout-59             [-1, 32, 1024]               0
           Conv1d-60             [-1, 32, 1024]             544
  MyConv1dPadSame-61             [-1, 32, 1024]               0
      BatchNorm1d-62             [-1, 32, 1024]              64
             ReLU-63             [-1, 32, 1024]               0
          Dropout-64             [-1, 32, 1024]               0
           Conv1d-65             [-1, 32, 1024]             544
  MyConv1dPadSame-66             [-1, 32, 1024]               0
       Bottleneck-67             [-1, 32, 1024]               0
      BatchNorm1d-68             [-1, 32, 1024]              64
             ReLU-69             [-1, 32, 1024]               0
          Dropout-70             [-1, 32, 1024]               0
           Conv1d-71             [-1, 64, 1024]           1,088
  MyConv1dPadSame-72             [-1, 64, 1024]               0
      BatchNorm1d-73             [-1, 64, 1024]             128
             ReLU-74             [-1, 64, 1024]               0
          Dropout-75             [-1, 64, 1024]               0
           Conv1d-76             [-1, 64, 1024]           2,112
  MyConv1dPadSame-77             [-1, 64, 1024]               0
       Bottleneck-78             [-1, 64, 1024]               0
      BatchNorm1d-79             [-1, 64, 1024]             128
             ReLU-80             [-1, 64, 1024]               0
          Dropout-81             [-1, 64, 1024]               0
           Conv1d-82             [-1, 64, 1024]           2,112
  MyConv1dPadSame-83             [-1, 64, 1024]               0
      BatchNorm1d-84             [-1, 64, 1024]             128
             ReLU-85             [-1, 64, 1024]               0
          Dropout-86             [-1, 64, 1024]               0
           Conv1d-87             [-1, 64, 1024]           2,112
  MyConv1dPadSame-88             [-1, 64, 1024]               0
       Bottleneck-89             [-1, 64, 1024]               0
      BatchNorm1d-90             [-1, 64, 1024]             128
             ReLU-91             [-1, 64, 1024]               0
           Linear-92                    [-1, 2]             130
================================================================
Total params: 11,162
Trainable params: 11,162
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 20.38
Params size (MB): 0.04
Estimated Total Size (MB): 20.42
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 8, kernel_size: 4, n_block: 16
************************************************************
************************************************************
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 8, 1024]              40
   MyConv1dPadSame-2              [-1, 8, 1024]               0
       BatchNorm1d-3              [-1, 8, 1024]              16
              ReLU-4              [-1, 8, 1024]               0
            Conv1d-5              [-1, 8, 1024]              40
   MyConv1dPadSame-6              [-1, 8, 1024]               0
       BatchNorm1d-7              [-1, 8, 1024]              16
              ReLU-8              [-1, 8, 1024]               0
           Dropout-9              [-1, 8, 1024]               0
           Conv1d-10              [-1, 8, 1024]              40
  MyConv1dPadSame-11              [-1, 8, 1024]               0
       Bottleneck-12              [-1, 8, 1024]               0
      BatchNorm1d-13              [-1, 8, 1024]              16
             ReLU-14              [-1, 8, 1024]               0
          Dropout-15              [-1, 8, 1024]               0
           Conv1d-16               [-1, 8, 512]              40
  MyConv1dPadSame-17               [-1, 8, 512]               0
      BatchNorm1d-18               [-1, 8, 512]              16
             ReLU-19               [-1, 8, 512]               0
          Dropout-20               [-1, 8, 512]               0
           Conv1d-21               [-1, 8, 512]              40
  MyConv1dPadSame-22               [-1, 8, 512]               0
        MaxPool1d-23               [-1, 8, 512]               0
MyMaxPool1dPadSame-24               [-1, 8, 512]               0
       Bottleneck-25               [-1, 8, 512]               0
      BatchNorm1d-26               [-1, 8, 512]              16
             ReLU-27               [-1, 8, 512]               0
          Dropout-28               [-1, 8, 512]               0
           Conv1d-29               [-1, 8, 512]              40
  MyConv1dPadSame-30               [-1, 8, 512]               0
      BatchNorm1d-31               [-1, 8, 512]              16
             ReLU-32               [-1, 8, 512]               0
          Dropout-33               [-1, 8, 512]               0
           Conv1d-34               [-1, 8, 512]              40
  MyConv1dPadSame-35               [-1, 8, 512]               0
       Bottleneck-36               [-1, 8, 512]               0
      BatchNorm1d-37               [-1, 8, 512]              16
             ReLU-38               [-1, 8, 512]               0
          Dropout-39               [-1, 8, 512]               0
           Conv1d-40               [-1, 8, 256]              40
  MyConv1dPadSame-41               [-1, 8, 256]               0
      BatchNorm1d-42               [-1, 8, 256]              16
             ReLU-43               [-1, 8, 256]               0
          Dropout-44               [-1, 8, 256]               0
           Conv1d-45               [-1, 8, 256]              40
  MyConv1dPadSame-46               [-1, 8, 256]               0
        MaxPool1d-47               [-1, 8, 256]               0
MyMaxPool1dPadSame-48               [-1, 8, 256]               0
       Bottleneck-49               [-1, 8, 256]               0
      BatchNorm1d-50               [-1, 8, 256]              16
             ReLU-51               [-1, 8, 256]               0
          Dropout-52               [-1, 8, 256]               0
           Conv1d-53              [-1, 16, 256]              80
  MyConv1dPadSame-54              [-1, 16, 256]               0
      BatchNorm1d-55              [-1, 16, 256]              32
             ReLU-56              [-1, 16, 256]               0
          Dropout-57              [-1, 16, 256]               0
           Conv1d-58              [-1, 16, 256]             144
  MyConv1dPadSame-59              [-1, 16, 256]               0
       Bottleneck-60              [-1, 16, 256]               0
      BatchNorm1d-61              [-1, 16, 256]              32
             ReLU-62              [-1, 16, 256]               0
          Dropout-63              [-1, 16, 256]               0
           Conv1d-64              [-1, 16, 128]             144
  MyConv1dPadSame-65              [-1, 16, 128]               0
      BatchNorm1d-66              [-1, 16, 128]              32
             ReLU-67              [-1, 16, 128]               0
          Dropout-68              [-1, 16, 128]               0
           Conv1d-69              [-1, 16, 128]             144
  MyConv1dPadSame-70              [-1, 16, 128]               0
        MaxPool1d-71              [-1, 16, 128]               0
MyMaxPool1dPadSame-72              [-1, 16, 128]               0
       Bottleneck-73              [-1, 16, 128]               0
      BatchNorm1d-74              [-1, 16, 128]              32
             ReLU-75              [-1, 16, 128]               0
          Dropout-76              [-1, 16, 128]               0
           Conv1d-77              [-1, 16, 128]             144
  MyConv1dPadSame-78              [-1, 16, 128]               0
      BatchNorm1d-79              [-1, 16, 128]              32
             ReLU-80              [-1, 16, 128]               0
          Dropout-81              [-1, 16, 128]               0
           Conv1d-82              [-1, 16, 128]             144
  MyConv1dPadSame-83              [-1, 16, 128]               0
       Bottleneck-84              [-1, 16, 128]               0
      BatchNorm1d-85              [-1, 16, 128]              32
             ReLU-86              [-1, 16, 128]               0
          Dropout-87              [-1, 16, 128]               0
           Conv1d-88               [-1, 16, 64]             144
  MyConv1dPadSame-89               [-1, 16, 64]               0
      BatchNorm1d-90               [-1, 16, 64]              32
             ReLU-91               [-1, 16, 64]               0
          Dropout-92               [-1, 16, 64]               0
           Conv1d-93               [-1, 16, 64]             144
  MyConv1dPadSame-94               [-1, 16, 64]               0
        MaxPool1d-95               [-1, 16, 64]               0
MyMaxPool1dPadSame-96               [-1, 16, 64]               0
       Bottleneck-97               [-1, 16, 64]               0
      BatchNorm1d-98               [-1, 16, 64]              32
             ReLU-99               [-1, 16, 64]               0
         Dropout-100               [-1, 16, 64]               0
          Conv1d-101               [-1, 32, 64]             288
 MyConv1dPadSame-102               [-1, 32, 64]               0
     BatchNorm1d-103               [-1, 32, 64]              64
            ReLU-104               [-1, 32, 64]               0
         Dropout-105               [-1, 32, 64]               0
          Conv1d-106               [-1, 32, 64]             544
 MyConv1dPadSame-107               [-1, 32, 64]               0
      Bottleneck-108               [-1, 32, 64]               0
     BatchNorm1d-109               [-1, 32, 64]              64
            ReLU-110               [-1, 32, 64]               0
         Dropout-111               [-1, 32, 64]               0
          Conv1d-112               [-1, 32, 32]             544
 MyConv1dPadSame-113               [-1, 32, 32]               0
     BatchNorm1d-114               [-1, 32, 32]              64
            ReLU-115               [-1, 32, 32]               0
         Dropout-116               [-1, 32, 32]               0
          Conv1d-117               [-1, 32, 32]             544
 MyConv1dPadSame-118               [-1, 32, 32]               0
       MaxPool1d-119               [-1, 32, 32]               0
MyMaxPool1dPadSame-120               [-1, 32, 32]               0
      Bottleneck-121               [-1, 32, 32]               0
     BatchNorm1d-122               [-1, 32, 32]              64
            ReLU-123               [-1, 32, 32]               0
         Dropout-124               [-1, 32, 32]               0
          Conv1d-125               [-1, 32, 32]             544
 MyConv1dPadSame-126               [-1, 32, 32]               0
     BatchNorm1d-127               [-1, 32, 32]              64
            ReLU-128               [-1, 32, 32]               0
         Dropout-129               [-1, 32, 32]               0
          Conv1d-130               [-1, 32, 32]             544
 MyConv1dPadSame-131               [-1, 32, 32]               0
      Bottleneck-132               [-1, 32, 32]               0
     BatchNorm1d-133               [-1, 32, 32]              64
            ReLU-134               [-1, 32, 32]               0
         Dropout-135               [-1, 32, 32]               0
          Conv1d-136               [-1, 32, 16]             544
 MyConv1dPadSame-137               [-1, 32, 16]               0
     BatchNorm1d-138               [-1, 32, 16]              64
            ReLU-139               [-1, 32, 16]               0
         Dropout-140               [-1, 32, 16]               0
          Conv1d-141               [-1, 32, 16]             544
 MyConv1dPadSame-142               [-1, 32, 16]               0
       MaxPool1d-143               [-1, 32, 16]               0
MyMaxPool1dPadSame-144               [-1, 32, 16]               0
      Bottleneck-145               [-1, 32, 16]               0
     BatchNorm1d-146               [-1, 32, 16]              64
            ReLU-147               [-1, 32, 16]               0
         Dropout-148               [-1, 32, 16]               0
          Conv1d-149               [-1, 64, 16]           1,088
 MyConv1dPadSame-150               [-1, 64, 16]               0
     BatchNorm1d-151               [-1, 64, 16]             128
            ReLU-152               [-1, 64, 16]               0
         Dropout-153               [-1, 64, 16]               0
          Conv1d-154               [-1, 64, 16]           2,112
 MyConv1dPadSame-155               [-1, 64, 16]               0
      Bottleneck-156               [-1, 64, 16]               0
     BatchNorm1d-157               [-1, 64, 16]             128
            ReLU-158               [-1, 64, 16]               0
         Dropout-159               [-1, 64, 16]               0
          Conv1d-160                [-1, 64, 8]           2,112
 MyConv1dPadSame-161                [-1, 64, 8]               0
     BatchNorm1d-162                [-1, 64, 8]             128
            ReLU-163                [-1, 64, 8]               0
         Dropout-164                [-1, 64, 8]               0
          Conv1d-165                [-1, 64, 8]           2,112
 MyConv1dPadSame-166                [-1, 64, 8]               0
       MaxPool1d-167                [-1, 64, 8]               0
MyMaxPool1dPadSame-168                [-1, 64, 8]               0
      Bottleneck-169                [-1, 64, 8]               0
     BatchNorm1d-170                [-1, 64, 8]             128
            ReLU-171                [-1, 64, 8]               0
         Dropout-172                [-1, 64, 8]               0
          Conv1d-173                [-1, 64, 8]           2,112
 MyConv1dPadSame-174                [-1, 64, 8]               0
     BatchNorm1d-175                [-1, 64, 8]             128
            ReLU-176                [-1, 64, 8]               0
         Dropout-177                [-1, 64, 8]               0
          Conv1d-178                [-1, 64, 8]           2,112
 MyConv1dPadSame-179                [-1, 64, 8]               0
      Bottleneck-180                [-1, 64, 8]               0
     BatchNorm1d-181                [-1, 64, 8]             128
            ReLU-182                [-1, 64, 8]               0
         Dropout-183                [-1, 64, 8]               0
          Conv1d-184                [-1, 64, 4]           2,112
 MyConv1dPadSame-185                [-1, 64, 4]               0
     BatchNorm1d-186                [-1, 64, 4]             128
            ReLU-187                [-1, 64, 4]               0
         Dropout-188                [-1, 64, 4]               0
          Conv1d-189                [-1, 64, 4]           2,112
 MyConv1dPadSame-190                [-1, 64, 4]               0
       MaxPool1d-191                [-1, 64, 4]               0
MyMaxPool1dPadSame-192                [-1, 64, 4]               0
      Bottleneck-193                [-1, 64, 4]               0
     BatchNorm1d-194                [-1, 64, 4]             128
            ReLU-195                [-1, 64, 4]               0
          Linear-196                    [-1, 2]             130
================================================================
Total params: 23,482
Trainable params: 23,482
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 3.32
Params size (MB): 0.09
Estimated Total Size (MB): 3.42
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 8, kernel_size: 8, n_block: 2
************************************************************
************************************************************
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 8, 1024]              72
   MyConv1dPadSame-2              [-1, 8, 1024]               0
       BatchNorm1d-3              [-1, 8, 1024]              16
              ReLU-4              [-1, 8, 1024]               0
            Conv1d-5              [-1, 8, 1024]              72
   MyConv1dPadSame-6              [-1, 8, 1024]               0
       BatchNorm1d-7              [-1, 8, 1024]              16
              ReLU-8              [-1, 8, 1024]               0
           Dropout-9              [-1, 8, 1024]               0
           Conv1d-10              [-1, 8, 1024]              72
  MyConv1dPadSame-11              [-1, 8, 1024]               0
       Bottleneck-12              [-1, 8, 1024]               0
      BatchNorm1d-13              [-1, 8, 1024]              16
             ReLU-14              [-1, 8, 1024]               0
          Dropout-15              [-1, 8, 1024]               0
           Conv1d-16             [-1, 16, 1024]             144
  MyConv1dPadSame-17             [-1, 16, 1024]               0
      BatchNorm1d-18             [-1, 16, 1024]              32
             ReLU-19             [-1, 16, 1024]               0
          Dropout-20             [-1, 16, 1024]               0
           Conv1d-21             [-1, 16, 1024]             272
  MyConv1dPadSame-22             [-1, 16, 1024]               0
       Bottleneck-23             [-1, 16, 1024]               0
      BatchNorm1d-24             [-1, 16, 1024]              32
             ReLU-25             [-1, 16, 1024]               0
           Linear-26                    [-1, 2]              34
================================================================
Total params: 778
Trainable params: 778
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 2.19
Params size (MB): 0.00
Estimated Total Size (MB): 2.19
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 8, kernel_size: 8, n_block: 4
************************************************************
************************************************************
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 8, 1024]              72
   MyConv1dPadSame-2              [-1, 8, 1024]               0
       BatchNorm1d-3              [-1, 8, 1024]              16
              ReLU-4              [-1, 8, 1024]               0
            Conv1d-5              [-1, 8, 1024]              72
   MyConv1dPadSame-6              [-1, 8, 1024]               0
       BatchNorm1d-7              [-1, 8, 1024]              16
              ReLU-8              [-1, 8, 1024]               0
           Dropout-9              [-1, 8, 1024]               0
           Conv1d-10              [-1, 8, 1024]              72
  MyConv1dPadSame-11              [-1, 8, 1024]               0
       Bottleneck-12              [-1, 8, 1024]               0
      BatchNorm1d-13              [-1, 8, 1024]              16
             ReLU-14              [-1, 8, 1024]               0
          Dropout-15              [-1, 8, 1024]               0
           Conv1d-16             [-1, 16, 1024]             144
  MyConv1dPadSame-17             [-1, 16, 1024]               0
      BatchNorm1d-18             [-1, 16, 1024]              32
             ReLU-19             [-1, 16, 1024]               0
          Dropout-20             [-1, 16, 1024]               0
           Conv1d-21             [-1, 16, 1024]             272
  MyConv1dPadSame-22             [-1, 16, 1024]               0
       Bottleneck-23             [-1, 16, 1024]               0
      BatchNorm1d-24             [-1, 16, 1024]              32
             ReLU-25             [-1, 16, 1024]               0
          Dropout-26             [-1, 16, 1024]               0
           Conv1d-27             [-1, 32, 1024]             544
  MyConv1dPadSame-28             [-1, 32, 1024]               0
      BatchNorm1d-29             [-1, 32, 1024]              64
             ReLU-30             [-1, 32, 1024]               0
          Dropout-31             [-1, 32, 1024]               0
           Conv1d-32             [-1, 32, 1024]           1,056
  MyConv1dPadSame-33             [-1, 32, 1024]               0
       Bottleneck-34             [-1, 32, 1024]               0
      BatchNorm1d-35             [-1, 32, 1024]              64
             ReLU-36             [-1, 32, 1024]               0
          Dropout-37             [-1, 32, 1024]               0
           Conv1d-38             [-1, 64, 1024]           2,112
  MyConv1dPadSame-39             [-1, 64, 1024]               0
      BatchNorm1d-40             [-1, 64, 1024]             128
             ReLU-41             [-1, 64, 1024]               0
          Dropout-42             [-1, 64, 1024]               0
           Conv1d-43             [-1, 64, 1024]           4,160
  MyConv1dPadSame-44             [-1, 64, 1024]               0
       Bottleneck-45             [-1, 64, 1024]               0
      BatchNorm1d-46             [-1, 64, 1024]             128
             ReLU-47             [-1, 64, 1024]               0
           Linear-48                    [-1, 2]             130
================================================================
Total params: 9,130
Trainable params: 9,130
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 10.06
Params size (MB): 0.03
Estimated Total Size (MB): 10.10
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 8, kernel_size: 8, n_block: 8
************************************************************
************************************************************
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 8, 1024]              72
   MyConv1dPadSame-2              [-1, 8, 1024]               0
       BatchNorm1d-3              [-1, 8, 1024]              16
              ReLU-4              [-1, 8, 1024]               0
            Conv1d-5              [-1, 8, 1024]              72
   MyConv1dPadSame-6              [-1, 8, 1024]               0
       BatchNorm1d-7              [-1, 8, 1024]              16
              ReLU-8              [-1, 8, 1024]               0
           Dropout-9              [-1, 8, 1024]               0
           Conv1d-10              [-1, 8, 1024]              72
  MyConv1dPadSame-11              [-1, 8, 1024]               0
       Bottleneck-12              [-1, 8, 1024]               0
      BatchNorm1d-13              [-1, 8, 1024]              16
             ReLU-14              [-1, 8, 1024]               0
          Dropout-15              [-1, 8, 1024]               0
           Conv1d-16              [-1, 8, 1024]              72
  MyConv1dPadSame-17              [-1, 8, 1024]               0
      BatchNorm1d-18              [-1, 8, 1024]              16
             ReLU-19              [-1, 8, 1024]               0
          Dropout-20              [-1, 8, 1024]               0
           Conv1d-21              [-1, 8, 1024]              72
  MyConv1dPadSame-22              [-1, 8, 1024]               0
       Bottleneck-23              [-1, 8, 1024]               0
      BatchNorm1d-24              [-1, 8, 1024]              16
             ReLU-25              [-1, 8, 1024]               0
          Dropout-26              [-1, 8, 1024]               0
           Conv1d-27             [-1, 16, 1024]             144
  MyConv1dPadSame-28             [-1, 16, 1024]               0
      BatchNorm1d-29             [-1, 16, 1024]              32
             ReLU-30             [-1, 16, 1024]               0
          Dropout-31             [-1, 16, 1024]               0
           Conv1d-32             [-1, 16, 1024]             272
  MyConv1dPadSame-33             [-1, 16, 1024]               0
       Bottleneck-34             [-1, 16, 1024]               0
      BatchNorm1d-35             [-1, 16, 1024]              32
             ReLU-36             [-1, 16, 1024]               0
          Dropout-37             [-1, 16, 1024]               0
           Conv1d-38             [-1, 16, 1024]             272
  MyConv1dPadSame-39             [-1, 16, 1024]               0
      BatchNorm1d-40             [-1, 16, 1024]              32
             ReLU-41             [-1, 16, 1024]               0
          Dropout-42             [-1, 16, 1024]               0
           Conv1d-43             [-1, 16, 1024]             272
  MyConv1dPadSame-44             [-1, 16, 1024]               0
       Bottleneck-45             [-1, 16, 1024]               0
      BatchNorm1d-46             [-1, 16, 1024]              32
             ReLU-47             [-1, 16, 1024]               0
          Dropout-48             [-1, 16, 1024]               0
           Conv1d-49             [-1, 32, 1024]             544
  MyConv1dPadSame-50             [-1, 32, 1024]               0
      BatchNorm1d-51             [-1, 32, 1024]              64
             ReLU-52             [-1, 32, 1024]               0
          Dropout-53             [-1, 32, 1024]               0
           Conv1d-54             [-1, 32, 1024]           1,056
  MyConv1dPadSame-55             [-1, 32, 1024]               0
       Bottleneck-56             [-1, 32, 1024]               0
      BatchNorm1d-57             [-1, 32, 1024]              64
             ReLU-58             [-1, 32, 1024]               0
          Dropout-59             [-1, 32, 1024]               0
           Conv1d-60             [-1, 32, 1024]           1,056
  MyConv1dPadSame-61             [-1, 32, 1024]               0
      BatchNorm1d-62             [-1, 32, 1024]              64
             ReLU-63             [-1, 32, 1024]               0
          Dropout-64             [-1, 32, 1024]               0
           Conv1d-65             [-1, 32, 1024]           1,056
  MyConv1dPadSame-66             [-1, 32, 1024]               0
       Bottleneck-67             [-1, 32, 1024]               0
      BatchNorm1d-68             [-1, 32, 1024]              64
             ReLU-69             [-1, 32, 1024]               0
          Dropout-70             [-1, 32, 1024]               0
           Conv1d-71             [-1, 64, 1024]           2,112
  MyConv1dPadSame-72             [-1, 64, 1024]               0
      BatchNorm1d-73             [-1, 64, 1024]             128
             ReLU-74             [-1, 64, 1024]               0
          Dropout-75             [-1, 64, 1024]               0
           Conv1d-76             [-1, 64, 1024]           4,160
  MyConv1dPadSame-77             [-1, 64, 1024]               0
       Bottleneck-78             [-1, 64, 1024]               0
      BatchNorm1d-79             [-1, 64, 1024]             128
             ReLU-80             [-1, 64, 1024]               0
          Dropout-81             [-1, 64, 1024]               0
           Conv1d-82             [-1, 64, 1024]           4,160
  MyConv1dPadSame-83             [-1, 64, 1024]               0
      BatchNorm1d-84             [-1, 64, 1024]             128
             ReLU-85             [-1, 64, 1024]               0
          Dropout-86             [-1, 64, 1024]               0
           Conv1d-87             [-1, 64, 1024]           4,160
  MyConv1dPadSame-88             [-1, 64, 1024]               0
       Bottleneck-89             [-1, 64, 1024]               0
      BatchNorm1d-90             [-1, 64, 1024]             128
             ReLU-91             [-1, 64, 1024]               0
           Linear-92                    [-1, 2]             130
================================================================
Total params: 20,730
Trainable params: 20,730
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 20.38
Params size (MB): 0.08
Estimated Total Size (MB): 20.46
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 8, kernel_size: 8, n_block: 16
************************************************************
************************************************************
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 8, 1024]              72
   MyConv1dPadSame-2              [-1, 8, 1024]               0
       BatchNorm1d-3              [-1, 8, 1024]              16
              ReLU-4              [-1, 8, 1024]               0
            Conv1d-5              [-1, 8, 1024]              72
   MyConv1dPadSame-6              [-1, 8, 1024]               0
       BatchNorm1d-7              [-1, 8, 1024]              16
              ReLU-8              [-1, 8, 1024]               0
           Dropout-9              [-1, 8, 1024]               0
           Conv1d-10              [-1, 8, 1024]              72
  MyConv1dPadSame-11              [-1, 8, 1024]               0
       Bottleneck-12              [-1, 8, 1024]               0
      BatchNorm1d-13              [-1, 8, 1024]              16
             ReLU-14              [-1, 8, 1024]               0
          Dropout-15              [-1, 8, 1024]               0
           Conv1d-16               [-1, 8, 512]              72
  MyConv1dPadSame-17               [-1, 8, 512]               0
      BatchNorm1d-18               [-1, 8, 512]              16
             ReLU-19               [-1, 8, 512]               0
          Dropout-20               [-1, 8, 512]               0
           Conv1d-21               [-1, 8, 512]              72
  MyConv1dPadSame-22               [-1, 8, 512]               0
        MaxPool1d-23               [-1, 8, 512]               0
MyMaxPool1dPadSame-24               [-1, 8, 512]               0
       Bottleneck-25               [-1, 8, 512]               0
      BatchNorm1d-26               [-1, 8, 512]              16
             ReLU-27               [-1, 8, 512]               0
          Dropout-28               [-1, 8, 512]               0
           Conv1d-29               [-1, 8, 512]              72
  MyConv1dPadSame-30               [-1, 8, 512]               0
      BatchNorm1d-31               [-1, 8, 512]              16
             ReLU-32               [-1, 8, 512]               0
          Dropout-33               [-1, 8, 512]               0
           Conv1d-34               [-1, 8, 512]              72
  MyConv1dPadSame-35               [-1, 8, 512]               0
       Bottleneck-36               [-1, 8, 512]               0
      BatchNorm1d-37               [-1, 8, 512]              16
             ReLU-38               [-1, 8, 512]               0
          Dropout-39               [-1, 8, 512]               0
           Conv1d-40               [-1, 8, 256]              72
  MyConv1dPadSame-41               [-1, 8, 256]               0
      BatchNorm1d-42               [-1, 8, 256]              16
             ReLU-43               [-1, 8, 256]               0
          Dropout-44               [-1, 8, 256]               0
           Conv1d-45               [-1, 8, 256]              72
  MyConv1dPadSame-46               [-1, 8, 256]               0
        MaxPool1d-47               [-1, 8, 256]               0
MyMaxPool1dPadSame-48               [-1, 8, 256]               0
       Bottleneck-49               [-1, 8, 256]               0
      BatchNorm1d-50               [-1, 8, 256]              16
             ReLU-51               [-1, 8, 256]               0
          Dropout-52               [-1, 8, 256]               0
           Conv1d-53              [-1, 16, 256]             144
  MyConv1dPadSame-54              [-1, 16, 256]               0
      BatchNorm1d-55              [-1, 16, 256]              32
             ReLU-56              [-1, 16, 256]               0
          Dropout-57              [-1, 16, 256]               0
           Conv1d-58              [-1, 16, 256]             272
  MyConv1dPadSame-59              [-1, 16, 256]               0
       Bottleneck-60              [-1, 16, 256]               0
      BatchNorm1d-61              [-1, 16, 256]              32
             ReLU-62              [-1, 16, 256]               0
          Dropout-63              [-1, 16, 256]               0
           Conv1d-64              [-1, 16, 128]             272
  MyConv1dPadSame-65              [-1, 16, 128]               0
      BatchNorm1d-66              [-1, 16, 128]              32
             ReLU-67              [-1, 16, 128]               0
          Dropout-68              [-1, 16, 128]               0
           Conv1d-69              [-1, 16, 128]             272
  MyConv1dPadSame-70              [-1, 16, 128]               0
        MaxPool1d-71              [-1, 16, 128]               0
MyMaxPool1dPadSame-72              [-1, 16, 128]               0
       Bottleneck-73              [-1, 16, 128]               0
      BatchNorm1d-74              [-1, 16, 128]              32
             ReLU-75              [-1, 16, 128]               0
          Dropout-76              [-1, 16, 128]               0
           Conv1d-77              [-1, 16, 128]             272
  MyConv1dPadSame-78              [-1, 16, 128]               0
      BatchNorm1d-79              [-1, 16, 128]              32
             ReLU-80              [-1, 16, 128]               0
          Dropout-81              [-1, 16, 128]               0
           Conv1d-82              [-1, 16, 128]             272
  MyConv1dPadSame-83              [-1, 16, 128]               0
       Bottleneck-84              [-1, 16, 128]               0
      BatchNorm1d-85              [-1, 16, 128]              32
             ReLU-86              [-1, 16, 128]               0
          Dropout-87              [-1, 16, 128]               0
           Conv1d-88               [-1, 16, 64]             272
  MyConv1dPadSame-89               [-1, 16, 64]               0
      BatchNorm1d-90               [-1, 16, 64]              32
             ReLU-91               [-1, 16, 64]               0
          Dropout-92               [-1, 16, 64]               0
           Conv1d-93               [-1, 16, 64]             272
  MyConv1dPadSame-94               [-1, 16, 64]               0
        MaxPool1d-95               [-1, 16, 64]               0
MyMaxPool1dPadSame-96               [-1, 16, 64]               0
       Bottleneck-97               [-1, 16, 64]               0
      BatchNorm1d-98               [-1, 16, 64]              32
             ReLU-99               [-1, 16, 64]               0
         Dropout-100               [-1, 16, 64]               0
          Conv1d-101               [-1, 32, 64]             544
 MyConv1dPadSame-102               [-1, 32, 64]               0
     BatchNorm1d-103               [-1, 32, 64]              64
            ReLU-104               [-1, 32, 64]               0
         Dropout-105               [-1, 32, 64]               0
          Conv1d-106               [-1, 32, 64]           1,056
 MyConv1dPadSame-107               [-1, 32, 64]               0
      Bottleneck-108               [-1, 32, 64]               0
     BatchNorm1d-109               [-1, 32, 64]              64
            ReLU-110               [-1, 32, 64]               0
         Dropout-111               [-1, 32, 64]               0
          Conv1d-112               [-1, 32, 32]           1,056
 MyConv1dPadSame-113               [-1, 32, 32]               0
     BatchNorm1d-114               [-1, 32, 32]              64
            ReLU-115               [-1, 32, 32]               0
         Dropout-116               [-1, 32, 32]               0
          Conv1d-117               [-1, 32, 32]           1,056
 MyConv1dPadSame-118               [-1, 32, 32]               0
       MaxPool1d-119               [-1, 32, 32]               0
MyMaxPool1dPadSame-120               [-1, 32, 32]               0
      Bottleneck-121               [-1, 32, 32]               0
     BatchNorm1d-122               [-1, 32, 32]              64
            ReLU-123               [-1, 32, 32]               0
         Dropout-124               [-1, 32, 32]               0
          Conv1d-125               [-1, 32, 32]           1,056
 MyConv1dPadSame-126               [-1, 32, 32]               0
     BatchNorm1d-127               [-1, 32, 32]              64
            ReLU-128               [-1, 32, 32]               0
         Dropout-129               [-1, 32, 32]               0
          Conv1d-130               [-1, 32, 32]           1,056
 MyConv1dPadSame-131               [-1, 32, 32]               0
      Bottleneck-132               [-1, 32, 32]               0
     BatchNorm1d-133               [-1, 32, 32]              64
            ReLU-134               [-1, 32, 32]               0
         Dropout-135               [-1, 32, 32]               0
          Conv1d-136               [-1, 32, 16]           1,056
 MyConv1dPadSame-137               [-1, 32, 16]               0
     BatchNorm1d-138               [-1, 32, 16]              64
            ReLU-139               [-1, 32, 16]               0
         Dropout-140               [-1, 32, 16]               0
          Conv1d-141               [-1, 32, 16]           1,056
 MyConv1dPadSame-142               [-1, 32, 16]               0
       MaxPool1d-143               [-1, 32, 16]               0
MyMaxPool1dPadSame-144               [-1, 32, 16]               0
      Bottleneck-145               [-1, 32, 16]               0
     BatchNorm1d-146               [-1, 32, 16]              64
            ReLU-147               [-1, 32, 16]               0
         Dropout-148               [-1, 32, 16]               0
          Conv1d-149               [-1, 64, 16]           2,112
 MyConv1dPadSame-150               [-1, 64, 16]               0
     BatchNorm1d-151               [-1, 64, 16]             128
            ReLU-152               [-1, 64, 16]               0
         Dropout-153               [-1, 64, 16]               0
          Conv1d-154               [-1, 64, 16]           4,160
 MyConv1dPadSame-155               [-1, 64, 16]               0
      Bottleneck-156               [-1, 64, 16]               0
     BatchNorm1d-157               [-1, 64, 16]             128
            ReLU-158               [-1, 64, 16]               0
         Dropout-159               [-1, 64, 16]               0
          Conv1d-160                [-1, 64, 8]           4,160
 MyConv1dPadSame-161                [-1, 64, 8]               0
     BatchNorm1d-162                [-1, 64, 8]             128
            ReLU-163                [-1, 64, 8]               0
         Dropout-164                [-1, 64, 8]               0
          Conv1d-165                [-1, 64, 8]           4,160
 MyConv1dPadSame-166                [-1, 64, 8]               0
       MaxPool1d-167                [-1, 64, 8]               0
MyMaxPool1dPadSame-168                [-1, 64, 8]               0
      Bottleneck-169                [-1, 64, 8]               0
     BatchNorm1d-170                [-1, 64, 8]             128
            ReLU-171                [-1, 64, 8]               0
         Dropout-172                [-1, 64, 8]               0
          Conv1d-173                [-1, 64, 8]           4,160
 MyConv1dPadSame-174                [-1, 64, 8]               0
     BatchNorm1d-175                [-1, 64, 8]             128
            ReLU-176                [-1, 64, 8]               0
         Dropout-177                [-1, 64, 8]               0
          Conv1d-178                [-1, 64, 8]           4,160
 MyConv1dPadSame-179                [-1, 64, 8]               0
      Bottleneck-180                [-1, 64, 8]               0
     BatchNorm1d-181                [-1, 64, 8]             128
            ReLU-182                [-1, 64, 8]               0
         Dropout-183                [-1, 64, 8]               0
          Conv1d-184                [-1, 64, 4]           4,160
 MyConv1dPadSame-185                [-1, 64, 4]               0
     BatchNorm1d-186                [-1, 64, 4]             128
            ReLU-187                [-1, 64, 4]               0
         Dropout-188                [-1, 64, 4]               0
          Conv1d-189                [-1, 64, 4]           4,160
 MyConv1dPadSame-190                [-1, 64, 4]               0
       MaxPool1d-191                [-1, 64, 4]               0
MyMaxPool1dPadSame-192                [-1, 64, 4]               0
      Bottleneck-193                [-1, 64, 4]               0
     BatchNorm1d-194                [-1, 64, 4]             128
            ReLU-195                [-1, 64, 4]               0
          Linear-196                    [-1, 2]             130
================================================================
Total params: 43,930
Trainable params: 43,930
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 3.32
Params size (MB): 0.17
Estimated Total Size (MB): 3.50
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 8, kernel_size: 16, n_block: 2
************************************************************
************************************************************
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 8, 1024]             136
   MyConv1dPadSame-2              [-1, 8, 1024]               0
       BatchNorm1d-3              [-1, 8, 1024]              16
              ReLU-4              [-1, 8, 1024]               0
            Conv1d-5              [-1, 8, 1024]             136
   MyConv1dPadSame-6              [-1, 8, 1024]               0
       BatchNorm1d-7              [-1, 8, 1024]              16
              ReLU-8              [-1, 8, 1024]               0
           Dropout-9              [-1, 8, 1024]               0
           Conv1d-10              [-1, 8, 1024]             136
  MyConv1dPadSame-11              [-1, 8, 1024]               0
       Bottleneck-12              [-1, 8, 1024]               0
      BatchNorm1d-13              [-1, 8, 1024]              16
             ReLU-14              [-1, 8, 1024]               0
          Dropout-15              [-1, 8, 1024]               0
           Conv1d-16             [-1, 16, 1024]             272
  MyConv1dPadSame-17             [-1, 16, 1024]               0
      BatchNorm1d-18             [-1, 16, 1024]              32
             ReLU-19             [-1, 16, 1024]               0
          Dropout-20             [-1, 16, 1024]               0
           Conv1d-21             [-1, 16, 1024]             528
  MyConv1dPadSame-22             [-1, 16, 1024]               0
       Bottleneck-23             [-1, 16, 1024]               0
      BatchNorm1d-24             [-1, 16, 1024]              32
             ReLU-25             [-1, 16, 1024]               0
           Linear-26                    [-1, 2]              34
================================================================
Total params: 1,354
Trainable params: 1,354
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 2.19
Params size (MB): 0.01
Estimated Total Size (MB): 2.20
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 8, kernel_size: 16, n_block: 4
************************************************************
************************************************************
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 8, 1024]             136
   MyConv1dPadSame-2              [-1, 8, 1024]               0
       BatchNorm1d-3              [-1, 8, 1024]              16
              ReLU-4              [-1, 8, 1024]               0
            Conv1d-5              [-1, 8, 1024]             136
   MyConv1dPadSame-6              [-1, 8, 1024]               0
       BatchNorm1d-7              [-1, 8, 1024]              16
              ReLU-8              [-1, 8, 1024]               0
           Dropout-9              [-1, 8, 1024]               0
           Conv1d-10              [-1, 8, 1024]             136
  MyConv1dPadSame-11              [-1, 8, 1024]               0
       Bottleneck-12              [-1, 8, 1024]               0
      BatchNorm1d-13              [-1, 8, 1024]              16
             ReLU-14              [-1, 8, 1024]               0
          Dropout-15              [-1, 8, 1024]               0
           Conv1d-16             [-1, 16, 1024]             272
  MyConv1dPadSame-17             [-1, 16, 1024]               0
      BatchNorm1d-18             [-1, 16, 1024]              32
             ReLU-19             [-1, 16, 1024]               0
          Dropout-20             [-1, 16, 1024]               0
           Conv1d-21             [-1, 16, 1024]             528
  MyConv1dPadSame-22             [-1, 16, 1024]               0
       Bottleneck-23             [-1, 16, 1024]               0
      BatchNorm1d-24             [-1, 16, 1024]              32
             ReLU-25             [-1, 16, 1024]               0
          Dropout-26             [-1, 16, 1024]               0
           Conv1d-27             [-1, 32, 1024]           1,056
  MyConv1dPadSame-28             [-1, 32, 1024]               0
      BatchNorm1d-29             [-1, 32, 1024]              64
             ReLU-30             [-1, 32, 1024]               0
          Dropout-31             [-1, 32, 1024]               0
           Conv1d-32             [-1, 32, 1024]           2,080
  MyConv1dPadSame-33             [-1, 32, 1024]               0
       Bottleneck-34             [-1, 32, 1024]               0
      BatchNorm1d-35             [-1, 32, 1024]              64
             ReLU-36             [-1, 32, 1024]               0
          Dropout-37             [-1, 32, 1024]               0
           Conv1d-38             [-1, 64, 1024]           4,160
  MyConv1dPadSame-39             [-1, 64, 1024]               0
      BatchNorm1d-40             [-1, 64, 1024]             128
             ReLU-41             [-1, 64, 1024]               0
          Dropout-42             [-1, 64, 1024]               0
           Conv1d-43             [-1, 64, 1024]           8,256
  MyConv1dPadSame-44             [-1, 64, 1024]               0
       Bottleneck-45             [-1, 64, 1024]               0
      BatchNorm1d-46             [-1, 64, 1024]             128
             ReLU-47             [-1, 64, 1024]               0
           Linear-48                    [-1, 2]             130
================================================================
Total params: 17,386
Trainable params: 17,386
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 10.06
Params size (MB): 0.07
Estimated Total Size (MB): 10.13
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 8, kernel_size: 16, n_block: 8
************************************************************
************************************************************
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 8, 1024]             136
   MyConv1dPadSame-2              [-1, 8, 1024]               0
       BatchNorm1d-3              [-1, 8, 1024]              16
              ReLU-4              [-1, 8, 1024]               0
            Conv1d-5              [-1, 8, 1024]             136
   MyConv1dPadSame-6              [-1, 8, 1024]               0
       BatchNorm1d-7              [-1, 8, 1024]              16
              ReLU-8              [-1, 8, 1024]               0
           Dropout-9              [-1, 8, 1024]               0
           Conv1d-10              [-1, 8, 1024]             136
  MyConv1dPadSame-11              [-1, 8, 1024]               0
       Bottleneck-12              [-1, 8, 1024]               0
      BatchNorm1d-13              [-1, 8, 1024]              16
             ReLU-14              [-1, 8, 1024]               0
          Dropout-15              [-1, 8, 1024]               0
           Conv1d-16              [-1, 8, 1024]             136
  MyConv1dPadSame-17              [-1, 8, 1024]               0
      BatchNorm1d-18              [-1, 8, 1024]              16
             ReLU-19              [-1, 8, 1024]               0
          Dropout-20              [-1, 8, 1024]               0
           Conv1d-21              [-1, 8, 1024]             136
  MyConv1dPadSame-22              [-1, 8, 1024]               0
       Bottleneck-23              [-1, 8, 1024]               0
      BatchNorm1d-24              [-1, 8, 1024]              16
             ReLU-25              [-1, 8, 1024]               0
          Dropout-26              [-1, 8, 1024]               0
           Conv1d-27             [-1, 16, 1024]             272
  MyConv1dPadSame-28             [-1, 16, 1024]               0
      BatchNorm1d-29             [-1, 16, 1024]              32
             ReLU-30             [-1, 16, 1024]               0
          Dropout-31             [-1, 16, 1024]               0
           Conv1d-32             [-1, 16, 1024]             528
  MyConv1dPadSame-33             [-1, 16, 1024]               0
       Bottleneck-34             [-1, 16, 1024]               0
      BatchNorm1d-35             [-1, 16, 1024]              32
             ReLU-36             [-1, 16, 1024]               0
          Dropout-37             [-1, 16, 1024]               0
           Conv1d-38             [-1, 16, 1024]             528
  MyConv1dPadSame-39             [-1, 16, 1024]               0
      BatchNorm1d-40             [-1, 16, 1024]              32
             ReLU-41             [-1, 16, 1024]               0
          Dropout-42             [-1, 16, 1024]               0
           Conv1d-43             [-1, 16, 1024]             528
  MyConv1dPadSame-44             [-1, 16, 1024]               0
       Bottleneck-45             [-1, 16, 1024]               0
      BatchNorm1d-46             [-1, 16, 1024]              32
             ReLU-47             [-1, 16, 1024]               0
          Dropout-48             [-1, 16, 1024]               0
           Conv1d-49             [-1, 32, 1024]           1,056
  MyConv1dPadSame-50             [-1, 32, 1024]               0
      BatchNorm1d-51             [-1, 32, 1024]              64
             ReLU-52             [-1, 32, 1024]               0
          Dropout-53             [-1, 32, 1024]               0
           Conv1d-54             [-1, 32, 1024]           2,080
  MyConv1dPadSame-55             [-1, 32, 1024]               0
       Bottleneck-56             [-1, 32, 1024]               0
      BatchNorm1d-57             [-1, 32, 1024]              64
             ReLU-58             [-1, 32, 1024]               0
          Dropout-59             [-1, 32, 1024]               0
           Conv1d-60             [-1, 32, 1024]           2,080
  MyConv1dPadSame-61             [-1, 32, 1024]               0
      BatchNorm1d-62             [-1, 32, 1024]              64
             ReLU-63             [-1, 32, 1024]               0
          Dropout-64             [-1, 32, 1024]               0
           Conv1d-65             [-1, 32, 1024]           2,080
  MyConv1dPadSame-66             [-1, 32, 1024]               0
       Bottleneck-67             [-1, 32, 1024]               0
      BatchNorm1d-68             [-1, 32, 1024]              64
             ReLU-69             [-1, 32, 1024]               0
          Dropout-70             [-1, 32, 1024]               0
           Conv1d-71             [-1, 64, 1024]           4,160
  MyConv1dPadSame-72             [-1, 64, 1024]               0
      BatchNorm1d-73             [-1, 64, 1024]             128
             ReLU-74             [-1, 64, 1024]               0
          Dropout-75             [-1, 64, 1024]               0
           Conv1d-76             [-1, 64, 1024]           8,256
  MyConv1dPadSame-77             [-1, 64, 1024]               0
       Bottleneck-78             [-1, 64, 1024]               0
      BatchNorm1d-79             [-1, 64, 1024]             128
             ReLU-80             [-1, 64, 1024]               0
          Dropout-81             [-1, 64, 1024]               0
           Conv1d-82             [-1, 64, 1024]           8,256
  MyConv1dPadSame-83             [-1, 64, 1024]               0
      BatchNorm1d-84             [-1, 64, 1024]             128
             ReLU-85             [-1, 64, 1024]               0
          Dropout-86             [-1, 64, 1024]               0
           Conv1d-87             [-1, 64, 1024]           8,256
  MyConv1dPadSame-88             [-1, 64, 1024]               0
       Bottleneck-89             [-1, 64, 1024]               0
      BatchNorm1d-90             [-1, 64, 1024]             128
             ReLU-91             [-1, 64, 1024]               0
           Linear-92                    [-1, 2]             130
================================================================
Total params: 39,866
Trainable params: 39,866
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 20.38
Params size (MB): 0.15
Estimated Total Size (MB): 20.53
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 8, kernel_size: 16, n_block: 16
************************************************************
************************************************************
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 8, 1024]             136
   MyConv1dPadSame-2              [-1, 8, 1024]               0
       BatchNorm1d-3              [-1, 8, 1024]              16
              ReLU-4              [-1, 8, 1024]               0
            Conv1d-5              [-1, 8, 1024]             136
   MyConv1dPadSame-6              [-1, 8, 1024]               0
       BatchNorm1d-7              [-1, 8, 1024]              16
              ReLU-8              [-1, 8, 1024]               0
           Dropout-9              [-1, 8, 1024]               0
           Conv1d-10              [-1, 8, 1024]             136
  MyConv1dPadSame-11              [-1, 8, 1024]               0
       Bottleneck-12              [-1, 8, 1024]               0
      BatchNorm1d-13              [-1, 8, 1024]              16
             ReLU-14              [-1, 8, 1024]               0
          Dropout-15              [-1, 8, 1024]               0
           Conv1d-16               [-1, 8, 512]             136
  MyConv1dPadSame-17               [-1, 8, 512]               0
      BatchNorm1d-18               [-1, 8, 512]              16
             ReLU-19               [-1, 8, 512]               0
          Dropout-20               [-1, 8, 512]               0
           Conv1d-21               [-1, 8, 512]             136
  MyConv1dPadSame-22               [-1, 8, 512]               0
        MaxPool1d-23               [-1, 8, 512]               0
MyMaxPool1dPadSame-24               [-1, 8, 512]               0
       Bottleneck-25               [-1, 8, 512]               0
      BatchNorm1d-26               [-1, 8, 512]              16
             ReLU-27               [-1, 8, 512]               0
          Dropout-28               [-1, 8, 512]               0
           Conv1d-29               [-1, 8, 512]             136
  MyConv1dPadSame-30               [-1, 8, 512]               0
      BatchNorm1d-31               [-1, 8, 512]              16
             ReLU-32               [-1, 8, 512]               0
          Dropout-33               [-1, 8, 512]               0
           Conv1d-34               [-1, 8, 512]             136
  MyConv1dPadSame-35               [-1, 8, 512]               0
       Bottleneck-36               [-1, 8, 512]               0
      BatchNorm1d-37               [-1, 8, 512]              16
             ReLU-38               [-1, 8, 512]               0
          Dropout-39               [-1, 8, 512]               0
           Conv1d-40               [-1, 8, 256]             136
  MyConv1dPadSame-41               [-1, 8, 256]               0
      BatchNorm1d-42               [-1, 8, 256]              16
             ReLU-43               [-1, 8, 256]               0
          Dropout-44               [-1, 8, 256]               0
           Conv1d-45               [-1, 8, 256]             136
  MyConv1dPadSame-46               [-1, 8, 256]               0
        MaxPool1d-47               [-1, 8, 256]               0
MyMaxPool1dPadSame-48               [-1, 8, 256]               0
       Bottleneck-49               [-1, 8, 256]               0
      BatchNorm1d-50               [-1, 8, 256]              16
             ReLU-51               [-1, 8, 256]               0
          Dropout-52               [-1, 8, 256]               0
           Conv1d-53              [-1, 16, 256]             272
  MyConv1dPadSame-54              [-1, 16, 256]               0
      BatchNorm1d-55              [-1, 16, 256]              32
             ReLU-56              [-1, 16, 256]               0
          Dropout-57              [-1, 16, 256]               0
           Conv1d-58              [-1, 16, 256]             528
  MyConv1dPadSame-59              [-1, 16, 256]               0
       Bottleneck-60              [-1, 16, 256]               0
      BatchNorm1d-61              [-1, 16, 256]              32
             ReLU-62              [-1, 16, 256]               0
          Dropout-63              [-1, 16, 256]               0
           Conv1d-64              [-1, 16, 128]             528
  MyConv1dPadSame-65              [-1, 16, 128]               0
      BatchNorm1d-66              [-1, 16, 128]              32
             ReLU-67              [-1, 16, 128]               0
          Dropout-68              [-1, 16, 128]               0
           Conv1d-69              [-1, 16, 128]             528
  MyConv1dPadSame-70              [-1, 16, 128]               0
        MaxPool1d-71              [-1, 16, 128]               0
MyMaxPool1dPadSame-72              [-1, 16, 128]               0
       Bottleneck-73              [-1, 16, 128]               0
      BatchNorm1d-74              [-1, 16, 128]              32
             ReLU-75              [-1, 16, 128]               0
          Dropout-76              [-1, 16, 128]               0
           Conv1d-77              [-1, 16, 128]             528
  MyConv1dPadSame-78              [-1, 16, 128]               0
      BatchNorm1d-79              [-1, 16, 128]              32
             ReLU-80              [-1, 16, 128]               0
          Dropout-81              [-1, 16, 128]               0
           Conv1d-82              [-1, 16, 128]             528
  MyConv1dPadSame-83              [-1, 16, 128]               0
       Bottleneck-84              [-1, 16, 128]               0
      BatchNorm1d-85              [-1, 16, 128]              32
             ReLU-86              [-1, 16, 128]               0
          Dropout-87              [-1, 16, 128]               0
           Conv1d-88               [-1, 16, 64]             528
  MyConv1dPadSame-89               [-1, 16, 64]               0
      BatchNorm1d-90               [-1, 16, 64]              32
             ReLU-91               [-1, 16, 64]               0
          Dropout-92               [-1, 16, 64]               0
           Conv1d-93               [-1, 16, 64]             528
  MyConv1dPadSame-94               [-1, 16, 64]               0
        MaxPool1d-95               [-1, 16, 64]               0
MyMaxPool1dPadSame-96               [-1, 16, 64]               0
       Bottleneck-97               [-1, 16, 64]               0
      BatchNorm1d-98               [-1, 16, 64]              32
             ReLU-99               [-1, 16, 64]               0
         Dropout-100               [-1, 16, 64]               0
          Conv1d-101               [-1, 32, 64]           1,056
 MyConv1dPadSame-102               [-1, 32, 64]               0
     BatchNorm1d-103               [-1, 32, 64]              64
            ReLU-104               [-1, 32, 64]               0
         Dropout-105               [-1, 32, 64]               0
          Conv1d-106               [-1, 32, 64]           2,080
 MyConv1dPadSame-107               [-1, 32, 64]               0
      Bottleneck-108               [-1, 32, 64]               0
     BatchNorm1d-109               [-1, 32, 64]              64
            ReLU-110               [-1, 32, 64]               0
         Dropout-111               [-1, 32, 64]               0
          Conv1d-112               [-1, 32, 32]           2,080
 MyConv1dPadSame-113               [-1, 32, 32]               0
     BatchNorm1d-114               [-1, 32, 32]              64
            ReLU-115               [-1, 32, 32]               0
         Dropout-116               [-1, 32, 32]               0
          Conv1d-117               [-1, 32, 32]           2,080
 MyConv1dPadSame-118               [-1, 32, 32]               0
       MaxPool1d-119               [-1, 32, 32]               0
MyMaxPool1dPadSame-120               [-1, 32, 32]               0
      Bottleneck-121               [-1, 32, 32]               0
     BatchNorm1d-122               [-1, 32, 32]              64
            ReLU-123               [-1, 32, 32]               0
         Dropout-124               [-1, 32, 32]               0
          Conv1d-125               [-1, 32, 32]           2,080
 MyConv1dPadSame-126               [-1, 32, 32]               0
     BatchNorm1d-127               [-1, 32, 32]              64
            ReLU-128               [-1, 32, 32]               0
         Dropout-129               [-1, 32, 32]               0
          Conv1d-130               [-1, 32, 32]           2,080
 MyConv1dPadSame-131               [-1, 32, 32]               0
      Bottleneck-132               [-1, 32, 32]               0
     BatchNorm1d-133               [-1, 32, 32]              64
            ReLU-134               [-1, 32, 32]               0
         Dropout-135               [-1, 32, 32]               0
          Conv1d-136               [-1, 32, 16]           2,080
 MyConv1dPadSame-137               [-1, 32, 16]               0
     BatchNorm1d-138               [-1, 32, 16]              64
            ReLU-139               [-1, 32, 16]               0
         Dropout-140               [-1, 32, 16]               0
          Conv1d-141               [-1, 32, 16]           2,080
 MyConv1dPadSame-142               [-1, 32, 16]               0
       MaxPool1d-143               [-1, 32, 16]               0
MyMaxPool1dPadSame-144               [-1, 32, 16]               0
      Bottleneck-145               [-1, 32, 16]               0
     BatchNorm1d-146               [-1, 32, 16]              64
            ReLU-147               [-1, 32, 16]               0
         Dropout-148               [-1, 32, 16]               0
          Conv1d-149               [-1, 64, 16]           4,160
 MyConv1dPadSame-150               [-1, 64, 16]               0
     BatchNorm1d-151               [-1, 64, 16]             128
            ReLU-152               [-1, 64, 16]               0
         Dropout-153               [-1, 64, 16]               0
          Conv1d-154               [-1, 64, 16]           8,256
 MyConv1dPadSame-155               [-1, 64, 16]               0
      Bottleneck-156               [-1, 64, 16]               0
     BatchNorm1d-157               [-1, 64, 16]             128
            ReLU-158               [-1, 64, 16]               0
         Dropout-159               [-1, 64, 16]               0
          Conv1d-160                [-1, 64, 8]           8,256
 MyConv1dPadSame-161                [-1, 64, 8]               0
     BatchNorm1d-162                [-1, 64, 8]             128
            ReLU-163                [-1, 64, 8]               0
         Dropout-164                [-1, 64, 8]               0
          Conv1d-165                [-1, 64, 8]           8,256
 MyConv1dPadSame-166                [-1, 64, 8]               0
       MaxPool1d-167                [-1, 64, 8]               0
MyMaxPool1dPadSame-168                [-1, 64, 8]               0
      Bottleneck-169                [-1, 64, 8]               0
     BatchNorm1d-170                [-1, 64, 8]             128
            ReLU-171                [-1, 64, 8]               0
         Dropout-172                [-1, 64, 8]               0
          Conv1d-173                [-1, 64, 8]           8,256
 MyConv1dPadSame-174                [-1, 64, 8]               0
     BatchNorm1d-175                [-1, 64, 8]             128
            ReLU-176                [-1, 64, 8]               0
         Dropout-177                [-1, 64, 8]               0
          Conv1d-178                [-1, 64, 8]           8,256
 MyConv1dPadSame-179                [-1, 64, 8]               0
      Bottleneck-180                [-1, 64, 8]               0
     BatchNorm1d-181                [-1, 64, 8]             128
            ReLU-182                [-1, 64, 8]               0
         Dropout-183                [-1, 64, 8]               0
          Conv1d-184                [-1, 64, 4]           8,256
 MyConv1dPadSame-185                [-1, 64, 4]               0
     BatchNorm1d-186                [-1, 64, 4]             128
            ReLU-187                [-1, 64, 4]               0
         Dropout-188                [-1, 64, 4]               0
          Conv1d-189                [-1, 64, 4]           8,256
 MyConv1dPadSame-190                [-1, 64, 4]               0
       MaxPool1d-191                [-1, 64, 4]               0
MyMaxPool1dPadSame-192                [-1, 64, 4]               0
      Bottleneck-193                [-1, 64, 4]               0
     BatchNorm1d-194                [-1, 64, 4]             128
            ReLU-195                [-1, 64, 4]               0
          Linear-196                    [-1, 2]             130
================================================================
Total params: 84,826
Trainable params: 84,826
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 3.32
Params size (MB): 0.32
Estimated Total Size (MB): 3.65
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 16, kernel_size: 2, n_block: 2
************************************************************
************************************************************
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 16, 1024]              48
   MyConv1dPadSame-2             [-1, 16, 1024]               0
       BatchNorm1d-3             [-1, 16, 1024]              32
              ReLU-4             [-1, 16, 1024]               0
            Conv1d-5             [-1, 16, 1024]              48
   MyConv1dPadSame-6             [-1, 16, 1024]               0
       BatchNorm1d-7             [-1, 16, 1024]              32
              ReLU-8             [-1, 16, 1024]               0
           Dropout-9             [-1, 16, 1024]               0
           Conv1d-10             [-1, 16, 1024]              48
  MyConv1dPadSame-11             [-1, 16, 1024]               0
       Bottleneck-12             [-1, 16, 1024]               0
      BatchNorm1d-13             [-1, 16, 1024]              32
             ReLU-14             [-1, 16, 1024]               0
          Dropout-15             [-1, 16, 1024]               0
           Conv1d-16             [-1, 32, 1024]              96
  MyConv1dPadSame-17             [-1, 32, 1024]               0
      BatchNorm1d-18             [-1, 32, 1024]              64
             ReLU-19             [-1, 32, 1024]               0
          Dropout-20             [-1, 32, 1024]               0
           Conv1d-21             [-1, 32, 1024]             160
  MyConv1dPadSame-22             [-1, 32, 1024]               0
       Bottleneck-23             [-1, 32, 1024]               0
      BatchNorm1d-24             [-1, 32, 1024]              64
             ReLU-25             [-1, 32, 1024]               0
           Linear-26                    [-1, 2]              66
================================================================
Total params: 690
Trainable params: 690
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 4.38
Params size (MB): 0.00
Estimated Total Size (MB): 4.38
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 16, kernel_size: 2, n_block: 4
************************************************************
************************************************************
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 16, 1024]              48
   MyConv1dPadSame-2             [-1, 16, 1024]               0
       BatchNorm1d-3             [-1, 16, 1024]              32
              ReLU-4             [-1, 16, 1024]               0
            Conv1d-5             [-1, 16, 1024]              48
   MyConv1dPadSame-6             [-1, 16, 1024]               0
       BatchNorm1d-7             [-1, 16, 1024]              32
              ReLU-8             [-1, 16, 1024]               0
           Dropout-9             [-1, 16, 1024]               0
           Conv1d-10             [-1, 16, 1024]              48
  MyConv1dPadSame-11             [-1, 16, 1024]               0
       Bottleneck-12             [-1, 16, 1024]               0
      BatchNorm1d-13             [-1, 16, 1024]              32
             ReLU-14             [-1, 16, 1024]               0
          Dropout-15             [-1, 16, 1024]               0
           Conv1d-16             [-1, 32, 1024]              96
  MyConv1dPadSame-17             [-1, 32, 1024]               0
      BatchNorm1d-18             [-1, 32, 1024]              64
             ReLU-19             [-1, 32, 1024]               0
          Dropout-20             [-1, 32, 1024]               0
           Conv1d-21             [-1, 32, 1024]             160
  MyConv1dPadSame-22             [-1, 32, 1024]               0
       Bottleneck-23             [-1, 32, 1024]               0
      BatchNorm1d-24             [-1, 32, 1024]              64
             ReLU-25             [-1, 32, 1024]               0
          Dropout-26             [-1, 32, 1024]               0
           Conv1d-27             [-1, 64, 1024]             320
  MyConv1dPadSame-28             [-1, 64, 1024]               0
      BatchNorm1d-29             [-1, 64, 1024]             128
             ReLU-30             [-1, 64, 1024]               0
          Dropout-31             [-1, 64, 1024]               0
           Conv1d-32             [-1, 64, 1024]             576
  MyConv1dPadSame-33             [-1, 64, 1024]               0
       Bottleneck-34             [-1, 64, 1024]               0
      BatchNorm1d-35             [-1, 64, 1024]             128
             ReLU-36             [-1, 64, 1024]               0
          Dropout-37             [-1, 64, 1024]               0
           Conv1d-38            [-1, 128, 1024]           1,152
  MyConv1dPadSame-39            [-1, 128, 1024]               0
      BatchNorm1d-40            [-1, 128, 1024]             256
             ReLU-41            [-1, 128, 1024]               0
          Dropout-42            [-1, 128, 1024]               0
           Conv1d-43            [-1, 128, 1024]           2,176
  MyConv1dPadSame-44            [-1, 128, 1024]               0
       Bottleneck-45            [-1, 128, 1024]               0
      BatchNorm1d-46            [-1, 128, 1024]             256
             ReLU-47            [-1, 128, 1024]               0
           Linear-48                    [-1, 2]             258
================================================================
Total params: 5,874
Trainable params: 5,874
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 20.13
Params size (MB): 0.02
Estimated Total Size (MB): 20.15
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 16, kernel_size: 2, n_block: 8
************************************************************
************************************************************
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 16, 1024]              48
   MyConv1dPadSame-2             [-1, 16, 1024]               0
       BatchNorm1d-3             [-1, 16, 1024]              32
              ReLU-4             [-1, 16, 1024]               0
            Conv1d-5             [-1, 16, 1024]              48
   MyConv1dPadSame-6             [-1, 16, 1024]               0
       BatchNorm1d-7             [-1, 16, 1024]              32
              ReLU-8             [-1, 16, 1024]               0
           Dropout-9             [-1, 16, 1024]               0
           Conv1d-10             [-1, 16, 1024]              48
  MyConv1dPadSame-11             [-1, 16, 1024]               0
       Bottleneck-12             [-1, 16, 1024]               0
      BatchNorm1d-13             [-1, 16, 1024]              32
             ReLU-14             [-1, 16, 1024]               0
          Dropout-15             [-1, 16, 1024]               0
           Conv1d-16             [-1, 16, 1024]              48
  MyConv1dPadSame-17             [-1, 16, 1024]               0
      BatchNorm1d-18             [-1, 16, 1024]              32
             ReLU-19             [-1, 16, 1024]               0
          Dropout-20             [-1, 16, 1024]               0
           Conv1d-21             [-1, 16, 1024]              48
  MyConv1dPadSame-22             [-1, 16, 1024]               0
       Bottleneck-23             [-1, 16, 1024]               0
      BatchNorm1d-24             [-1, 16, 1024]              32
             ReLU-25             [-1, 16, 1024]               0
          Dropout-26             [-1, 16, 1024]               0
           Conv1d-27             [-1, 32, 1024]              96
  MyConv1dPadSame-28             [-1, 32, 1024]               0
      BatchNorm1d-29             [-1, 32, 1024]              64
             ReLU-30             [-1, 32, 1024]               0
          Dropout-31             [-1, 32, 1024]               0
           Conv1d-32             [-1, 32, 1024]             160
  MyConv1dPadSame-33             [-1, 32, 1024]               0
       Bottleneck-34             [-1, 32, 1024]               0
      BatchNorm1d-35             [-1, 32, 1024]              64
             ReLU-36             [-1, 32, 1024]               0
          Dropout-37             [-1, 32, 1024]               0
           Conv1d-38             [-1, 32, 1024]             160
  MyConv1dPadSame-39             [-1, 32, 1024]               0
      BatchNorm1d-40             [-1, 32, 1024]              64
             ReLU-41             [-1, 32, 1024]               0
          Dropout-42             [-1, 32, 1024]               0
           Conv1d-43             [-1, 32, 1024]             160
  MyConv1dPadSame-44             [-1, 32, 1024]               0
       Bottleneck-45             [-1, 32, 1024]               0
      BatchNorm1d-46             [-1, 32, 1024]              64
             ReLU-47             [-1, 32, 1024]               0
          Dropout-48             [-1, 32, 1024]               0
           Conv1d-49             [-1, 64, 1024]             320
  MyConv1dPadSame-50             [-1, 64, 1024]               0
      BatchNorm1d-51             [-1, 64, 1024]             128
             ReLU-52             [-1, 64, 1024]               0
          Dropout-53             [-1, 64, 1024]               0
           Conv1d-54             [-1, 64, 1024]             576
  MyConv1dPadSame-55             [-1, 64, 1024]               0
       Bottleneck-56             [-1, 64, 1024]               0
      BatchNorm1d-57             [-1, 64, 1024]             128
             ReLU-58             [-1, 64, 1024]               0
          Dropout-59             [-1, 64, 1024]               0
           Conv1d-60             [-1, 64, 1024]             576
  MyConv1dPadSame-61             [-1, 64, 1024]               0
      BatchNorm1d-62             [-1, 64, 1024]             128
             ReLU-63             [-1, 64, 1024]               0
          Dropout-64             [-1, 64, 1024]               0
           Conv1d-65             [-1, 64, 1024]             576
  MyConv1dPadSame-66             [-1, 64, 1024]               0
       Bottleneck-67             [-1, 64, 1024]               0
      BatchNorm1d-68             [-1, 64, 1024]             128
             ReLU-69             [-1, 64, 1024]               0
          Dropout-70             [-1, 64, 1024]               0
           Conv1d-71            [-1, 128, 1024]           1,152
  MyConv1dPadSame-72            [-1, 128, 1024]               0
      BatchNorm1d-73            [-1, 128, 1024]             256
             ReLU-74            [-1, 128, 1024]               0
          Dropout-75            [-1, 128, 1024]               0
           Conv1d-76            [-1, 128, 1024]           2,176
  MyConv1dPadSame-77            [-1, 128, 1024]               0
       Bottleneck-78            [-1, 128, 1024]               0
      BatchNorm1d-79            [-1, 128, 1024]             256
             ReLU-80            [-1, 128, 1024]               0
          Dropout-81            [-1, 128, 1024]               0
           Conv1d-82            [-1, 128, 1024]           2,176
  MyConv1dPadSame-83            [-1, 128, 1024]               0
      BatchNorm1d-84            [-1, 128, 1024]             256
             ReLU-85            [-1, 128, 1024]               0
          Dropout-86            [-1, 128, 1024]               0
           Conv1d-87            [-1, 128, 1024]           2,176
  MyConv1dPadSame-88            [-1, 128, 1024]               0
       Bottleneck-89            [-1, 128, 1024]               0
      BatchNorm1d-90            [-1, 128, 1024]             256
             ReLU-91            [-1, 128, 1024]               0
           Linear-92                    [-1, 2]             258
================================================================
Total params: 12,754
Trainable params: 12,754
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 40.75
Params size (MB): 0.05
Estimated Total Size (MB): 40.80
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 16, kernel_size: 2, n_block: 16
************************************************************
************************************************************
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 16, 1024]              48
   MyConv1dPadSame-2             [-1, 16, 1024]               0
       BatchNorm1d-3             [-1, 16, 1024]              32
              ReLU-4             [-1, 16, 1024]               0
            Conv1d-5             [-1, 16, 1024]              48
   MyConv1dPadSame-6             [-1, 16, 1024]               0
       BatchNorm1d-7             [-1, 16, 1024]              32
              ReLU-8             [-1, 16, 1024]               0
           Dropout-9             [-1, 16, 1024]               0
           Conv1d-10             [-1, 16, 1024]              48
  MyConv1dPadSame-11             [-1, 16, 1024]               0
       Bottleneck-12             [-1, 16, 1024]               0
      BatchNorm1d-13             [-1, 16, 1024]              32
             ReLU-14             [-1, 16, 1024]               0
          Dropout-15             [-1, 16, 1024]               0
           Conv1d-16              [-1, 16, 512]              48
  MyConv1dPadSame-17              [-1, 16, 512]               0
      BatchNorm1d-18              [-1, 16, 512]              32
             ReLU-19              [-1, 16, 512]               0
          Dropout-20              [-1, 16, 512]               0
           Conv1d-21              [-1, 16, 512]              48
  MyConv1dPadSame-22              [-1, 16, 512]               0
        MaxPool1d-23              [-1, 16, 512]               0
MyMaxPool1dPadSame-24              [-1, 16, 512]               0
       Bottleneck-25              [-1, 16, 512]               0
      BatchNorm1d-26              [-1, 16, 512]              32
             ReLU-27              [-1, 16, 512]               0
          Dropout-28              [-1, 16, 512]               0
           Conv1d-29              [-1, 16, 512]              48
  MyConv1dPadSame-30              [-1, 16, 512]               0
      BatchNorm1d-31              [-1, 16, 512]              32
             ReLU-32              [-1, 16, 512]               0
          Dropout-33              [-1, 16, 512]               0
           Conv1d-34              [-1, 16, 512]              48
  MyConv1dPadSame-35              [-1, 16, 512]               0
       Bottleneck-36              [-1, 16, 512]               0
      BatchNorm1d-37              [-1, 16, 512]              32
             ReLU-38              [-1, 16, 512]               0
          Dropout-39              [-1, 16, 512]               0
           Conv1d-40              [-1, 16, 256]              48
  MyConv1dPadSame-41              [-1, 16, 256]               0
      BatchNorm1d-42              [-1, 16, 256]              32
             ReLU-43              [-1, 16, 256]               0
          Dropout-44              [-1, 16, 256]               0
           Conv1d-45              [-1, 16, 256]              48
  MyConv1dPadSame-46              [-1, 16, 256]               0
        MaxPool1d-47              [-1, 16, 256]               0
MyMaxPool1dPadSame-48              [-1, 16, 256]               0
       Bottleneck-49              [-1, 16, 256]               0
      BatchNorm1d-50              [-1, 16, 256]              32
             ReLU-51              [-1, 16, 256]               0
          Dropout-52              [-1, 16, 256]               0
           Conv1d-53              [-1, 32, 256]              96
  MyConv1dPadSame-54              [-1, 32, 256]               0
      BatchNorm1d-55              [-1, 32, 256]              64
             ReLU-56              [-1, 32, 256]               0
          Dropout-57              [-1, 32, 256]               0
           Conv1d-58              [-1, 32, 256]             160
  MyConv1dPadSame-59              [-1, 32, 256]               0
       Bottleneck-60              [-1, 32, 256]               0
      BatchNorm1d-61              [-1, 32, 256]              64
             ReLU-62              [-1, 32, 256]               0
          Dropout-63              [-1, 32, 256]               0
           Conv1d-64              [-1, 32, 128]             160
  MyConv1dPadSame-65              [-1, 32, 128]               0
      BatchNorm1d-66              [-1, 32, 128]              64
             ReLU-67              [-1, 32, 128]               0
          Dropout-68              [-1, 32, 128]               0
           Conv1d-69              [-1, 32, 128]             160
  MyConv1dPadSame-70              [-1, 32, 128]               0
        MaxPool1d-71              [-1, 32, 128]               0
MyMaxPool1dPadSame-72              [-1, 32, 128]               0
       Bottleneck-73              [-1, 32, 128]               0
      BatchNorm1d-74              [-1, 32, 128]              64
             ReLU-75              [-1, 32, 128]               0
          Dropout-76              [-1, 32, 128]               0
           Conv1d-77              [-1, 32, 128]             160
  MyConv1dPadSame-78              [-1, 32, 128]               0
      BatchNorm1d-79              [-1, 32, 128]              64
             ReLU-80              [-1, 32, 128]               0
          Dropout-81              [-1, 32, 128]               0
           Conv1d-82              [-1, 32, 128]             160
  MyConv1dPadSame-83              [-1, 32, 128]               0
       Bottleneck-84              [-1, 32, 128]               0
      BatchNorm1d-85              [-1, 32, 128]              64
             ReLU-86              [-1, 32, 128]               0
          Dropout-87              [-1, 32, 128]               0
           Conv1d-88               [-1, 32, 64]             160
  MyConv1dPadSame-89               [-1, 32, 64]               0
      BatchNorm1d-90               [-1, 32, 64]              64
             ReLU-91               [-1, 32, 64]               0
          Dropout-92               [-1, 32, 64]               0
           Conv1d-93               [-1, 32, 64]             160
  MyConv1dPadSame-94               [-1, 32, 64]               0
        MaxPool1d-95               [-1, 32, 64]               0
MyMaxPool1dPadSame-96               [-1, 32, 64]               0
       Bottleneck-97               [-1, 32, 64]               0
      BatchNorm1d-98               [-1, 32, 64]              64
             ReLU-99               [-1, 32, 64]               0
         Dropout-100               [-1, 32, 64]               0
          Conv1d-101               [-1, 64, 64]             320
 MyConv1dPadSame-102               [-1, 64, 64]               0
     BatchNorm1d-103               [-1, 64, 64]             128
            ReLU-104               [-1, 64, 64]               0
         Dropout-105               [-1, 64, 64]               0
          Conv1d-106               [-1, 64, 64]             576
 MyConv1dPadSame-107               [-1, 64, 64]               0
      Bottleneck-108               [-1, 64, 64]               0
     BatchNorm1d-109               [-1, 64, 64]             128
            ReLU-110               [-1, 64, 64]               0
         Dropout-111               [-1, 64, 64]               0
          Conv1d-112               [-1, 64, 32]             576
 MyConv1dPadSame-113               [-1, 64, 32]               0
     BatchNorm1d-114               [-1, 64, 32]             128
            ReLU-115               [-1, 64, 32]               0
         Dropout-116               [-1, 64, 32]               0
          Conv1d-117               [-1, 64, 32]             576
 MyConv1dPadSame-118               [-1, 64, 32]               0
       MaxPool1d-119               [-1, 64, 32]               0
MyMaxPool1dPadSame-120               [-1, 64, 32]               0
      Bottleneck-121               [-1, 64, 32]               0
     BatchNorm1d-122               [-1, 64, 32]             128
            ReLU-123               [-1, 64, 32]               0
         Dropout-124               [-1, 64, 32]               0
          Conv1d-125               [-1, 64, 32]             576
 MyConv1dPadSame-126               [-1, 64, 32]               0
     BatchNorm1d-127               [-1, 64, 32]             128
            ReLU-128               [-1, 64, 32]               0
         Dropout-129               [-1, 64, 32]               0
          Conv1d-130               [-1, 64, 32]             576
 MyConv1dPadSame-131               [-1, 64, 32]               0
      Bottleneck-132               [-1, 64, 32]               0
     BatchNorm1d-133               [-1, 64, 32]             128
            ReLU-134               [-1, 64, 32]               0
         Dropout-135               [-1, 64, 32]               0
          Conv1d-136               [-1, 64, 16]             576
 MyConv1dPadSame-137               [-1, 64, 16]               0
     BatchNorm1d-138               [-1, 64, 16]             128
            ReLU-139               [-1, 64, 16]               0
         Dropout-140               [-1, 64, 16]               0
          Conv1d-141               [-1, 64, 16]             576
 MyConv1dPadSame-142               [-1, 64, 16]               0
       MaxPool1d-143               [-1, 64, 16]               0
MyMaxPool1dPadSame-144               [-1, 64, 16]               0
      Bottleneck-145               [-1, 64, 16]               0
     BatchNorm1d-146               [-1, 64, 16]             128
            ReLU-147               [-1, 64, 16]               0
         Dropout-148               [-1, 64, 16]               0
          Conv1d-149              [-1, 128, 16]           1,152
 MyConv1dPadSame-150              [-1, 128, 16]               0
     BatchNorm1d-151              [-1, 128, 16]             256
            ReLU-152              [-1, 128, 16]               0
         Dropout-153              [-1, 128, 16]               0
          Conv1d-154              [-1, 128, 16]           2,176
 MyConv1dPadSame-155              [-1, 128, 16]               0
      Bottleneck-156              [-1, 128, 16]               0
     BatchNorm1d-157              [-1, 128, 16]             256
            ReLU-158              [-1, 128, 16]               0
         Dropout-159              [-1, 128, 16]               0
          Conv1d-160               [-1, 128, 8]           2,176
 MyConv1dPadSame-161               [-1, 128, 8]               0
     BatchNorm1d-162               [-1, 128, 8]             256
            ReLU-163               [-1, 128, 8]               0
         Dropout-164               [-1, 128, 8]               0
          Conv1d-165               [-1, 128, 8]           2,176
 MyConv1dPadSame-166               [-1, 128, 8]               0
       MaxPool1d-167               [-1, 128, 8]               0
MyMaxPool1dPadSame-168               [-1, 128, 8]               0
      Bottleneck-169               [-1, 128, 8]               0
     BatchNorm1d-170               [-1, 128, 8]             256
            ReLU-171               [-1, 128, 8]               0
         Dropout-172               [-1, 128, 8]               0
          Conv1d-173               [-1, 128, 8]           2,176
 MyConv1dPadSame-174               [-1, 128, 8]               0
     BatchNorm1d-175               [-1, 128, 8]             256
            ReLU-176               [-1, 128, 8]               0
         Dropout-177               [-1, 128, 8]               0
          Conv1d-178               [-1, 128, 8]           2,176
 MyConv1dPadSame-179               [-1, 128, 8]               0
      Bottleneck-180               [-1, 128, 8]               0
     BatchNorm1d-181               [-1, 128, 8]             256
            ReLU-182               [-1, 128, 8]               0
         Dropout-183               [-1, 128, 8]               0
          Conv1d-184               [-1, 128, 4]           2,176
 MyConv1dPadSame-185               [-1, 128, 4]               0
     BatchNorm1d-186               [-1, 128, 4]             256
            ReLU-187               [-1, 128, 4]               0
         Dropout-188               [-1, 128, 4]               0
          Conv1d-189               [-1, 128, 4]           2,176
 MyConv1dPadSame-190               [-1, 128, 4]               0
       MaxPool1d-191               [-1, 128, 4]               0
MyMaxPool1dPadSame-192               [-1, 128, 4]               0
      Bottleneck-193               [-1, 128, 4]               0
     BatchNorm1d-194               [-1, 128, 4]             256
            ReLU-195               [-1, 128, 4]               0
          Linear-196                    [-1, 2]             258
================================================================
Total params: 26,514
Trainable params: 26,514
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 6.65
Params size (MB): 0.10
Estimated Total Size (MB): 6.75
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 16, kernel_size: 4, n_block: 2
************************************************************
************************************************************
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 16, 1024]              80
   MyConv1dPadSame-2             [-1, 16, 1024]               0
       BatchNorm1d-3             [-1, 16, 1024]              32
              ReLU-4             [-1, 16, 1024]               0
            Conv1d-5             [-1, 16, 1024]              80
   MyConv1dPadSame-6             [-1, 16, 1024]               0
       BatchNorm1d-7             [-1, 16, 1024]              32
              ReLU-8             [-1, 16, 1024]               0
           Dropout-9             [-1, 16, 1024]               0
           Conv1d-10             [-1, 16, 1024]              80
  MyConv1dPadSame-11             [-1, 16, 1024]               0
       Bottleneck-12             [-1, 16, 1024]               0
      BatchNorm1d-13             [-1, 16, 1024]              32
             ReLU-14             [-1, 16, 1024]               0
          Dropout-15             [-1, 16, 1024]               0
           Conv1d-16             [-1, 32, 1024]             160
  MyConv1dPadSame-17             [-1, 32, 1024]               0
      BatchNorm1d-18             [-1, 32, 1024]              64
             ReLU-19             [-1, 32, 1024]               0
          Dropout-20             [-1, 32, 1024]               0
           Conv1d-21             [-1, 32, 1024]             288
  MyConv1dPadSame-22             [-1, 32, 1024]               0
       Bottleneck-23             [-1, 32, 1024]               0
      BatchNorm1d-24             [-1, 32, 1024]              64
             ReLU-25             [-1, 32, 1024]               0
           Linear-26                    [-1, 2]              66
================================================================
Total params: 978
Trainable params: 978
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 4.38
Params size (MB): 0.00
Estimated Total Size (MB): 4.38
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 16, kernel_size: 4, n_block: 4
************************************************************
************************************************************
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 16, 1024]              80
   MyConv1dPadSame-2             [-1, 16, 1024]               0
       BatchNorm1d-3             [-1, 16, 1024]              32
              ReLU-4             [-1, 16, 1024]               0
            Conv1d-5             [-1, 16, 1024]              80
   MyConv1dPadSame-6             [-1, 16, 1024]               0
       BatchNorm1d-7             [-1, 16, 1024]              32
              ReLU-8             [-1, 16, 1024]               0
           Dropout-9             [-1, 16, 1024]               0
           Conv1d-10             [-1, 16, 1024]              80
  MyConv1dPadSame-11             [-1, 16, 1024]               0
       Bottleneck-12             [-1, 16, 1024]               0
      BatchNorm1d-13             [-1, 16, 1024]              32
             ReLU-14             [-1, 16, 1024]               0
          Dropout-15             [-1, 16, 1024]               0
           Conv1d-16             [-1, 32, 1024]             160
  MyConv1dPadSame-17             [-1, 32, 1024]               0
      BatchNorm1d-18             [-1, 32, 1024]              64
             ReLU-19             [-1, 32, 1024]               0
          Dropout-20             [-1, 32, 1024]               0
           Conv1d-21             [-1, 32, 1024]             288
  MyConv1dPadSame-22             [-1, 32, 1024]               0
       Bottleneck-23             [-1, 32, 1024]               0
      BatchNorm1d-24             [-1, 32, 1024]              64
             ReLU-25             [-1, 32, 1024]               0
          Dropout-26             [-1, 32, 1024]               0
           Conv1d-27             [-1, 64, 1024]             576
  MyConv1dPadSame-28             [-1, 64, 1024]               0
      BatchNorm1d-29             [-1, 64, 1024]             128
             ReLU-30             [-1, 64, 1024]               0
          Dropout-31             [-1, 64, 1024]               0
           Conv1d-32             [-1, 64, 1024]           1,088
  MyConv1dPadSame-33             [-1, 64, 1024]               0
       Bottleneck-34             [-1, 64, 1024]               0
      BatchNorm1d-35             [-1, 64, 1024]             128
             ReLU-36             [-1, 64, 1024]               0
          Dropout-37             [-1, 64, 1024]               0
           Conv1d-38            [-1, 128, 1024]           2,176
  MyConv1dPadSame-39            [-1, 128, 1024]               0
      BatchNorm1d-40            [-1, 128, 1024]             256
             ReLU-41            [-1, 128, 1024]               0
          Dropout-42            [-1, 128, 1024]               0
           Conv1d-43            [-1, 128, 1024]           4,224
  MyConv1dPadSame-44            [-1, 128, 1024]               0
       Bottleneck-45            [-1, 128, 1024]               0
      BatchNorm1d-46            [-1, 128, 1024]             256
             ReLU-47            [-1, 128, 1024]               0
           Linear-48                    [-1, 2]             258
================================================================
Total params: 10,002
Trainable params: 10,002
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 20.13
Params size (MB): 0.04
Estimated Total Size (MB): 20.17
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 16, kernel_size: 4, n_block: 8
************************************************************
************************************************************
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 16, 1024]              80
   MyConv1dPadSame-2             [-1, 16, 1024]               0
       BatchNorm1d-3             [-1, 16, 1024]              32
              ReLU-4             [-1, 16, 1024]               0
            Conv1d-5             [-1, 16, 1024]              80
   MyConv1dPadSame-6             [-1, 16, 1024]               0
       BatchNorm1d-7             [-1, 16, 1024]              32
              ReLU-8             [-1, 16, 1024]               0
           Dropout-9             [-1, 16, 1024]               0
           Conv1d-10             [-1, 16, 1024]              80
  MyConv1dPadSame-11             [-1, 16, 1024]               0
       Bottleneck-12             [-1, 16, 1024]               0
      BatchNorm1d-13             [-1, 16, 1024]              32
             ReLU-14             [-1, 16, 1024]               0
          Dropout-15             [-1, 16, 1024]               0
           Conv1d-16             [-1, 16, 1024]              80
  MyConv1dPadSame-17             [-1, 16, 1024]               0
      BatchNorm1d-18             [-1, 16, 1024]              32
             ReLU-19             [-1, 16, 1024]               0
          Dropout-20             [-1, 16, 1024]               0
           Conv1d-21             [-1, 16, 1024]              80
  MyConv1dPadSame-22             [-1, 16, 1024]               0
       Bottleneck-23             [-1, 16, 1024]               0
      BatchNorm1d-24             [-1, 16, 1024]              32
             ReLU-25             [-1, 16, 1024]               0
          Dropout-26             [-1, 16, 1024]               0
           Conv1d-27             [-1, 32, 1024]             160
  MyConv1dPadSame-28             [-1, 32, 1024]               0
      BatchNorm1d-29             [-1, 32, 1024]              64
             ReLU-30             [-1, 32, 1024]               0
          Dropout-31             [-1, 32, 1024]               0
           Conv1d-32             [-1, 32, 1024]             288
  MyConv1dPadSame-33             [-1, 32, 1024]               0
       Bottleneck-34             [-1, 32, 1024]               0
      BatchNorm1d-35             [-1, 32, 1024]              64
             ReLU-36             [-1, 32, 1024]               0
          Dropout-37             [-1, 32, 1024]               0
           Conv1d-38             [-1, 32, 1024]             288
  MyConv1dPadSame-39             [-1, 32, 1024]               0
      BatchNorm1d-40             [-1, 32, 1024]              64
             ReLU-41             [-1, 32, 1024]               0
          Dropout-42             [-1, 32, 1024]               0
           Conv1d-43             [-1, 32, 1024]             288
  MyConv1dPadSame-44             [-1, 32, 1024]               0
       Bottleneck-45             [-1, 32, 1024]               0
      BatchNorm1d-46             [-1, 32, 1024]              64
             ReLU-47             [-1, 32, 1024]               0
          Dropout-48             [-1, 32, 1024]               0
           Conv1d-49             [-1, 64, 1024]             576
  MyConv1dPadSame-50             [-1, 64, 1024]               0
      BatchNorm1d-51             [-1, 64, 1024]             128
             ReLU-52             [-1, 64, 1024]               0
          Dropout-53             [-1, 64, 1024]               0
           Conv1d-54             [-1, 64, 1024]           1,088
  MyConv1dPadSame-55             [-1, 64, 1024]               0
       Bottleneck-56             [-1, 64, 1024]               0
      BatchNorm1d-57             [-1, 64, 1024]             128
             ReLU-58             [-1, 64, 1024]               0
          Dropout-59             [-1, 64, 1024]               0
           Conv1d-60             [-1, 64, 1024]           1,088
  MyConv1dPadSame-61             [-1, 64, 1024]               0
      BatchNorm1d-62             [-1, 64, 1024]             128
             ReLU-63             [-1, 64, 1024]               0
          Dropout-64             [-1, 64, 1024]               0
           Conv1d-65             [-1, 64, 1024]           1,088
  MyConv1dPadSame-66             [-1, 64, 1024]               0
       Bottleneck-67             [-1, 64, 1024]               0
      BatchNorm1d-68             [-1, 64, 1024]             128
             ReLU-69             [-1, 64, 1024]               0
          Dropout-70             [-1, 64, 1024]               0
           Conv1d-71            [-1, 128, 1024]           2,176
  MyConv1dPadSame-72            [-1, 128, 1024]               0
      BatchNorm1d-73            [-1, 128, 1024]             256
             ReLU-74            [-1, 128, 1024]               0
          Dropout-75            [-1, 128, 1024]               0
           Conv1d-76            [-1, 128, 1024]           4,224
  MyConv1dPadSame-77            [-1, 128, 1024]               0
       Bottleneck-78            [-1, 128, 1024]               0
      BatchNorm1d-79            [-1, 128, 1024]             256
             ReLU-80            [-1, 128, 1024]               0
          Dropout-81            [-1, 128, 1024]               0
           Conv1d-82            [-1, 128, 1024]           4,224
  MyConv1dPadSame-83            [-1, 128, 1024]               0
      BatchNorm1d-84            [-1, 128, 1024]             256
             ReLU-85            [-1, 128, 1024]               0
          Dropout-86            [-1, 128, 1024]               0
           Conv1d-87            [-1, 128, 1024]           4,224
  MyConv1dPadSame-88            [-1, 128, 1024]               0
       Bottleneck-89            [-1, 128, 1024]               0
      BatchNorm1d-90            [-1, 128, 1024]             256
             ReLU-91            [-1, 128, 1024]               0
           Linear-92                    [-1, 2]             258
================================================================
Total params: 22,322
Trainable params: 22,322
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 40.75
Params size (MB): 0.09
Estimated Total Size (MB): 40.84
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 16, kernel_size: 4, n_block: 16
************************************************************
************************************************************
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 16, 1024]              80
   MyConv1dPadSame-2             [-1, 16, 1024]               0
       BatchNorm1d-3             [-1, 16, 1024]              32
              ReLU-4             [-1, 16, 1024]               0
            Conv1d-5             [-1, 16, 1024]              80
   MyConv1dPadSame-6             [-1, 16, 1024]               0
       BatchNorm1d-7             [-1, 16, 1024]              32
              ReLU-8             [-1, 16, 1024]               0
           Dropout-9             [-1, 16, 1024]               0
           Conv1d-10             [-1, 16, 1024]              80
  MyConv1dPadSame-11             [-1, 16, 1024]               0
       Bottleneck-12             [-1, 16, 1024]               0
      BatchNorm1d-13             [-1, 16, 1024]              32
             ReLU-14             [-1, 16, 1024]               0
          Dropout-15             [-1, 16, 1024]               0
           Conv1d-16              [-1, 16, 512]              80
  MyConv1dPadSame-17              [-1, 16, 512]               0
      BatchNorm1d-18              [-1, 16, 512]              32
             ReLU-19              [-1, 16, 512]               0
          Dropout-20              [-1, 16, 512]               0
           Conv1d-21              [-1, 16, 512]              80
  MyConv1dPadSame-22              [-1, 16, 512]               0
        MaxPool1d-23              [-1, 16, 512]               0
MyMaxPool1dPadSame-24              [-1, 16, 512]               0
       Bottleneck-25              [-1, 16, 512]               0
      BatchNorm1d-26              [-1, 16, 512]              32
             ReLU-27              [-1, 16, 512]               0
          Dropout-28              [-1, 16, 512]               0
           Conv1d-29              [-1, 16, 512]              80
  MyConv1dPadSame-30              [-1, 16, 512]               0
      BatchNorm1d-31              [-1, 16, 512]              32
             ReLU-32              [-1, 16, 512]               0
          Dropout-33              [-1, 16, 512]               0
           Conv1d-34              [-1, 16, 512]              80
  MyConv1dPadSame-35              [-1, 16, 512]               0
       Bottleneck-36              [-1, 16, 512]               0
      BatchNorm1d-37              [-1, 16, 512]              32
             ReLU-38              [-1, 16, 512]               0
          Dropout-39              [-1, 16, 512]               0
           Conv1d-40              [-1, 16, 256]              80
  MyConv1dPadSame-41              [-1, 16, 256]               0
      BatchNorm1d-42              [-1, 16, 256]              32
             ReLU-43              [-1, 16, 256]               0
          Dropout-44              [-1, 16, 256]               0
           Conv1d-45              [-1, 16, 256]              80
  MyConv1dPadSame-46              [-1, 16, 256]               0
        MaxPool1d-47              [-1, 16, 256]               0
MyMaxPool1dPadSame-48              [-1, 16, 256]               0
       Bottleneck-49              [-1, 16, 256]               0
      BatchNorm1d-50              [-1, 16, 256]              32
             ReLU-51              [-1, 16, 256]               0
          Dropout-52              [-1, 16, 256]               0
           Conv1d-53              [-1, 32, 256]             160
  MyConv1dPadSame-54              [-1, 32, 256]               0
      BatchNorm1d-55              [-1, 32, 256]              64
             ReLU-56              [-1, 32, 256]               0
          Dropout-57              [-1, 32, 256]               0
           Conv1d-58              [-1, 32, 256]             288
  MyConv1dPadSame-59              [-1, 32, 256]               0
       Bottleneck-60              [-1, 32, 256]               0
      BatchNorm1d-61              [-1, 32, 256]              64
             ReLU-62              [-1, 32, 256]               0
          Dropout-63              [-1, 32, 256]               0
           Conv1d-64              [-1, 32, 128]             288
  MyConv1dPadSame-65              [-1, 32, 128]               0
      BatchNorm1d-66              [-1, 32, 128]              64
             ReLU-67              [-1, 32, 128]               0
          Dropout-68              [-1, 32, 128]               0
           Conv1d-69              [-1, 32, 128]             288
  MyConv1dPadSame-70              [-1, 32, 128]               0
        MaxPool1d-71              [-1, 32, 128]               0
MyMaxPool1dPadSame-72              [-1, 32, 128]               0
       Bottleneck-73              [-1, 32, 128]               0
      BatchNorm1d-74              [-1, 32, 128]              64
             ReLU-75              [-1, 32, 128]               0
          Dropout-76              [-1, 32, 128]               0
           Conv1d-77              [-1, 32, 128]             288
  MyConv1dPadSame-78              [-1, 32, 128]               0
      BatchNorm1d-79              [-1, 32, 128]              64
             ReLU-80              [-1, 32, 128]               0
          Dropout-81              [-1, 32, 128]               0
           Conv1d-82              [-1, 32, 128]             288
  MyConv1dPadSame-83              [-1, 32, 128]               0
       Bottleneck-84              [-1, 32, 128]               0
      BatchNorm1d-85              [-1, 32, 128]              64
             ReLU-86              [-1, 32, 128]               0
          Dropout-87              [-1, 32, 128]               0
           Conv1d-88               [-1, 32, 64]             288
  MyConv1dPadSame-89               [-1, 32, 64]               0
      BatchNorm1d-90               [-1, 32, 64]              64
             ReLU-91               [-1, 32, 64]               0
          Dropout-92               [-1, 32, 64]               0
           Conv1d-93               [-1, 32, 64]             288
  MyConv1dPadSame-94               [-1, 32, 64]               0
        MaxPool1d-95               [-1, 32, 64]               0
MyMaxPool1dPadSame-96               [-1, 32, 64]               0
       Bottleneck-97               [-1, 32, 64]               0
      BatchNorm1d-98               [-1, 32, 64]              64
             ReLU-99               [-1, 32, 64]               0
         Dropout-100               [-1, 32, 64]               0
          Conv1d-101               [-1, 64, 64]             576
 MyConv1dPadSame-102               [-1, 64, 64]               0
     BatchNorm1d-103               [-1, 64, 64]             128
            ReLU-104               [-1, 64, 64]               0
         Dropout-105               [-1, 64, 64]               0
          Conv1d-106               [-1, 64, 64]           1,088
 MyConv1dPadSame-107               [-1, 64, 64]               0
      Bottleneck-108               [-1, 64, 64]               0
     BatchNorm1d-109               [-1, 64, 64]             128
            ReLU-110               [-1, 64, 64]               0
         Dropout-111               [-1, 64, 64]               0
          Conv1d-112               [-1, 64, 32]           1,088
 MyConv1dPadSame-113               [-1, 64, 32]               0
     BatchNorm1d-114               [-1, 64, 32]             128
            ReLU-115               [-1, 64, 32]               0
         Dropout-116               [-1, 64, 32]               0
          Conv1d-117               [-1, 64, 32]           1,088
 MyConv1dPadSame-118               [-1, 64, 32]               0
       MaxPool1d-119               [-1, 64, 32]               0
MyMaxPool1dPadSame-120               [-1, 64, 32]               0
      Bottleneck-121               [-1, 64, 32]               0
     BatchNorm1d-122               [-1, 64, 32]             128
            ReLU-123               [-1, 64, 32]               0
         Dropout-124               [-1, 64, 32]               0
          Conv1d-125               [-1, 64, 32]           1,088
 MyConv1dPadSame-126               [-1, 64, 32]               0
     BatchNorm1d-127               [-1, 64, 32]             128
            ReLU-128               [-1, 64, 32]               0
         Dropout-129               [-1, 64, 32]               0
          Conv1d-130               [-1, 64, 32]           1,088
 MyConv1dPadSame-131               [-1, 64, 32]               0
      Bottleneck-132               [-1, 64, 32]               0
     BatchNorm1d-133               [-1, 64, 32]             128
            ReLU-134               [-1, 64, 32]               0
         Dropout-135               [-1, 64, 32]               0
          Conv1d-136               [-1, 64, 16]           1,088
 MyConv1dPadSame-137               [-1, 64, 16]               0
     BatchNorm1d-138               [-1, 64, 16]             128
            ReLU-139               [-1, 64, 16]               0
         Dropout-140               [-1, 64, 16]               0
          Conv1d-141               [-1, 64, 16]           1,088
 MyConv1dPadSame-142               [-1, 64, 16]               0
       MaxPool1d-143               [-1, 64, 16]               0
MyMaxPool1dPadSame-144               [-1, 64, 16]               0
      Bottleneck-145               [-1, 64, 16]               0
     BatchNorm1d-146               [-1, 64, 16]             128
            ReLU-147               [-1, 64, 16]               0
         Dropout-148               [-1, 64, 16]               0
          Conv1d-149              [-1, 128, 16]           2,176
 MyConv1dPadSame-150              [-1, 128, 16]               0
     BatchNorm1d-151              [-1, 128, 16]             256
            ReLU-152              [-1, 128, 16]               0
         Dropout-153              [-1, 128, 16]               0
          Conv1d-154              [-1, 128, 16]           4,224
 MyConv1dPadSame-155              [-1, 128, 16]               0
      Bottleneck-156              [-1, 128, 16]               0
     BatchNorm1d-157              [-1, 128, 16]             256
            ReLU-158              [-1, 128, 16]               0
         Dropout-159              [-1, 128, 16]               0
          Conv1d-160               [-1, 128, 8]           4,224
 MyConv1dPadSame-161               [-1, 128, 8]               0
     BatchNorm1d-162               [-1, 128, 8]             256
            ReLU-163               [-1, 128, 8]               0
         Dropout-164               [-1, 128, 8]               0
          Conv1d-165               [-1, 128, 8]           4,224
 MyConv1dPadSame-166               [-1, 128, 8]               0
       MaxPool1d-167               [-1, 128, 8]               0
MyMaxPool1dPadSame-168               [-1, 128, 8]               0
      Bottleneck-169               [-1, 128, 8]               0
     BatchNorm1d-170               [-1, 128, 8]             256
            ReLU-171               [-1, 128, 8]               0
         Dropout-172               [-1, 128, 8]               0
          Conv1d-173               [-1, 128, 8]           4,224
 MyConv1dPadSame-174               [-1, 128, 8]               0
     BatchNorm1d-175               [-1, 128, 8]             256
            ReLU-176               [-1, 128, 8]               0
         Dropout-177               [-1, 128, 8]               0
          Conv1d-178               [-1, 128, 8]           4,224
 MyConv1dPadSame-179               [-1, 128, 8]               0
      Bottleneck-180               [-1, 128, 8]               0
     BatchNorm1d-181               [-1, 128, 8]             256
            ReLU-182               [-1, 128, 8]               0
         Dropout-183               [-1, 128, 8]               0
          Conv1d-184               [-1, 128, 4]           4,224
 MyConv1dPadSame-185               [-1, 128, 4]               0
     BatchNorm1d-186               [-1, 128, 4]             256
            ReLU-187               [-1, 128, 4]               0
         Dropout-188               [-1, 128, 4]               0
          Conv1d-189               [-1, 128, 4]           4,224
 MyConv1dPadSame-190               [-1, 128, 4]               0
       MaxPool1d-191               [-1, 128, 4]               0
MyMaxPool1dPadSame-192               [-1, 128, 4]               0
      Bottleneck-193               [-1, 128, 4]               0
     BatchNorm1d-194               [-1, 128, 4]             256
            ReLU-195               [-1, 128, 4]               0
          Linear-196                    [-1, 2]             258
================================================================
Total params: 46,962
Trainable params: 46,962
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 6.65
Params size (MB): 0.18
Estimated Total Size (MB): 6.83
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 16, kernel_size: 8, n_block: 2
************************************************************
************************************************************
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 16, 1024]             144
   MyConv1dPadSame-2             [-1, 16, 1024]               0
       BatchNorm1d-3             [-1, 16, 1024]              32
              ReLU-4             [-1, 16, 1024]               0
            Conv1d-5             [-1, 16, 1024]             144
   MyConv1dPadSame-6             [-1, 16, 1024]               0
       BatchNorm1d-7             [-1, 16, 1024]              32
              ReLU-8             [-1, 16, 1024]               0
           Dropout-9             [-1, 16, 1024]               0
           Conv1d-10             [-1, 16, 1024]             144
  MyConv1dPadSame-11             [-1, 16, 1024]               0
       Bottleneck-12             [-1, 16, 1024]               0
      BatchNorm1d-13             [-1, 16, 1024]              32
             ReLU-14             [-1, 16, 1024]               0
          Dropout-15             [-1, 16, 1024]               0
           Conv1d-16             [-1, 32, 1024]             288
  MyConv1dPadSame-17             [-1, 32, 1024]               0
      BatchNorm1d-18             [-1, 32, 1024]              64
             ReLU-19             [-1, 32, 1024]               0
          Dropout-20             [-1, 32, 1024]               0
           Conv1d-21             [-1, 32, 1024]             544
  MyConv1dPadSame-22             [-1, 32, 1024]               0
       Bottleneck-23             [-1, 32, 1024]               0
      BatchNorm1d-24             [-1, 32, 1024]              64
             ReLU-25             [-1, 32, 1024]               0
           Linear-26                    [-1, 2]              66
================================================================
Total params: 1,554
Trainable params: 1,554
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 4.38
Params size (MB): 0.01
Estimated Total Size (MB): 4.38
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 16, kernel_size: 8, n_block: 4
************************************************************
************************************************************
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 16, 1024]             144
   MyConv1dPadSame-2             [-1, 16, 1024]               0
       BatchNorm1d-3             [-1, 16, 1024]              32
              ReLU-4             [-1, 16, 1024]               0
            Conv1d-5             [-1, 16, 1024]             144
   MyConv1dPadSame-6             [-1, 16, 1024]               0
       BatchNorm1d-7             [-1, 16, 1024]              32
              ReLU-8             [-1, 16, 1024]               0
           Dropout-9             [-1, 16, 1024]               0
           Conv1d-10             [-1, 16, 1024]             144
  MyConv1dPadSame-11             [-1, 16, 1024]               0
       Bottleneck-12             [-1, 16, 1024]               0
      BatchNorm1d-13             [-1, 16, 1024]              32
             ReLU-14             [-1, 16, 1024]               0
          Dropout-15             [-1, 16, 1024]               0
           Conv1d-16             [-1, 32, 1024]             288
  MyConv1dPadSame-17             [-1, 32, 1024]               0
      BatchNorm1d-18             [-1, 32, 1024]              64
             ReLU-19             [-1, 32, 1024]               0
          Dropout-20             [-1, 32, 1024]               0
           Conv1d-21             [-1, 32, 1024]             544
  MyConv1dPadSame-22             [-1, 32, 1024]               0
       Bottleneck-23             [-1, 32, 1024]               0
      BatchNorm1d-24             [-1, 32, 1024]              64
             ReLU-25             [-1, 32, 1024]               0
          Dropout-26             [-1, 32, 1024]               0
           Conv1d-27             [-1, 64, 1024]           1,088
  MyConv1dPadSame-28             [-1, 64, 1024]               0
      BatchNorm1d-29             [-1, 64, 1024]             128
             ReLU-30             [-1, 64, 1024]               0
          Dropout-31             [-1, 64, 1024]               0
           Conv1d-32             [-1, 64, 1024]           2,112
  MyConv1dPadSame-33             [-1, 64, 1024]               0
       Bottleneck-34             [-1, 64, 1024]               0
      BatchNorm1d-35             [-1, 64, 1024]             128
             ReLU-36             [-1, 64, 1024]               0
          Dropout-37             [-1, 64, 1024]               0
           Conv1d-38            [-1, 128, 1024]           4,224
  MyConv1dPadSame-39            [-1, 128, 1024]               0
      BatchNorm1d-40            [-1, 128, 1024]             256
             ReLU-41            [-1, 128, 1024]               0
          Dropout-42            [-1, 128, 1024]               0
           Conv1d-43            [-1, 128, 1024]           8,320
  MyConv1dPadSame-44            [-1, 128, 1024]               0
       Bottleneck-45            [-1, 128, 1024]               0
      BatchNorm1d-46            [-1, 128, 1024]             256
             ReLU-47            [-1, 128, 1024]               0
           Linear-48                    [-1, 2]             258
================================================================
Total params: 18,258
Trainable params: 18,258
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 20.13
Params size (MB): 0.07
Estimated Total Size (MB): 20.20
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 16, kernel_size: 8, n_block: 8
************************************************************
************************************************************
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 16, 1024]             144
   MyConv1dPadSame-2             [-1, 16, 1024]               0
       BatchNorm1d-3             [-1, 16, 1024]              32
              ReLU-4             [-1, 16, 1024]               0
            Conv1d-5             [-1, 16, 1024]             144
   MyConv1dPadSame-6             [-1, 16, 1024]               0
       BatchNorm1d-7             [-1, 16, 1024]              32
              ReLU-8             [-1, 16, 1024]               0
           Dropout-9             [-1, 16, 1024]               0
           Conv1d-10             [-1, 16, 1024]             144
  MyConv1dPadSame-11             [-1, 16, 1024]               0
       Bottleneck-12             [-1, 16, 1024]               0
      BatchNorm1d-13             [-1, 16, 1024]              32
             ReLU-14             [-1, 16, 1024]               0
          Dropout-15             [-1, 16, 1024]               0
           Conv1d-16             [-1, 16, 1024]             144
  MyConv1dPadSame-17             [-1, 16, 1024]               0
      BatchNorm1d-18             [-1, 16, 1024]              32
             ReLU-19             [-1, 16, 1024]               0
          Dropout-20             [-1, 16, 1024]               0
           Conv1d-21             [-1, 16, 1024]             144
  MyConv1dPadSame-22             [-1, 16, 1024]               0
       Bottleneck-23             [-1, 16, 1024]               0
      BatchNorm1d-24             [-1, 16, 1024]              32
             ReLU-25             [-1, 16, 1024]               0
          Dropout-26             [-1, 16, 1024]               0
           Conv1d-27             [-1, 32, 1024]             288
  MyConv1dPadSame-28             [-1, 32, 1024]               0
      BatchNorm1d-29             [-1, 32, 1024]              64
             ReLU-30             [-1, 32, 1024]               0
          Dropout-31             [-1, 32, 1024]               0
           Conv1d-32             [-1, 32, 1024]             544
  MyConv1dPadSame-33             [-1, 32, 1024]               0
       Bottleneck-34             [-1, 32, 1024]               0
      BatchNorm1d-35             [-1, 32, 1024]              64
             ReLU-36             [-1, 32, 1024]               0
          Dropout-37             [-1, 32, 1024]               0
           Conv1d-38             [-1, 32, 1024]             544
  MyConv1dPadSame-39             [-1, 32, 1024]               0
      BatchNorm1d-40             [-1, 32, 1024]              64
             ReLU-41             [-1, 32, 1024]               0
          Dropout-42             [-1, 32, 1024]               0
           Conv1d-43             [-1, 32, 1024]             544
  MyConv1dPadSame-44             [-1, 32, 1024]               0
       Bottleneck-45             [-1, 32, 1024]               0
      BatchNorm1d-46             [-1, 32, 1024]              64
             ReLU-47             [-1, 32, 1024]               0
          Dropout-48             [-1, 32, 1024]               0
           Conv1d-49             [-1, 64, 1024]           1,088
  MyConv1dPadSame-50             [-1, 64, 1024]               0
      BatchNorm1d-51             [-1, 64, 1024]             128
             ReLU-52             [-1, 64, 1024]               0
          Dropout-53             [-1, 64, 1024]               0
           Conv1d-54             [-1, 64, 1024]           2,112
  MyConv1dPadSame-55             [-1, 64, 1024]               0
       Bottleneck-56             [-1, 64, 1024]               0
      BatchNorm1d-57             [-1, 64, 1024]             128
             ReLU-58             [-1, 64, 1024]               0
          Dropout-59             [-1, 64, 1024]               0
           Conv1d-60             [-1, 64, 1024]           2,112
  MyConv1dPadSame-61             [-1, 64, 1024]               0
      BatchNorm1d-62             [-1, 64, 1024]             128
             ReLU-63             [-1, 64, 1024]               0
          Dropout-64             [-1, 64, 1024]               0
           Conv1d-65             [-1, 64, 1024]           2,112
  MyConv1dPadSame-66             [-1, 64, 1024]               0
       Bottleneck-67             [-1, 64, 1024]               0
      BatchNorm1d-68             [-1, 64, 1024]             128
             ReLU-69             [-1, 64, 1024]               0
          Dropout-70             [-1, 64, 1024]               0
           Conv1d-71            [-1, 128, 1024]           4,224
  MyConv1dPadSame-72            [-1, 128, 1024]               0
      BatchNorm1d-73            [-1, 128, 1024]             256
             ReLU-74            [-1, 128, 1024]               0
          Dropout-75            [-1, 128, 1024]               0
           Conv1d-76            [-1, 128, 1024]           8,320
  MyConv1dPadSame-77            [-1, 128, 1024]               0
       Bottleneck-78            [-1, 128, 1024]               0
      BatchNorm1d-79            [-1, 128, 1024]             256
             ReLU-80            [-1, 128, 1024]               0
          Dropout-81            [-1, 128, 1024]               0
           Conv1d-82            [-1, 128, 1024]           8,320
  MyConv1dPadSame-83            [-1, 128, 1024]               0
      BatchNorm1d-84            [-1, 128, 1024]             256
             ReLU-85            [-1, 128, 1024]               0
          Dropout-86            [-1, 128, 1024]               0
           Conv1d-87            [-1, 128, 1024]           8,320
  MyConv1dPadSame-88            [-1, 128, 1024]               0
       Bottleneck-89            [-1, 128, 1024]               0
      BatchNorm1d-90            [-1, 128, 1024]             256
             ReLU-91            [-1, 128, 1024]               0
           Linear-92                    [-1, 2]             258
================================================================
Total params: 41,458
Trainable params: 41,458
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 40.75
Params size (MB): 0.16
Estimated Total Size (MB): 40.91
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 16, kernel_size: 8, n_block: 16
************************************************************
************************************************************
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 16, 1024]             144
   MyConv1dPadSame-2             [-1, 16, 1024]               0
       BatchNorm1d-3             [-1, 16, 1024]              32
              ReLU-4             [-1, 16, 1024]               0
            Conv1d-5             [-1, 16, 1024]             144
   MyConv1dPadSame-6             [-1, 16, 1024]               0
       BatchNorm1d-7             [-1, 16, 1024]              32
              ReLU-8             [-1, 16, 1024]               0
           Dropout-9             [-1, 16, 1024]               0
           Conv1d-10             [-1, 16, 1024]             144
  MyConv1dPadSame-11             [-1, 16, 1024]               0
       Bottleneck-12             [-1, 16, 1024]               0
      BatchNorm1d-13             [-1, 16, 1024]              32
             ReLU-14             [-1, 16, 1024]               0
          Dropout-15             [-1, 16, 1024]               0
           Conv1d-16              [-1, 16, 512]             144
  MyConv1dPadSame-17              [-1, 16, 512]               0
      BatchNorm1d-18              [-1, 16, 512]              32
             ReLU-19              [-1, 16, 512]               0
          Dropout-20              [-1, 16, 512]               0
           Conv1d-21              [-1, 16, 512]             144
  MyConv1dPadSame-22              [-1, 16, 512]               0
        MaxPool1d-23              [-1, 16, 512]               0
MyMaxPool1dPadSame-24              [-1, 16, 512]               0
       Bottleneck-25              [-1, 16, 512]               0
      BatchNorm1d-26              [-1, 16, 512]              32
             ReLU-27              [-1, 16, 512]               0
          Dropout-28              [-1, 16, 512]               0
           Conv1d-29              [-1, 16, 512]             144
  MyConv1dPadSame-30              [-1, 16, 512]               0
      BatchNorm1d-31              [-1, 16, 512]              32
             ReLU-32              [-1, 16, 512]               0
          Dropout-33              [-1, 16, 512]               0
           Conv1d-34              [-1, 16, 512]             144
  MyConv1dPadSame-35              [-1, 16, 512]               0
       Bottleneck-36              [-1, 16, 512]               0
      BatchNorm1d-37              [-1, 16, 512]              32
             ReLU-38              [-1, 16, 512]               0
          Dropout-39              [-1, 16, 512]               0
           Conv1d-40              [-1, 16, 256]             144
  MyConv1dPadSame-41              [-1, 16, 256]               0
      BatchNorm1d-42              [-1, 16, 256]              32
             ReLU-43              [-1, 16, 256]               0
          Dropout-44              [-1, 16, 256]               0
           Conv1d-45              [-1, 16, 256]             144
  MyConv1dPadSame-46              [-1, 16, 256]               0
        MaxPool1d-47              [-1, 16, 256]               0
MyMaxPool1dPadSame-48              [-1, 16, 256]               0
       Bottleneck-49              [-1, 16, 256]               0
      BatchNorm1d-50              [-1, 16, 256]              32
             ReLU-51              [-1, 16, 256]               0
          Dropout-52              [-1, 16, 256]               0
           Conv1d-53              [-1, 32, 256]             288
  MyConv1dPadSame-54              [-1, 32, 256]               0
      BatchNorm1d-55              [-1, 32, 256]              64
             ReLU-56              [-1, 32, 256]               0
          Dropout-57              [-1, 32, 256]               0
           Conv1d-58              [-1, 32, 256]             544
  MyConv1dPadSame-59              [-1, 32, 256]               0
       Bottleneck-60              [-1, 32, 256]               0
      BatchNorm1d-61              [-1, 32, 256]              64
             ReLU-62              [-1, 32, 256]               0
          Dropout-63              [-1, 32, 256]               0
           Conv1d-64              [-1, 32, 128]             544
  MyConv1dPadSame-65              [-1, 32, 128]               0
      BatchNorm1d-66              [-1, 32, 128]              64
             ReLU-67              [-1, 32, 128]               0
          Dropout-68              [-1, 32, 128]               0
           Conv1d-69              [-1, 32, 128]             544
  MyConv1dPadSame-70              [-1, 32, 128]               0
        MaxPool1d-71              [-1, 32, 128]               0
MyMaxPool1dPadSame-72              [-1, 32, 128]               0
       Bottleneck-73              [-1, 32, 128]               0
      BatchNorm1d-74              [-1, 32, 128]              64
             ReLU-75              [-1, 32, 128]               0
          Dropout-76              [-1, 32, 128]               0
           Conv1d-77              [-1, 32, 128]             544
  MyConv1dPadSame-78              [-1, 32, 128]               0
      BatchNorm1d-79              [-1, 32, 128]              64
             ReLU-80              [-1, 32, 128]               0
          Dropout-81              [-1, 32, 128]               0
           Conv1d-82              [-1, 32, 128]             544
  MyConv1dPadSame-83              [-1, 32, 128]               0
       Bottleneck-84              [-1, 32, 128]               0
      BatchNorm1d-85              [-1, 32, 128]              64
             ReLU-86              [-1, 32, 128]               0
          Dropout-87              [-1, 32, 128]               0
           Conv1d-88               [-1, 32, 64]             544
  MyConv1dPadSame-89               [-1, 32, 64]               0
      BatchNorm1d-90               [-1, 32, 64]              64
             ReLU-91               [-1, 32, 64]               0
          Dropout-92               [-1, 32, 64]               0
           Conv1d-93               [-1, 32, 64]             544
  MyConv1dPadSame-94               [-1, 32, 64]               0
        MaxPool1d-95               [-1, 32, 64]               0
MyMaxPool1dPadSame-96               [-1, 32, 64]               0
       Bottleneck-97               [-1, 32, 64]               0
      BatchNorm1d-98               [-1, 32, 64]              64
             ReLU-99               [-1, 32, 64]               0
         Dropout-100               [-1, 32, 64]               0
          Conv1d-101               [-1, 64, 64]           1,088
 MyConv1dPadSame-102               [-1, 64, 64]               0
     BatchNorm1d-103               [-1, 64, 64]             128
            ReLU-104               [-1, 64, 64]               0
         Dropout-105               [-1, 64, 64]               0
          Conv1d-106               [-1, 64, 64]           2,112
 MyConv1dPadSame-107               [-1, 64, 64]               0
      Bottleneck-108               [-1, 64, 64]               0
     BatchNorm1d-109               [-1, 64, 64]             128
            ReLU-110               [-1, 64, 64]               0
         Dropout-111               [-1, 64, 64]               0
          Conv1d-112               [-1, 64, 32]           2,112
 MyConv1dPadSame-113               [-1, 64, 32]               0
     BatchNorm1d-114               [-1, 64, 32]             128
            ReLU-115               [-1, 64, 32]               0
         Dropout-116               [-1, 64, 32]               0
          Conv1d-117               [-1, 64, 32]           2,112
 MyConv1dPadSame-118               [-1, 64, 32]               0
       MaxPool1d-119               [-1, 64, 32]               0
MyMaxPool1dPadSame-120               [-1, 64, 32]               0
      Bottleneck-121               [-1, 64, 32]               0
     BatchNorm1d-122               [-1, 64, 32]             128
            ReLU-123               [-1, 64, 32]               0
         Dropout-124               [-1, 64, 32]               0
          Conv1d-125               [-1, 64, 32]           2,112
 MyConv1dPadSame-126               [-1, 64, 32]               0
     BatchNorm1d-127               [-1, 64, 32]             128
            ReLU-128               [-1, 64, 32]               0
         Dropout-129               [-1, 64, 32]               0
          Conv1d-130               [-1, 64, 32]           2,112
 MyConv1dPadSame-131               [-1, 64, 32]               0
      Bottleneck-132               [-1, 64, 32]               0
     BatchNorm1d-133               [-1, 64, 32]             128
            ReLU-134               [-1, 64, 32]               0
         Dropout-135               [-1, 64, 32]               0
          Conv1d-136               [-1, 64, 16]           2,112
 MyConv1dPadSame-137               [-1, 64, 16]               0
     BatchNorm1d-138               [-1, 64, 16]             128
            ReLU-139               [-1, 64, 16]               0
         Dropout-140               [-1, 64, 16]               0
          Conv1d-141               [-1, 64, 16]           2,112
 MyConv1dPadSame-142               [-1, 64, 16]               0
       MaxPool1d-143               [-1, 64, 16]               0
MyMaxPool1dPadSame-144               [-1, 64, 16]               0
      Bottleneck-145               [-1, 64, 16]               0
     BatchNorm1d-146               [-1, 64, 16]             128
            ReLU-147               [-1, 64, 16]               0
         Dropout-148               [-1, 64, 16]               0
          Conv1d-149              [-1, 128, 16]           4,224
 MyConv1dPadSame-150              [-1, 128, 16]               0
     BatchNorm1d-151              [-1, 128, 16]             256
            ReLU-152              [-1, 128, 16]               0
         Dropout-153              [-1, 128, 16]               0
          Conv1d-154              [-1, 128, 16]           8,320
 MyConv1dPadSame-155              [-1, 128, 16]               0
      Bottleneck-156              [-1, 128, 16]               0
     BatchNorm1d-157              [-1, 128, 16]             256
            ReLU-158              [-1, 128, 16]               0
         Dropout-159              [-1, 128, 16]               0
          Conv1d-160               [-1, 128, 8]           8,320
 MyConv1dPadSame-161               [-1, 128, 8]               0
     BatchNorm1d-162               [-1, 128, 8]             256
            ReLU-163               [-1, 128, 8]               0
         Dropout-164               [-1, 128, 8]               0
          Conv1d-165               [-1, 128, 8]           8,320
 MyConv1dPadSame-166               [-1, 128, 8]               0
       MaxPool1d-167               [-1, 128, 8]               0
MyMaxPool1dPadSame-168               [-1, 128, 8]               0
      Bottleneck-169               [-1, 128, 8]               0
     BatchNorm1d-170               [-1, 128, 8]             256
            ReLU-171               [-1, 128, 8]               0
         Dropout-172               [-1, 128, 8]               0
          Conv1d-173               [-1, 128, 8]           8,320
 MyConv1dPadSame-174               [-1, 128, 8]               0
     BatchNorm1d-175               [-1, 128, 8]             256
            ReLU-176               [-1, 128, 8]               0
         Dropout-177               [-1, 128, 8]               0
          Conv1d-178               [-1, 128, 8]           8,320
 MyConv1dPadSame-179               [-1, 128, 8]               0
      Bottleneck-180               [-1, 128, 8]               0
     BatchNorm1d-181               [-1, 128, 8]             256
            ReLU-182               [-1, 128, 8]               0
         Dropout-183               [-1, 128, 8]               0
          Conv1d-184               [-1, 128, 4]           8,320
 MyConv1dPadSame-185               [-1, 128, 4]               0
     BatchNorm1d-186               [-1, 128, 4]             256
            ReLU-187               [-1, 128, 4]               0
         Dropout-188               [-1, 128, 4]               0
          Conv1d-189               [-1, 128, 4]           8,320
 MyConv1dPadSame-190               [-1, 128, 4]               0
       MaxPool1d-191               [-1, 128, 4]               0
MyMaxPool1dPadSame-192               [-1, 128, 4]               0
      Bottleneck-193               [-1, 128, 4]               0
     BatchNorm1d-194               [-1, 128, 4]             256
            ReLU-195               [-1, 128, 4]               0
          Linear-196                    [-1, 2]             258
================================================================
Total params: 87,858
Trainable params: 87,858
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 6.65
Params size (MB): 0.34
Estimated Total Size (MB): 6.99
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 16, kernel_size: 16, n_block: 2
************************************************************
************************************************************
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 16, 1024]             272
   MyConv1dPadSame-2             [-1, 16, 1024]               0
       BatchNorm1d-3             [-1, 16, 1024]              32
              ReLU-4             [-1, 16, 1024]               0
            Conv1d-5             [-1, 16, 1024]             272
   MyConv1dPadSame-6             [-1, 16, 1024]               0
       BatchNorm1d-7             [-1, 16, 1024]              32
              ReLU-8             [-1, 16, 1024]               0
           Dropout-9             [-1, 16, 1024]               0
           Conv1d-10             [-1, 16, 1024]             272
  MyConv1dPadSame-11             [-1, 16, 1024]               0
       Bottleneck-12             [-1, 16, 1024]               0
      BatchNorm1d-13             [-1, 16, 1024]              32
             ReLU-14             [-1, 16, 1024]               0
          Dropout-15             [-1, 16, 1024]               0
           Conv1d-16             [-1, 32, 1024]             544
  MyConv1dPadSame-17             [-1, 32, 1024]               0
      BatchNorm1d-18             [-1, 32, 1024]              64
             ReLU-19             [-1, 32, 1024]               0
          Dropout-20             [-1, 32, 1024]               0
           Conv1d-21             [-1, 32, 1024]           1,056
  MyConv1dPadSame-22             [-1, 32, 1024]               0
       Bottleneck-23             [-1, 32, 1024]               0
      BatchNorm1d-24             [-1, 32, 1024]              64
             ReLU-25             [-1, 32, 1024]               0
           Linear-26                    [-1, 2]              66
================================================================
Total params: 2,706
Trainable params: 2,706
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 4.38
Params size (MB): 0.01
Estimated Total Size (MB): 4.39
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 16, kernel_size: 16, n_block: 4
************************************************************
************************************************************
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 16, 1024]             272
   MyConv1dPadSame-2             [-1, 16, 1024]               0
       BatchNorm1d-3             [-1, 16, 1024]              32
              ReLU-4             [-1, 16, 1024]               0
            Conv1d-5             [-1, 16, 1024]             272
   MyConv1dPadSame-6             [-1, 16, 1024]               0
       BatchNorm1d-7             [-1, 16, 1024]              32
              ReLU-8             [-1, 16, 1024]               0
           Dropout-9             [-1, 16, 1024]               0
           Conv1d-10             [-1, 16, 1024]             272
  MyConv1dPadSame-11             [-1, 16, 1024]               0
       Bottleneck-12             [-1, 16, 1024]               0
      BatchNorm1d-13             [-1, 16, 1024]              32
             ReLU-14             [-1, 16, 1024]               0
          Dropout-15             [-1, 16, 1024]               0
           Conv1d-16             [-1, 32, 1024]             544
  MyConv1dPadSame-17             [-1, 32, 1024]               0
      BatchNorm1d-18             [-1, 32, 1024]              64
             ReLU-19             [-1, 32, 1024]               0
          Dropout-20             [-1, 32, 1024]               0
           Conv1d-21             [-1, 32, 1024]           1,056
  MyConv1dPadSame-22             [-1, 32, 1024]               0
       Bottleneck-23             [-1, 32, 1024]               0
      BatchNorm1d-24             [-1, 32, 1024]              64
             ReLU-25             [-1, 32, 1024]               0
          Dropout-26             [-1, 32, 1024]               0
           Conv1d-27             [-1, 64, 1024]           2,112
  MyConv1dPadSame-28             [-1, 64, 1024]               0
      BatchNorm1d-29             [-1, 64, 1024]             128
             ReLU-30             [-1, 64, 1024]               0
          Dropout-31             [-1, 64, 1024]               0
           Conv1d-32             [-1, 64, 1024]           4,160
  MyConv1dPadSame-33             [-1, 64, 1024]               0
       Bottleneck-34             [-1, 64, 1024]               0
      BatchNorm1d-35             [-1, 64, 1024]             128
             ReLU-36             [-1, 64, 1024]               0
          Dropout-37             [-1, 64, 1024]               0
           Conv1d-38            [-1, 128, 1024]           8,320
  MyConv1dPadSame-39            [-1, 128, 1024]               0
      BatchNorm1d-40            [-1, 128, 1024]             256
             ReLU-41            [-1, 128, 1024]               0
          Dropout-42            [-1, 128, 1024]               0
           Conv1d-43            [-1, 128, 1024]          16,512
  MyConv1dPadSame-44            [-1, 128, 1024]               0
       Bottleneck-45            [-1, 128, 1024]               0
      BatchNorm1d-46            [-1, 128, 1024]             256
             ReLU-47            [-1, 128, 1024]               0
           Linear-48                    [-1, 2]             258
================================================================
Total params: 34,770
Trainable params: 34,770
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 20.13
Params size (MB): 0.13
Estimated Total Size (MB): 20.26
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 16, kernel_size: 16, n_block: 8
************************************************************
************************************************************
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 16, 1024]             272
   MyConv1dPadSame-2             [-1, 16, 1024]               0
       BatchNorm1d-3             [-1, 16, 1024]              32
              ReLU-4             [-1, 16, 1024]               0
            Conv1d-5             [-1, 16, 1024]             272
   MyConv1dPadSame-6             [-1, 16, 1024]               0
       BatchNorm1d-7             [-1, 16, 1024]              32
              ReLU-8             [-1, 16, 1024]               0
           Dropout-9             [-1, 16, 1024]               0
           Conv1d-10             [-1, 16, 1024]             272
  MyConv1dPadSame-11             [-1, 16, 1024]               0
       Bottleneck-12             [-1, 16, 1024]               0
      BatchNorm1d-13             [-1, 16, 1024]              32
             ReLU-14             [-1, 16, 1024]               0
          Dropout-15             [-1, 16, 1024]               0
           Conv1d-16             [-1, 16, 1024]             272
  MyConv1dPadSame-17             [-1, 16, 1024]               0
      BatchNorm1d-18             [-1, 16, 1024]              32
             ReLU-19             [-1, 16, 1024]               0
          Dropout-20             [-1, 16, 1024]               0
           Conv1d-21             [-1, 16, 1024]             272
  MyConv1dPadSame-22             [-1, 16, 1024]               0
       Bottleneck-23             [-1, 16, 1024]               0
      BatchNorm1d-24             [-1, 16, 1024]              32
             ReLU-25             [-1, 16, 1024]               0
          Dropout-26             [-1, 16, 1024]               0
           Conv1d-27             [-1, 32, 1024]             544
  MyConv1dPadSame-28             [-1, 32, 1024]               0
      BatchNorm1d-29             [-1, 32, 1024]              64
             ReLU-30             [-1, 32, 1024]               0
          Dropout-31             [-1, 32, 1024]               0
           Conv1d-32             [-1, 32, 1024]           1,056
  MyConv1dPadSame-33             [-1, 32, 1024]               0
       Bottleneck-34             [-1, 32, 1024]               0
      BatchNorm1d-35             [-1, 32, 1024]              64
             ReLU-36             [-1, 32, 1024]               0
          Dropout-37             [-1, 32, 1024]               0
           Conv1d-38             [-1, 32, 1024]           1,056
  MyConv1dPadSame-39             [-1, 32, 1024]               0
      BatchNorm1d-40             [-1, 32, 1024]              64
             ReLU-41             [-1, 32, 1024]               0
          Dropout-42             [-1, 32, 1024]               0
           Conv1d-43             [-1, 32, 1024]           1,056
  MyConv1dPadSame-44             [-1, 32, 1024]               0
       Bottleneck-45             [-1, 32, 1024]               0
      BatchNorm1d-46             [-1, 32, 1024]              64
             ReLU-47             [-1, 32, 1024]               0
          Dropout-48             [-1, 32, 1024]               0
           Conv1d-49             [-1, 64, 1024]           2,112
  MyConv1dPadSame-50             [-1, 64, 1024]               0
      BatchNorm1d-51             [-1, 64, 1024]             128
             ReLU-52             [-1, 64, 1024]               0
          Dropout-53             [-1, 64, 1024]               0
           Conv1d-54             [-1, 64, 1024]           4,160
  MyConv1dPadSame-55             [-1, 64, 1024]               0
       Bottleneck-56             [-1, 64, 1024]               0
      BatchNorm1d-57             [-1, 64, 1024]             128
             ReLU-58             [-1, 64, 1024]               0
          Dropout-59             [-1, 64, 1024]               0
           Conv1d-60             [-1, 64, 1024]           4,160
  MyConv1dPadSame-61             [-1, 64, 1024]               0
      BatchNorm1d-62             [-1, 64, 1024]             128
             ReLU-63             [-1, 64, 1024]               0
          Dropout-64             [-1, 64, 1024]               0
           Conv1d-65             [-1, 64, 1024]           4,160
  MyConv1dPadSame-66             [-1, 64, 1024]               0
       Bottleneck-67             [-1, 64, 1024]               0
      BatchNorm1d-68             [-1, 64, 1024]             128
             ReLU-69             [-1, 64, 1024]               0
          Dropout-70             [-1, 64, 1024]               0
           Conv1d-71            [-1, 128, 1024]           8,320
  MyConv1dPadSame-72            [-1, 128, 1024]               0
      BatchNorm1d-73            [-1, 128, 1024]             256
             ReLU-74            [-1, 128, 1024]               0
          Dropout-75            [-1, 128, 1024]               0
           Conv1d-76            [-1, 128, 1024]          16,512
  MyConv1dPadSame-77            [-1, 128, 1024]               0
       Bottleneck-78            [-1, 128, 1024]               0
      BatchNorm1d-79            [-1, 128, 1024]             256
             ReLU-80            [-1, 128, 1024]               0
          Dropout-81            [-1, 128, 1024]               0
           Conv1d-82            [-1, 128, 1024]          16,512
  MyConv1dPadSame-83            [-1, 128, 1024]               0
      BatchNorm1d-84            [-1, 128, 1024]             256
             ReLU-85            [-1, 128, 1024]               0
          Dropout-86            [-1, 128, 1024]               0
           Conv1d-87            [-1, 128, 1024]          16,512
  MyConv1dPadSame-88            [-1, 128, 1024]               0
       Bottleneck-89            [-1, 128, 1024]               0
      BatchNorm1d-90            [-1, 128, 1024]             256
             ReLU-91            [-1, 128, 1024]               0
           Linear-92                    [-1, 2]             258
================================================================
Total params: 79,730
Trainable params: 79,730
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 40.75
Params size (MB): 0.30
Estimated Total Size (MB): 41.06
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 16, kernel_size: 16, n_block: 16
************************************************************
************************************************************
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 16, 1024]             272
   MyConv1dPadSame-2             [-1, 16, 1024]               0
       BatchNorm1d-3             [-1, 16, 1024]              32
              ReLU-4             [-1, 16, 1024]               0
            Conv1d-5             [-1, 16, 1024]             272
   MyConv1dPadSame-6             [-1, 16, 1024]               0
       BatchNorm1d-7             [-1, 16, 1024]              32
              ReLU-8             [-1, 16, 1024]               0
           Dropout-9             [-1, 16, 1024]               0
           Conv1d-10             [-1, 16, 1024]             272
  MyConv1dPadSame-11             [-1, 16, 1024]               0
       Bottleneck-12             [-1, 16, 1024]               0
      BatchNorm1d-13             [-1, 16, 1024]              32
             ReLU-14             [-1, 16, 1024]               0
          Dropout-15             [-1, 16, 1024]               0
           Conv1d-16              [-1, 16, 512]             272
  MyConv1dPadSame-17              [-1, 16, 512]               0
      BatchNorm1d-18              [-1, 16, 512]              32
             ReLU-19              [-1, 16, 512]               0
          Dropout-20              [-1, 16, 512]               0
           Conv1d-21              [-1, 16, 512]             272
  MyConv1dPadSame-22              [-1, 16, 512]               0
        MaxPool1d-23              [-1, 16, 512]               0
MyMaxPool1dPadSame-24              [-1, 16, 512]               0
       Bottleneck-25              [-1, 16, 512]               0
      BatchNorm1d-26              [-1, 16, 512]              32
             ReLU-27              [-1, 16, 512]               0
          Dropout-28              [-1, 16, 512]               0
           Conv1d-29              [-1, 16, 512]             272
  MyConv1dPadSame-30              [-1, 16, 512]               0
      BatchNorm1d-31              [-1, 16, 512]              32
             ReLU-32              [-1, 16, 512]               0
          Dropout-33              [-1, 16, 512]               0
           Conv1d-34              [-1, 16, 512]             272
  MyConv1dPadSame-35              [-1, 16, 512]               0
       Bottleneck-36              [-1, 16, 512]               0
      BatchNorm1d-37              [-1, 16, 512]              32
             ReLU-38              [-1, 16, 512]               0
          Dropout-39              [-1, 16, 512]               0
           Conv1d-40              [-1, 16, 256]             272
  MyConv1dPadSame-41              [-1, 16, 256]               0
      BatchNorm1d-42              [-1, 16, 256]              32
             ReLU-43              [-1, 16, 256]               0
          Dropout-44              [-1, 16, 256]               0
           Conv1d-45              [-1, 16, 256]             272
  MyConv1dPadSame-46              [-1, 16, 256]               0
        MaxPool1d-47              [-1, 16, 256]               0
MyMaxPool1dPadSame-48              [-1, 16, 256]               0
       Bottleneck-49              [-1, 16, 256]               0
      BatchNorm1d-50              [-1, 16, 256]              32
             ReLU-51              [-1, 16, 256]               0
          Dropout-52              [-1, 16, 256]               0
           Conv1d-53              [-1, 32, 256]             544
  MyConv1dPadSame-54              [-1, 32, 256]               0
      BatchNorm1d-55              [-1, 32, 256]              64
             ReLU-56              [-1, 32, 256]               0
          Dropout-57              [-1, 32, 256]               0
           Conv1d-58              [-1, 32, 256]           1,056
  MyConv1dPadSame-59              [-1, 32, 256]               0
       Bottleneck-60              [-1, 32, 256]               0
      BatchNorm1d-61              [-1, 32, 256]              64
             ReLU-62              [-1, 32, 256]               0
          Dropout-63              [-1, 32, 256]               0
           Conv1d-64              [-1, 32, 128]           1,056
  MyConv1dPadSame-65              [-1, 32, 128]               0
      BatchNorm1d-66              [-1, 32, 128]              64
             ReLU-67              [-1, 32, 128]               0
          Dropout-68              [-1, 32, 128]               0
           Conv1d-69              [-1, 32, 128]           1,056
  MyConv1dPadSame-70              [-1, 32, 128]               0
        MaxPool1d-71              [-1, 32, 128]               0
MyMaxPool1dPadSame-72              [-1, 32, 128]               0
       Bottleneck-73              [-1, 32, 128]               0
      BatchNorm1d-74              [-1, 32, 128]              64
             ReLU-75              [-1, 32, 128]               0
          Dropout-76              [-1, 32, 128]               0
           Conv1d-77              [-1, 32, 128]           1,056
  MyConv1dPadSame-78              [-1, 32, 128]               0
      BatchNorm1d-79              [-1, 32, 128]              64
             ReLU-80              [-1, 32, 128]               0
          Dropout-81              [-1, 32, 128]               0
           Conv1d-82              [-1, 32, 128]           1,056
  MyConv1dPadSame-83              [-1, 32, 128]               0
       Bottleneck-84              [-1, 32, 128]               0
      BatchNorm1d-85              [-1, 32, 128]              64
             ReLU-86              [-1, 32, 128]               0
          Dropout-87              [-1, 32, 128]               0
           Conv1d-88               [-1, 32, 64]           1,056
  MyConv1dPadSame-89               [-1, 32, 64]               0
      BatchNorm1d-90               [-1, 32, 64]              64
             ReLU-91               [-1, 32, 64]               0
          Dropout-92               [-1, 32, 64]               0
           Conv1d-93               [-1, 32, 64]           1,056
  MyConv1dPadSame-94               [-1, 32, 64]               0
        MaxPool1d-95               [-1, 32, 64]               0
MyMaxPool1dPadSame-96               [-1, 32, 64]               0
       Bottleneck-97               [-1, 32, 64]               0
      BatchNorm1d-98               [-1, 32, 64]              64
             ReLU-99               [-1, 32, 64]               0
         Dropout-100               [-1, 32, 64]               0
          Conv1d-101               [-1, 64, 64]           2,112
 MyConv1dPadSame-102               [-1, 64, 64]               0
     BatchNorm1d-103               [-1, 64, 64]             128
            ReLU-104               [-1, 64, 64]               0
         Dropout-105               [-1, 64, 64]               0
          Conv1d-106               [-1, 64, 64]           4,160
 MyConv1dPadSame-107               [-1, 64, 64]               0
      Bottleneck-108               [-1, 64, 64]               0
     BatchNorm1d-109               [-1, 64, 64]             128
            ReLU-110               [-1, 64, 64]               0
         Dropout-111               [-1, 64, 64]               0
          Conv1d-112               [-1, 64, 32]           4,160
 MyConv1dPadSame-113               [-1, 64, 32]               0
     BatchNorm1d-114               [-1, 64, 32]             128
            ReLU-115               [-1, 64, 32]               0
         Dropout-116               [-1, 64, 32]               0
          Conv1d-117               [-1, 64, 32]           4,160
 MyConv1dPadSame-118               [-1, 64, 32]               0
       MaxPool1d-119               [-1, 64, 32]               0
MyMaxPool1dPadSame-120               [-1, 64, 32]               0
      Bottleneck-121               [-1, 64, 32]               0
     BatchNorm1d-122               [-1, 64, 32]             128
            ReLU-123               [-1, 64, 32]               0
         Dropout-124               [-1, 64, 32]               0
          Conv1d-125               [-1, 64, 32]           4,160
 MyConv1dPadSame-126               [-1, 64, 32]               0
     BatchNorm1d-127               [-1, 64, 32]             128
            ReLU-128               [-1, 64, 32]               0
         Dropout-129               [-1, 64, 32]               0
          Conv1d-130               [-1, 64, 32]           4,160
 MyConv1dPadSame-131               [-1, 64, 32]               0
      Bottleneck-132               [-1, 64, 32]               0
     BatchNorm1d-133               [-1, 64, 32]             128
            ReLU-134               [-1, 64, 32]               0
         Dropout-135               [-1, 64, 32]               0
          Conv1d-136               [-1, 64, 16]           4,160
 MyConv1dPadSame-137               [-1, 64, 16]               0
     BatchNorm1d-138               [-1, 64, 16]             128
            ReLU-139               [-1, 64, 16]               0
         Dropout-140               [-1, 64, 16]               0
          Conv1d-141               [-1, 64, 16]           4,160
 MyConv1dPadSame-142               [-1, 64, 16]               0
       MaxPool1d-143               [-1, 64, 16]               0
MyMaxPool1dPadSame-144               [-1, 64, 16]               0
      Bottleneck-145               [-1, 64, 16]               0
     BatchNorm1d-146               [-1, 64, 16]             128
            ReLU-147               [-1, 64, 16]               0
         Dropout-148               [-1, 64, 16]               0
          Conv1d-149              [-1, 128, 16]           8,320
 MyConv1dPadSame-150              [-1, 128, 16]               0
     BatchNorm1d-151              [-1, 128, 16]             256
            ReLU-152              [-1, 128, 16]               0
         Dropout-153              [-1, 128, 16]               0
          Conv1d-154              [-1, 128, 16]          16,512
 MyConv1dPadSame-155              [-1, 128, 16]               0
      Bottleneck-156              [-1, 128, 16]               0
     BatchNorm1d-157              [-1, 128, 16]             256
            ReLU-158              [-1, 128, 16]               0
         Dropout-159              [-1, 128, 16]               0
          Conv1d-160               [-1, 128, 8]          16,512
 MyConv1dPadSame-161               [-1, 128, 8]               0
     BatchNorm1d-162               [-1, 128, 8]             256
            ReLU-163               [-1, 128, 8]               0
         Dropout-164               [-1, 128, 8]               0
          Conv1d-165               [-1, 128, 8]          16,512
 MyConv1dPadSame-166               [-1, 128, 8]               0
       MaxPool1d-167               [-1, 128, 8]               0
MyMaxPool1dPadSame-168               [-1, 128, 8]               0
      Bottleneck-169               [-1, 128, 8]               0
     BatchNorm1d-170               [-1, 128, 8]             256
            ReLU-171               [-1, 128, 8]               0
         Dropout-172               [-1, 128, 8]               0
          Conv1d-173               [-1, 128, 8]          16,512
 MyConv1dPadSame-174               [-1, 128, 8]               0
     BatchNorm1d-175               [-1, 128, 8]             256
            ReLU-176               [-1, 128, 8]               0
         Dropout-177               [-1, 128, 8]               0
          Conv1d-178               [-1, 128, 8]          16,512
 MyConv1dPadSame-179               [-1, 128, 8]               0
      Bottleneck-180               [-1, 128, 8]               0
     BatchNorm1d-181               [-1, 128, 8]             256
            ReLU-182               [-1, 128, 8]               0
         Dropout-183               [-1, 128, 8]               0
          Conv1d-184               [-1, 128, 4]          16,512
 MyConv1dPadSame-185               [-1, 128, 4]               0
     BatchNorm1d-186               [-1, 128, 4]             256
            ReLU-187               [-1, 128, 4]               0
         Dropout-188               [-1, 128, 4]               0
          Conv1d-189               [-1, 128, 4]          16,512
 MyConv1dPadSame-190               [-1, 128, 4]               0
       MaxPool1d-191               [-1, 128, 4]               0
MyMaxPool1dPadSame-192               [-1, 128, 4]               0
      Bottleneck-193               [-1, 128, 4]               0
     BatchNorm1d-194               [-1, 128, 4]             256
            ReLU-195               [-1, 128, 4]               0
          Linear-196                    [-1, 2]             258
================================================================
Total params: 169,650
Trainable params: 169,650
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 6.65
Params size (MB): 0.65
Estimated Total Size (MB): 7.30
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 32, kernel_size: 2, n_block: 2
************************************************************
************************************************************
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 32, 1024]              96
   MyConv1dPadSame-2             [-1, 32, 1024]               0
       BatchNorm1d-3             [-1, 32, 1024]              64
              ReLU-4             [-1, 32, 1024]               0
            Conv1d-5             [-1, 32, 1024]              96
   MyConv1dPadSame-6             [-1, 32, 1024]               0
       BatchNorm1d-7             [-1, 32, 1024]              64
              ReLU-8             [-1, 32, 1024]               0
           Dropout-9             [-1, 32, 1024]               0
           Conv1d-10             [-1, 32, 1024]              96
  MyConv1dPadSame-11             [-1, 32, 1024]               0
       Bottleneck-12             [-1, 32, 1024]               0
      BatchNorm1d-13             [-1, 32, 1024]              64
             ReLU-14             [-1, 32, 1024]               0
          Dropout-15             [-1, 32, 1024]               0
           Conv1d-16             [-1, 64, 1024]             192
  MyConv1dPadSame-17             [-1, 64, 1024]               0
      BatchNorm1d-18             [-1, 64, 1024]             128
             ReLU-19             [-1, 64, 1024]               0
          Dropout-20             [-1, 64, 1024]               0
           Conv1d-21             [-1, 64, 1024]             320
  MyConv1dPadSame-22             [-1, 64, 1024]               0
       Bottleneck-23             [-1, 64, 1024]               0
      BatchNorm1d-24             [-1, 64, 1024]             128
             ReLU-25             [-1, 64, 1024]               0
           Linear-26                    [-1, 2]             130
================================================================
Total params: 1,378
Trainable params: 1,378
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 8.75
Params size (MB): 0.01
Estimated Total Size (MB): 8.76
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 32, kernel_size: 2, n_block: 4
************************************************************
************************************************************
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 32, 1024]              96
   MyConv1dPadSame-2             [-1, 32, 1024]               0
       BatchNorm1d-3             [-1, 32, 1024]              64
              ReLU-4             [-1, 32, 1024]               0
            Conv1d-5             [-1, 32, 1024]              96
   MyConv1dPadSame-6             [-1, 32, 1024]               0
       BatchNorm1d-7             [-1, 32, 1024]              64
              ReLU-8             [-1, 32, 1024]               0
           Dropout-9             [-1, 32, 1024]               0
           Conv1d-10             [-1, 32, 1024]              96
  MyConv1dPadSame-11             [-1, 32, 1024]               0
       Bottleneck-12             [-1, 32, 1024]               0
      BatchNorm1d-13             [-1, 32, 1024]              64
             ReLU-14             [-1, 32, 1024]               0
          Dropout-15             [-1, 32, 1024]               0
           Conv1d-16             [-1, 64, 1024]             192
  MyConv1dPadSame-17             [-1, 64, 1024]               0
      BatchNorm1d-18             [-1, 64, 1024]             128
             ReLU-19             [-1, 64, 1024]               0
          Dropout-20             [-1, 64, 1024]               0
           Conv1d-21             [-1, 64, 1024]             320
  MyConv1dPadSame-22             [-1, 64, 1024]               0
       Bottleneck-23             [-1, 64, 1024]               0
      BatchNorm1d-24             [-1, 64, 1024]             128
             ReLU-25             [-1, 64, 1024]               0
          Dropout-26             [-1, 64, 1024]               0
           Conv1d-27            [-1, 128, 1024]             640
  MyConv1dPadSame-28            [-1, 128, 1024]               0
      BatchNorm1d-29            [-1, 128, 1024]             256
             ReLU-30            [-1, 128, 1024]               0
          Dropout-31            [-1, 128, 1024]               0
           Conv1d-32            [-1, 128, 1024]           1,152
  MyConv1dPadSame-33            [-1, 128, 1024]               0
       Bottleneck-34            [-1, 128, 1024]               0
      BatchNorm1d-35            [-1, 128, 1024]             256
             ReLU-36            [-1, 128, 1024]               0
          Dropout-37            [-1, 128, 1024]               0
           Conv1d-38            [-1, 256, 1024]           2,304
  MyConv1dPadSame-39            [-1, 256, 1024]               0
      BatchNorm1d-40            [-1, 256, 1024]             512
             ReLU-41            [-1, 256, 1024]               0
          Dropout-42            [-1, 256, 1024]               0
           Conv1d-43            [-1, 256, 1024]           4,352
  MyConv1dPadSame-44            [-1, 256, 1024]               0
       Bottleneck-45            [-1, 256, 1024]               0
      BatchNorm1d-46            [-1, 256, 1024]             512
             ReLU-47            [-1, 256, 1024]               0
           Linear-48                    [-1, 2]             514
================================================================
Total params: 11,746
Trainable params: 11,746
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 40.25
Params size (MB): 0.04
Estimated Total Size (MB): 40.30
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 32, kernel_size: 2, n_block: 8
************************************************************
************************************************************
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 32, 1024]              96
   MyConv1dPadSame-2             [-1, 32, 1024]               0
       BatchNorm1d-3             [-1, 32, 1024]              64
              ReLU-4             [-1, 32, 1024]               0
            Conv1d-5             [-1, 32, 1024]              96
   MyConv1dPadSame-6             [-1, 32, 1024]               0
       BatchNorm1d-7             [-1, 32, 1024]              64
              ReLU-8             [-1, 32, 1024]               0
           Dropout-9             [-1, 32, 1024]               0
           Conv1d-10             [-1, 32, 1024]              96
  MyConv1dPadSame-11             [-1, 32, 1024]               0
       Bottleneck-12             [-1, 32, 1024]               0
      BatchNorm1d-13             [-1, 32, 1024]              64
             ReLU-14             [-1, 32, 1024]               0
          Dropout-15             [-1, 32, 1024]               0
           Conv1d-16             [-1, 32, 1024]              96
  MyConv1dPadSame-17             [-1, 32, 1024]               0
      BatchNorm1d-18             [-1, 32, 1024]              64
             ReLU-19             [-1, 32, 1024]               0
          Dropout-20             [-1, 32, 1024]               0
           Conv1d-21             [-1, 32, 1024]              96
  MyConv1dPadSame-22             [-1, 32, 1024]               0
       Bottleneck-23             [-1, 32, 1024]               0
      BatchNorm1d-24             [-1, 32, 1024]              64
             ReLU-25             [-1, 32, 1024]               0
          Dropout-26             [-1, 32, 1024]               0
           Conv1d-27             [-1, 64, 1024]             192
  MyConv1dPadSame-28             [-1, 64, 1024]               0
      BatchNorm1d-29             [-1, 64, 1024]             128
             ReLU-30             [-1, 64, 1024]               0
          Dropout-31             [-1, 64, 1024]               0
           Conv1d-32             [-1, 64, 1024]             320
  MyConv1dPadSame-33             [-1, 64, 1024]               0
       Bottleneck-34             [-1, 64, 1024]               0
      BatchNorm1d-35             [-1, 64, 1024]             128
             ReLU-36             [-1, 64, 1024]               0
          Dropout-37             [-1, 64, 1024]               0
           Conv1d-38             [-1, 64, 1024]             320
  MyConv1dPadSame-39             [-1, 64, 1024]               0
      BatchNorm1d-40             [-1, 64, 1024]             128
             ReLU-41             [-1, 64, 1024]               0
          Dropout-42             [-1, 64, 1024]               0
           Conv1d-43             [-1, 64, 1024]             320
  MyConv1dPadSame-44             [-1, 64, 1024]               0
       Bottleneck-45             [-1, 64, 1024]               0
      BatchNorm1d-46             [-1, 64, 1024]             128
             ReLU-47             [-1, 64, 1024]               0
          Dropout-48             [-1, 64, 1024]               0
           Conv1d-49            [-1, 128, 1024]             640
  MyConv1dPadSame-50            [-1, 128, 1024]               0
      BatchNorm1d-51            [-1, 128, 1024]             256
             ReLU-52            [-1, 128, 1024]               0
          Dropout-53            [-1, 128, 1024]               0
           Conv1d-54            [-1, 128, 1024]           1,152
  MyConv1dPadSame-55            [-1, 128, 1024]               0
       Bottleneck-56            [-1, 128, 1024]               0
      BatchNorm1d-57            [-1, 128, 1024]             256
             ReLU-58            [-1, 128, 1024]               0
          Dropout-59            [-1, 128, 1024]               0
           Conv1d-60            [-1, 128, 1024]           1,152
  MyConv1dPadSame-61            [-1, 128, 1024]               0
      BatchNorm1d-62            [-1, 128, 1024]             256
             ReLU-63            [-1, 128, 1024]               0
          Dropout-64            [-1, 128, 1024]               0
           Conv1d-65            [-1, 128, 1024]           1,152
  MyConv1dPadSame-66            [-1, 128, 1024]               0
       Bottleneck-67            [-1, 128, 1024]               0
      BatchNorm1d-68            [-1, 128, 1024]             256
             ReLU-69            [-1, 128, 1024]               0
          Dropout-70            [-1, 128, 1024]               0
           Conv1d-71            [-1, 256, 1024]           2,304
  MyConv1dPadSame-72            [-1, 256, 1024]               0
      BatchNorm1d-73            [-1, 256, 1024]             512
             ReLU-74            [-1, 256, 1024]               0
          Dropout-75            [-1, 256, 1024]               0
           Conv1d-76            [-1, 256, 1024]           4,352
  MyConv1dPadSame-77            [-1, 256, 1024]               0
       Bottleneck-78            [-1, 256, 1024]               0
      BatchNorm1d-79            [-1, 256, 1024]             512
             ReLU-80            [-1, 256, 1024]               0
          Dropout-81            [-1, 256, 1024]               0
           Conv1d-82            [-1, 256, 1024]           4,352
  MyConv1dPadSame-83            [-1, 256, 1024]               0
      BatchNorm1d-84            [-1, 256, 1024]             512
             ReLU-85            [-1, 256, 1024]               0
          Dropout-86            [-1, 256, 1024]               0
           Conv1d-87            [-1, 256, 1024]           4,352
  MyConv1dPadSame-88            [-1, 256, 1024]               0
       Bottleneck-89            [-1, 256, 1024]               0
      BatchNorm1d-90            [-1, 256, 1024]             512
             ReLU-91            [-1, 256, 1024]               0
           Linear-92                    [-1, 2]             514
================================================================
Total params: 25,506
Trainable params: 25,506
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 81.50
Params size (MB): 0.10
Estimated Total Size (MB): 81.60
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 32, kernel_size: 2, n_block: 16
************************************************************
************************************************************
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 32, 1024]              96
   MyConv1dPadSame-2             [-1, 32, 1024]               0
       BatchNorm1d-3             [-1, 32, 1024]              64
              ReLU-4             [-1, 32, 1024]               0
            Conv1d-5             [-1, 32, 1024]              96
   MyConv1dPadSame-6             [-1, 32, 1024]               0
       BatchNorm1d-7             [-1, 32, 1024]              64
              ReLU-8             [-1, 32, 1024]               0
           Dropout-9             [-1, 32, 1024]               0
           Conv1d-10             [-1, 32, 1024]              96
  MyConv1dPadSame-11             [-1, 32, 1024]               0
       Bottleneck-12             [-1, 32, 1024]               0
      BatchNorm1d-13             [-1, 32, 1024]              64
             ReLU-14             [-1, 32, 1024]               0
          Dropout-15             [-1, 32, 1024]               0
           Conv1d-16              [-1, 32, 512]              96
  MyConv1dPadSame-17              [-1, 32, 512]               0
      BatchNorm1d-18              [-1, 32, 512]              64
             ReLU-19              [-1, 32, 512]               0
          Dropout-20              [-1, 32, 512]               0
           Conv1d-21              [-1, 32, 512]              96
  MyConv1dPadSame-22              [-1, 32, 512]               0
        MaxPool1d-23              [-1, 32, 512]               0
MyMaxPool1dPadSame-24              [-1, 32, 512]               0
       Bottleneck-25              [-1, 32, 512]               0
      BatchNorm1d-26              [-1, 32, 512]              64
             ReLU-27              [-1, 32, 512]               0
          Dropout-28              [-1, 32, 512]               0
           Conv1d-29              [-1, 32, 512]              96
  MyConv1dPadSame-30              [-1, 32, 512]               0
      BatchNorm1d-31              [-1, 32, 512]              64
             ReLU-32              [-1, 32, 512]               0
          Dropout-33              [-1, 32, 512]               0
           Conv1d-34              [-1, 32, 512]              96
  MyConv1dPadSame-35              [-1, 32, 512]               0
       Bottleneck-36              [-1, 32, 512]               0
      BatchNorm1d-37              [-1, 32, 512]              64
             ReLU-38              [-1, 32, 512]               0
          Dropout-39              [-1, 32, 512]               0
           Conv1d-40              [-1, 32, 256]              96
  MyConv1dPadSame-41              [-1, 32, 256]               0
      BatchNorm1d-42              [-1, 32, 256]              64
             ReLU-43              [-1, 32, 256]               0
          Dropout-44              [-1, 32, 256]               0
           Conv1d-45              [-1, 32, 256]              96
  MyConv1dPadSame-46              [-1, 32, 256]               0
        MaxPool1d-47              [-1, 32, 256]               0
MyMaxPool1dPadSame-48              [-1, 32, 256]               0
       Bottleneck-49              [-1, 32, 256]               0
      BatchNorm1d-50              [-1, 32, 256]              64
             ReLU-51              [-1, 32, 256]               0
          Dropout-52              [-1, 32, 256]               0
           Conv1d-53              [-1, 64, 256]             192
  MyConv1dPadSame-54              [-1, 64, 256]               0
      BatchNorm1d-55              [-1, 64, 256]             128
             ReLU-56              [-1, 64, 256]               0
          Dropout-57              [-1, 64, 256]               0
           Conv1d-58              [-1, 64, 256]             320
  MyConv1dPadSame-59              [-1, 64, 256]               0
       Bottleneck-60              [-1, 64, 256]               0
      BatchNorm1d-61              [-1, 64, 256]             128
             ReLU-62              [-1, 64, 256]               0
          Dropout-63              [-1, 64, 256]               0
           Conv1d-64              [-1, 64, 128]             320
  MyConv1dPadSame-65              [-1, 64, 128]               0
      BatchNorm1d-66              [-1, 64, 128]             128
             ReLU-67              [-1, 64, 128]               0
          Dropout-68              [-1, 64, 128]               0
           Conv1d-69              [-1, 64, 128]             320
  MyConv1dPadSame-70              [-1, 64, 128]               0
        MaxPool1d-71              [-1, 64, 128]               0
MyMaxPool1dPadSame-72              [-1, 64, 128]               0
       Bottleneck-73              [-1, 64, 128]               0
      BatchNorm1d-74              [-1, 64, 128]             128
             ReLU-75              [-1, 64, 128]               0
          Dropout-76              [-1, 64, 128]               0
           Conv1d-77              [-1, 64, 128]             320
  MyConv1dPadSame-78              [-1, 64, 128]               0
      BatchNorm1d-79              [-1, 64, 128]             128
             ReLU-80              [-1, 64, 128]               0
          Dropout-81              [-1, 64, 128]               0
           Conv1d-82              [-1, 64, 128]             320
  MyConv1dPadSame-83              [-1, 64, 128]               0
       Bottleneck-84              [-1, 64, 128]               0
      BatchNorm1d-85              [-1, 64, 128]             128
             ReLU-86              [-1, 64, 128]               0
          Dropout-87              [-1, 64, 128]               0
           Conv1d-88               [-1, 64, 64]             320
  MyConv1dPadSame-89               [-1, 64, 64]               0
      BatchNorm1d-90               [-1, 64, 64]             128
             ReLU-91               [-1, 64, 64]               0
          Dropout-92               [-1, 64, 64]               0
           Conv1d-93               [-1, 64, 64]             320
  MyConv1dPadSame-94               [-1, 64, 64]               0
        MaxPool1d-95               [-1, 64, 64]               0
MyMaxPool1dPadSame-96               [-1, 64, 64]               0
       Bottleneck-97               [-1, 64, 64]               0
      BatchNorm1d-98               [-1, 64, 64]             128
             ReLU-99               [-1, 64, 64]               0
         Dropout-100               [-1, 64, 64]               0
          Conv1d-101              [-1, 128, 64]             640
 MyConv1dPadSame-102              [-1, 128, 64]               0
     BatchNorm1d-103              [-1, 128, 64]             256
            ReLU-104              [-1, 128, 64]               0
         Dropout-105              [-1, 128, 64]               0
          Conv1d-106              [-1, 128, 64]           1,152
 MyConv1dPadSame-107              [-1, 128, 64]               0
      Bottleneck-108              [-1, 128, 64]               0
     BatchNorm1d-109              [-1, 128, 64]             256
            ReLU-110              [-1, 128, 64]               0
         Dropout-111              [-1, 128, 64]               0
          Conv1d-112              [-1, 128, 32]           1,152
 MyConv1dPadSame-113              [-1, 128, 32]               0
     BatchNorm1d-114              [-1, 128, 32]             256
            ReLU-115              [-1, 128, 32]               0
         Dropout-116              [-1, 128, 32]               0
          Conv1d-117              [-1, 128, 32]           1,152
 MyConv1dPadSame-118              [-1, 128, 32]               0
       MaxPool1d-119              [-1, 128, 32]               0
MyMaxPool1dPadSame-120              [-1, 128, 32]               0
      Bottleneck-121              [-1, 128, 32]               0
     BatchNorm1d-122              [-1, 128, 32]             256
            ReLU-123              [-1, 128, 32]               0
         Dropout-124              [-1, 128, 32]               0
          Conv1d-125              [-1, 128, 32]           1,152
 MyConv1dPadSame-126              [-1, 128, 32]               0
     BatchNorm1d-127              [-1, 128, 32]             256
            ReLU-128              [-1, 128, 32]               0
         Dropout-129              [-1, 128, 32]               0
          Conv1d-130              [-1, 128, 32]           1,152
 MyConv1dPadSame-131              [-1, 128, 32]               0
      Bottleneck-132              [-1, 128, 32]               0
     BatchNorm1d-133              [-1, 128, 32]             256
            ReLU-134              [-1, 128, 32]               0
         Dropout-135              [-1, 128, 32]               0
          Conv1d-136              [-1, 128, 16]           1,152
 MyConv1dPadSame-137              [-1, 128, 16]               0
     BatchNorm1d-138              [-1, 128, 16]             256
            ReLU-139              [-1, 128, 16]               0
         Dropout-140              [-1, 128, 16]               0
          Conv1d-141              [-1, 128, 16]           1,152
 MyConv1dPadSame-142              [-1, 128, 16]               0
       MaxPool1d-143              [-1, 128, 16]               0
MyMaxPool1dPadSame-144              [-1, 128, 16]               0
      Bottleneck-145              [-1, 128, 16]               0
     BatchNorm1d-146              [-1, 128, 16]             256
            ReLU-147              [-1, 128, 16]               0
         Dropout-148              [-1, 128, 16]               0
          Conv1d-149              [-1, 256, 16]           2,304
 MyConv1dPadSame-150              [-1, 256, 16]               0
     BatchNorm1d-151              [-1, 256, 16]             512
            ReLU-152              [-1, 256, 16]               0
         Dropout-153              [-1, 256, 16]               0
          Conv1d-154              [-1, 256, 16]           4,352
 MyConv1dPadSame-155              [-1, 256, 16]               0
      Bottleneck-156              [-1, 256, 16]               0
     BatchNorm1d-157              [-1, 256, 16]             512
            ReLU-158              [-1, 256, 16]               0
         Dropout-159              [-1, 256, 16]               0
          Conv1d-160               [-1, 256, 8]           4,352
 MyConv1dPadSame-161               [-1, 256, 8]               0
     BatchNorm1d-162               [-1, 256, 8]             512
            ReLU-163               [-1, 256, 8]               0
         Dropout-164               [-1, 256, 8]               0
          Conv1d-165               [-1, 256, 8]           4,352
 MyConv1dPadSame-166               [-1, 256, 8]               0
       MaxPool1d-167               [-1, 256, 8]               0
MyMaxPool1dPadSame-168               [-1, 256, 8]               0
      Bottleneck-169               [-1, 256, 8]               0
     BatchNorm1d-170               [-1, 256, 8]             512
            ReLU-171               [-1, 256, 8]               0
         Dropout-172               [-1, 256, 8]               0
          Conv1d-173               [-1, 256, 8]           4,352
 MyConv1dPadSame-174               [-1, 256, 8]               0
     BatchNorm1d-175               [-1, 256, 8]             512
            ReLU-176               [-1, 256, 8]               0
         Dropout-177               [-1, 256, 8]               0
          Conv1d-178               [-1, 256, 8]           4,352
 MyConv1dPadSame-179               [-1, 256, 8]               0
      Bottleneck-180               [-1, 256, 8]               0
     BatchNorm1d-181               [-1, 256, 8]             512
            ReLU-182               [-1, 256, 8]               0
         Dropout-183               [-1, 256, 8]               0
          Conv1d-184               [-1, 256, 4]           4,352
 MyConv1dPadSame-185               [-1, 256, 4]               0
     BatchNorm1d-186               [-1, 256, 4]             512
            ReLU-187               [-1, 256, 4]               0
         Dropout-188               [-1, 256, 4]               0
          Conv1d-189               [-1, 256, 4]           4,352
 MyConv1dPadSame-190               [-1, 256, 4]               0
       MaxPool1d-191               [-1, 256, 4]               0
MyMaxPool1dPadSame-192               [-1, 256, 4]               0
      Bottleneck-193               [-1, 256, 4]               0
     BatchNorm1d-194               [-1, 256, 4]             512
            ReLU-195               [-1, 256, 4]               0
          Linear-196                    [-1, 2]             514
================================================================
Total params: 53,026
Trainable params: 53,026
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 13.30
Params size (MB): 0.20
Estimated Total Size (MB): 13.50
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 32, kernel_size: 4, n_block: 2
************************************************************
************************************************************
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 32, 1024]             160
   MyConv1dPadSame-2             [-1, 32, 1024]               0
       BatchNorm1d-3             [-1, 32, 1024]              64
              ReLU-4             [-1, 32, 1024]               0
            Conv1d-5             [-1, 32, 1024]             160
   MyConv1dPadSame-6             [-1, 32, 1024]               0
       BatchNorm1d-7             [-1, 32, 1024]              64
              ReLU-8             [-1, 32, 1024]               0
           Dropout-9             [-1, 32, 1024]               0
           Conv1d-10             [-1, 32, 1024]             160
  MyConv1dPadSame-11             [-1, 32, 1024]               0
       Bottleneck-12             [-1, 32, 1024]               0
      BatchNorm1d-13             [-1, 32, 1024]              64
             ReLU-14             [-1, 32, 1024]               0
          Dropout-15             [-1, 32, 1024]               0
           Conv1d-16             [-1, 64, 1024]             320
  MyConv1dPadSame-17             [-1, 64, 1024]               0
      BatchNorm1d-18             [-1, 64, 1024]             128
             ReLU-19             [-1, 64, 1024]               0
          Dropout-20             [-1, 64, 1024]               0
           Conv1d-21             [-1, 64, 1024]             576
  MyConv1dPadSame-22             [-1, 64, 1024]               0
       Bottleneck-23             [-1, 64, 1024]               0
      BatchNorm1d-24             [-1, 64, 1024]             128
             ReLU-25             [-1, 64, 1024]               0
           Linear-26                    [-1, 2]             130
================================================================
Total params: 1,954
Trainable params: 1,954
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 8.75
Params size (MB): 0.01
Estimated Total Size (MB): 8.76
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 32, kernel_size: 4, n_block: 4
************************************************************
************************************************************
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 32, 1024]             160
   MyConv1dPadSame-2             [-1, 32, 1024]               0
       BatchNorm1d-3             [-1, 32, 1024]              64
              ReLU-4             [-1, 32, 1024]               0
            Conv1d-5             [-1, 32, 1024]             160
   MyConv1dPadSame-6             [-1, 32, 1024]               0
       BatchNorm1d-7             [-1, 32, 1024]              64
              ReLU-8             [-1, 32, 1024]               0
           Dropout-9             [-1, 32, 1024]               0
           Conv1d-10             [-1, 32, 1024]             160
  MyConv1dPadSame-11             [-1, 32, 1024]               0
       Bottleneck-12             [-1, 32, 1024]               0
      BatchNorm1d-13             [-1, 32, 1024]              64
             ReLU-14             [-1, 32, 1024]               0
          Dropout-15             [-1, 32, 1024]               0
           Conv1d-16             [-1, 64, 1024]             320
  MyConv1dPadSame-17             [-1, 64, 1024]               0
      BatchNorm1d-18             [-1, 64, 1024]             128
             ReLU-19             [-1, 64, 1024]               0
          Dropout-20             [-1, 64, 1024]               0
           Conv1d-21             [-1, 64, 1024]             576
  MyConv1dPadSame-22             [-1, 64, 1024]               0
       Bottleneck-23             [-1, 64, 1024]               0
      BatchNorm1d-24             [-1, 64, 1024]             128
             ReLU-25             [-1, 64, 1024]               0
          Dropout-26             [-1, 64, 1024]               0
           Conv1d-27            [-1, 128, 1024]           1,152
  MyConv1dPadSame-28            [-1, 128, 1024]               0
      BatchNorm1d-29            [-1, 128, 1024]             256
             ReLU-30            [-1, 128, 1024]               0
          Dropout-31            [-1, 128, 1024]               0
           Conv1d-32            [-1, 128, 1024]           2,176
  MyConv1dPadSame-33            [-1, 128, 1024]               0
       Bottleneck-34            [-1, 128, 1024]               0
      BatchNorm1d-35            [-1, 128, 1024]             256
             ReLU-36            [-1, 128, 1024]               0
          Dropout-37            [-1, 128, 1024]               0
           Conv1d-38            [-1, 256, 1024]           4,352
  MyConv1dPadSame-39            [-1, 256, 1024]               0
      BatchNorm1d-40            [-1, 256, 1024]             512
             ReLU-41            [-1, 256, 1024]               0
          Dropout-42            [-1, 256, 1024]               0
           Conv1d-43            [-1, 256, 1024]           8,448
  MyConv1dPadSame-44            [-1, 256, 1024]               0
       Bottleneck-45            [-1, 256, 1024]               0
      BatchNorm1d-46            [-1, 256, 1024]             512
             ReLU-47            [-1, 256, 1024]               0
           Linear-48                    [-1, 2]             514
================================================================
Total params: 20,002
Trainable params: 20,002
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 40.25
Params size (MB): 0.08
Estimated Total Size (MB): 40.33
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 32, kernel_size: 4, n_block: 8
************************************************************
************************************************************
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 32, 1024]             160
   MyConv1dPadSame-2             [-1, 32, 1024]               0
       BatchNorm1d-3             [-1, 32, 1024]              64
              ReLU-4             [-1, 32, 1024]               0
            Conv1d-5             [-1, 32, 1024]             160
   MyConv1dPadSame-6             [-1, 32, 1024]               0
       BatchNorm1d-7             [-1, 32, 1024]              64
              ReLU-8             [-1, 32, 1024]               0
           Dropout-9             [-1, 32, 1024]               0
           Conv1d-10             [-1, 32, 1024]             160
  MyConv1dPadSame-11             [-1, 32, 1024]               0
       Bottleneck-12             [-1, 32, 1024]               0
      BatchNorm1d-13             [-1, 32, 1024]              64
             ReLU-14             [-1, 32, 1024]               0
          Dropout-15             [-1, 32, 1024]               0
           Conv1d-16             [-1, 32, 1024]             160
  MyConv1dPadSame-17             [-1, 32, 1024]               0
      BatchNorm1d-18             [-1, 32, 1024]              64
             ReLU-19             [-1, 32, 1024]               0
          Dropout-20             [-1, 32, 1024]               0
           Conv1d-21             [-1, 32, 1024]             160
  MyConv1dPadSame-22             [-1, 32, 1024]               0
       Bottleneck-23             [-1, 32, 1024]               0
      BatchNorm1d-24             [-1, 32, 1024]              64
             ReLU-25             [-1, 32, 1024]               0
          Dropout-26             [-1, 32, 1024]               0
           Conv1d-27             [-1, 64, 1024]             320
  MyConv1dPadSame-28             [-1, 64, 1024]               0
      BatchNorm1d-29             [-1, 64, 1024]             128
             ReLU-30             [-1, 64, 1024]               0
          Dropout-31             [-1, 64, 1024]               0
           Conv1d-32             [-1, 64, 1024]             576
  MyConv1dPadSame-33             [-1, 64, 1024]               0
       Bottleneck-34             [-1, 64, 1024]               0
      BatchNorm1d-35             [-1, 64, 1024]             128
             ReLU-36             [-1, 64, 1024]               0
          Dropout-37             [-1, 64, 1024]               0
           Conv1d-38             [-1, 64, 1024]             576
  MyConv1dPadSame-39             [-1, 64, 1024]               0
      BatchNorm1d-40             [-1, 64, 1024]             128
             ReLU-41             [-1, 64, 1024]               0
          Dropout-42             [-1, 64, 1024]               0
           Conv1d-43             [-1, 64, 1024]             576
  MyConv1dPadSame-44             [-1, 64, 1024]               0
       Bottleneck-45             [-1, 64, 1024]               0
      BatchNorm1d-46             [-1, 64, 1024]             128
             ReLU-47             [-1, 64, 1024]               0
          Dropout-48             [-1, 64, 1024]               0
           Conv1d-49            [-1, 128, 1024]           1,152
  MyConv1dPadSame-50            [-1, 128, 1024]               0
      BatchNorm1d-51            [-1, 128, 1024]             256
             ReLU-52            [-1, 128, 1024]               0
          Dropout-53            [-1, 128, 1024]               0
           Conv1d-54            [-1, 128, 1024]           2,176
  MyConv1dPadSame-55            [-1, 128, 1024]               0
       Bottleneck-56            [-1, 128, 1024]               0
      BatchNorm1d-57            [-1, 128, 1024]             256
             ReLU-58            [-1, 128, 1024]               0
          Dropout-59            [-1, 128, 1024]               0
           Conv1d-60            [-1, 128, 1024]           2,176
  MyConv1dPadSame-61            [-1, 128, 1024]               0
      BatchNorm1d-62            [-1, 128, 1024]             256
             ReLU-63            [-1, 128, 1024]               0
          Dropout-64            [-1, 128, 1024]               0
           Conv1d-65            [-1, 128, 1024]           2,176
  MyConv1dPadSame-66            [-1, 128, 1024]               0
       Bottleneck-67            [-1, 128, 1024]               0
      BatchNorm1d-68            [-1, 128, 1024]             256
             ReLU-69            [-1, 128, 1024]               0
          Dropout-70            [-1, 128, 1024]               0
           Conv1d-71            [-1, 256, 1024]           4,352
  MyConv1dPadSame-72            [-1, 256, 1024]               0
      BatchNorm1d-73            [-1, 256, 1024]             512
             ReLU-74            [-1, 256, 1024]               0
          Dropout-75            [-1, 256, 1024]               0
           Conv1d-76            [-1, 256, 1024]           8,448
  MyConv1dPadSame-77            [-1, 256, 1024]               0
       Bottleneck-78            [-1, 256, 1024]               0
      BatchNorm1d-79            [-1, 256, 1024]             512
             ReLU-80            [-1, 256, 1024]               0
          Dropout-81            [-1, 256, 1024]               0
           Conv1d-82            [-1, 256, 1024]           8,448
  MyConv1dPadSame-83            [-1, 256, 1024]               0
      BatchNorm1d-84            [-1, 256, 1024]             512
             ReLU-85            [-1, 256, 1024]               0
          Dropout-86            [-1, 256, 1024]               0
           Conv1d-87            [-1, 256, 1024]           8,448
  MyConv1dPadSame-88            [-1, 256, 1024]               0
       Bottleneck-89            [-1, 256, 1024]               0
      BatchNorm1d-90            [-1, 256, 1024]             512
             ReLU-91            [-1, 256, 1024]               0
           Linear-92                    [-1, 2]             514
================================================================
Total params: 44,642
Trainable params: 44,642
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 81.50
Params size (MB): 0.17
Estimated Total Size (MB): 81.67
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 32, kernel_size: 4, n_block: 16
************************************************************
************************************************************
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 32, 1024]             160
   MyConv1dPadSame-2             [-1, 32, 1024]               0
       BatchNorm1d-3             [-1, 32, 1024]              64
              ReLU-4             [-1, 32, 1024]               0
            Conv1d-5             [-1, 32, 1024]             160
   MyConv1dPadSame-6             [-1, 32, 1024]               0
       BatchNorm1d-7             [-1, 32, 1024]              64
              ReLU-8             [-1, 32, 1024]               0
           Dropout-9             [-1, 32, 1024]               0
           Conv1d-10             [-1, 32, 1024]             160
  MyConv1dPadSame-11             [-1, 32, 1024]               0
       Bottleneck-12             [-1, 32, 1024]               0
      BatchNorm1d-13             [-1, 32, 1024]              64
             ReLU-14             [-1, 32, 1024]               0
          Dropout-15             [-1, 32, 1024]               0
           Conv1d-16              [-1, 32, 512]             160
  MyConv1dPadSame-17              [-1, 32, 512]               0
      BatchNorm1d-18              [-1, 32, 512]              64
             ReLU-19              [-1, 32, 512]               0
          Dropout-20              [-1, 32, 512]               0
           Conv1d-21              [-1, 32, 512]             160
  MyConv1dPadSame-22              [-1, 32, 512]               0
        MaxPool1d-23              [-1, 32, 512]               0
MyMaxPool1dPadSame-24              [-1, 32, 512]               0
       Bottleneck-25              [-1, 32, 512]               0
      BatchNorm1d-26              [-1, 32, 512]              64
             ReLU-27              [-1, 32, 512]               0
          Dropout-28              [-1, 32, 512]               0
           Conv1d-29              [-1, 32, 512]             160
  MyConv1dPadSame-30              [-1, 32, 512]               0
      BatchNorm1d-31              [-1, 32, 512]              64
             ReLU-32              [-1, 32, 512]               0
          Dropout-33              [-1, 32, 512]               0
           Conv1d-34              [-1, 32, 512]             160
  MyConv1dPadSame-35              [-1, 32, 512]               0
       Bottleneck-36              [-1, 32, 512]               0
      BatchNorm1d-37              [-1, 32, 512]              64
             ReLU-38              [-1, 32, 512]               0
          Dropout-39              [-1, 32, 512]               0
           Conv1d-40              [-1, 32, 256]             160
  MyConv1dPadSame-41              [-1, 32, 256]               0
      BatchNorm1d-42              [-1, 32, 256]              64
             ReLU-43              [-1, 32, 256]               0
          Dropout-44              [-1, 32, 256]               0
           Conv1d-45              [-1, 32, 256]             160
  MyConv1dPadSame-46              [-1, 32, 256]               0
        MaxPool1d-47              [-1, 32, 256]               0
MyMaxPool1dPadSame-48              [-1, 32, 256]               0
       Bottleneck-49              [-1, 32, 256]               0
      BatchNorm1d-50              [-1, 32, 256]              64
             ReLU-51              [-1, 32, 256]               0
          Dropout-52              [-1, 32, 256]               0
           Conv1d-53              [-1, 64, 256]             320
  MyConv1dPadSame-54              [-1, 64, 256]               0
      BatchNorm1d-55              [-1, 64, 256]             128
             ReLU-56              [-1, 64, 256]               0
          Dropout-57              [-1, 64, 256]               0
           Conv1d-58              [-1, 64, 256]             576
  MyConv1dPadSame-59              [-1, 64, 256]               0
       Bottleneck-60              [-1, 64, 256]               0
      BatchNorm1d-61              [-1, 64, 256]             128
             ReLU-62              [-1, 64, 256]               0
          Dropout-63              [-1, 64, 256]               0
           Conv1d-64              [-1, 64, 128]             576
  MyConv1dPadSame-65              [-1, 64, 128]               0
      BatchNorm1d-66              [-1, 64, 128]             128
             ReLU-67              [-1, 64, 128]               0
          Dropout-68              [-1, 64, 128]               0
           Conv1d-69              [-1, 64, 128]             576
  MyConv1dPadSame-70              [-1, 64, 128]               0
        MaxPool1d-71              [-1, 64, 128]               0
MyMaxPool1dPadSame-72              [-1, 64, 128]               0
       Bottleneck-73              [-1, 64, 128]               0
      BatchNorm1d-74              [-1, 64, 128]             128
             ReLU-75              [-1, 64, 128]               0
          Dropout-76              [-1, 64, 128]               0
           Conv1d-77              [-1, 64, 128]             576
  MyConv1dPadSame-78              [-1, 64, 128]               0
      BatchNorm1d-79              [-1, 64, 128]             128
             ReLU-80              [-1, 64, 128]               0
          Dropout-81              [-1, 64, 128]               0
           Conv1d-82              [-1, 64, 128]             576
  MyConv1dPadSame-83              [-1, 64, 128]               0
       Bottleneck-84              [-1, 64, 128]               0
      BatchNorm1d-85              [-1, 64, 128]             128
             ReLU-86              [-1, 64, 128]               0
          Dropout-87              [-1, 64, 128]               0
           Conv1d-88               [-1, 64, 64]             576
  MyConv1dPadSame-89               [-1, 64, 64]               0
      BatchNorm1d-90               [-1, 64, 64]             128
             ReLU-91               [-1, 64, 64]               0
          Dropout-92               [-1, 64, 64]               0
           Conv1d-93               [-1, 64, 64]             576
  MyConv1dPadSame-94               [-1, 64, 64]               0
        MaxPool1d-95               [-1, 64, 64]               0
MyMaxPool1dPadSame-96               [-1, 64, 64]               0
       Bottleneck-97               [-1, 64, 64]               0
      BatchNorm1d-98               [-1, 64, 64]             128
             ReLU-99               [-1, 64, 64]               0
         Dropout-100               [-1, 64, 64]               0
          Conv1d-101              [-1, 128, 64]           1,152
 MyConv1dPadSame-102              [-1, 128, 64]               0
     BatchNorm1d-103              [-1, 128, 64]             256
            ReLU-104              [-1, 128, 64]               0
         Dropout-105              [-1, 128, 64]               0
          Conv1d-106              [-1, 128, 64]           2,176
 MyConv1dPadSame-107              [-1, 128, 64]               0
      Bottleneck-108              [-1, 128, 64]               0
     BatchNorm1d-109              [-1, 128, 64]             256
            ReLU-110              [-1, 128, 64]               0
         Dropout-111              [-1, 128, 64]               0
          Conv1d-112              [-1, 128, 32]           2,176
 MyConv1dPadSame-113              [-1, 128, 32]               0
     BatchNorm1d-114              [-1, 128, 32]             256
            ReLU-115              [-1, 128, 32]               0
         Dropout-116              [-1, 128, 32]               0
          Conv1d-117              [-1, 128, 32]           2,176
 MyConv1dPadSame-118              [-1, 128, 32]               0
       MaxPool1d-119              [-1, 128, 32]               0
MyMaxPool1dPadSame-120              [-1, 128, 32]               0
      Bottleneck-121              [-1, 128, 32]               0
     BatchNorm1d-122              [-1, 128, 32]             256
            ReLU-123              [-1, 128, 32]               0
         Dropout-124              [-1, 128, 32]               0
          Conv1d-125              [-1, 128, 32]           2,176
 MyConv1dPadSame-126              [-1, 128, 32]               0
     BatchNorm1d-127              [-1, 128, 32]             256
            ReLU-128              [-1, 128, 32]               0
         Dropout-129              [-1, 128, 32]               0
          Conv1d-130              [-1, 128, 32]           2,176
 MyConv1dPadSame-131              [-1, 128, 32]               0
      Bottleneck-132              [-1, 128, 32]               0
     BatchNorm1d-133              [-1, 128, 32]             256
            ReLU-134              [-1, 128, 32]               0
         Dropout-135              [-1, 128, 32]               0
          Conv1d-136              [-1, 128, 16]           2,176
 MyConv1dPadSame-137              [-1, 128, 16]               0
     BatchNorm1d-138              [-1, 128, 16]             256
            ReLU-139              [-1, 128, 16]               0
         Dropout-140              [-1, 128, 16]               0
          Conv1d-141              [-1, 128, 16]           2,176
 MyConv1dPadSame-142              [-1, 128, 16]               0
       MaxPool1d-143              [-1, 128, 16]               0
MyMaxPool1dPadSame-144              [-1, 128, 16]               0
      Bottleneck-145              [-1, 128, 16]               0
     BatchNorm1d-146              [-1, 128, 16]             256
            ReLU-147              [-1, 128, 16]               0
         Dropout-148              [-1, 128, 16]               0
          Conv1d-149              [-1, 256, 16]           4,352
 MyConv1dPadSame-150              [-1, 256, 16]               0
     BatchNorm1d-151              [-1, 256, 16]             512
            ReLU-152              [-1, 256, 16]               0
         Dropout-153              [-1, 256, 16]               0
          Conv1d-154              [-1, 256, 16]           8,448
 MyConv1dPadSame-155              [-1, 256, 16]               0
      Bottleneck-156              [-1, 256, 16]               0
     BatchNorm1d-157              [-1, 256, 16]             512
            ReLU-158              [-1, 256, 16]               0
         Dropout-159              [-1, 256, 16]               0
          Conv1d-160               [-1, 256, 8]           8,448
 MyConv1dPadSame-161               [-1, 256, 8]               0
     BatchNorm1d-162               [-1, 256, 8]             512
            ReLU-163               [-1, 256, 8]               0
         Dropout-164               [-1, 256, 8]               0
          Conv1d-165               [-1, 256, 8]           8,448
 MyConv1dPadSame-166               [-1, 256, 8]               0
       MaxPool1d-167               [-1, 256, 8]               0
MyMaxPool1dPadSame-168               [-1, 256, 8]               0
      Bottleneck-169               [-1, 256, 8]               0
     BatchNorm1d-170               [-1, 256, 8]             512
            ReLU-171               [-1, 256, 8]               0
         Dropout-172               [-1, 256, 8]               0
          Conv1d-173               [-1, 256, 8]           8,448
 MyConv1dPadSame-174               [-1, 256, 8]               0
     BatchNorm1d-175               [-1, 256, 8]             512
            ReLU-176               [-1, 256, 8]               0
         Dropout-177               [-1, 256, 8]               0
          Conv1d-178               [-1, 256, 8]           8,448
 MyConv1dPadSame-179               [-1, 256, 8]               0
      Bottleneck-180               [-1, 256, 8]               0
     BatchNorm1d-181               [-1, 256, 8]             512
            ReLU-182               [-1, 256, 8]               0
         Dropout-183               [-1, 256, 8]               0
          Conv1d-184               [-1, 256, 4]           8,448
 MyConv1dPadSame-185               [-1, 256, 4]               0
     BatchNorm1d-186               [-1, 256, 4]             512
            ReLU-187               [-1, 256, 4]               0
         Dropout-188               [-1, 256, 4]               0
          Conv1d-189               [-1, 256, 4]           8,448
 MyConv1dPadSame-190               [-1, 256, 4]               0
       MaxPool1d-191               [-1, 256, 4]               0
MyMaxPool1dPadSame-192               [-1, 256, 4]               0
      Bottleneck-193               [-1, 256, 4]               0
     BatchNorm1d-194               [-1, 256, 4]             512
            ReLU-195               [-1, 256, 4]               0
          Linear-196                    [-1, 2]             514
================================================================
Total params: 93,922
Trainable params: 93,922
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 13.30
Params size (MB): 0.36
Estimated Total Size (MB): 13.66
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 32, kernel_size: 8, n_block: 2
************************************************************
************************************************************
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 32, 1024]             288
   MyConv1dPadSame-2             [-1, 32, 1024]               0
       BatchNorm1d-3             [-1, 32, 1024]              64
              ReLU-4             [-1, 32, 1024]               0
            Conv1d-5             [-1, 32, 1024]             288
   MyConv1dPadSame-6             [-1, 32, 1024]               0
       BatchNorm1d-7             [-1, 32, 1024]              64
              ReLU-8             [-1, 32, 1024]               0
           Dropout-9             [-1, 32, 1024]               0
           Conv1d-10             [-1, 32, 1024]             288
  MyConv1dPadSame-11             [-1, 32, 1024]               0
       Bottleneck-12             [-1, 32, 1024]               0
      BatchNorm1d-13             [-1, 32, 1024]              64
             ReLU-14             [-1, 32, 1024]               0
          Dropout-15             [-1, 32, 1024]               0
           Conv1d-16             [-1, 64, 1024]             576
  MyConv1dPadSame-17             [-1, 64, 1024]               0
      BatchNorm1d-18             [-1, 64, 1024]             128
             ReLU-19             [-1, 64, 1024]               0
          Dropout-20             [-1, 64, 1024]               0
           Conv1d-21             [-1, 64, 1024]           1,088
  MyConv1dPadSame-22             [-1, 64, 1024]               0
       Bottleneck-23             [-1, 64, 1024]               0
      BatchNorm1d-24             [-1, 64, 1024]             128
             ReLU-25             [-1, 64, 1024]               0
           Linear-26                    [-1, 2]             130
================================================================
Total params: 3,106
Trainable params: 3,106
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 8.75
Params size (MB): 0.01
Estimated Total Size (MB): 8.77
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 32, kernel_size: 8, n_block: 4
************************************************************
************************************************************
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 32, 1024]             288
   MyConv1dPadSame-2             [-1, 32, 1024]               0
       BatchNorm1d-3             [-1, 32, 1024]              64
              ReLU-4             [-1, 32, 1024]               0
            Conv1d-5             [-1, 32, 1024]             288
   MyConv1dPadSame-6             [-1, 32, 1024]               0
       BatchNorm1d-7             [-1, 32, 1024]              64
              ReLU-8             [-1, 32, 1024]               0
           Dropout-9             [-1, 32, 1024]               0
           Conv1d-10             [-1, 32, 1024]             288
  MyConv1dPadSame-11             [-1, 32, 1024]               0
       Bottleneck-12             [-1, 32, 1024]               0
      BatchNorm1d-13             [-1, 32, 1024]              64
             ReLU-14             [-1, 32, 1024]               0
          Dropout-15             [-1, 32, 1024]               0
           Conv1d-16             [-1, 64, 1024]             576
  MyConv1dPadSame-17             [-1, 64, 1024]               0
      BatchNorm1d-18             [-1, 64, 1024]             128
             ReLU-19             [-1, 64, 1024]               0
          Dropout-20             [-1, 64, 1024]               0
           Conv1d-21             [-1, 64, 1024]           1,088
  MyConv1dPadSame-22             [-1, 64, 1024]               0
       Bottleneck-23             [-1, 64, 1024]               0
      BatchNorm1d-24             [-1, 64, 1024]             128
             ReLU-25             [-1, 64, 1024]               0
          Dropout-26             [-1, 64, 1024]               0
           Conv1d-27            [-1, 128, 1024]           2,176
  MyConv1dPadSame-28            [-1, 128, 1024]               0
      BatchNorm1d-29            [-1, 128, 1024]             256
             ReLU-30            [-1, 128, 1024]               0
          Dropout-31            [-1, 128, 1024]               0
           Conv1d-32            [-1, 128, 1024]           4,224
  MyConv1dPadSame-33            [-1, 128, 1024]               0
       Bottleneck-34            [-1, 128, 1024]               0
      BatchNorm1d-35            [-1, 128, 1024]             256
             ReLU-36            [-1, 128, 1024]               0
          Dropout-37            [-1, 128, 1024]               0
           Conv1d-38            [-1, 256, 1024]           8,448
  MyConv1dPadSame-39            [-1, 256, 1024]               0
      BatchNorm1d-40            [-1, 256, 1024]             512
             ReLU-41            [-1, 256, 1024]               0
          Dropout-42            [-1, 256, 1024]               0
           Conv1d-43            [-1, 256, 1024]          16,640
  MyConv1dPadSame-44            [-1, 256, 1024]               0
       Bottleneck-45            [-1, 256, 1024]               0
      BatchNorm1d-46            [-1, 256, 1024]             512
             ReLU-47            [-1, 256, 1024]               0
           Linear-48                    [-1, 2]             514
================================================================
Total params: 36,514
Trainable params: 36,514
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 40.25
Params size (MB): 0.14
Estimated Total Size (MB): 40.39
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 32, kernel_size: 8, n_block: 8
************************************************************
************************************************************
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 32, 1024]             288
   MyConv1dPadSame-2             [-1, 32, 1024]               0
       BatchNorm1d-3             [-1, 32, 1024]              64
              ReLU-4             [-1, 32, 1024]               0
            Conv1d-5             [-1, 32, 1024]             288
   MyConv1dPadSame-6             [-1, 32, 1024]               0
       BatchNorm1d-7             [-1, 32, 1024]              64
              ReLU-8             [-1, 32, 1024]               0
           Dropout-9             [-1, 32, 1024]               0
           Conv1d-10             [-1, 32, 1024]             288
  MyConv1dPadSame-11             [-1, 32, 1024]               0
       Bottleneck-12             [-1, 32, 1024]               0
      BatchNorm1d-13             [-1, 32, 1024]              64
             ReLU-14             [-1, 32, 1024]               0
          Dropout-15             [-1, 32, 1024]               0
           Conv1d-16             [-1, 32, 1024]             288
  MyConv1dPadSame-17             [-1, 32, 1024]               0
      BatchNorm1d-18             [-1, 32, 1024]              64
             ReLU-19             [-1, 32, 1024]               0
          Dropout-20             [-1, 32, 1024]               0
           Conv1d-21             [-1, 32, 1024]             288
  MyConv1dPadSame-22             [-1, 32, 1024]               0
       Bottleneck-23             [-1, 32, 1024]               0
      BatchNorm1d-24             [-1, 32, 1024]              64
             ReLU-25             [-1, 32, 1024]               0
          Dropout-26             [-1, 32, 1024]               0
           Conv1d-27             [-1, 64, 1024]             576
  MyConv1dPadSame-28             [-1, 64, 1024]               0
      BatchNorm1d-29             [-1, 64, 1024]             128
             ReLU-30             [-1, 64, 1024]               0
          Dropout-31             [-1, 64, 1024]               0
           Conv1d-32             [-1, 64, 1024]           1,088
  MyConv1dPadSame-33             [-1, 64, 1024]               0
       Bottleneck-34             [-1, 64, 1024]               0
      BatchNorm1d-35             [-1, 64, 1024]             128
             ReLU-36             [-1, 64, 1024]               0
          Dropout-37             [-1, 64, 1024]               0
           Conv1d-38             [-1, 64, 1024]           1,088
  MyConv1dPadSame-39             [-1, 64, 1024]               0
      BatchNorm1d-40             [-1, 64, 1024]             128
             ReLU-41             [-1, 64, 1024]               0
          Dropout-42             [-1, 64, 1024]               0
           Conv1d-43             [-1, 64, 1024]           1,088
  MyConv1dPadSame-44             [-1, 64, 1024]               0
       Bottleneck-45             [-1, 64, 1024]               0
      BatchNorm1d-46             [-1, 64, 1024]             128
             ReLU-47             [-1, 64, 1024]               0
          Dropout-48             [-1, 64, 1024]               0
           Conv1d-49            [-1, 128, 1024]           2,176
  MyConv1dPadSame-50            [-1, 128, 1024]               0
      BatchNorm1d-51            [-1, 128, 1024]             256
             ReLU-52            [-1, 128, 1024]               0
          Dropout-53            [-1, 128, 1024]               0
           Conv1d-54            [-1, 128, 1024]           4,224
  MyConv1dPadSame-55            [-1, 128, 1024]               0
       Bottleneck-56            [-1, 128, 1024]               0
      BatchNorm1d-57            [-1, 128, 1024]             256
             ReLU-58            [-1, 128, 1024]               0
          Dropout-59            [-1, 128, 1024]               0
           Conv1d-60            [-1, 128, 1024]           4,224
  MyConv1dPadSame-61            [-1, 128, 1024]               0
      BatchNorm1d-62            [-1, 128, 1024]             256
             ReLU-63            [-1, 128, 1024]               0
          Dropout-64            [-1, 128, 1024]               0
           Conv1d-65            [-1, 128, 1024]           4,224
  MyConv1dPadSame-66            [-1, 128, 1024]               0
       Bottleneck-67            [-1, 128, 1024]               0
      BatchNorm1d-68            [-1, 128, 1024]             256
             ReLU-69            [-1, 128, 1024]               0
          Dropout-70            [-1, 128, 1024]               0
           Conv1d-71            [-1, 256, 1024]           8,448
  MyConv1dPadSame-72            [-1, 256, 1024]               0
      BatchNorm1d-73            [-1, 256, 1024]             512
             ReLU-74            [-1, 256, 1024]               0
          Dropout-75            [-1, 256, 1024]               0
           Conv1d-76            [-1, 256, 1024]          16,640
  MyConv1dPadSame-77            [-1, 256, 1024]               0
       Bottleneck-78            [-1, 256, 1024]               0
      BatchNorm1d-79            [-1, 256, 1024]             512
             ReLU-80            [-1, 256, 1024]               0
          Dropout-81            [-1, 256, 1024]               0
           Conv1d-82            [-1, 256, 1024]          16,640
  MyConv1dPadSame-83            [-1, 256, 1024]               0
      BatchNorm1d-84            [-1, 256, 1024]             512
             ReLU-85            [-1, 256, 1024]               0
          Dropout-86            [-1, 256, 1024]               0
           Conv1d-87            [-1, 256, 1024]          16,640
  MyConv1dPadSame-88            [-1, 256, 1024]               0
       Bottleneck-89            [-1, 256, 1024]               0
      BatchNorm1d-90            [-1, 256, 1024]             512
             ReLU-91            [-1, 256, 1024]               0
           Linear-92                    [-1, 2]             514
================================================================
Total params: 82,914
Trainable params: 82,914
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 81.50
Params size (MB): 0.32
Estimated Total Size (MB): 81.82
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 32, kernel_size: 8, n_block: 16
************************************************************
************************************************************
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 32, 1024]             288
   MyConv1dPadSame-2             [-1, 32, 1024]               0
       BatchNorm1d-3             [-1, 32, 1024]              64
              ReLU-4             [-1, 32, 1024]               0
            Conv1d-5             [-1, 32, 1024]             288
   MyConv1dPadSame-6             [-1, 32, 1024]               0
       BatchNorm1d-7             [-1, 32, 1024]              64
              ReLU-8             [-1, 32, 1024]               0
           Dropout-9             [-1, 32, 1024]               0
           Conv1d-10             [-1, 32, 1024]             288
  MyConv1dPadSame-11             [-1, 32, 1024]               0
       Bottleneck-12             [-1, 32, 1024]               0
      BatchNorm1d-13             [-1, 32, 1024]              64
             ReLU-14             [-1, 32, 1024]               0
          Dropout-15             [-1, 32, 1024]               0
           Conv1d-16              [-1, 32, 512]             288
  MyConv1dPadSame-17              [-1, 32, 512]               0
      BatchNorm1d-18              [-1, 32, 512]              64
             ReLU-19              [-1, 32, 512]               0
          Dropout-20              [-1, 32, 512]               0
           Conv1d-21              [-1, 32, 512]             288
  MyConv1dPadSame-22              [-1, 32, 512]               0
        MaxPool1d-23              [-1, 32, 512]               0
MyMaxPool1dPadSame-24              [-1, 32, 512]               0
       Bottleneck-25              [-1, 32, 512]               0
      BatchNorm1d-26              [-1, 32, 512]              64
             ReLU-27              [-1, 32, 512]               0
          Dropout-28              [-1, 32, 512]               0
           Conv1d-29              [-1, 32, 512]             288
  MyConv1dPadSame-30              [-1, 32, 512]               0
      BatchNorm1d-31              [-1, 32, 512]              64
             ReLU-32              [-1, 32, 512]               0
          Dropout-33              [-1, 32, 512]               0
           Conv1d-34              [-1, 32, 512]             288
  MyConv1dPadSame-35              [-1, 32, 512]               0
       Bottleneck-36              [-1, 32, 512]               0
      BatchNorm1d-37              [-1, 32, 512]              64
             ReLU-38              [-1, 32, 512]               0
          Dropout-39              [-1, 32, 512]               0
           Conv1d-40              [-1, 32, 256]             288
  MyConv1dPadSame-41              [-1, 32, 256]               0
      BatchNorm1d-42              [-1, 32, 256]              64
             ReLU-43              [-1, 32, 256]               0
          Dropout-44              [-1, 32, 256]               0
           Conv1d-45              [-1, 32, 256]             288
  MyConv1dPadSame-46              [-1, 32, 256]               0
        MaxPool1d-47              [-1, 32, 256]               0
MyMaxPool1dPadSame-48              [-1, 32, 256]               0
       Bottleneck-49              [-1, 32, 256]               0
      BatchNorm1d-50              [-1, 32, 256]              64
             ReLU-51              [-1, 32, 256]               0
          Dropout-52              [-1, 32, 256]               0
           Conv1d-53              [-1, 64, 256]             576
  MyConv1dPadSame-54              [-1, 64, 256]               0
      BatchNorm1d-55              [-1, 64, 256]             128
             ReLU-56              [-1, 64, 256]               0
          Dropout-57              [-1, 64, 256]               0
           Conv1d-58              [-1, 64, 256]           1,088
  MyConv1dPadSame-59              [-1, 64, 256]               0
       Bottleneck-60              [-1, 64, 256]               0
      BatchNorm1d-61              [-1, 64, 256]             128
             ReLU-62              [-1, 64, 256]               0
          Dropout-63              [-1, 64, 256]               0
           Conv1d-64              [-1, 64, 128]           1,088
  MyConv1dPadSame-65              [-1, 64, 128]               0
      BatchNorm1d-66              [-1, 64, 128]             128
             ReLU-67              [-1, 64, 128]               0
          Dropout-68              [-1, 64, 128]               0
           Conv1d-69              [-1, 64, 128]           1,088
  MyConv1dPadSame-70              [-1, 64, 128]               0
        MaxPool1d-71              [-1, 64, 128]               0
MyMaxPool1dPadSame-72              [-1, 64, 128]               0
       Bottleneck-73              [-1, 64, 128]               0
      BatchNorm1d-74              [-1, 64, 128]             128
             ReLU-75              [-1, 64, 128]               0
          Dropout-76              [-1, 64, 128]               0
           Conv1d-77              [-1, 64, 128]           1,088
  MyConv1dPadSame-78              [-1, 64, 128]               0
      BatchNorm1d-79              [-1, 64, 128]             128
             ReLU-80              [-1, 64, 128]               0
          Dropout-81              [-1, 64, 128]               0
           Conv1d-82              [-1, 64, 128]           1,088
  MyConv1dPadSame-83              [-1, 64, 128]               0
       Bottleneck-84              [-1, 64, 128]               0
      BatchNorm1d-85              [-1, 64, 128]             128
             ReLU-86              [-1, 64, 128]               0
          Dropout-87              [-1, 64, 128]               0
           Conv1d-88               [-1, 64, 64]           1,088
  MyConv1dPadSame-89               [-1, 64, 64]               0
      BatchNorm1d-90               [-1, 64, 64]             128
             ReLU-91               [-1, 64, 64]               0
          Dropout-92               [-1, 64, 64]               0
           Conv1d-93               [-1, 64, 64]           1,088
  MyConv1dPadSame-94               [-1, 64, 64]               0
        MaxPool1d-95               [-1, 64, 64]               0
MyMaxPool1dPadSame-96               [-1, 64, 64]               0
       Bottleneck-97               [-1, 64, 64]               0
      BatchNorm1d-98               [-1, 64, 64]             128
             ReLU-99               [-1, 64, 64]               0
         Dropout-100               [-1, 64, 64]               0
          Conv1d-101              [-1, 128, 64]           2,176
 MyConv1dPadSame-102              [-1, 128, 64]               0
     BatchNorm1d-103              [-1, 128, 64]             256
            ReLU-104              [-1, 128, 64]               0
         Dropout-105              [-1, 128, 64]               0
          Conv1d-106              [-1, 128, 64]           4,224
 MyConv1dPadSame-107              [-1, 128, 64]               0
      Bottleneck-108              [-1, 128, 64]               0
     BatchNorm1d-109              [-1, 128, 64]             256
            ReLU-110              [-1, 128, 64]               0
         Dropout-111              [-1, 128, 64]               0
          Conv1d-112              [-1, 128, 32]           4,224
 MyConv1dPadSame-113              [-1, 128, 32]               0
     BatchNorm1d-114              [-1, 128, 32]             256
            ReLU-115              [-1, 128, 32]               0
         Dropout-116              [-1, 128, 32]               0
          Conv1d-117              [-1, 128, 32]           4,224
 MyConv1dPadSame-118              [-1, 128, 32]               0
       MaxPool1d-119              [-1, 128, 32]               0
MyMaxPool1dPadSame-120              [-1, 128, 32]               0
      Bottleneck-121              [-1, 128, 32]               0
     BatchNorm1d-122              [-1, 128, 32]             256
            ReLU-123              [-1, 128, 32]               0
         Dropout-124              [-1, 128, 32]               0
          Conv1d-125              [-1, 128, 32]           4,224
 MyConv1dPadSame-126              [-1, 128, 32]               0
     BatchNorm1d-127              [-1, 128, 32]             256
            ReLU-128              [-1, 128, 32]               0
         Dropout-129              [-1, 128, 32]               0
          Conv1d-130              [-1, 128, 32]           4,224
 MyConv1dPadSame-131              [-1, 128, 32]               0
      Bottleneck-132              [-1, 128, 32]               0
     BatchNorm1d-133              [-1, 128, 32]             256
            ReLU-134              [-1, 128, 32]               0
         Dropout-135              [-1, 128, 32]               0
          Conv1d-136              [-1, 128, 16]           4,224
 MyConv1dPadSame-137              [-1, 128, 16]               0
     BatchNorm1d-138              [-1, 128, 16]             256
            ReLU-139              [-1, 128, 16]               0
         Dropout-140              [-1, 128, 16]               0
          Conv1d-141              [-1, 128, 16]           4,224
 MyConv1dPadSame-142              [-1, 128, 16]               0
       MaxPool1d-143              [-1, 128, 16]               0
MyMaxPool1dPadSame-144              [-1, 128, 16]               0
      Bottleneck-145              [-1, 128, 16]               0
     BatchNorm1d-146              [-1, 128, 16]             256
            ReLU-147              [-1, 128, 16]               0
         Dropout-148              [-1, 128, 16]               0
          Conv1d-149              [-1, 256, 16]           8,448
 MyConv1dPadSame-150              [-1, 256, 16]               0
     BatchNorm1d-151              [-1, 256, 16]             512
            ReLU-152              [-1, 256, 16]               0
         Dropout-153              [-1, 256, 16]               0
          Conv1d-154              [-1, 256, 16]          16,640
 MyConv1dPadSame-155              [-1, 256, 16]               0
      Bottleneck-156              [-1, 256, 16]               0
     BatchNorm1d-157              [-1, 256, 16]             512
            ReLU-158              [-1, 256, 16]               0
         Dropout-159              [-1, 256, 16]               0
          Conv1d-160               [-1, 256, 8]          16,640
 MyConv1dPadSame-161               [-1, 256, 8]               0
     BatchNorm1d-162               [-1, 256, 8]             512
            ReLU-163               [-1, 256, 8]               0
         Dropout-164               [-1, 256, 8]               0
          Conv1d-165               [-1, 256, 8]          16,640
 MyConv1dPadSame-166               [-1, 256, 8]               0
       MaxPool1d-167               [-1, 256, 8]               0
MyMaxPool1dPadSame-168               [-1, 256, 8]               0
      Bottleneck-169               [-1, 256, 8]               0
     BatchNorm1d-170               [-1, 256, 8]             512
            ReLU-171               [-1, 256, 8]               0
         Dropout-172               [-1, 256, 8]               0
          Conv1d-173               [-1, 256, 8]          16,640
 MyConv1dPadSame-174               [-1, 256, 8]               0
     BatchNorm1d-175               [-1, 256, 8]             512
            ReLU-176               [-1, 256, 8]               0
         Dropout-177               [-1, 256, 8]               0
          Conv1d-178               [-1, 256, 8]          16,640
 MyConv1dPadSame-179               [-1, 256, 8]               0
      Bottleneck-180               [-1, 256, 8]               0
     BatchNorm1d-181               [-1, 256, 8]             512
            ReLU-182               [-1, 256, 8]               0
         Dropout-183               [-1, 256, 8]               0
          Conv1d-184               [-1, 256, 4]          16,640
 MyConv1dPadSame-185               [-1, 256, 4]               0
     BatchNorm1d-186               [-1, 256, 4]             512
            ReLU-187               [-1, 256, 4]               0
         Dropout-188               [-1, 256, 4]               0
          Conv1d-189               [-1, 256, 4]          16,640
 MyConv1dPadSame-190               [-1, 256, 4]               0
       MaxPool1d-191               [-1, 256, 4]               0
MyMaxPool1dPadSame-192               [-1, 256, 4]               0
      Bottleneck-193               [-1, 256, 4]               0
     BatchNorm1d-194               [-1, 256, 4]             512
            ReLU-195               [-1, 256, 4]               0
          Linear-196                    [-1, 2]             514
================================================================
Total params: 175,714
Trainable params: 175,714
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 13.30
Params size (MB): 0.67
Estimated Total Size (MB): 13.97
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 32, kernel_size: 16, n_block: 2
************************************************************
************************************************************
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 32, 1024]             544
   MyConv1dPadSame-2             [-1, 32, 1024]               0
       BatchNorm1d-3             [-1, 32, 1024]              64
              ReLU-4             [-1, 32, 1024]               0
            Conv1d-5             [-1, 32, 1024]             544
   MyConv1dPadSame-6             [-1, 32, 1024]               0
       BatchNorm1d-7             [-1, 32, 1024]              64
              ReLU-8             [-1, 32, 1024]               0
           Dropout-9             [-1, 32, 1024]               0
           Conv1d-10             [-1, 32, 1024]             544
  MyConv1dPadSame-11             [-1, 32, 1024]               0
       Bottleneck-12             [-1, 32, 1024]               0
      BatchNorm1d-13             [-1, 32, 1024]              64
             ReLU-14             [-1, 32, 1024]               0
          Dropout-15             [-1, 32, 1024]               0
           Conv1d-16             [-1, 64, 1024]           1,088
  MyConv1dPadSame-17             [-1, 64, 1024]               0
      BatchNorm1d-18             [-1, 64, 1024]             128
             ReLU-19             [-1, 64, 1024]               0
          Dropout-20             [-1, 64, 1024]               0
           Conv1d-21             [-1, 64, 1024]           2,112
  MyConv1dPadSame-22             [-1, 64, 1024]               0
       Bottleneck-23             [-1, 64, 1024]               0
      BatchNorm1d-24             [-1, 64, 1024]             128
             ReLU-25             [-1, 64, 1024]               0
           Linear-26                    [-1, 2]             130
================================================================
Total params: 5,410
Trainable params: 5,410
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 8.75
Params size (MB): 0.02
Estimated Total Size (MB): 8.77
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 32, kernel_size: 16, n_block: 4
************************************************************
************************************************************
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 32, 1024]             544
   MyConv1dPadSame-2             [-1, 32, 1024]               0
       BatchNorm1d-3             [-1, 32, 1024]              64
              ReLU-4             [-1, 32, 1024]               0
            Conv1d-5             [-1, 32, 1024]             544
   MyConv1dPadSame-6             [-1, 32, 1024]               0
       BatchNorm1d-7             [-1, 32, 1024]              64
              ReLU-8             [-1, 32, 1024]               0
           Dropout-9             [-1, 32, 1024]               0
           Conv1d-10             [-1, 32, 1024]             544
  MyConv1dPadSame-11             [-1, 32, 1024]               0
       Bottleneck-12             [-1, 32, 1024]               0
      BatchNorm1d-13             [-1, 32, 1024]              64
             ReLU-14             [-1, 32, 1024]               0
          Dropout-15             [-1, 32, 1024]               0
           Conv1d-16             [-1, 64, 1024]           1,088
  MyConv1dPadSame-17             [-1, 64, 1024]               0
      BatchNorm1d-18             [-1, 64, 1024]             128
             ReLU-19             [-1, 64, 1024]               0
          Dropout-20             [-1, 64, 1024]               0
           Conv1d-21             [-1, 64, 1024]           2,112
  MyConv1dPadSame-22             [-1, 64, 1024]               0
       Bottleneck-23             [-1, 64, 1024]               0
      BatchNorm1d-24             [-1, 64, 1024]             128
             ReLU-25             [-1, 64, 1024]               0
          Dropout-26             [-1, 64, 1024]               0
           Conv1d-27            [-1, 128, 1024]           4,224
  MyConv1dPadSame-28            [-1, 128, 1024]               0
      BatchNorm1d-29            [-1, 128, 1024]             256
             ReLU-30            [-1, 128, 1024]               0
          Dropout-31            [-1, 128, 1024]               0
           Conv1d-32            [-1, 128, 1024]           8,320
  MyConv1dPadSame-33            [-1, 128, 1024]               0
       Bottleneck-34            [-1, 128, 1024]               0
      BatchNorm1d-35            [-1, 128, 1024]             256
             ReLU-36            [-1, 128, 1024]               0
          Dropout-37            [-1, 128, 1024]               0
           Conv1d-38            [-1, 256, 1024]          16,640
  MyConv1dPadSame-39            [-1, 256, 1024]               0
      BatchNorm1d-40            [-1, 256, 1024]             512
             ReLU-41            [-1, 256, 1024]               0
          Dropout-42            [-1, 256, 1024]               0
           Conv1d-43            [-1, 256, 1024]          33,024
  MyConv1dPadSame-44            [-1, 256, 1024]               0
       Bottleneck-45            [-1, 256, 1024]               0
      BatchNorm1d-46            [-1, 256, 1024]             512
             ReLU-47            [-1, 256, 1024]               0
           Linear-48                    [-1, 2]             514
================================================================
Total params: 69,538
Trainable params: 69,538
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 40.25
Params size (MB): 0.27
Estimated Total Size (MB): 40.52
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 32, kernel_size: 16, n_block: 8
************************************************************
************************************************************
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 32, 1024]             544
   MyConv1dPadSame-2             [-1, 32, 1024]               0
       BatchNorm1d-3             [-1, 32, 1024]              64
              ReLU-4             [-1, 32, 1024]               0
            Conv1d-5             [-1, 32, 1024]             544
   MyConv1dPadSame-6             [-1, 32, 1024]               0
       BatchNorm1d-7             [-1, 32, 1024]              64
              ReLU-8             [-1, 32, 1024]               0
           Dropout-9             [-1, 32, 1024]               0
           Conv1d-10             [-1, 32, 1024]             544
  MyConv1dPadSame-11             [-1, 32, 1024]               0
       Bottleneck-12             [-1, 32, 1024]               0
      BatchNorm1d-13             [-1, 32, 1024]              64
             ReLU-14             [-1, 32, 1024]               0
          Dropout-15             [-1, 32, 1024]               0
           Conv1d-16             [-1, 32, 1024]             544
  MyConv1dPadSame-17             [-1, 32, 1024]               0
      BatchNorm1d-18             [-1, 32, 1024]              64
             ReLU-19             [-1, 32, 1024]               0
          Dropout-20             [-1, 32, 1024]               0
           Conv1d-21             [-1, 32, 1024]             544
  MyConv1dPadSame-22             [-1, 32, 1024]               0
       Bottleneck-23             [-1, 32, 1024]               0
      BatchNorm1d-24             [-1, 32, 1024]              64
             ReLU-25             [-1, 32, 1024]               0
          Dropout-26             [-1, 32, 1024]               0
           Conv1d-27             [-1, 64, 1024]           1,088
  MyConv1dPadSame-28             [-1, 64, 1024]               0
      BatchNorm1d-29             [-1, 64, 1024]             128
             ReLU-30             [-1, 64, 1024]               0
          Dropout-31             [-1, 64, 1024]               0
           Conv1d-32             [-1, 64, 1024]           2,112
  MyConv1dPadSame-33             [-1, 64, 1024]               0
       Bottleneck-34             [-1, 64, 1024]               0
      BatchNorm1d-35             [-1, 64, 1024]             128
             ReLU-36             [-1, 64, 1024]               0
          Dropout-37             [-1, 64, 1024]               0
           Conv1d-38             [-1, 64, 1024]           2,112
  MyConv1dPadSame-39             [-1, 64, 1024]               0
      BatchNorm1d-40             [-1, 64, 1024]             128
             ReLU-41             [-1, 64, 1024]               0
          Dropout-42             [-1, 64, 1024]               0
           Conv1d-43             [-1, 64, 1024]           2,112
  MyConv1dPadSame-44             [-1, 64, 1024]               0
       Bottleneck-45             [-1, 64, 1024]               0
      BatchNorm1d-46             [-1, 64, 1024]             128
             ReLU-47             [-1, 64, 1024]               0
          Dropout-48             [-1, 64, 1024]               0
           Conv1d-49            [-1, 128, 1024]           4,224
  MyConv1dPadSame-50            [-1, 128, 1024]               0
      BatchNorm1d-51            [-1, 128, 1024]             256
             ReLU-52            [-1, 128, 1024]               0
          Dropout-53            [-1, 128, 1024]               0
           Conv1d-54            [-1, 128, 1024]           8,320
  MyConv1dPadSame-55            [-1, 128, 1024]               0
       Bottleneck-56            [-1, 128, 1024]               0
      BatchNorm1d-57            [-1, 128, 1024]             256
             ReLU-58            [-1, 128, 1024]               0
          Dropout-59            [-1, 128, 1024]               0
           Conv1d-60            [-1, 128, 1024]           8,320
  MyConv1dPadSame-61            [-1, 128, 1024]               0
      BatchNorm1d-62            [-1, 128, 1024]             256
             ReLU-63            [-1, 128, 1024]               0
          Dropout-64            [-1, 128, 1024]               0
           Conv1d-65            [-1, 128, 1024]           8,320
  MyConv1dPadSame-66            [-1, 128, 1024]               0
       Bottleneck-67            [-1, 128, 1024]               0
      BatchNorm1d-68            [-1, 128, 1024]             256
             ReLU-69            [-1, 128, 1024]               0
          Dropout-70            [-1, 128, 1024]               0
           Conv1d-71            [-1, 256, 1024]          16,640
  MyConv1dPadSame-72            [-1, 256, 1024]               0
      BatchNorm1d-73            [-1, 256, 1024]             512
             ReLU-74            [-1, 256, 1024]               0
          Dropout-75            [-1, 256, 1024]               0
           Conv1d-76            [-1, 256, 1024]          33,024
  MyConv1dPadSame-77            [-1, 256, 1024]               0
       Bottleneck-78            [-1, 256, 1024]               0
      BatchNorm1d-79            [-1, 256, 1024]             512
             ReLU-80            [-1, 256, 1024]               0
          Dropout-81            [-1, 256, 1024]               0
           Conv1d-82            [-1, 256, 1024]          33,024
  MyConv1dPadSame-83            [-1, 256, 1024]               0
      BatchNorm1d-84            [-1, 256, 1024]             512
             ReLU-85            [-1, 256, 1024]               0
          Dropout-86            [-1, 256, 1024]               0
           Conv1d-87            [-1, 256, 1024]          33,024
  MyConv1dPadSame-88            [-1, 256, 1024]               0
       Bottleneck-89            [-1, 256, 1024]               0
      BatchNorm1d-90            [-1, 256, 1024]             512
             ReLU-91            [-1, 256, 1024]               0
           Linear-92                    [-1, 2]             514
================================================================
Total params: 159,458
Trainable params: 159,458
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 81.50
Params size (MB): 0.61
Estimated Total Size (MB): 82.11
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 32, kernel_size: 16, n_block: 16
************************************************************
************************************************************
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 32, 1024]             544
   MyConv1dPadSame-2             [-1, 32, 1024]               0
       BatchNorm1d-3             [-1, 32, 1024]              64
              ReLU-4             [-1, 32, 1024]               0
            Conv1d-5             [-1, 32, 1024]             544
   MyConv1dPadSame-6             [-1, 32, 1024]               0
       BatchNorm1d-7             [-1, 32, 1024]              64
              ReLU-8             [-1, 32, 1024]               0
           Dropout-9             [-1, 32, 1024]               0
           Conv1d-10             [-1, 32, 1024]             544
  MyConv1dPadSame-11             [-1, 32, 1024]               0
       Bottleneck-12             [-1, 32, 1024]               0
      BatchNorm1d-13             [-1, 32, 1024]              64
             ReLU-14             [-1, 32, 1024]               0
          Dropout-15             [-1, 32, 1024]               0
           Conv1d-16              [-1, 32, 512]             544
  MyConv1dPadSame-17              [-1, 32, 512]               0
      BatchNorm1d-18              [-1, 32, 512]              64
             ReLU-19              [-1, 32, 512]               0
          Dropout-20              [-1, 32, 512]               0
           Conv1d-21              [-1, 32, 512]             544
  MyConv1dPadSame-22              [-1, 32, 512]               0
        MaxPool1d-23              [-1, 32, 512]               0
MyMaxPool1dPadSame-24              [-1, 32, 512]               0
       Bottleneck-25              [-1, 32, 512]               0
      BatchNorm1d-26              [-1, 32, 512]              64
             ReLU-27              [-1, 32, 512]               0
          Dropout-28              [-1, 32, 512]               0
           Conv1d-29              [-1, 32, 512]             544
  MyConv1dPadSame-30              [-1, 32, 512]               0
      BatchNorm1d-31              [-1, 32, 512]              64
             ReLU-32              [-1, 32, 512]               0
          Dropout-33              [-1, 32, 512]               0
           Conv1d-34              [-1, 32, 512]             544
  MyConv1dPadSame-35              [-1, 32, 512]               0
       Bottleneck-36              [-1, 32, 512]               0
      BatchNorm1d-37              [-1, 32, 512]              64
             ReLU-38              [-1, 32, 512]               0
          Dropout-39              [-1, 32, 512]               0
           Conv1d-40              [-1, 32, 256]             544
  MyConv1dPadSame-41              [-1, 32, 256]               0
      BatchNorm1d-42              [-1, 32, 256]              64
             ReLU-43              [-1, 32, 256]               0
          Dropout-44              [-1, 32, 256]               0
           Conv1d-45              [-1, 32, 256]             544
  MyConv1dPadSame-46              [-1, 32, 256]               0
        MaxPool1d-47              [-1, 32, 256]               0
MyMaxPool1dPadSame-48              [-1, 32, 256]               0
       Bottleneck-49              [-1, 32, 256]               0
      BatchNorm1d-50              [-1, 32, 256]              64
             ReLU-51              [-1, 32, 256]               0
          Dropout-52              [-1, 32, 256]               0
           Conv1d-53              [-1, 64, 256]           1,088
  MyConv1dPadSame-54              [-1, 64, 256]               0
      BatchNorm1d-55              [-1, 64, 256]             128
             ReLU-56              [-1, 64, 256]               0
          Dropout-57              [-1, 64, 256]               0
           Conv1d-58              [-1, 64, 256]           2,112
  MyConv1dPadSame-59              [-1, 64, 256]               0
       Bottleneck-60              [-1, 64, 256]               0
      BatchNorm1d-61              [-1, 64, 256]             128
             ReLU-62              [-1, 64, 256]               0
          Dropout-63              [-1, 64, 256]               0
           Conv1d-64              [-1, 64, 128]           2,112
  MyConv1dPadSame-65              [-1, 64, 128]               0
      BatchNorm1d-66              [-1, 64, 128]             128
             ReLU-67              [-1, 64, 128]               0
          Dropout-68              [-1, 64, 128]               0
           Conv1d-69              [-1, 64, 128]           2,112
  MyConv1dPadSame-70              [-1, 64, 128]               0
        MaxPool1d-71              [-1, 64, 128]               0
MyMaxPool1dPadSame-72              [-1, 64, 128]               0
       Bottleneck-73              [-1, 64, 128]               0
      BatchNorm1d-74              [-1, 64, 128]             128
             ReLU-75              [-1, 64, 128]               0
          Dropout-76              [-1, 64, 128]               0
           Conv1d-77              [-1, 64, 128]           2,112
  MyConv1dPadSame-78              [-1, 64, 128]               0
      BatchNorm1d-79              [-1, 64, 128]             128
             ReLU-80              [-1, 64, 128]               0
          Dropout-81              [-1, 64, 128]               0
           Conv1d-82              [-1, 64, 128]           2,112
  MyConv1dPadSame-83              [-1, 64, 128]               0
       Bottleneck-84              [-1, 64, 128]               0
      BatchNorm1d-85              [-1, 64, 128]             128
             ReLU-86              [-1, 64, 128]               0
          Dropout-87              [-1, 64, 128]               0
           Conv1d-88               [-1, 64, 64]           2,112
  MyConv1dPadSame-89               [-1, 64, 64]               0
      BatchNorm1d-90               [-1, 64, 64]             128
             ReLU-91               [-1, 64, 64]               0
          Dropout-92               [-1, 64, 64]               0
           Conv1d-93               [-1, 64, 64]           2,112
  MyConv1dPadSame-94               [-1, 64, 64]               0
        MaxPool1d-95               [-1, 64, 64]               0
MyMaxPool1dPadSame-96               [-1, 64, 64]               0
       Bottleneck-97               [-1, 64, 64]               0
      BatchNorm1d-98               [-1, 64, 64]             128
             ReLU-99               [-1, 64, 64]               0
         Dropout-100               [-1, 64, 64]               0
          Conv1d-101              [-1, 128, 64]           4,224
 MyConv1dPadSame-102              [-1, 128, 64]               0
     BatchNorm1d-103              [-1, 128, 64]             256
            ReLU-104              [-1, 128, 64]               0
         Dropout-105              [-1, 128, 64]               0
          Conv1d-106              [-1, 128, 64]           8,320
 MyConv1dPadSame-107              [-1, 128, 64]               0
      Bottleneck-108              [-1, 128, 64]               0
     BatchNorm1d-109              [-1, 128, 64]             256
            ReLU-110              [-1, 128, 64]               0
         Dropout-111              [-1, 128, 64]               0
          Conv1d-112              [-1, 128, 32]           8,320
 MyConv1dPadSame-113              [-1, 128, 32]               0
     BatchNorm1d-114              [-1, 128, 32]             256
            ReLU-115              [-1, 128, 32]               0
         Dropout-116              [-1, 128, 32]               0
          Conv1d-117              [-1, 128, 32]           8,320
 MyConv1dPadSame-118              [-1, 128, 32]               0
       MaxPool1d-119              [-1, 128, 32]               0
MyMaxPool1dPadSame-120              [-1, 128, 32]               0
      Bottleneck-121              [-1, 128, 32]               0
     BatchNorm1d-122              [-1, 128, 32]             256
            ReLU-123              [-1, 128, 32]               0
         Dropout-124              [-1, 128, 32]               0
          Conv1d-125              [-1, 128, 32]           8,320
 MyConv1dPadSame-126              [-1, 128, 32]               0
     BatchNorm1d-127              [-1, 128, 32]             256
            ReLU-128              [-1, 128, 32]               0
         Dropout-129              [-1, 128, 32]               0
          Conv1d-130              [-1, 128, 32]           8,320
 MyConv1dPadSame-131              [-1, 128, 32]               0
      Bottleneck-132              [-1, 128, 32]               0
     BatchNorm1d-133              [-1, 128, 32]             256
            ReLU-134              [-1, 128, 32]               0
         Dropout-135              [-1, 128, 32]               0
          Conv1d-136              [-1, 128, 16]           8,320
 MyConv1dPadSame-137              [-1, 128, 16]               0
     BatchNorm1d-138              [-1, 128, 16]             256
            ReLU-139              [-1, 128, 16]               0
         Dropout-140              [-1, 128, 16]               0
          Conv1d-141              [-1, 128, 16]           8,320
 MyConv1dPadSame-142              [-1, 128, 16]               0
       MaxPool1d-143              [-1, 128, 16]               0
MyMaxPool1dPadSame-144              [-1, 128, 16]               0
      Bottleneck-145              [-1, 128, 16]               0
     BatchNorm1d-146              [-1, 128, 16]             256
            ReLU-147              [-1, 128, 16]               0
         Dropout-148              [-1, 128, 16]               0
          Conv1d-149              [-1, 256, 16]          16,640
 MyConv1dPadSame-150              [-1, 256, 16]               0
     BatchNorm1d-151              [-1, 256, 16]             512
            ReLU-152              [-1, 256, 16]               0
         Dropout-153              [-1, 256, 16]               0
          Conv1d-154              [-1, 256, 16]          33,024
 MyConv1dPadSame-155              [-1, 256, 16]               0
      Bottleneck-156              [-1, 256, 16]               0
     BatchNorm1d-157              [-1, 256, 16]             512
            ReLU-158              [-1, 256, 16]               0
         Dropout-159              [-1, 256, 16]               0
          Conv1d-160               [-1, 256, 8]          33,024
 MyConv1dPadSame-161               [-1, 256, 8]               0
     BatchNorm1d-162               [-1, 256, 8]             512
            ReLU-163               [-1, 256, 8]               0
         Dropout-164               [-1, 256, 8]               0
          Conv1d-165               [-1, 256, 8]          33,024
 MyConv1dPadSame-166               [-1, 256, 8]               0
       MaxPool1d-167               [-1, 256, 8]               0
MyMaxPool1dPadSame-168               [-1, 256, 8]               0
      Bottleneck-169               [-1, 256, 8]               0
     BatchNorm1d-170               [-1, 256, 8]             512
            ReLU-171               [-1, 256, 8]               0
         Dropout-172               [-1, 256, 8]               0
          Conv1d-173               [-1, 256, 8]          33,024
 MyConv1dPadSame-174               [-1, 256, 8]               0
     BatchNorm1d-175               [-1, 256, 8]             512
            ReLU-176               [-1, 256, 8]               0
         Dropout-177               [-1, 256, 8]               0
          Conv1d-178               [-1, 256, 8]          33,024
 MyConv1dPadSame-179               [-1, 256, 8]               0
      Bottleneck-180               [-1, 256, 8]               0
     BatchNorm1d-181               [-1, 256, 8]             512
            ReLU-182               [-1, 256, 8]               0
         Dropout-183               [-1, 256, 8]               0
          Conv1d-184               [-1, 256, 4]          33,024
 MyConv1dPadSame-185               [-1, 256, 4]               0
     BatchNorm1d-186               [-1, 256, 4]             512
            ReLU-187               [-1, 256, 4]               0
         Dropout-188               [-1, 256, 4]               0
          Conv1d-189               [-1, 256, 4]          33,024
 MyConv1dPadSame-190               [-1, 256, 4]               0
       MaxPool1d-191               [-1, 256, 4]               0
MyMaxPool1dPadSame-192               [-1, 256, 4]               0
      Bottleneck-193               [-1, 256, 4]               0
     BatchNorm1d-194               [-1, 256, 4]             512
            ReLU-195               [-1, 256, 4]               0
          Linear-196                    [-1, 2]             514
================================================================
Total params: 339,298
Trainable params: 339,298
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 13.30
Params size (MB): 1.29
Estimated Total Size (MB): 14.60
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 64, kernel_size: 2, n_block: 2
************************************************************
************************************************************
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 64, 1024]             192
   MyConv1dPadSame-2             [-1, 64, 1024]               0
       BatchNorm1d-3             [-1, 64, 1024]             128
              ReLU-4             [-1, 64, 1024]               0
            Conv1d-5             [-1, 64, 1024]             192
   MyConv1dPadSame-6             [-1, 64, 1024]               0
       BatchNorm1d-7             [-1, 64, 1024]             128
              ReLU-8             [-1, 64, 1024]               0
           Dropout-9             [-1, 64, 1024]               0
           Conv1d-10             [-1, 64, 1024]             192
  MyConv1dPadSame-11             [-1, 64, 1024]               0
       Bottleneck-12             [-1, 64, 1024]               0
      BatchNorm1d-13             [-1, 64, 1024]             128
             ReLU-14             [-1, 64, 1024]               0
          Dropout-15             [-1, 64, 1024]               0
           Conv1d-16            [-1, 128, 1024]             384
  MyConv1dPadSame-17            [-1, 128, 1024]               0
      BatchNorm1d-18            [-1, 128, 1024]             256
             ReLU-19            [-1, 128, 1024]               0
          Dropout-20            [-1, 128, 1024]               0
           Conv1d-21            [-1, 128, 1024]             640
  MyConv1dPadSame-22            [-1, 128, 1024]               0
       Bottleneck-23            [-1, 128, 1024]               0
      BatchNorm1d-24            [-1, 128, 1024]             256
             ReLU-25            [-1, 128, 1024]               0
           Linear-26                    [-1, 2]             258
================================================================
Total params: 2,754
Trainable params: 2,754
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 17.50
Params size (MB): 0.01
Estimated Total Size (MB): 17.51
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 64, kernel_size: 2, n_block: 4
************************************************************
************************************************************
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 64, 1024]             192
   MyConv1dPadSame-2             [-1, 64, 1024]               0
       BatchNorm1d-3             [-1, 64, 1024]             128
              ReLU-4             [-1, 64, 1024]               0
            Conv1d-5             [-1, 64, 1024]             192
   MyConv1dPadSame-6             [-1, 64, 1024]               0
       BatchNorm1d-7             [-1, 64, 1024]             128
              ReLU-8             [-1, 64, 1024]               0
           Dropout-9             [-1, 64, 1024]               0
           Conv1d-10             [-1, 64, 1024]             192
  MyConv1dPadSame-11             [-1, 64, 1024]               0
       Bottleneck-12             [-1, 64, 1024]               0
      BatchNorm1d-13             [-1, 64, 1024]             128
             ReLU-14             [-1, 64, 1024]               0
          Dropout-15             [-1, 64, 1024]               0
           Conv1d-16            [-1, 128, 1024]             384
  MyConv1dPadSame-17            [-1, 128, 1024]               0
      BatchNorm1d-18            [-1, 128, 1024]             256
             ReLU-19            [-1, 128, 1024]               0
          Dropout-20            [-1, 128, 1024]               0
           Conv1d-21            [-1, 128, 1024]             640
  MyConv1dPadSame-22            [-1, 128, 1024]               0
       Bottleneck-23            [-1, 128, 1024]               0
      BatchNorm1d-24            [-1, 128, 1024]             256
             ReLU-25            [-1, 128, 1024]               0
          Dropout-26            [-1, 128, 1024]               0
           Conv1d-27            [-1, 256, 1024]           1,280
  MyConv1dPadSame-28            [-1, 256, 1024]               0
      BatchNorm1d-29            [-1, 256, 1024]             512
             ReLU-30            [-1, 256, 1024]               0
          Dropout-31            [-1, 256, 1024]               0
           Conv1d-32            [-1, 256, 1024]           2,304
  MyConv1dPadSame-33            [-1, 256, 1024]               0
       Bottleneck-34            [-1, 256, 1024]               0
      BatchNorm1d-35            [-1, 256, 1024]             512
             ReLU-36            [-1, 256, 1024]               0
          Dropout-37            [-1, 256, 1024]               0
           Conv1d-38            [-1, 512, 1024]           4,608
  MyConv1dPadSame-39            [-1, 512, 1024]               0
      BatchNorm1d-40            [-1, 512, 1024]           1,024
             ReLU-41            [-1, 512, 1024]               0
          Dropout-42            [-1, 512, 1024]               0
           Conv1d-43            [-1, 512, 1024]           8,704
  MyConv1dPadSame-44            [-1, 512, 1024]               0
       Bottleneck-45            [-1, 512, 1024]               0
      BatchNorm1d-46            [-1, 512, 1024]           1,024
             ReLU-47            [-1, 512, 1024]               0
           Linear-48                    [-1, 2]           1,026
================================================================
Total params: 23,490
Trainable params: 23,490
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 80.50
Params size (MB): 0.09
Estimated Total Size (MB): 80.59
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 64, kernel_size: 2, n_block: 8
************************************************************
************************************************************
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 64, 1024]             192
   MyConv1dPadSame-2             [-1, 64, 1024]               0
       BatchNorm1d-3             [-1, 64, 1024]             128
              ReLU-4             [-1, 64, 1024]               0
            Conv1d-5             [-1, 64, 1024]             192
   MyConv1dPadSame-6             [-1, 64, 1024]               0
       BatchNorm1d-7             [-1, 64, 1024]             128
              ReLU-8             [-1, 64, 1024]               0
           Dropout-9             [-1, 64, 1024]               0
           Conv1d-10             [-1, 64, 1024]             192
  MyConv1dPadSame-11             [-1, 64, 1024]               0
       Bottleneck-12             [-1, 64, 1024]               0
      BatchNorm1d-13             [-1, 64, 1024]             128
             ReLU-14             [-1, 64, 1024]               0
          Dropout-15             [-1, 64, 1024]               0
           Conv1d-16             [-1, 64, 1024]             192
  MyConv1dPadSame-17             [-1, 64, 1024]               0
      BatchNorm1d-18             [-1, 64, 1024]             128
             ReLU-19             [-1, 64, 1024]               0
          Dropout-20             [-1, 64, 1024]               0
           Conv1d-21             [-1, 64, 1024]             192
  MyConv1dPadSame-22             [-1, 64, 1024]               0
       Bottleneck-23             [-1, 64, 1024]               0
      BatchNorm1d-24             [-1, 64, 1024]             128
             ReLU-25             [-1, 64, 1024]               0
          Dropout-26             [-1, 64, 1024]               0
           Conv1d-27            [-1, 128, 1024]             384
  MyConv1dPadSame-28            [-1, 128, 1024]               0
      BatchNorm1d-29            [-1, 128, 1024]             256
             ReLU-30            [-1, 128, 1024]               0
          Dropout-31            [-1, 128, 1024]               0
           Conv1d-32            [-1, 128, 1024]             640
  MyConv1dPadSame-33            [-1, 128, 1024]               0
       Bottleneck-34            [-1, 128, 1024]               0
      BatchNorm1d-35            [-1, 128, 1024]             256
             ReLU-36            [-1, 128, 1024]               0
          Dropout-37            [-1, 128, 1024]               0
           Conv1d-38            [-1, 128, 1024]             640
  MyConv1dPadSame-39            [-1, 128, 1024]               0
      BatchNorm1d-40            [-1, 128, 1024]             256
             ReLU-41            [-1, 128, 1024]               0
          Dropout-42            [-1, 128, 1024]               0
           Conv1d-43            [-1, 128, 1024]             640
  MyConv1dPadSame-44            [-1, 128, 1024]               0
       Bottleneck-45            [-1, 128, 1024]               0
      BatchNorm1d-46            [-1, 128, 1024]             256
             ReLU-47            [-1, 128, 1024]               0
          Dropout-48            [-1, 128, 1024]               0
           Conv1d-49            [-1, 256, 1024]           1,280
  MyConv1dPadSame-50            [-1, 256, 1024]               0
      BatchNorm1d-51            [-1, 256, 1024]             512
             ReLU-52            [-1, 256, 1024]               0
          Dropout-53            [-1, 256, 1024]               0
           Conv1d-54            [-1, 256, 1024]           2,304
  MyConv1dPadSame-55            [-1, 256, 1024]               0
       Bottleneck-56            [-1, 256, 1024]               0
      BatchNorm1d-57            [-1, 256, 1024]             512
             ReLU-58            [-1, 256, 1024]               0
          Dropout-59            [-1, 256, 1024]               0
           Conv1d-60            [-1, 256, 1024]           2,304
  MyConv1dPadSame-61            [-1, 256, 1024]               0
      BatchNorm1d-62            [-1, 256, 1024]             512
             ReLU-63            [-1, 256, 1024]               0
          Dropout-64            [-1, 256, 1024]               0
           Conv1d-65            [-1, 256, 1024]           2,304
  MyConv1dPadSame-66            [-1, 256, 1024]               0
       Bottleneck-67            [-1, 256, 1024]               0
      BatchNorm1d-68            [-1, 256, 1024]             512
             ReLU-69            [-1, 256, 1024]               0
          Dropout-70            [-1, 256, 1024]               0
           Conv1d-71            [-1, 512, 1024]           4,608
  MyConv1dPadSame-72            [-1, 512, 1024]               0
      BatchNorm1d-73            [-1, 512, 1024]           1,024
             ReLU-74            [-1, 512, 1024]               0
          Dropout-75            [-1, 512, 1024]               0
           Conv1d-76            [-1, 512, 1024]           8,704
  MyConv1dPadSame-77            [-1, 512, 1024]               0
       Bottleneck-78            [-1, 512, 1024]               0
      BatchNorm1d-79            [-1, 512, 1024]           1,024
             ReLU-80            [-1, 512, 1024]               0
          Dropout-81            [-1, 512, 1024]               0
           Conv1d-82            [-1, 512, 1024]           8,704
  MyConv1dPadSame-83            [-1, 512, 1024]               0
      BatchNorm1d-84            [-1, 512, 1024]           1,024
             ReLU-85            [-1, 512, 1024]               0
          Dropout-86            [-1, 512, 1024]               0
           Conv1d-87            [-1, 512, 1024]           8,704
  MyConv1dPadSame-88            [-1, 512, 1024]               0
       Bottleneck-89            [-1, 512, 1024]               0
      BatchNorm1d-90            [-1, 512, 1024]           1,024
             ReLU-91            [-1, 512, 1024]               0
           Linear-92                    [-1, 2]           1,026
================================================================
Total params: 51,010
Trainable params: 51,010
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 163.00
Params size (MB): 0.19
Estimated Total Size (MB): 163.20
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 64, kernel_size: 2, n_block: 16
************************************************************
************************************************************
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 64, 1024]             192
   MyConv1dPadSame-2             [-1, 64, 1024]               0
       BatchNorm1d-3             [-1, 64, 1024]             128
              ReLU-4             [-1, 64, 1024]               0
            Conv1d-5             [-1, 64, 1024]             192
   MyConv1dPadSame-6             [-1, 64, 1024]               0
       BatchNorm1d-7             [-1, 64, 1024]             128
              ReLU-8             [-1, 64, 1024]               0
           Dropout-9             [-1, 64, 1024]               0
           Conv1d-10             [-1, 64, 1024]             192
  MyConv1dPadSame-11             [-1, 64, 1024]               0
       Bottleneck-12             [-1, 64, 1024]               0
      BatchNorm1d-13             [-1, 64, 1024]             128
             ReLU-14             [-1, 64, 1024]               0
          Dropout-15             [-1, 64, 1024]               0
           Conv1d-16              [-1, 64, 512]             192
  MyConv1dPadSame-17              [-1, 64, 512]               0
      BatchNorm1d-18              [-1, 64, 512]             128
             ReLU-19              [-1, 64, 512]               0
          Dropout-20              [-1, 64, 512]               0
           Conv1d-21              [-1, 64, 512]             192
  MyConv1dPadSame-22              [-1, 64, 512]               0
        MaxPool1d-23              [-1, 64, 512]               0
MyMaxPool1dPadSame-24              [-1, 64, 512]               0
       Bottleneck-25              [-1, 64, 512]               0
      BatchNorm1d-26              [-1, 64, 512]             128
             ReLU-27              [-1, 64, 512]               0
          Dropout-28              [-1, 64, 512]               0
           Conv1d-29              [-1, 64, 512]             192
  MyConv1dPadSame-30              [-1, 64, 512]               0
      BatchNorm1d-31              [-1, 64, 512]             128
             ReLU-32              [-1, 64, 512]               0
          Dropout-33              [-1, 64, 512]               0
           Conv1d-34              [-1, 64, 512]             192
  MyConv1dPadSame-35              [-1, 64, 512]               0
       Bottleneck-36              [-1, 64, 512]               0
      BatchNorm1d-37              [-1, 64, 512]             128
             ReLU-38              [-1, 64, 512]               0
          Dropout-39              [-1, 64, 512]               0
           Conv1d-40              [-1, 64, 256]             192
  MyConv1dPadSame-41              [-1, 64, 256]               0
      BatchNorm1d-42              [-1, 64, 256]             128
             ReLU-43              [-1, 64, 256]               0
          Dropout-44              [-1, 64, 256]               0
           Conv1d-45              [-1, 64, 256]             192
  MyConv1dPadSame-46              [-1, 64, 256]               0
        MaxPool1d-47              [-1, 64, 256]               0
MyMaxPool1dPadSame-48              [-1, 64, 256]               0
       Bottleneck-49              [-1, 64, 256]               0
      BatchNorm1d-50              [-1, 64, 256]             128
             ReLU-51              [-1, 64, 256]               0
          Dropout-52              [-1, 64, 256]               0
           Conv1d-53             [-1, 128, 256]             384
  MyConv1dPadSame-54             [-1, 128, 256]               0
      BatchNorm1d-55             [-1, 128, 256]             256
             ReLU-56             [-1, 128, 256]               0
          Dropout-57             [-1, 128, 256]               0
           Conv1d-58             [-1, 128, 256]             640
  MyConv1dPadSame-59             [-1, 128, 256]               0
       Bottleneck-60             [-1, 128, 256]               0
      BatchNorm1d-61             [-1, 128, 256]             256
             ReLU-62             [-1, 128, 256]               0
          Dropout-63             [-1, 128, 256]               0
           Conv1d-64             [-1, 128, 128]             640
  MyConv1dPadSame-65             [-1, 128, 128]               0
      BatchNorm1d-66             [-1, 128, 128]             256
             ReLU-67             [-1, 128, 128]               0
          Dropout-68             [-1, 128, 128]               0
           Conv1d-69             [-1, 128, 128]             640
  MyConv1dPadSame-70             [-1, 128, 128]               0
        MaxPool1d-71             [-1, 128, 128]               0
MyMaxPool1dPadSame-72             [-1, 128, 128]               0
       Bottleneck-73             [-1, 128, 128]               0
      BatchNorm1d-74             [-1, 128, 128]             256
             ReLU-75             [-1, 128, 128]               0
          Dropout-76             [-1, 128, 128]               0
           Conv1d-77             [-1, 128, 128]             640
  MyConv1dPadSame-78             [-1, 128, 128]               0
      BatchNorm1d-79             [-1, 128, 128]             256
             ReLU-80             [-1, 128, 128]               0
          Dropout-81             [-1, 128, 128]               0
           Conv1d-82             [-1, 128, 128]             640
  MyConv1dPadSame-83             [-1, 128, 128]               0
       Bottleneck-84             [-1, 128, 128]               0
      BatchNorm1d-85             [-1, 128, 128]             256
             ReLU-86             [-1, 128, 128]               0
          Dropout-87             [-1, 128, 128]               0
           Conv1d-88              [-1, 128, 64]             640
  MyConv1dPadSame-89              [-1, 128, 64]               0
      BatchNorm1d-90              [-1, 128, 64]             256
             ReLU-91              [-1, 128, 64]               0
          Dropout-92              [-1, 128, 64]               0
           Conv1d-93              [-1, 128, 64]             640
  MyConv1dPadSame-94              [-1, 128, 64]               0
        MaxPool1d-95              [-1, 128, 64]               0
MyMaxPool1dPadSame-96              [-1, 128, 64]               0
       Bottleneck-97              [-1, 128, 64]               0
      BatchNorm1d-98              [-1, 128, 64]             256
             ReLU-99              [-1, 128, 64]               0
         Dropout-100              [-1, 128, 64]               0
          Conv1d-101              [-1, 256, 64]           1,280
 MyConv1dPadSame-102              [-1, 256, 64]               0
     BatchNorm1d-103              [-1, 256, 64]             512
            ReLU-104              [-1, 256, 64]               0
         Dropout-105              [-1, 256, 64]               0
          Conv1d-106              [-1, 256, 64]           2,304
 MyConv1dPadSame-107              [-1, 256, 64]               0
      Bottleneck-108              [-1, 256, 64]               0
     BatchNorm1d-109              [-1, 256, 64]             512
            ReLU-110              [-1, 256, 64]               0
         Dropout-111              [-1, 256, 64]               0
          Conv1d-112              [-1, 256, 32]           2,304
 MyConv1dPadSame-113              [-1, 256, 32]               0
     BatchNorm1d-114              [-1, 256, 32]             512
            ReLU-115              [-1, 256, 32]               0
         Dropout-116              [-1, 256, 32]               0
          Conv1d-117              [-1, 256, 32]           2,304
 MyConv1dPadSame-118              [-1, 256, 32]               0
       MaxPool1d-119              [-1, 256, 32]               0
MyMaxPool1dPadSame-120              [-1, 256, 32]               0
      Bottleneck-121              [-1, 256, 32]               0
     BatchNorm1d-122              [-1, 256, 32]             512
            ReLU-123              [-1, 256, 32]               0
         Dropout-124              [-1, 256, 32]               0
          Conv1d-125              [-1, 256, 32]           2,304
 MyConv1dPadSame-126              [-1, 256, 32]               0
     BatchNorm1d-127              [-1, 256, 32]             512
            ReLU-128              [-1, 256, 32]               0
         Dropout-129              [-1, 256, 32]               0
          Conv1d-130              [-1, 256, 32]           2,304
 MyConv1dPadSame-131              [-1, 256, 32]               0
      Bottleneck-132              [-1, 256, 32]               0
     BatchNorm1d-133              [-1, 256, 32]             512
            ReLU-134              [-1, 256, 32]               0
         Dropout-135              [-1, 256, 32]               0
          Conv1d-136              [-1, 256, 16]           2,304
 MyConv1dPadSame-137              [-1, 256, 16]               0
     BatchNorm1d-138              [-1, 256, 16]             512
            ReLU-139              [-1, 256, 16]               0
         Dropout-140              [-1, 256, 16]               0
          Conv1d-141              [-1, 256, 16]           2,304
 MyConv1dPadSame-142              [-1, 256, 16]               0
       MaxPool1d-143              [-1, 256, 16]               0
MyMaxPool1dPadSame-144              [-1, 256, 16]               0
      Bottleneck-145              [-1, 256, 16]               0
     BatchNorm1d-146              [-1, 256, 16]             512
            ReLU-147              [-1, 256, 16]               0
         Dropout-148              [-1, 256, 16]               0
          Conv1d-149              [-1, 512, 16]           4,608
 MyConv1dPadSame-150              [-1, 512, 16]               0
     BatchNorm1d-151              [-1, 512, 16]           1,024
            ReLU-152              [-1, 512, 16]               0
         Dropout-153              [-1, 512, 16]               0
          Conv1d-154              [-1, 512, 16]           8,704
 MyConv1dPadSame-155              [-1, 512, 16]               0
      Bottleneck-156              [-1, 512, 16]               0
     BatchNorm1d-157              [-1, 512, 16]           1,024
            ReLU-158              [-1, 512, 16]               0
         Dropout-159              [-1, 512, 16]               0
          Conv1d-160               [-1, 512, 8]           8,704
 MyConv1dPadSame-161               [-1, 512, 8]               0
     BatchNorm1d-162               [-1, 512, 8]           1,024
            ReLU-163               [-1, 512, 8]               0
         Dropout-164               [-1, 512, 8]               0
          Conv1d-165               [-1, 512, 8]           8,704
 MyConv1dPadSame-166               [-1, 512, 8]               0
       MaxPool1d-167               [-1, 512, 8]               0
MyMaxPool1dPadSame-168               [-1, 512, 8]               0
      Bottleneck-169               [-1, 512, 8]               0
     BatchNorm1d-170               [-1, 512, 8]           1,024
            ReLU-171               [-1, 512, 8]               0
         Dropout-172               [-1, 512, 8]               0
          Conv1d-173               [-1, 512, 8]           8,704
 MyConv1dPadSame-174               [-1, 512, 8]               0
     BatchNorm1d-175               [-1, 512, 8]           1,024
            ReLU-176               [-1, 512, 8]               0
         Dropout-177               [-1, 512, 8]               0
          Conv1d-178               [-1, 512, 8]           8,704
 MyConv1dPadSame-179               [-1, 512, 8]               0
      Bottleneck-180               [-1, 512, 8]               0
     BatchNorm1d-181               [-1, 512, 8]           1,024
            ReLU-182               [-1, 512, 8]               0
         Dropout-183               [-1, 512, 8]               0
          Conv1d-184               [-1, 512, 4]           8,704
 MyConv1dPadSame-185               [-1, 512, 4]               0
     BatchNorm1d-186               [-1, 512, 4]           1,024
            ReLU-187               [-1, 512, 4]               0
         Dropout-188               [-1, 512, 4]               0
          Conv1d-189               [-1, 512, 4]           8,704
 MyConv1dPadSame-190               [-1, 512, 4]               0
       MaxPool1d-191               [-1, 512, 4]               0
MyMaxPool1dPadSame-192               [-1, 512, 4]               0
      Bottleneck-193               [-1, 512, 4]               0
     BatchNorm1d-194               [-1, 512, 4]           1,024
            ReLU-195               [-1, 512, 4]               0
          Linear-196                    [-1, 2]           1,026
================================================================
Total params: 106,050
Trainable params: 106,050
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 26.59
Params size (MB): 0.40
Estimated Total Size (MB): 27.00
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 64, kernel_size: 4, n_block: 2
************************************************************
************************************************************
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 64, 1024]             320
   MyConv1dPadSame-2             [-1, 64, 1024]               0
       BatchNorm1d-3             [-1, 64, 1024]             128
              ReLU-4             [-1, 64, 1024]               0
            Conv1d-5             [-1, 64, 1024]             320
   MyConv1dPadSame-6             [-1, 64, 1024]               0
       BatchNorm1d-7             [-1, 64, 1024]             128
              ReLU-8             [-1, 64, 1024]               0
           Dropout-9             [-1, 64, 1024]               0
           Conv1d-10             [-1, 64, 1024]             320
  MyConv1dPadSame-11             [-1, 64, 1024]               0
       Bottleneck-12             [-1, 64, 1024]               0
      BatchNorm1d-13             [-1, 64, 1024]             128
             ReLU-14             [-1, 64, 1024]               0
          Dropout-15             [-1, 64, 1024]               0
           Conv1d-16            [-1, 128, 1024]             640
  MyConv1dPadSame-17            [-1, 128, 1024]               0
      BatchNorm1d-18            [-1, 128, 1024]             256
             ReLU-19            [-1, 128, 1024]               0
          Dropout-20            [-1, 128, 1024]               0
           Conv1d-21            [-1, 128, 1024]           1,152
  MyConv1dPadSame-22            [-1, 128, 1024]               0
       Bottleneck-23            [-1, 128, 1024]               0
      BatchNorm1d-24            [-1, 128, 1024]             256
             ReLU-25            [-1, 128, 1024]               0
           Linear-26                    [-1, 2]             258
================================================================
Total params: 3,906
Trainable params: 3,906
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 17.50
Params size (MB): 0.01
Estimated Total Size (MB): 17.52
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 64, kernel_size: 4, n_block: 4
************************************************************
************************************************************
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 64, 1024]             320
   MyConv1dPadSame-2             [-1, 64, 1024]               0
       BatchNorm1d-3             [-1, 64, 1024]             128
              ReLU-4             [-1, 64, 1024]               0
            Conv1d-5             [-1, 64, 1024]             320
   MyConv1dPadSame-6             [-1, 64, 1024]               0
       BatchNorm1d-7             [-1, 64, 1024]             128
              ReLU-8             [-1, 64, 1024]               0
           Dropout-9             [-1, 64, 1024]               0
           Conv1d-10             [-1, 64, 1024]             320
  MyConv1dPadSame-11             [-1, 64, 1024]               0
       Bottleneck-12             [-1, 64, 1024]               0
      BatchNorm1d-13             [-1, 64, 1024]             128
             ReLU-14             [-1, 64, 1024]               0
          Dropout-15             [-1, 64, 1024]               0
           Conv1d-16            [-1, 128, 1024]             640
  MyConv1dPadSame-17            [-1, 128, 1024]               0
      BatchNorm1d-18            [-1, 128, 1024]             256
             ReLU-19            [-1, 128, 1024]               0
          Dropout-20            [-1, 128, 1024]               0
           Conv1d-21            [-1, 128, 1024]           1,152
  MyConv1dPadSame-22            [-1, 128, 1024]               0
       Bottleneck-23            [-1, 128, 1024]               0
      BatchNorm1d-24            [-1, 128, 1024]             256
             ReLU-25            [-1, 128, 1024]               0
          Dropout-26            [-1, 128, 1024]               0
           Conv1d-27            [-1, 256, 1024]           2,304
  MyConv1dPadSame-28            [-1, 256, 1024]               0
      BatchNorm1d-29            [-1, 256, 1024]             512
             ReLU-30            [-1, 256, 1024]               0
          Dropout-31            [-1, 256, 1024]               0
           Conv1d-32            [-1, 256, 1024]           4,352
  MyConv1dPadSame-33            [-1, 256, 1024]               0
       Bottleneck-34            [-1, 256, 1024]               0
      BatchNorm1d-35            [-1, 256, 1024]             512
             ReLU-36            [-1, 256, 1024]               0
          Dropout-37            [-1, 256, 1024]               0
           Conv1d-38            [-1, 512, 1024]           8,704
  MyConv1dPadSame-39            [-1, 512, 1024]               0
      BatchNorm1d-40            [-1, 512, 1024]           1,024
             ReLU-41            [-1, 512, 1024]               0
          Dropout-42            [-1, 512, 1024]               0
           Conv1d-43            [-1, 512, 1024]          16,896
  MyConv1dPadSame-44            [-1, 512, 1024]               0
       Bottleneck-45            [-1, 512, 1024]               0
      BatchNorm1d-46            [-1, 512, 1024]           1,024
             ReLU-47            [-1, 512, 1024]               0
           Linear-48                    [-1, 2]           1,026
================================================================
Total params: 40,002
Trainable params: 40,002
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 80.50
Params size (MB): 0.15
Estimated Total Size (MB): 80.66
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 64, kernel_size: 4, n_block: 8
************************************************************
************************************************************
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 64, 1024]             320
   MyConv1dPadSame-2             [-1, 64, 1024]               0
       BatchNorm1d-3             [-1, 64, 1024]             128
              ReLU-4             [-1, 64, 1024]               0
            Conv1d-5             [-1, 64, 1024]             320
   MyConv1dPadSame-6             [-1, 64, 1024]               0
       BatchNorm1d-7             [-1, 64, 1024]             128
              ReLU-8             [-1, 64, 1024]               0
           Dropout-9             [-1, 64, 1024]               0
           Conv1d-10             [-1, 64, 1024]             320
  MyConv1dPadSame-11             [-1, 64, 1024]               0
       Bottleneck-12             [-1, 64, 1024]               0
      BatchNorm1d-13             [-1, 64, 1024]             128
             ReLU-14             [-1, 64, 1024]               0
          Dropout-15             [-1, 64, 1024]               0
           Conv1d-16             [-1, 64, 1024]             320
  MyConv1dPadSame-17             [-1, 64, 1024]               0
      BatchNorm1d-18             [-1, 64, 1024]             128
             ReLU-19             [-1, 64, 1024]               0
          Dropout-20             [-1, 64, 1024]               0
           Conv1d-21             [-1, 64, 1024]             320
  MyConv1dPadSame-22             [-1, 64, 1024]               0
       Bottleneck-23             [-1, 64, 1024]               0
      BatchNorm1d-24             [-1, 64, 1024]             128
             ReLU-25             [-1, 64, 1024]               0
          Dropout-26             [-1, 64, 1024]               0
           Conv1d-27            [-1, 128, 1024]             640
  MyConv1dPadSame-28            [-1, 128, 1024]               0
      BatchNorm1d-29            [-1, 128, 1024]             256
             ReLU-30            [-1, 128, 1024]               0
          Dropout-31            [-1, 128, 1024]               0
           Conv1d-32            [-1, 128, 1024]           1,152
  MyConv1dPadSame-33            [-1, 128, 1024]               0
       Bottleneck-34            [-1, 128, 1024]               0
      BatchNorm1d-35            [-1, 128, 1024]             256
             ReLU-36            [-1, 128, 1024]               0
          Dropout-37            [-1, 128, 1024]               0
           Conv1d-38            [-1, 128, 1024]           1,152
  MyConv1dPadSame-39            [-1, 128, 1024]               0
      BatchNorm1d-40            [-1, 128, 1024]             256
             ReLU-41            [-1, 128, 1024]               0
          Dropout-42            [-1, 128, 1024]               0
           Conv1d-43            [-1, 128, 1024]           1,152
  MyConv1dPadSame-44            [-1, 128, 1024]               0
       Bottleneck-45            [-1, 128, 1024]               0
      BatchNorm1d-46            [-1, 128, 1024]             256
             ReLU-47            [-1, 128, 1024]               0
          Dropout-48            [-1, 128, 1024]               0
           Conv1d-49            [-1, 256, 1024]           2,304
  MyConv1dPadSame-50            [-1, 256, 1024]               0
      BatchNorm1d-51            [-1, 256, 1024]             512
             ReLU-52            [-1, 256, 1024]               0
          Dropout-53            [-1, 256, 1024]               0
           Conv1d-54            [-1, 256, 1024]           4,352
  MyConv1dPadSame-55            [-1, 256, 1024]               0
       Bottleneck-56            [-1, 256, 1024]               0
      BatchNorm1d-57            [-1, 256, 1024]             512
             ReLU-58            [-1, 256, 1024]               0
          Dropout-59            [-1, 256, 1024]               0
           Conv1d-60            [-1, 256, 1024]           4,352
  MyConv1dPadSame-61            [-1, 256, 1024]               0
      BatchNorm1d-62            [-1, 256, 1024]             512
             ReLU-63            [-1, 256, 1024]               0
          Dropout-64            [-1, 256, 1024]               0
           Conv1d-65            [-1, 256, 1024]           4,352
  MyConv1dPadSame-66            [-1, 256, 1024]               0
       Bottleneck-67            [-1, 256, 1024]               0
      BatchNorm1d-68            [-1, 256, 1024]             512
             ReLU-69            [-1, 256, 1024]               0
          Dropout-70            [-1, 256, 1024]               0
           Conv1d-71            [-1, 512, 1024]           8,704
  MyConv1dPadSame-72            [-1, 512, 1024]               0
      BatchNorm1d-73            [-1, 512, 1024]           1,024
             ReLU-74            [-1, 512, 1024]               0
          Dropout-75            [-1, 512, 1024]               0
           Conv1d-76            [-1, 512, 1024]          16,896
  MyConv1dPadSame-77            [-1, 512, 1024]               0
       Bottleneck-78            [-1, 512, 1024]               0
      BatchNorm1d-79            [-1, 512, 1024]           1,024
             ReLU-80            [-1, 512, 1024]               0
          Dropout-81            [-1, 512, 1024]               0
           Conv1d-82            [-1, 512, 1024]          16,896
  MyConv1dPadSame-83            [-1, 512, 1024]               0
      BatchNorm1d-84            [-1, 512, 1024]           1,024
             ReLU-85            [-1, 512, 1024]               0
          Dropout-86            [-1, 512, 1024]               0
           Conv1d-87            [-1, 512, 1024]          16,896
  MyConv1dPadSame-88            [-1, 512, 1024]               0
       Bottleneck-89            [-1, 512, 1024]               0
      BatchNorm1d-90            [-1, 512, 1024]           1,024
             ReLU-91            [-1, 512, 1024]               0
           Linear-92                    [-1, 2]           1,026
================================================================
Total params: 89,282
Trainable params: 89,282
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 163.00
Params size (MB): 0.34
Estimated Total Size (MB): 163.34
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 64, kernel_size: 4, n_block: 16
************************************************************
************************************************************
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 64, 1024]             320
   MyConv1dPadSame-2             [-1, 64, 1024]               0
       BatchNorm1d-3             [-1, 64, 1024]             128
              ReLU-4             [-1, 64, 1024]               0
            Conv1d-5             [-1, 64, 1024]             320
   MyConv1dPadSame-6             [-1, 64, 1024]               0
       BatchNorm1d-7             [-1, 64, 1024]             128
              ReLU-8             [-1, 64, 1024]               0
           Dropout-9             [-1, 64, 1024]               0
           Conv1d-10             [-1, 64, 1024]             320
  MyConv1dPadSame-11             [-1, 64, 1024]               0
       Bottleneck-12             [-1, 64, 1024]               0
      BatchNorm1d-13             [-1, 64, 1024]             128
             ReLU-14             [-1, 64, 1024]               0
          Dropout-15             [-1, 64, 1024]               0
           Conv1d-16              [-1, 64, 512]             320
  MyConv1dPadSame-17              [-1, 64, 512]               0
      BatchNorm1d-18              [-1, 64, 512]             128
             ReLU-19              [-1, 64, 512]               0
          Dropout-20              [-1, 64, 512]               0
           Conv1d-21              [-1, 64, 512]             320
  MyConv1dPadSame-22              [-1, 64, 512]               0
        MaxPool1d-23              [-1, 64, 512]               0
MyMaxPool1dPadSame-24              [-1, 64, 512]               0
       Bottleneck-25              [-1, 64, 512]               0
      BatchNorm1d-26              [-1, 64, 512]             128
             ReLU-27              [-1, 64, 512]               0
          Dropout-28              [-1, 64, 512]               0
           Conv1d-29              [-1, 64, 512]             320
  MyConv1dPadSame-30              [-1, 64, 512]               0
      BatchNorm1d-31              [-1, 64, 512]             128
             ReLU-32              [-1, 64, 512]               0
          Dropout-33              [-1, 64, 512]               0
           Conv1d-34              [-1, 64, 512]             320
  MyConv1dPadSame-35              [-1, 64, 512]               0
       Bottleneck-36              [-1, 64, 512]               0
      BatchNorm1d-37              [-1, 64, 512]             128
             ReLU-38              [-1, 64, 512]               0
          Dropout-39              [-1, 64, 512]               0
           Conv1d-40              [-1, 64, 256]             320
  MyConv1dPadSame-41              [-1, 64, 256]               0
      BatchNorm1d-42              [-1, 64, 256]             128
             ReLU-43              [-1, 64, 256]               0
          Dropout-44              [-1, 64, 256]               0
           Conv1d-45              [-1, 64, 256]             320
  MyConv1dPadSame-46              [-1, 64, 256]               0
        MaxPool1d-47              [-1, 64, 256]               0
MyMaxPool1dPadSame-48              [-1, 64, 256]               0
       Bottleneck-49              [-1, 64, 256]               0
      BatchNorm1d-50              [-1, 64, 256]             128
             ReLU-51              [-1, 64, 256]               0
          Dropout-52              [-1, 64, 256]               0
           Conv1d-53             [-1, 128, 256]             640
  MyConv1dPadSame-54             [-1, 128, 256]               0
      BatchNorm1d-55             [-1, 128, 256]             256
             ReLU-56             [-1, 128, 256]               0
          Dropout-57             [-1, 128, 256]               0
           Conv1d-58             [-1, 128, 256]           1,152
  MyConv1dPadSame-59             [-1, 128, 256]               0
       Bottleneck-60             [-1, 128, 256]               0
      BatchNorm1d-61             [-1, 128, 256]             256
             ReLU-62             [-1, 128, 256]               0
          Dropout-63             [-1, 128, 256]               0
           Conv1d-64             [-1, 128, 128]           1,152
  MyConv1dPadSame-65             [-1, 128, 128]               0
      BatchNorm1d-66             [-1, 128, 128]             256
             ReLU-67             [-1, 128, 128]               0
          Dropout-68             [-1, 128, 128]               0
           Conv1d-69             [-1, 128, 128]           1,152
  MyConv1dPadSame-70             [-1, 128, 128]               0
        MaxPool1d-71             [-1, 128, 128]               0
MyMaxPool1dPadSame-72             [-1, 128, 128]               0
       Bottleneck-73             [-1, 128, 128]               0
      BatchNorm1d-74             [-1, 128, 128]             256
             ReLU-75             [-1, 128, 128]               0
          Dropout-76             [-1, 128, 128]               0
           Conv1d-77             [-1, 128, 128]           1,152
  MyConv1dPadSame-78             [-1, 128, 128]               0
      BatchNorm1d-79             [-1, 128, 128]             256
             ReLU-80             [-1, 128, 128]               0
          Dropout-81             [-1, 128, 128]               0
           Conv1d-82             [-1, 128, 128]           1,152
  MyConv1dPadSame-83             [-1, 128, 128]               0
       Bottleneck-84             [-1, 128, 128]               0
      BatchNorm1d-85             [-1, 128, 128]             256
             ReLU-86             [-1, 128, 128]               0
          Dropout-87             [-1, 128, 128]               0
           Conv1d-88              [-1, 128, 64]           1,152
  MyConv1dPadSame-89              [-1, 128, 64]               0
      BatchNorm1d-90              [-1, 128, 64]             256
             ReLU-91              [-1, 128, 64]               0
          Dropout-92              [-1, 128, 64]               0
           Conv1d-93              [-1, 128, 64]           1,152
  MyConv1dPadSame-94              [-1, 128, 64]               0
        MaxPool1d-95              [-1, 128, 64]               0
MyMaxPool1dPadSame-96              [-1, 128, 64]               0
       Bottleneck-97              [-1, 128, 64]               0
      BatchNorm1d-98              [-1, 128, 64]             256
             ReLU-99              [-1, 128, 64]               0
         Dropout-100              [-1, 128, 64]               0
          Conv1d-101              [-1, 256, 64]           2,304
 MyConv1dPadSame-102              [-1, 256, 64]               0
     BatchNorm1d-103              [-1, 256, 64]             512
            ReLU-104              [-1, 256, 64]               0
         Dropout-105              [-1, 256, 64]               0
          Conv1d-106              [-1, 256, 64]           4,352
 MyConv1dPadSame-107              [-1, 256, 64]               0
      Bottleneck-108              [-1, 256, 64]               0
     BatchNorm1d-109              [-1, 256, 64]             512
            ReLU-110              [-1, 256, 64]               0
         Dropout-111              [-1, 256, 64]               0
          Conv1d-112              [-1, 256, 32]           4,352
 MyConv1dPadSame-113              [-1, 256, 32]               0
     BatchNorm1d-114              [-1, 256, 32]             512
            ReLU-115              [-1, 256, 32]               0
         Dropout-116              [-1, 256, 32]               0
          Conv1d-117              [-1, 256, 32]           4,352
 MyConv1dPadSame-118              [-1, 256, 32]               0
       MaxPool1d-119              [-1, 256, 32]               0
MyMaxPool1dPadSame-120              [-1, 256, 32]               0
      Bottleneck-121              [-1, 256, 32]               0
     BatchNorm1d-122              [-1, 256, 32]             512
            ReLU-123              [-1, 256, 32]               0
         Dropout-124              [-1, 256, 32]               0
          Conv1d-125              [-1, 256, 32]           4,352
 MyConv1dPadSame-126              [-1, 256, 32]               0
     BatchNorm1d-127              [-1, 256, 32]             512
            ReLU-128              [-1, 256, 32]               0
         Dropout-129              [-1, 256, 32]               0
          Conv1d-130              [-1, 256, 32]           4,352
 MyConv1dPadSame-131              [-1, 256, 32]               0
      Bottleneck-132              [-1, 256, 32]               0
     BatchNorm1d-133              [-1, 256, 32]             512
            ReLU-134              [-1, 256, 32]               0
         Dropout-135              [-1, 256, 32]               0
          Conv1d-136              [-1, 256, 16]           4,352
 MyConv1dPadSame-137              [-1, 256, 16]               0
     BatchNorm1d-138              [-1, 256, 16]             512
            ReLU-139              [-1, 256, 16]               0
         Dropout-140              [-1, 256, 16]               0
          Conv1d-141              [-1, 256, 16]           4,352
 MyConv1dPadSame-142              [-1, 256, 16]               0
       MaxPool1d-143              [-1, 256, 16]               0
MyMaxPool1dPadSame-144              [-1, 256, 16]               0
      Bottleneck-145              [-1, 256, 16]               0
     BatchNorm1d-146              [-1, 256, 16]             512
            ReLU-147              [-1, 256, 16]               0
         Dropout-148              [-1, 256, 16]               0
          Conv1d-149              [-1, 512, 16]           8,704
 MyConv1dPadSame-150              [-1, 512, 16]               0
     BatchNorm1d-151              [-1, 512, 16]           1,024
            ReLU-152              [-1, 512, 16]               0
         Dropout-153              [-1, 512, 16]               0
          Conv1d-154              [-1, 512, 16]          16,896
 MyConv1dPadSame-155              [-1, 512, 16]               0
      Bottleneck-156              [-1, 512, 16]               0
     BatchNorm1d-157              [-1, 512, 16]           1,024
            ReLU-158              [-1, 512, 16]               0
         Dropout-159              [-1, 512, 16]               0
          Conv1d-160               [-1, 512, 8]          16,896
 MyConv1dPadSame-161               [-1, 512, 8]               0
     BatchNorm1d-162               [-1, 512, 8]           1,024
            ReLU-163               [-1, 512, 8]               0
         Dropout-164               [-1, 512, 8]               0
          Conv1d-165               [-1, 512, 8]          16,896
 MyConv1dPadSame-166               [-1, 512, 8]               0
       MaxPool1d-167               [-1, 512, 8]               0
MyMaxPool1dPadSame-168               [-1, 512, 8]               0
      Bottleneck-169               [-1, 512, 8]               0
     BatchNorm1d-170               [-1, 512, 8]           1,024
            ReLU-171               [-1, 512, 8]               0
         Dropout-172               [-1, 512, 8]               0
          Conv1d-173               [-1, 512, 8]          16,896
 MyConv1dPadSame-174               [-1, 512, 8]               0
     BatchNorm1d-175               [-1, 512, 8]           1,024
            ReLU-176               [-1, 512, 8]               0
         Dropout-177               [-1, 512, 8]               0
          Conv1d-178               [-1, 512, 8]          16,896
 MyConv1dPadSame-179               [-1, 512, 8]               0
      Bottleneck-180               [-1, 512, 8]               0
     BatchNorm1d-181               [-1, 512, 8]           1,024
            ReLU-182               [-1, 512, 8]               0
         Dropout-183               [-1, 512, 8]               0
          Conv1d-184               [-1, 512, 4]          16,896
 MyConv1dPadSame-185               [-1, 512, 4]               0
     BatchNorm1d-186               [-1, 512, 4]           1,024
            ReLU-187               [-1, 512, 4]               0
         Dropout-188               [-1, 512, 4]               0
          Conv1d-189               [-1, 512, 4]          16,896
 MyConv1dPadSame-190               [-1, 512, 4]               0
       MaxPool1d-191               [-1, 512, 4]               0
MyMaxPool1dPadSame-192               [-1, 512, 4]               0
      Bottleneck-193               [-1, 512, 4]               0
     BatchNorm1d-194               [-1, 512, 4]           1,024
            ReLU-195               [-1, 512, 4]               0
          Linear-196                    [-1, 2]           1,026
================================================================
Total params: 187,842
Trainable params: 187,842
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 26.59
Params size (MB): 0.72
Estimated Total Size (MB): 27.31
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 64, kernel_size: 8, n_block: 2
************************************************************
************************************************************
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 64, 1024]             576
   MyConv1dPadSame-2             [-1, 64, 1024]               0
       BatchNorm1d-3             [-1, 64, 1024]             128
              ReLU-4             [-1, 64, 1024]               0
            Conv1d-5             [-1, 64, 1024]             576
   MyConv1dPadSame-6             [-1, 64, 1024]               0
       BatchNorm1d-7             [-1, 64, 1024]             128
              ReLU-8             [-1, 64, 1024]               0
           Dropout-9             [-1, 64, 1024]               0
           Conv1d-10             [-1, 64, 1024]             576
  MyConv1dPadSame-11             [-1, 64, 1024]               0
       Bottleneck-12             [-1, 64, 1024]               0
      BatchNorm1d-13             [-1, 64, 1024]             128
             ReLU-14             [-1, 64, 1024]               0
          Dropout-15             [-1, 64, 1024]               0
           Conv1d-16            [-1, 128, 1024]           1,152
  MyConv1dPadSame-17            [-1, 128, 1024]               0
      BatchNorm1d-18            [-1, 128, 1024]             256
             ReLU-19            [-1, 128, 1024]               0
          Dropout-20            [-1, 128, 1024]               0
           Conv1d-21            [-1, 128, 1024]           2,176
  MyConv1dPadSame-22            [-1, 128, 1024]               0
       Bottleneck-23            [-1, 128, 1024]               0
      BatchNorm1d-24            [-1, 128, 1024]             256
             ReLU-25            [-1, 128, 1024]               0
           Linear-26                    [-1, 2]             258
================================================================
Total params: 6,210
Trainable params: 6,210
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 17.50
Params size (MB): 0.02
Estimated Total Size (MB): 17.53
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 64, kernel_size: 8, n_block: 4
************************************************************
************************************************************
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 64, 1024]             576
   MyConv1dPadSame-2             [-1, 64, 1024]               0
       BatchNorm1d-3             [-1, 64, 1024]             128
              ReLU-4             [-1, 64, 1024]               0
            Conv1d-5             [-1, 64, 1024]             576
   MyConv1dPadSame-6             [-1, 64, 1024]               0
       BatchNorm1d-7             [-1, 64, 1024]             128
              ReLU-8             [-1, 64, 1024]               0
           Dropout-9             [-1, 64, 1024]               0
           Conv1d-10             [-1, 64, 1024]             576
  MyConv1dPadSame-11             [-1, 64, 1024]               0
       Bottleneck-12             [-1, 64, 1024]               0
      BatchNorm1d-13             [-1, 64, 1024]             128
             ReLU-14             [-1, 64, 1024]               0
          Dropout-15             [-1, 64, 1024]               0
           Conv1d-16            [-1, 128, 1024]           1,152
  MyConv1dPadSame-17            [-1, 128, 1024]               0
      BatchNorm1d-18            [-1, 128, 1024]             256
             ReLU-19            [-1, 128, 1024]               0
          Dropout-20            [-1, 128, 1024]               0
           Conv1d-21            [-1, 128, 1024]           2,176
  MyConv1dPadSame-22            [-1, 128, 1024]               0
       Bottleneck-23            [-1, 128, 1024]               0
      BatchNorm1d-24            [-1, 128, 1024]             256
             ReLU-25            [-1, 128, 1024]               0
          Dropout-26            [-1, 128, 1024]               0
           Conv1d-27            [-1, 256, 1024]           4,352
  MyConv1dPadSame-28            [-1, 256, 1024]               0
      BatchNorm1d-29            [-1, 256, 1024]             512
             ReLU-30            [-1, 256, 1024]               0
          Dropout-31            [-1, 256, 1024]               0
           Conv1d-32            [-1, 256, 1024]           8,448
  MyConv1dPadSame-33            [-1, 256, 1024]               0
       Bottleneck-34            [-1, 256, 1024]               0
      BatchNorm1d-35            [-1, 256, 1024]             512
             ReLU-36            [-1, 256, 1024]               0
          Dropout-37            [-1, 256, 1024]               0
           Conv1d-38            [-1, 512, 1024]          16,896
  MyConv1dPadSame-39            [-1, 512, 1024]               0
      BatchNorm1d-40            [-1, 512, 1024]           1,024
             ReLU-41            [-1, 512, 1024]               0
          Dropout-42            [-1, 512, 1024]               0
           Conv1d-43            [-1, 512, 1024]          33,280
  MyConv1dPadSame-44            [-1, 512, 1024]               0
       Bottleneck-45            [-1, 512, 1024]               0
      BatchNorm1d-46            [-1, 512, 1024]           1,024
             ReLU-47            [-1, 512, 1024]               0
           Linear-48                    [-1, 2]           1,026
================================================================
Total params: 73,026
Trainable params: 73,026
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 80.50
Params size (MB): 0.28
Estimated Total Size (MB): 80.78
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 64, kernel_size: 8, n_block: 8
************************************************************
************************************************************
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 64, 1024]             576
   MyConv1dPadSame-2             [-1, 64, 1024]               0
       BatchNorm1d-3             [-1, 64, 1024]             128
              ReLU-4             [-1, 64, 1024]               0
            Conv1d-5             [-1, 64, 1024]             576
   MyConv1dPadSame-6             [-1, 64, 1024]               0
       BatchNorm1d-7             [-1, 64, 1024]             128
              ReLU-8             [-1, 64, 1024]               0
           Dropout-9             [-1, 64, 1024]               0
           Conv1d-10             [-1, 64, 1024]             576
  MyConv1dPadSame-11             [-1, 64, 1024]               0
       Bottleneck-12             [-1, 64, 1024]               0
      BatchNorm1d-13             [-1, 64, 1024]             128
             ReLU-14             [-1, 64, 1024]               0
          Dropout-15             [-1, 64, 1024]               0
           Conv1d-16             [-1, 64, 1024]             576
  MyConv1dPadSame-17             [-1, 64, 1024]               0
      BatchNorm1d-18             [-1, 64, 1024]             128
             ReLU-19             [-1, 64, 1024]               0
          Dropout-20             [-1, 64, 1024]               0
           Conv1d-21             [-1, 64, 1024]             576
  MyConv1dPadSame-22             [-1, 64, 1024]               0
       Bottleneck-23             [-1, 64, 1024]               0
      BatchNorm1d-24             [-1, 64, 1024]             128
             ReLU-25             [-1, 64, 1024]               0
          Dropout-26             [-1, 64, 1024]               0
           Conv1d-27            [-1, 128, 1024]           1,152
  MyConv1dPadSame-28            [-1, 128, 1024]               0
      BatchNorm1d-29            [-1, 128, 1024]             256
             ReLU-30            [-1, 128, 1024]               0
          Dropout-31            [-1, 128, 1024]               0
           Conv1d-32            [-1, 128, 1024]           2,176
  MyConv1dPadSame-33            [-1, 128, 1024]               0
       Bottleneck-34            [-1, 128, 1024]               0
      BatchNorm1d-35            [-1, 128, 1024]             256
             ReLU-36            [-1, 128, 1024]               0
          Dropout-37            [-1, 128, 1024]               0
           Conv1d-38            [-1, 128, 1024]           2,176
  MyConv1dPadSame-39            [-1, 128, 1024]               0
      BatchNorm1d-40            [-1, 128, 1024]             256
             ReLU-41            [-1, 128, 1024]               0
          Dropout-42            [-1, 128, 1024]               0
           Conv1d-43            [-1, 128, 1024]           2,176
  MyConv1dPadSame-44            [-1, 128, 1024]               0
       Bottleneck-45            [-1, 128, 1024]               0
      BatchNorm1d-46            [-1, 128, 1024]             256
             ReLU-47            [-1, 128, 1024]               0
          Dropout-48            [-1, 128, 1024]               0
           Conv1d-49            [-1, 256, 1024]           4,352
  MyConv1dPadSame-50            [-1, 256, 1024]               0
      BatchNorm1d-51            [-1, 256, 1024]             512
             ReLU-52            [-1, 256, 1024]               0
          Dropout-53            [-1, 256, 1024]               0
           Conv1d-54            [-1, 256, 1024]           8,448
  MyConv1dPadSame-55            [-1, 256, 1024]               0
       Bottleneck-56            [-1, 256, 1024]               0
      BatchNorm1d-57            [-1, 256, 1024]             512
             ReLU-58            [-1, 256, 1024]               0
          Dropout-59            [-1, 256, 1024]               0
           Conv1d-60            [-1, 256, 1024]           8,448
  MyConv1dPadSame-61            [-1, 256, 1024]               0
      BatchNorm1d-62            [-1, 256, 1024]             512
             ReLU-63            [-1, 256, 1024]               0
          Dropout-64            [-1, 256, 1024]               0
           Conv1d-65            [-1, 256, 1024]           8,448
  MyConv1dPadSame-66            [-1, 256, 1024]               0
       Bottleneck-67            [-1, 256, 1024]               0
      BatchNorm1d-68            [-1, 256, 1024]             512
             ReLU-69            [-1, 256, 1024]               0
          Dropout-70            [-1, 256, 1024]               0
           Conv1d-71            [-1, 512, 1024]          16,896
  MyConv1dPadSame-72            [-1, 512, 1024]               0
      BatchNorm1d-73            [-1, 512, 1024]           1,024
             ReLU-74            [-1, 512, 1024]               0
          Dropout-75            [-1, 512, 1024]               0
           Conv1d-76            [-1, 512, 1024]          33,280
  MyConv1dPadSame-77            [-1, 512, 1024]               0
       Bottleneck-78            [-1, 512, 1024]               0
      BatchNorm1d-79            [-1, 512, 1024]           1,024
             ReLU-80            [-1, 512, 1024]               0
          Dropout-81            [-1, 512, 1024]               0
           Conv1d-82            [-1, 512, 1024]          33,280
  MyConv1dPadSame-83            [-1, 512, 1024]               0
      BatchNorm1d-84            [-1, 512, 1024]           1,024
             ReLU-85            [-1, 512, 1024]               0
          Dropout-86            [-1, 512, 1024]               0
           Conv1d-87            [-1, 512, 1024]          33,280
  MyConv1dPadSame-88            [-1, 512, 1024]               0
       Bottleneck-89            [-1, 512, 1024]               0
      BatchNorm1d-90            [-1, 512, 1024]           1,024
             ReLU-91            [-1, 512, 1024]               0
           Linear-92                    [-1, 2]           1,026
================================================================
Total params: 165,826
Trainable params: 165,826
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 163.00
Params size (MB): 0.63
Estimated Total Size (MB): 163.64
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 64, kernel_size: 8, n_block: 16
************************************************************
************************************************************
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 64, 1024]             576
   MyConv1dPadSame-2             [-1, 64, 1024]               0
       BatchNorm1d-3             [-1, 64, 1024]             128
              ReLU-4             [-1, 64, 1024]               0
            Conv1d-5             [-1, 64, 1024]             576
   MyConv1dPadSame-6             [-1, 64, 1024]               0
       BatchNorm1d-7             [-1, 64, 1024]             128
              ReLU-8             [-1, 64, 1024]               0
           Dropout-9             [-1, 64, 1024]               0
           Conv1d-10             [-1, 64, 1024]             576
  MyConv1dPadSame-11             [-1, 64, 1024]               0
       Bottleneck-12             [-1, 64, 1024]               0
      BatchNorm1d-13             [-1, 64, 1024]             128
             ReLU-14             [-1, 64, 1024]               0
          Dropout-15             [-1, 64, 1024]               0
           Conv1d-16              [-1, 64, 512]             576
  MyConv1dPadSame-17              [-1, 64, 512]               0
      BatchNorm1d-18              [-1, 64, 512]             128
             ReLU-19              [-1, 64, 512]               0
          Dropout-20              [-1, 64, 512]               0
           Conv1d-21              [-1, 64, 512]             576
  MyConv1dPadSame-22              [-1, 64, 512]               0
        MaxPool1d-23              [-1, 64, 512]               0
MyMaxPool1dPadSame-24              [-1, 64, 512]               0
       Bottleneck-25              [-1, 64, 512]               0
      BatchNorm1d-26              [-1, 64, 512]             128
             ReLU-27              [-1, 64, 512]               0
          Dropout-28              [-1, 64, 512]               0
           Conv1d-29              [-1, 64, 512]             576
  MyConv1dPadSame-30              [-1, 64, 512]               0
      BatchNorm1d-31              [-1, 64, 512]             128
             ReLU-32              [-1, 64, 512]               0
          Dropout-33              [-1, 64, 512]               0
           Conv1d-34              [-1, 64, 512]             576
  MyConv1dPadSame-35              [-1, 64, 512]               0
       Bottleneck-36              [-1, 64, 512]               0
      BatchNorm1d-37              [-1, 64, 512]             128
             ReLU-38              [-1, 64, 512]               0
          Dropout-39              [-1, 64, 512]               0
           Conv1d-40              [-1, 64, 256]             576
  MyConv1dPadSame-41              [-1, 64, 256]               0
      BatchNorm1d-42              [-1, 64, 256]             128
             ReLU-43              [-1, 64, 256]               0
          Dropout-44              [-1, 64, 256]               0
           Conv1d-45              [-1, 64, 256]             576
  MyConv1dPadSame-46              [-1, 64, 256]               0
        MaxPool1d-47              [-1, 64, 256]               0
MyMaxPool1dPadSame-48              [-1, 64, 256]               0
       Bottleneck-49              [-1, 64, 256]               0
      BatchNorm1d-50              [-1, 64, 256]             128
             ReLU-51              [-1, 64, 256]               0
          Dropout-52              [-1, 64, 256]               0
           Conv1d-53             [-1, 128, 256]           1,152
  MyConv1dPadSame-54             [-1, 128, 256]               0
      BatchNorm1d-55             [-1, 128, 256]             256
             ReLU-56             [-1, 128, 256]               0
          Dropout-57             [-1, 128, 256]               0
           Conv1d-58             [-1, 128, 256]           2,176
  MyConv1dPadSame-59             [-1, 128, 256]               0
       Bottleneck-60             [-1, 128, 256]               0
      BatchNorm1d-61             [-1, 128, 256]             256
             ReLU-62             [-1, 128, 256]               0
          Dropout-63             [-1, 128, 256]               0
           Conv1d-64             [-1, 128, 128]           2,176
  MyConv1dPadSame-65             [-1, 128, 128]               0
      BatchNorm1d-66             [-1, 128, 128]             256
             ReLU-67             [-1, 128, 128]               0
          Dropout-68             [-1, 128, 128]               0
           Conv1d-69             [-1, 128, 128]           2,176
  MyConv1dPadSame-70             [-1, 128, 128]               0
        MaxPool1d-71             [-1, 128, 128]               0
MyMaxPool1dPadSame-72             [-1, 128, 128]               0
       Bottleneck-73             [-1, 128, 128]               0
      BatchNorm1d-74             [-1, 128, 128]             256
             ReLU-75             [-1, 128, 128]               0
          Dropout-76             [-1, 128, 128]               0
           Conv1d-77             [-1, 128, 128]           2,176
  MyConv1dPadSame-78             [-1, 128, 128]               0
      BatchNorm1d-79             [-1, 128, 128]             256
             ReLU-80             [-1, 128, 128]               0
          Dropout-81             [-1, 128, 128]               0
           Conv1d-82             [-1, 128, 128]           2,176
  MyConv1dPadSame-83             [-1, 128, 128]               0
       Bottleneck-84             [-1, 128, 128]               0
      BatchNorm1d-85             [-1, 128, 128]             256
             ReLU-86             [-1, 128, 128]               0
          Dropout-87             [-1, 128, 128]               0
           Conv1d-88              [-1, 128, 64]           2,176
  MyConv1dPadSame-89              [-1, 128, 64]               0
      BatchNorm1d-90              [-1, 128, 64]             256
             ReLU-91              [-1, 128, 64]               0
          Dropout-92              [-1, 128, 64]               0
           Conv1d-93              [-1, 128, 64]           2,176
  MyConv1dPadSame-94              [-1, 128, 64]               0
        MaxPool1d-95              [-1, 128, 64]               0
MyMaxPool1dPadSame-96              [-1, 128, 64]               0
       Bottleneck-97              [-1, 128, 64]               0
      BatchNorm1d-98              [-1, 128, 64]             256
             ReLU-99              [-1, 128, 64]               0
         Dropout-100              [-1, 128, 64]               0
          Conv1d-101              [-1, 256, 64]           4,352
 MyConv1dPadSame-102              [-1, 256, 64]               0
     BatchNorm1d-103              [-1, 256, 64]             512
            ReLU-104              [-1, 256, 64]               0
         Dropout-105              [-1, 256, 64]               0
          Conv1d-106              [-1, 256, 64]           8,448
 MyConv1dPadSame-107              [-1, 256, 64]               0
      Bottleneck-108              [-1, 256, 64]               0
     BatchNorm1d-109              [-1, 256, 64]             512
            ReLU-110              [-1, 256, 64]               0
         Dropout-111              [-1, 256, 64]               0
          Conv1d-112              [-1, 256, 32]           8,448
 MyConv1dPadSame-113              [-1, 256, 32]               0
     BatchNorm1d-114              [-1, 256, 32]             512
            ReLU-115              [-1, 256, 32]               0
         Dropout-116              [-1, 256, 32]               0
          Conv1d-117              [-1, 256, 32]           8,448
 MyConv1dPadSame-118              [-1, 256, 32]               0
       MaxPool1d-119              [-1, 256, 32]               0
MyMaxPool1dPadSame-120              [-1, 256, 32]               0
      Bottleneck-121              [-1, 256, 32]               0
     BatchNorm1d-122              [-1, 256, 32]             512
            ReLU-123              [-1, 256, 32]               0
         Dropout-124              [-1, 256, 32]               0
          Conv1d-125              [-1, 256, 32]           8,448
 MyConv1dPadSame-126              [-1, 256, 32]               0
     BatchNorm1d-127              [-1, 256, 32]             512
            ReLU-128              [-1, 256, 32]               0
         Dropout-129              [-1, 256, 32]               0
          Conv1d-130              [-1, 256, 32]           8,448
 MyConv1dPadSame-131              [-1, 256, 32]               0
      Bottleneck-132              [-1, 256, 32]               0
     BatchNorm1d-133              [-1, 256, 32]             512
            ReLU-134              [-1, 256, 32]               0
         Dropout-135              [-1, 256, 32]               0
          Conv1d-136              [-1, 256, 16]           8,448
 MyConv1dPadSame-137              [-1, 256, 16]               0
     BatchNorm1d-138              [-1, 256, 16]             512
            ReLU-139              [-1, 256, 16]               0
         Dropout-140              [-1, 256, 16]               0
          Conv1d-141              [-1, 256, 16]           8,448
 MyConv1dPadSame-142              [-1, 256, 16]               0
       MaxPool1d-143              [-1, 256, 16]               0
MyMaxPool1dPadSame-144              [-1, 256, 16]               0
      Bottleneck-145              [-1, 256, 16]               0
     BatchNorm1d-146              [-1, 256, 16]             512
            ReLU-147              [-1, 256, 16]               0
         Dropout-148              [-1, 256, 16]               0
          Conv1d-149              [-1, 512, 16]          16,896
 MyConv1dPadSame-150              [-1, 512, 16]               0
     BatchNorm1d-151              [-1, 512, 16]           1,024
            ReLU-152              [-1, 512, 16]               0
         Dropout-153              [-1, 512, 16]               0
          Conv1d-154              [-1, 512, 16]          33,280
 MyConv1dPadSame-155              [-1, 512, 16]               0
      Bottleneck-156              [-1, 512, 16]               0
     BatchNorm1d-157              [-1, 512, 16]           1,024
            ReLU-158              [-1, 512, 16]               0
         Dropout-159              [-1, 512, 16]               0
          Conv1d-160               [-1, 512, 8]          33,280
 MyConv1dPadSame-161               [-1, 512, 8]               0
     BatchNorm1d-162               [-1, 512, 8]           1,024
            ReLU-163               [-1, 512, 8]               0
         Dropout-164               [-1, 512, 8]               0
          Conv1d-165               [-1, 512, 8]          33,280
 MyConv1dPadSame-166               [-1, 512, 8]               0
       MaxPool1d-167               [-1, 512, 8]               0
MyMaxPool1dPadSame-168               [-1, 512, 8]               0
      Bottleneck-169               [-1, 512, 8]               0
     BatchNorm1d-170               [-1, 512, 8]           1,024
            ReLU-171               [-1, 512, 8]               0
         Dropout-172               [-1, 512, 8]               0
          Conv1d-173               [-1, 512, 8]          33,280
 MyConv1dPadSame-174               [-1, 512, 8]               0
     BatchNorm1d-175               [-1, 512, 8]           1,024
            ReLU-176               [-1, 512, 8]               0
         Dropout-177               [-1, 512, 8]               0
          Conv1d-178               [-1, 512, 8]          33,280
 MyConv1dPadSame-179               [-1, 512, 8]               0
      Bottleneck-180               [-1, 512, 8]               0
     BatchNorm1d-181               [-1, 512, 8]           1,024
            ReLU-182               [-1, 512, 8]               0
         Dropout-183               [-1, 512, 8]               0
          Conv1d-184               [-1, 512, 4]          33,280
 MyConv1dPadSame-185               [-1, 512, 4]               0
     BatchNorm1d-186               [-1, 512, 4]           1,024
            ReLU-187               [-1, 512, 4]               0
         Dropout-188               [-1, 512, 4]               0
          Conv1d-189               [-1, 512, 4]          33,280
 MyConv1dPadSame-190               [-1, 512, 4]               0
       MaxPool1d-191               [-1, 512, 4]               0
MyMaxPool1dPadSame-192               [-1, 512, 4]               0
      Bottleneck-193               [-1, 512, 4]               0
     BatchNorm1d-194               [-1, 512, 4]           1,024
            ReLU-195               [-1, 512, 4]               0
          Linear-196                    [-1, 2]           1,026
================================================================
Total params: 351,426
Trainable params: 351,426
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 26.59
Params size (MB): 1.34
Estimated Total Size (MB): 27.94
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 64, kernel_size: 16, n_block: 2
************************************************************
************************************************************
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 64, 1024]           1,088
   MyConv1dPadSame-2             [-1, 64, 1024]               0
       BatchNorm1d-3             [-1, 64, 1024]             128
              ReLU-4             [-1, 64, 1024]               0
            Conv1d-5             [-1, 64, 1024]           1,088
   MyConv1dPadSame-6             [-1, 64, 1024]               0
       BatchNorm1d-7             [-1, 64, 1024]             128
              ReLU-8             [-1, 64, 1024]               0
           Dropout-9             [-1, 64, 1024]               0
           Conv1d-10             [-1, 64, 1024]           1,088
  MyConv1dPadSame-11             [-1, 64, 1024]               0
       Bottleneck-12             [-1, 64, 1024]               0
      BatchNorm1d-13             [-1, 64, 1024]             128
             ReLU-14             [-1, 64, 1024]               0
          Dropout-15             [-1, 64, 1024]               0
           Conv1d-16            [-1, 128, 1024]           2,176
  MyConv1dPadSame-17            [-1, 128, 1024]               0
      BatchNorm1d-18            [-1, 128, 1024]             256
             ReLU-19            [-1, 128, 1024]               0
          Dropout-20            [-1, 128, 1024]               0
           Conv1d-21            [-1, 128, 1024]           4,224
  MyConv1dPadSame-22            [-1, 128, 1024]               0
       Bottleneck-23            [-1, 128, 1024]               0
      BatchNorm1d-24            [-1, 128, 1024]             256
             ReLU-25            [-1, 128, 1024]               0
           Linear-26                    [-1, 2]             258
================================================================
Total params: 10,818
Trainable params: 10,818
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 17.50
Params size (MB): 0.04
Estimated Total Size (MB): 17.55
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 64, kernel_size: 16, n_block: 4
************************************************************
************************************************************
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 64, 1024]           1,088
   MyConv1dPadSame-2             [-1, 64, 1024]               0
       BatchNorm1d-3             [-1, 64, 1024]             128
              ReLU-4             [-1, 64, 1024]               0
            Conv1d-5             [-1, 64, 1024]           1,088
   MyConv1dPadSame-6             [-1, 64, 1024]               0
       BatchNorm1d-7             [-1, 64, 1024]             128
              ReLU-8             [-1, 64, 1024]               0
           Dropout-9             [-1, 64, 1024]               0
           Conv1d-10             [-1, 64, 1024]           1,088
  MyConv1dPadSame-11             [-1, 64, 1024]               0
       Bottleneck-12             [-1, 64, 1024]               0
      BatchNorm1d-13             [-1, 64, 1024]             128
             ReLU-14             [-1, 64, 1024]               0
          Dropout-15             [-1, 64, 1024]               0
           Conv1d-16            [-1, 128, 1024]           2,176
  MyConv1dPadSame-17            [-1, 128, 1024]               0
      BatchNorm1d-18            [-1, 128, 1024]             256
             ReLU-19            [-1, 128, 1024]               0
          Dropout-20            [-1, 128, 1024]               0
           Conv1d-21            [-1, 128, 1024]           4,224
  MyConv1dPadSame-22            [-1, 128, 1024]               0
       Bottleneck-23            [-1, 128, 1024]               0
      BatchNorm1d-24            [-1, 128, 1024]             256
             ReLU-25            [-1, 128, 1024]               0
          Dropout-26            [-1, 128, 1024]               0
           Conv1d-27            [-1, 256, 1024]           8,448
  MyConv1dPadSame-28            [-1, 256, 1024]               0
      BatchNorm1d-29            [-1, 256, 1024]             512
             ReLU-30            [-1, 256, 1024]               0
          Dropout-31            [-1, 256, 1024]               0
           Conv1d-32            [-1, 256, 1024]          16,640
  MyConv1dPadSame-33            [-1, 256, 1024]               0
       Bottleneck-34            [-1, 256, 1024]               0
      BatchNorm1d-35            [-1, 256, 1024]             512
             ReLU-36            [-1, 256, 1024]               0
          Dropout-37            [-1, 256, 1024]               0
           Conv1d-38            [-1, 512, 1024]          33,280
  MyConv1dPadSame-39            [-1, 512, 1024]               0
      BatchNorm1d-40            [-1, 512, 1024]           1,024
             ReLU-41            [-1, 512, 1024]               0
          Dropout-42            [-1, 512, 1024]               0
           Conv1d-43            [-1, 512, 1024]          66,048
  MyConv1dPadSame-44            [-1, 512, 1024]               0
       Bottleneck-45            [-1, 512, 1024]               0
      BatchNorm1d-46            [-1, 512, 1024]           1,024
             ReLU-47            [-1, 512, 1024]               0
           Linear-48                    [-1, 2]           1,026
================================================================
Total params: 139,074
Trainable params: 139,074
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 80.50
Params size (MB): 0.53
Estimated Total Size (MB): 81.03
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 64, kernel_size: 16, n_block: 8
************************************************************
************************************************************
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 64, 1024]           1,088
   MyConv1dPadSame-2             [-1, 64, 1024]               0
       BatchNorm1d-3             [-1, 64, 1024]             128
              ReLU-4             [-1, 64, 1024]               0
            Conv1d-5             [-1, 64, 1024]           1,088
   MyConv1dPadSame-6             [-1, 64, 1024]               0
       BatchNorm1d-7             [-1, 64, 1024]             128
              ReLU-8             [-1, 64, 1024]               0
           Dropout-9             [-1, 64, 1024]               0
           Conv1d-10             [-1, 64, 1024]           1,088
  MyConv1dPadSame-11             [-1, 64, 1024]               0
       Bottleneck-12             [-1, 64, 1024]               0
      BatchNorm1d-13             [-1, 64, 1024]             128
             ReLU-14             [-1, 64, 1024]               0
          Dropout-15             [-1, 64, 1024]               0
           Conv1d-16             [-1, 64, 1024]           1,088
  MyConv1dPadSame-17             [-1, 64, 1024]               0
      BatchNorm1d-18             [-1, 64, 1024]             128
             ReLU-19             [-1, 64, 1024]               0
          Dropout-20             [-1, 64, 1024]               0
           Conv1d-21             [-1, 64, 1024]           1,088
  MyConv1dPadSame-22             [-1, 64, 1024]               0
       Bottleneck-23             [-1, 64, 1024]               0
      BatchNorm1d-24             [-1, 64, 1024]             128
             ReLU-25             [-1, 64, 1024]               0
          Dropout-26             [-1, 64, 1024]               0
           Conv1d-27            [-1, 128, 1024]           2,176
  MyConv1dPadSame-28            [-1, 128, 1024]               0
      BatchNorm1d-29            [-1, 128, 1024]             256
             ReLU-30            [-1, 128, 1024]               0
          Dropout-31            [-1, 128, 1024]               0
           Conv1d-32            [-1, 128, 1024]           4,224
  MyConv1dPadSame-33            [-1, 128, 1024]               0
       Bottleneck-34            [-1, 128, 1024]               0
      BatchNorm1d-35            [-1, 128, 1024]             256
             ReLU-36            [-1, 128, 1024]               0
          Dropout-37            [-1, 128, 1024]               0
           Conv1d-38            [-1, 128, 1024]           4,224
  MyConv1dPadSame-39            [-1, 128, 1024]               0
      BatchNorm1d-40            [-1, 128, 1024]             256
             ReLU-41            [-1, 128, 1024]               0
          Dropout-42            [-1, 128, 1024]               0
           Conv1d-43            [-1, 128, 1024]           4,224
  MyConv1dPadSame-44            [-1, 128, 1024]               0
       Bottleneck-45            [-1, 128, 1024]               0
      BatchNorm1d-46            [-1, 128, 1024]             256
             ReLU-47            [-1, 128, 1024]               0
          Dropout-48            [-1, 128, 1024]               0
           Conv1d-49            [-1, 256, 1024]           8,448
  MyConv1dPadSame-50            [-1, 256, 1024]               0
      BatchNorm1d-51            [-1, 256, 1024]             512
             ReLU-52            [-1, 256, 1024]               0
          Dropout-53            [-1, 256, 1024]               0
           Conv1d-54            [-1, 256, 1024]          16,640
  MyConv1dPadSame-55            [-1, 256, 1024]               0
       Bottleneck-56            [-1, 256, 1024]               0
      BatchNorm1d-57            [-1, 256, 1024]             512
             ReLU-58            [-1, 256, 1024]               0
          Dropout-59            [-1, 256, 1024]               0
           Conv1d-60            [-1, 256, 1024]          16,640
  MyConv1dPadSame-61            [-1, 256, 1024]               0
      BatchNorm1d-62            [-1, 256, 1024]             512
             ReLU-63            [-1, 256, 1024]               0
          Dropout-64            [-1, 256, 1024]               0
           Conv1d-65            [-1, 256, 1024]          16,640
  MyConv1dPadSame-66            [-1, 256, 1024]               0
       Bottleneck-67            [-1, 256, 1024]               0
      BatchNorm1d-68            [-1, 256, 1024]             512
             ReLU-69            [-1, 256, 1024]               0
          Dropout-70            [-1, 256, 1024]               0
           Conv1d-71            [-1, 512, 1024]          33,280
  MyConv1dPadSame-72            [-1, 512, 1024]               0
      BatchNorm1d-73            [-1, 512, 1024]           1,024
             ReLU-74            [-1, 512, 1024]               0
          Dropout-75            [-1, 512, 1024]               0
           Conv1d-76            [-1, 512, 1024]          66,048
  MyConv1dPadSame-77            [-1, 512, 1024]               0
       Bottleneck-78            [-1, 512, 1024]               0
      BatchNorm1d-79            [-1, 512, 1024]           1,024
             ReLU-80            [-1, 512, 1024]               0
          Dropout-81            [-1, 512, 1024]               0
           Conv1d-82            [-1, 512, 1024]          66,048
  MyConv1dPadSame-83            [-1, 512, 1024]               0
      BatchNorm1d-84            [-1, 512, 1024]           1,024
             ReLU-85            [-1, 512, 1024]               0
          Dropout-86            [-1, 512, 1024]               0
           Conv1d-87            [-1, 512, 1024]          66,048
  MyConv1dPadSame-88            [-1, 512, 1024]               0
       Bottleneck-89            [-1, 512, 1024]               0
      BatchNorm1d-90            [-1, 512, 1024]           1,024
             ReLU-91            [-1, 512, 1024]               0
           Linear-92                    [-1, 2]           1,026
================================================================
Total params: 318,914
Trainable params: 318,914
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 163.00
Params size (MB): 1.22
Estimated Total Size (MB): 164.22
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 64, kernel_size: 16, n_block: 16
************************************************************
************************************************************
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 64, 1024]           1,088
   MyConv1dPadSame-2             [-1, 64, 1024]               0
       BatchNorm1d-3             [-1, 64, 1024]             128
              ReLU-4             [-1, 64, 1024]               0
            Conv1d-5             [-1, 64, 1024]           1,088
   MyConv1dPadSame-6             [-1, 64, 1024]               0
       BatchNorm1d-7             [-1, 64, 1024]             128
              ReLU-8             [-1, 64, 1024]               0
           Dropout-9             [-1, 64, 1024]               0
           Conv1d-10             [-1, 64, 1024]           1,088
  MyConv1dPadSame-11             [-1, 64, 1024]               0
       Bottleneck-12             [-1, 64, 1024]               0
      BatchNorm1d-13             [-1, 64, 1024]             128
             ReLU-14             [-1, 64, 1024]               0
          Dropout-15             [-1, 64, 1024]               0
           Conv1d-16              [-1, 64, 512]           1,088
  MyConv1dPadSame-17              [-1, 64, 512]               0
      BatchNorm1d-18              [-1, 64, 512]             128
             ReLU-19              [-1, 64, 512]               0
          Dropout-20              [-1, 64, 512]               0
           Conv1d-21              [-1, 64, 512]           1,088
  MyConv1dPadSame-22              [-1, 64, 512]               0
        MaxPool1d-23              [-1, 64, 512]               0
MyMaxPool1dPadSame-24              [-1, 64, 512]               0
       Bottleneck-25              [-1, 64, 512]               0
      BatchNorm1d-26              [-1, 64, 512]             128
             ReLU-27              [-1, 64, 512]               0
          Dropout-28              [-1, 64, 512]               0
           Conv1d-29              [-1, 64, 512]           1,088
  MyConv1dPadSame-30              [-1, 64, 512]               0
      BatchNorm1d-31              [-1, 64, 512]             128
             ReLU-32              [-1, 64, 512]               0
          Dropout-33              [-1, 64, 512]               0
           Conv1d-34              [-1, 64, 512]           1,088
  MyConv1dPadSame-35              [-1, 64, 512]               0
       Bottleneck-36              [-1, 64, 512]               0
      BatchNorm1d-37              [-1, 64, 512]             128
             ReLU-38              [-1, 64, 512]               0
          Dropout-39              [-1, 64, 512]               0
           Conv1d-40              [-1, 64, 256]           1,088
  MyConv1dPadSame-41              [-1, 64, 256]               0
      BatchNorm1d-42              [-1, 64, 256]             128
             ReLU-43              [-1, 64, 256]               0
          Dropout-44              [-1, 64, 256]               0
           Conv1d-45              [-1, 64, 256]           1,088
  MyConv1dPadSame-46              [-1, 64, 256]               0
        MaxPool1d-47              [-1, 64, 256]               0
MyMaxPool1dPadSame-48              [-1, 64, 256]               0
       Bottleneck-49              [-1, 64, 256]               0
      BatchNorm1d-50              [-1, 64, 256]             128
             ReLU-51              [-1, 64, 256]               0
          Dropout-52              [-1, 64, 256]               0
           Conv1d-53             [-1, 128, 256]           2,176
  MyConv1dPadSame-54             [-1, 128, 256]               0
      BatchNorm1d-55             [-1, 128, 256]             256
             ReLU-56             [-1, 128, 256]               0
          Dropout-57             [-1, 128, 256]               0
           Conv1d-58             [-1, 128, 256]           4,224
  MyConv1dPadSame-59             [-1, 128, 256]               0
       Bottleneck-60             [-1, 128, 256]               0
      BatchNorm1d-61             [-1, 128, 256]             256
             ReLU-62             [-1, 128, 256]               0
          Dropout-63             [-1, 128, 256]               0
           Conv1d-64             [-1, 128, 128]           4,224
  MyConv1dPadSame-65             [-1, 128, 128]               0
      BatchNorm1d-66             [-1, 128, 128]             256
             ReLU-67             [-1, 128, 128]               0
          Dropout-68             [-1, 128, 128]               0
           Conv1d-69             [-1, 128, 128]           4,224
  MyConv1dPadSame-70             [-1, 128, 128]               0
        MaxPool1d-71             [-1, 128, 128]               0
MyMaxPool1dPadSame-72             [-1, 128, 128]               0
       Bottleneck-73             [-1, 128, 128]               0
      BatchNorm1d-74             [-1, 128, 128]             256
             ReLU-75             [-1, 128, 128]               0
          Dropout-76             [-1, 128, 128]               0
           Conv1d-77             [-1, 128, 128]           4,224
  MyConv1dPadSame-78             [-1, 128, 128]               0
      BatchNorm1d-79             [-1, 128, 128]             256
             ReLU-80             [-1, 128, 128]               0
          Dropout-81             [-1, 128, 128]               0
           Conv1d-82             [-1, 128, 128]           4,224
  MyConv1dPadSame-83             [-1, 128, 128]               0
       Bottleneck-84             [-1, 128, 128]               0
      BatchNorm1d-85             [-1, 128, 128]             256
             ReLU-86             [-1, 128, 128]               0
          Dropout-87             [-1, 128, 128]               0
           Conv1d-88              [-1, 128, 64]           4,224
  MyConv1dPadSame-89              [-1, 128, 64]               0
      BatchNorm1d-90              [-1, 128, 64]             256
             ReLU-91              [-1, 128, 64]               0
          Dropout-92              [-1, 128, 64]               0
           Conv1d-93              [-1, 128, 64]           4,224
  MyConv1dPadSame-94              [-1, 128, 64]               0
        MaxPool1d-95              [-1, 128, 64]               0
MyMaxPool1dPadSame-96              [-1, 128, 64]               0
       Bottleneck-97              [-1, 128, 64]               0
      BatchNorm1d-98              [-1, 128, 64]             256
             ReLU-99              [-1, 128, 64]               0
         Dropout-100              [-1, 128, 64]               0
          Conv1d-101              [-1, 256, 64]           8,448
 MyConv1dPadSame-102              [-1, 256, 64]               0
     BatchNorm1d-103              [-1, 256, 64]             512
            ReLU-104              [-1, 256, 64]               0
         Dropout-105              [-1, 256, 64]               0
          Conv1d-106              [-1, 256, 64]          16,640
 MyConv1dPadSame-107              [-1, 256, 64]               0
      Bottleneck-108              [-1, 256, 64]               0
     BatchNorm1d-109              [-1, 256, 64]             512
            ReLU-110              [-1, 256, 64]               0
         Dropout-111              [-1, 256, 64]               0
          Conv1d-112              [-1, 256, 32]          16,640
 MyConv1dPadSame-113              [-1, 256, 32]               0
     BatchNorm1d-114              [-1, 256, 32]             512
            ReLU-115              [-1, 256, 32]               0
         Dropout-116              [-1, 256, 32]               0
          Conv1d-117              [-1, 256, 32]          16,640
 MyConv1dPadSame-118              [-1, 256, 32]               0
       MaxPool1d-119              [-1, 256, 32]               0
MyMaxPool1dPadSame-120              [-1, 256, 32]               0
      Bottleneck-121              [-1, 256, 32]               0
     BatchNorm1d-122              [-1, 256, 32]             512
            ReLU-123              [-1, 256, 32]               0
         Dropout-124              [-1, 256, 32]               0
          Conv1d-125              [-1, 256, 32]          16,640
 MyConv1dPadSame-126              [-1, 256, 32]               0
     BatchNorm1d-127              [-1, 256, 32]             512
            ReLU-128              [-1, 256, 32]               0
         Dropout-129              [-1, 256, 32]               0
          Conv1d-130              [-1, 256, 32]          16,640
 MyConv1dPadSame-131              [-1, 256, 32]               0
      Bottleneck-132              [-1, 256, 32]               0
     BatchNorm1d-133              [-1, 256, 32]             512
            ReLU-134              [-1, 256, 32]               0
         Dropout-135              [-1, 256, 32]               0
          Conv1d-136              [-1, 256, 16]          16,640
 MyConv1dPadSame-137              [-1, 256, 16]               0
     BatchNorm1d-138              [-1, 256, 16]             512
            ReLU-139              [-1, 256, 16]               0
         Dropout-140              [-1, 256, 16]               0
          Conv1d-141              [-1, 256, 16]          16,640
 MyConv1dPadSame-142              [-1, 256, 16]               0
       MaxPool1d-143              [-1, 256, 16]               0
MyMaxPool1dPadSame-144              [-1, 256, 16]               0
      Bottleneck-145              [-1, 256, 16]               0
     BatchNorm1d-146              [-1, 256, 16]             512
            ReLU-147              [-1, 256, 16]               0
         Dropout-148              [-1, 256, 16]               0
          Conv1d-149              [-1, 512, 16]          33,280
 MyConv1dPadSame-150              [-1, 512, 16]               0
     BatchNorm1d-151              [-1, 512, 16]           1,024
            ReLU-152              [-1, 512, 16]               0
         Dropout-153              [-1, 512, 16]               0
          Conv1d-154              [-1, 512, 16]          66,048
 MyConv1dPadSame-155              [-1, 512, 16]               0
      Bottleneck-156              [-1, 512, 16]               0
     BatchNorm1d-157              [-1, 512, 16]           1,024
            ReLU-158              [-1, 512, 16]               0
         Dropout-159              [-1, 512, 16]               0
          Conv1d-160               [-1, 512, 8]          66,048
 MyConv1dPadSame-161               [-1, 512, 8]               0
     BatchNorm1d-162               [-1, 512, 8]           1,024
            ReLU-163               [-1, 512, 8]               0
         Dropout-164               [-1, 512, 8]               0
          Conv1d-165               [-1, 512, 8]          66,048
 MyConv1dPadSame-166               [-1, 512, 8]               0
       MaxPool1d-167               [-1, 512, 8]               0
MyMaxPool1dPadSame-168               [-1, 512, 8]               0
      Bottleneck-169               [-1, 512, 8]               0
     BatchNorm1d-170               [-1, 512, 8]           1,024
            ReLU-171               [-1, 512, 8]               0
         Dropout-172               [-1, 512, 8]               0
          Conv1d-173               [-1, 512, 8]          66,048
 MyConv1dPadSame-174               [-1, 512, 8]               0
     BatchNorm1d-175               [-1, 512, 8]           1,024
            ReLU-176               [-1, 512, 8]               0
         Dropout-177               [-1, 512, 8]               0
          Conv1d-178               [-1, 512, 8]          66,048
 MyConv1dPadSame-179               [-1, 512, 8]               0
      Bottleneck-180               [-1, 512, 8]               0
     BatchNorm1d-181               [-1, 512, 8]           1,024
            ReLU-182               [-1, 512, 8]               0
         Dropout-183               [-1, 512, 8]               0
          Conv1d-184               [-1, 512, 4]          66,048
 MyConv1dPadSame-185               [-1, 512, 4]               0
     BatchNorm1d-186               [-1, 512, 4]           1,024
            ReLU-187               [-1, 512, 4]               0
         Dropout-188               [-1, 512, 4]               0
          Conv1d-189               [-1, 512, 4]          66,048
 MyConv1dPadSame-190               [-1, 512, 4]               0
       MaxPool1d-191               [-1, 512, 4]               0
MyMaxPool1dPadSame-192               [-1, 512, 4]               0
      Bottleneck-193               [-1, 512, 4]               0
     BatchNorm1d-194               [-1, 512, 4]           1,024
            ReLU-195               [-1, 512, 4]               0
          Linear-196                    [-1, 2]           1,026
================================================================
Total params: 678,594
Trainable params: 678,594
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 26.59
Params size (MB): 2.59
Estimated Total Size (MB): 29.19
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 128, kernel_size: 2, n_block: 2
************************************************************
************************************************************
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1            [-1, 128, 1024]             384
   MyConv1dPadSame-2            [-1, 128, 1024]               0
       BatchNorm1d-3            [-1, 128, 1024]             256
              ReLU-4            [-1, 128, 1024]               0
            Conv1d-5            [-1, 128, 1024]             384
   MyConv1dPadSame-6            [-1, 128, 1024]               0
       BatchNorm1d-7            [-1, 128, 1024]             256
              ReLU-8            [-1, 128, 1024]               0
           Dropout-9            [-1, 128, 1024]               0
           Conv1d-10            [-1, 128, 1024]             384
  MyConv1dPadSame-11            [-1, 128, 1024]               0
       Bottleneck-12            [-1, 128, 1024]               0
      BatchNorm1d-13            [-1, 128, 1024]             256
             ReLU-14            [-1, 128, 1024]               0
          Dropout-15            [-1, 128, 1024]               0
           Conv1d-16            [-1, 256, 1024]             768
  MyConv1dPadSame-17            [-1, 256, 1024]               0
      BatchNorm1d-18            [-1, 256, 1024]             512
             ReLU-19            [-1, 256, 1024]               0
          Dropout-20            [-1, 256, 1024]               0
           Conv1d-21            [-1, 256, 1024]           1,280
  MyConv1dPadSame-22            [-1, 256, 1024]               0
       Bottleneck-23            [-1, 256, 1024]               0
      BatchNorm1d-24            [-1, 256, 1024]             512
             ReLU-25            [-1, 256, 1024]               0
           Linear-26                    [-1, 2]             514
================================================================
Total params: 5,506
Trainable params: 5,506
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 35.00
Params size (MB): 0.02
Estimated Total Size (MB): 35.02
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 128, kernel_size: 2, n_block: 4
************************************************************
************************************************************
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1            [-1, 128, 1024]             384
   MyConv1dPadSame-2            [-1, 128, 1024]               0
       BatchNorm1d-3            [-1, 128, 1024]             256
              ReLU-4            [-1, 128, 1024]               0
            Conv1d-5            [-1, 128, 1024]             384
   MyConv1dPadSame-6            [-1, 128, 1024]               0
       BatchNorm1d-7            [-1, 128, 1024]             256
              ReLU-8            [-1, 128, 1024]               0
           Dropout-9            [-1, 128, 1024]               0
           Conv1d-10            [-1, 128, 1024]             384
  MyConv1dPadSame-11            [-1, 128, 1024]               0
       Bottleneck-12            [-1, 128, 1024]               0
      BatchNorm1d-13            [-1, 128, 1024]             256
             ReLU-14            [-1, 128, 1024]               0
          Dropout-15            [-1, 128, 1024]               0
           Conv1d-16            [-1, 256, 1024]             768
  MyConv1dPadSame-17            [-1, 256, 1024]               0
      BatchNorm1d-18            [-1, 256, 1024]             512
             ReLU-19            [-1, 256, 1024]               0
          Dropout-20            [-1, 256, 1024]               0
           Conv1d-21            [-1, 256, 1024]           1,280
  MyConv1dPadSame-22            [-1, 256, 1024]               0
       Bottleneck-23            [-1, 256, 1024]               0
      BatchNorm1d-24            [-1, 256, 1024]             512
             ReLU-25            [-1, 256, 1024]               0
          Dropout-26            [-1, 256, 1024]               0
           Conv1d-27            [-1, 512, 1024]           2,560
  MyConv1dPadSame-28            [-1, 512, 1024]               0
      BatchNorm1d-29            [-1, 512, 1024]           1,024
             ReLU-30            [-1, 512, 1024]               0
          Dropout-31            [-1, 512, 1024]               0
           Conv1d-32            [-1, 512, 1024]           4,608
  MyConv1dPadSame-33            [-1, 512, 1024]               0
       Bottleneck-34            [-1, 512, 1024]               0
      BatchNorm1d-35            [-1, 512, 1024]           1,024
             ReLU-36            [-1, 512, 1024]               0
          Dropout-37            [-1, 512, 1024]               0
           Conv1d-38           [-1, 1024, 1024]           9,216
  MyConv1dPadSame-39           [-1, 1024, 1024]               0
      BatchNorm1d-40           [-1, 1024, 1024]           2,048
             ReLU-41           [-1, 1024, 1024]               0
          Dropout-42           [-1, 1024, 1024]               0
           Conv1d-43           [-1, 1024, 1024]          17,408
  MyConv1dPadSame-44           [-1, 1024, 1024]               0
       Bottleneck-45           [-1, 1024, 1024]               0
      BatchNorm1d-46           [-1, 1024, 1024]           2,048
             ReLU-47           [-1, 1024, 1024]               0
           Linear-48                    [-1, 2]           2,050
================================================================
Total params: 46,978
Trainable params: 46,978
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 161.00
Params size (MB): 0.18
Estimated Total Size (MB): 161.18
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 128, kernel_size: 2, n_block: 8
************************************************************
************************************************************
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1            [-1, 128, 1024]             384
   MyConv1dPadSame-2            [-1, 128, 1024]               0
       BatchNorm1d-3            [-1, 128, 1024]             256
              ReLU-4            [-1, 128, 1024]               0
            Conv1d-5            [-1, 128, 1024]             384
   MyConv1dPadSame-6            [-1, 128, 1024]               0
       BatchNorm1d-7            [-1, 128, 1024]             256
              ReLU-8            [-1, 128, 1024]               0
           Dropout-9            [-1, 128, 1024]               0
           Conv1d-10            [-1, 128, 1024]             384
  MyConv1dPadSame-11            [-1, 128, 1024]               0
       Bottleneck-12            [-1, 128, 1024]               0
      BatchNorm1d-13            [-1, 128, 1024]             256
             ReLU-14            [-1, 128, 1024]               0
          Dropout-15            [-1, 128, 1024]               0
           Conv1d-16            [-1, 128, 1024]             384
  MyConv1dPadSame-17            [-1, 128, 1024]               0
      BatchNorm1d-18            [-1, 128, 1024]             256
             ReLU-19            [-1, 128, 1024]               0
          Dropout-20            [-1, 128, 1024]               0
           Conv1d-21            [-1, 128, 1024]             384
  MyConv1dPadSame-22            [-1, 128, 1024]               0
       Bottleneck-23            [-1, 128, 1024]               0
      BatchNorm1d-24            [-1, 128, 1024]             256
             ReLU-25            [-1, 128, 1024]               0
          Dropout-26            [-1, 128, 1024]               0
           Conv1d-27            [-1, 256, 1024]             768
  MyConv1dPadSame-28            [-1, 256, 1024]               0
      BatchNorm1d-29            [-1, 256, 1024]             512
             ReLU-30            [-1, 256, 1024]               0
          Dropout-31            [-1, 256, 1024]               0
           Conv1d-32            [-1, 256, 1024]           1,280
  MyConv1dPadSame-33            [-1, 256, 1024]               0
       Bottleneck-34            [-1, 256, 1024]               0
      BatchNorm1d-35            [-1, 256, 1024]             512
             ReLU-36            [-1, 256, 1024]               0
          Dropout-37            [-1, 256, 1024]               0
           Conv1d-38            [-1, 256, 1024]           1,280
  MyConv1dPadSame-39            [-1, 256, 1024]               0
      BatchNorm1d-40            [-1, 256, 1024]             512
             ReLU-41            [-1, 256, 1024]               0
          Dropout-42            [-1, 256, 1024]               0
           Conv1d-43            [-1, 256, 1024]           1,280
  MyConv1dPadSame-44            [-1, 256, 1024]               0
       Bottleneck-45            [-1, 256, 1024]               0
      BatchNorm1d-46            [-1, 256, 1024]             512
             ReLU-47            [-1, 256, 1024]               0
          Dropout-48            [-1, 256, 1024]               0
           Conv1d-49            [-1, 512, 1024]           2,560
  MyConv1dPadSame-50            [-1, 512, 1024]               0
      BatchNorm1d-51            [-1, 512, 1024]           1,024
             ReLU-52            [-1, 512, 1024]               0
          Dropout-53            [-1, 512, 1024]               0
           Conv1d-54            [-1, 512, 1024]           4,608
  MyConv1dPadSame-55            [-1, 512, 1024]               0
       Bottleneck-56            [-1, 512, 1024]               0
      BatchNorm1d-57            [-1, 512, 1024]           1,024
             ReLU-58            [-1, 512, 1024]               0
          Dropout-59            [-1, 512, 1024]               0
           Conv1d-60            [-1, 512, 1024]           4,608
  MyConv1dPadSame-61            [-1, 512, 1024]               0
      BatchNorm1d-62            [-1, 512, 1024]           1,024
             ReLU-63            [-1, 512, 1024]               0
          Dropout-64            [-1, 512, 1024]               0
           Conv1d-65            [-1, 512, 1024]           4,608
  MyConv1dPadSame-66            [-1, 512, 1024]               0
       Bottleneck-67            [-1, 512, 1024]               0
      BatchNorm1d-68            [-1, 512, 1024]           1,024
             ReLU-69            [-1, 512, 1024]               0
          Dropout-70            [-1, 512, 1024]               0
           Conv1d-71           [-1, 1024, 1024]           9,216
  MyConv1dPadSame-72           [-1, 1024, 1024]               0
      BatchNorm1d-73           [-1, 1024, 1024]           2,048
             ReLU-74           [-1, 1024, 1024]               0
          Dropout-75           [-1, 1024, 1024]               0
           Conv1d-76           [-1, 1024, 1024]          17,408
  MyConv1dPadSame-77           [-1, 1024, 1024]               0
       Bottleneck-78           [-1, 1024, 1024]               0
      BatchNorm1d-79           [-1, 1024, 1024]           2,048
             ReLU-80           [-1, 1024, 1024]               0
          Dropout-81           [-1, 1024, 1024]               0
           Conv1d-82           [-1, 1024, 1024]          17,408
  MyConv1dPadSame-83           [-1, 1024, 1024]               0
      BatchNorm1d-84           [-1, 1024, 1024]           2,048
             ReLU-85           [-1, 1024, 1024]               0
          Dropout-86           [-1, 1024, 1024]               0
           Conv1d-87           [-1, 1024, 1024]          17,408
  MyConv1dPadSame-88           [-1, 1024, 1024]               0
       Bottleneck-89           [-1, 1024, 1024]               0
      BatchNorm1d-90           [-1, 1024, 1024]           2,048
             ReLU-91           [-1, 1024, 1024]               0
           Linear-92                    [-1, 2]           2,050
================================================================
Total params: 102,018
Trainable params: 102,018
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 326.00
Params size (MB): 0.39
Estimated Total Size (MB): 326.39
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 128, kernel_size: 2, n_block: 16
************************************************************
************************************************************
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1            [-1, 128, 1024]             384
   MyConv1dPadSame-2            [-1, 128, 1024]               0
       BatchNorm1d-3            [-1, 128, 1024]             256
              ReLU-4            [-1, 128, 1024]               0
            Conv1d-5            [-1, 128, 1024]             384
   MyConv1dPadSame-6            [-1, 128, 1024]               0
       BatchNorm1d-7            [-1, 128, 1024]             256
              ReLU-8            [-1, 128, 1024]               0
           Dropout-9            [-1, 128, 1024]               0
           Conv1d-10            [-1, 128, 1024]             384
  MyConv1dPadSame-11            [-1, 128, 1024]               0
       Bottleneck-12            [-1, 128, 1024]               0
      BatchNorm1d-13            [-1, 128, 1024]             256
             ReLU-14            [-1, 128, 1024]               0
          Dropout-15            [-1, 128, 1024]               0
           Conv1d-16             [-1, 128, 512]             384
  MyConv1dPadSame-17             [-1, 128, 512]               0
      BatchNorm1d-18             [-1, 128, 512]             256
             ReLU-19             [-1, 128, 512]               0
          Dropout-20             [-1, 128, 512]               0
           Conv1d-21             [-1, 128, 512]             384
  MyConv1dPadSame-22             [-1, 128, 512]               0
        MaxPool1d-23             [-1, 128, 512]               0
MyMaxPool1dPadSame-24             [-1, 128, 512]               0
       Bottleneck-25             [-1, 128, 512]               0
      BatchNorm1d-26             [-1, 128, 512]             256
             ReLU-27             [-1, 128, 512]               0
          Dropout-28             [-1, 128, 512]               0
           Conv1d-29             [-1, 128, 512]             384
  MyConv1dPadSame-30             [-1, 128, 512]               0
      BatchNorm1d-31             [-1, 128, 512]             256
             ReLU-32             [-1, 128, 512]               0
          Dropout-33             [-1, 128, 512]               0
           Conv1d-34             [-1, 128, 512]             384
  MyConv1dPadSame-35             [-1, 128, 512]               0
       Bottleneck-36             [-1, 128, 512]               0
      BatchNorm1d-37             [-1, 128, 512]             256
             ReLU-38             [-1, 128, 512]               0
          Dropout-39             [-1, 128, 512]               0
           Conv1d-40             [-1, 128, 256]             384
  MyConv1dPadSame-41             [-1, 128, 256]               0
      BatchNorm1d-42             [-1, 128, 256]             256
             ReLU-43             [-1, 128, 256]               0
          Dropout-44             [-1, 128, 256]               0
           Conv1d-45             [-1, 128, 256]             384
  MyConv1dPadSame-46             [-1, 128, 256]               0
        MaxPool1d-47             [-1, 128, 256]               0
MyMaxPool1dPadSame-48             [-1, 128, 256]               0
       Bottleneck-49             [-1, 128, 256]               0
      BatchNorm1d-50             [-1, 128, 256]             256
             ReLU-51             [-1, 128, 256]               0
          Dropout-52             [-1, 128, 256]               0
           Conv1d-53             [-1, 256, 256]             768
  MyConv1dPadSame-54             [-1, 256, 256]               0
      BatchNorm1d-55             [-1, 256, 256]             512
             ReLU-56             [-1, 256, 256]               0
          Dropout-57             [-1, 256, 256]               0
           Conv1d-58             [-1, 256, 256]           1,280
  MyConv1dPadSame-59             [-1, 256, 256]               0
       Bottleneck-60             [-1, 256, 256]               0
      BatchNorm1d-61             [-1, 256, 256]             512
             ReLU-62             [-1, 256, 256]               0
          Dropout-63             [-1, 256, 256]               0
           Conv1d-64             [-1, 256, 128]           1,280
  MyConv1dPadSame-65             [-1, 256, 128]               0
      BatchNorm1d-66             [-1, 256, 128]             512
             ReLU-67             [-1, 256, 128]               0
          Dropout-68             [-1, 256, 128]               0
           Conv1d-69             [-1, 256, 128]           1,280
  MyConv1dPadSame-70             [-1, 256, 128]               0
        MaxPool1d-71             [-1, 256, 128]               0
MyMaxPool1dPadSame-72             [-1, 256, 128]               0
       Bottleneck-73             [-1, 256, 128]               0
      BatchNorm1d-74             [-1, 256, 128]             512
             ReLU-75             [-1, 256, 128]               0
          Dropout-76             [-1, 256, 128]               0
           Conv1d-77             [-1, 256, 128]           1,280
  MyConv1dPadSame-78             [-1, 256, 128]               0
      BatchNorm1d-79             [-1, 256, 128]             512
             ReLU-80             [-1, 256, 128]               0
          Dropout-81             [-1, 256, 128]               0
           Conv1d-82             [-1, 256, 128]           1,280
  MyConv1dPadSame-83             [-1, 256, 128]               0
       Bottleneck-84             [-1, 256, 128]               0
      BatchNorm1d-85             [-1, 256, 128]             512
             ReLU-86             [-1, 256, 128]               0
          Dropout-87             [-1, 256, 128]               0
           Conv1d-88              [-1, 256, 64]           1,280
  MyConv1dPadSame-89              [-1, 256, 64]               0
      BatchNorm1d-90              [-1, 256, 64]             512
             ReLU-91              [-1, 256, 64]               0
          Dropout-92              [-1, 256, 64]               0
           Conv1d-93              [-1, 256, 64]           1,280
  MyConv1dPadSame-94              [-1, 256, 64]               0
        MaxPool1d-95              [-1, 256, 64]               0
MyMaxPool1dPadSame-96              [-1, 256, 64]               0
       Bottleneck-97              [-1, 256, 64]               0
      BatchNorm1d-98              [-1, 256, 64]             512
             ReLU-99              [-1, 256, 64]               0
         Dropout-100              [-1, 256, 64]               0
          Conv1d-101              [-1, 512, 64]           2,560
 MyConv1dPadSame-102              [-1, 512, 64]               0
     BatchNorm1d-103              [-1, 512, 64]           1,024
            ReLU-104              [-1, 512, 64]               0
         Dropout-105              [-1, 512, 64]               0
          Conv1d-106              [-1, 512, 64]           4,608
 MyConv1dPadSame-107              [-1, 512, 64]               0
      Bottleneck-108              [-1, 512, 64]               0
     BatchNorm1d-109              [-1, 512, 64]           1,024
            ReLU-110              [-1, 512, 64]               0
         Dropout-111              [-1, 512, 64]               0
          Conv1d-112              [-1, 512, 32]           4,608
 MyConv1dPadSame-113              [-1, 512, 32]               0
     BatchNorm1d-114              [-1, 512, 32]           1,024
            ReLU-115              [-1, 512, 32]               0
         Dropout-116              [-1, 512, 32]               0
          Conv1d-117              [-1, 512, 32]           4,608
 MyConv1dPadSame-118              [-1, 512, 32]               0
       MaxPool1d-119              [-1, 512, 32]               0
MyMaxPool1dPadSame-120              [-1, 512, 32]               0
      Bottleneck-121              [-1, 512, 32]               0
     BatchNorm1d-122              [-1, 512, 32]           1,024
            ReLU-123              [-1, 512, 32]               0
         Dropout-124              [-1, 512, 32]               0
          Conv1d-125              [-1, 512, 32]           4,608
 MyConv1dPadSame-126              [-1, 512, 32]               0
     BatchNorm1d-127              [-1, 512, 32]           1,024
            ReLU-128              [-1, 512, 32]               0
         Dropout-129              [-1, 512, 32]               0
          Conv1d-130              [-1, 512, 32]           4,608
 MyConv1dPadSame-131              [-1, 512, 32]               0
      Bottleneck-132              [-1, 512, 32]               0
     BatchNorm1d-133              [-1, 512, 32]           1,024
            ReLU-134              [-1, 512, 32]               0
         Dropout-135              [-1, 512, 32]               0
          Conv1d-136              [-1, 512, 16]           4,608
 MyConv1dPadSame-137              [-1, 512, 16]               0
     BatchNorm1d-138              [-1, 512, 16]           1,024
            ReLU-139              [-1, 512, 16]               0
         Dropout-140              [-1, 512, 16]               0
          Conv1d-141              [-1, 512, 16]           4,608
 MyConv1dPadSame-142              [-1, 512, 16]               0
       MaxPool1d-143              [-1, 512, 16]               0
MyMaxPool1dPadSame-144              [-1, 512, 16]               0
      Bottleneck-145              [-1, 512, 16]               0
     BatchNorm1d-146              [-1, 512, 16]           1,024
            ReLU-147              [-1, 512, 16]               0
         Dropout-148              [-1, 512, 16]               0
          Conv1d-149             [-1, 1024, 16]           9,216
 MyConv1dPadSame-150             [-1, 1024, 16]               0
     BatchNorm1d-151             [-1, 1024, 16]           2,048
            ReLU-152             [-1, 1024, 16]               0
         Dropout-153             [-1, 1024, 16]               0
          Conv1d-154             [-1, 1024, 16]          17,408
 MyConv1dPadSame-155             [-1, 1024, 16]               0
      Bottleneck-156             [-1, 1024, 16]               0
     BatchNorm1d-157             [-1, 1024, 16]           2,048
            ReLU-158             [-1, 1024, 16]               0
         Dropout-159             [-1, 1024, 16]               0
          Conv1d-160              [-1, 1024, 8]          17,408
 MyConv1dPadSame-161              [-1, 1024, 8]               0
     BatchNorm1d-162              [-1, 1024, 8]           2,048
            ReLU-163              [-1, 1024, 8]               0
         Dropout-164              [-1, 1024, 8]               0
          Conv1d-165              [-1, 1024, 8]          17,408
 MyConv1dPadSame-166              [-1, 1024, 8]               0
       MaxPool1d-167              [-1, 1024, 8]               0
MyMaxPool1dPadSame-168              [-1, 1024, 8]               0
      Bottleneck-169              [-1, 1024, 8]               0
     BatchNorm1d-170              [-1, 1024, 8]           2,048
            ReLU-171              [-1, 1024, 8]               0
         Dropout-172              [-1, 1024, 8]               0
          Conv1d-173              [-1, 1024, 8]          17,408
 MyConv1dPadSame-174              [-1, 1024, 8]               0
     BatchNorm1d-175              [-1, 1024, 8]           2,048
            ReLU-176              [-1, 1024, 8]               0
         Dropout-177              [-1, 1024, 8]               0
          Conv1d-178              [-1, 1024, 8]          17,408
 MyConv1dPadSame-179              [-1, 1024, 8]               0
      Bottleneck-180              [-1, 1024, 8]               0
     BatchNorm1d-181              [-1, 1024, 8]           2,048
            ReLU-182              [-1, 1024, 8]               0
         Dropout-183              [-1, 1024, 8]               0
          Conv1d-184              [-1, 1024, 4]          17,408
 MyConv1dPadSame-185              [-1, 1024, 4]               0
     BatchNorm1d-186              [-1, 1024, 4]           2,048
            ReLU-187              [-1, 1024, 4]               0
         Dropout-188              [-1, 1024, 4]               0
          Conv1d-189              [-1, 1024, 4]          17,408
 MyConv1dPadSame-190              [-1, 1024, 4]               0
       MaxPool1d-191              [-1, 1024, 4]               0
MyMaxPool1dPadSame-192              [-1, 1024, 4]               0
      Bottleneck-193              [-1, 1024, 4]               0
     BatchNorm1d-194              [-1, 1024, 4]           2,048
            ReLU-195              [-1, 1024, 4]               0
          Linear-196                    [-1, 2]           2,050
================================================================
Total params: 212,098
Trainable params: 212,098
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 53.19
Params size (MB): 0.81
Estimated Total Size (MB): 54.00
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 128, kernel_size: 4, n_block: 2
************************************************************
************************************************************
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1            [-1, 128, 1024]             640
   MyConv1dPadSame-2            [-1, 128, 1024]               0
       BatchNorm1d-3            [-1, 128, 1024]             256
              ReLU-4            [-1, 128, 1024]               0
            Conv1d-5            [-1, 128, 1024]             640
   MyConv1dPadSame-6            [-1, 128, 1024]               0
       BatchNorm1d-7            [-1, 128, 1024]             256
              ReLU-8            [-1, 128, 1024]               0
           Dropout-9            [-1, 128, 1024]               0
           Conv1d-10            [-1, 128, 1024]             640
  MyConv1dPadSame-11            [-1, 128, 1024]               0
       Bottleneck-12            [-1, 128, 1024]               0
      BatchNorm1d-13            [-1, 128, 1024]             256
             ReLU-14            [-1, 128, 1024]               0
          Dropout-15            [-1, 128, 1024]               0
           Conv1d-16            [-1, 256, 1024]           1,280
  MyConv1dPadSame-17            [-1, 256, 1024]               0
      BatchNorm1d-18            [-1, 256, 1024]             512
             ReLU-19            [-1, 256, 1024]               0
          Dropout-20            [-1, 256, 1024]               0
           Conv1d-21            [-1, 256, 1024]           2,304
  MyConv1dPadSame-22            [-1, 256, 1024]               0
       Bottleneck-23            [-1, 256, 1024]               0
      BatchNorm1d-24            [-1, 256, 1024]             512
             ReLU-25            [-1, 256, 1024]               0
           Linear-26                    [-1, 2]             514
================================================================
Total params: 7,810
Trainable params: 7,810
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 35.00
Params size (MB): 0.03
Estimated Total Size (MB): 35.03
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 128, kernel_size: 4, n_block: 4
************************************************************
************************************************************
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1            [-1, 128, 1024]             640
   MyConv1dPadSame-2            [-1, 128, 1024]               0
       BatchNorm1d-3            [-1, 128, 1024]             256
              ReLU-4            [-1, 128, 1024]               0
            Conv1d-5            [-1, 128, 1024]             640
   MyConv1dPadSame-6            [-1, 128, 1024]               0
       BatchNorm1d-7            [-1, 128, 1024]             256
              ReLU-8            [-1, 128, 1024]               0
           Dropout-9            [-1, 128, 1024]               0
           Conv1d-10            [-1, 128, 1024]             640
  MyConv1dPadSame-11            [-1, 128, 1024]               0
       Bottleneck-12            [-1, 128, 1024]               0
      BatchNorm1d-13            [-1, 128, 1024]             256
             ReLU-14            [-1, 128, 1024]               0
          Dropout-15            [-1, 128, 1024]               0
           Conv1d-16            [-1, 256, 1024]           1,280
  MyConv1dPadSame-17            [-1, 256, 1024]               0
      BatchNorm1d-18            [-1, 256, 1024]             512
             ReLU-19            [-1, 256, 1024]               0
          Dropout-20            [-1, 256, 1024]               0
           Conv1d-21            [-1, 256, 1024]           2,304
  MyConv1dPadSame-22            [-1, 256, 1024]               0
       Bottleneck-23            [-1, 256, 1024]               0
      BatchNorm1d-24            [-1, 256, 1024]             512
             ReLU-25            [-1, 256, 1024]               0
          Dropout-26            [-1, 256, 1024]               0
           Conv1d-27            [-1, 512, 1024]           4,608
  MyConv1dPadSame-28            [-1, 512, 1024]               0
      BatchNorm1d-29            [-1, 512, 1024]           1,024
             ReLU-30            [-1, 512, 1024]               0
          Dropout-31            [-1, 512, 1024]               0
           Conv1d-32            [-1, 512, 1024]           8,704
  MyConv1dPadSame-33            [-1, 512, 1024]               0
       Bottleneck-34            [-1, 512, 1024]               0
      BatchNorm1d-35            [-1, 512, 1024]           1,024
             ReLU-36            [-1, 512, 1024]               0
          Dropout-37            [-1, 512, 1024]               0
           Conv1d-38           [-1, 1024, 1024]          17,408
  MyConv1dPadSame-39           [-1, 1024, 1024]               0
      BatchNorm1d-40           [-1, 1024, 1024]           2,048
             ReLU-41           [-1, 1024, 1024]               0
          Dropout-42           [-1, 1024, 1024]               0
           Conv1d-43           [-1, 1024, 1024]          33,792
  MyConv1dPadSame-44           [-1, 1024, 1024]               0
       Bottleneck-45           [-1, 1024, 1024]               0
      BatchNorm1d-46           [-1, 1024, 1024]           2,048
             ReLU-47           [-1, 1024, 1024]               0
           Linear-48                    [-1, 2]           2,050
================================================================
Total params: 80,002
Trainable params: 80,002
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 161.00
Params size (MB): 0.31
Estimated Total Size (MB): 161.31
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 128, kernel_size: 4, n_block: 8
************************************************************
************************************************************
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1            [-1, 128, 1024]             640
   MyConv1dPadSame-2            [-1, 128, 1024]               0
       BatchNorm1d-3            [-1, 128, 1024]             256
              ReLU-4            [-1, 128, 1024]               0
            Conv1d-5            [-1, 128, 1024]             640
   MyConv1dPadSame-6            [-1, 128, 1024]               0
       BatchNorm1d-7            [-1, 128, 1024]             256
              ReLU-8            [-1, 128, 1024]               0
           Dropout-9            [-1, 128, 1024]               0
           Conv1d-10            [-1, 128, 1024]             640
  MyConv1dPadSame-11            [-1, 128, 1024]               0
       Bottleneck-12            [-1, 128, 1024]               0
      BatchNorm1d-13            [-1, 128, 1024]             256
             ReLU-14            [-1, 128, 1024]               0
          Dropout-15            [-1, 128, 1024]               0
           Conv1d-16            [-1, 128, 1024]             640
  MyConv1dPadSame-17            [-1, 128, 1024]               0
      BatchNorm1d-18            [-1, 128, 1024]             256
             ReLU-19            [-1, 128, 1024]               0
          Dropout-20            [-1, 128, 1024]               0
           Conv1d-21            [-1, 128, 1024]             640
  MyConv1dPadSame-22            [-1, 128, 1024]               0
       Bottleneck-23            [-1, 128, 1024]               0
      BatchNorm1d-24            [-1, 128, 1024]             256
             ReLU-25            [-1, 128, 1024]               0
          Dropout-26            [-1, 128, 1024]               0
           Conv1d-27            [-1, 256, 1024]           1,280
  MyConv1dPadSame-28            [-1, 256, 1024]               0
      BatchNorm1d-29            [-1, 256, 1024]             512
             ReLU-30            [-1, 256, 1024]               0
          Dropout-31            [-1, 256, 1024]               0
           Conv1d-32            [-1, 256, 1024]           2,304
  MyConv1dPadSame-33            [-1, 256, 1024]               0
       Bottleneck-34            [-1, 256, 1024]               0
      BatchNorm1d-35            [-1, 256, 1024]             512
             ReLU-36            [-1, 256, 1024]               0
          Dropout-37            [-1, 256, 1024]               0
           Conv1d-38            [-1, 256, 1024]           2,304
  MyConv1dPadSame-39            [-1, 256, 1024]               0
      BatchNorm1d-40            [-1, 256, 1024]             512
             ReLU-41            [-1, 256, 1024]               0
          Dropout-42            [-1, 256, 1024]               0
           Conv1d-43            [-1, 256, 1024]           2,304
  MyConv1dPadSame-44            [-1, 256, 1024]               0
       Bottleneck-45            [-1, 256, 1024]               0
      BatchNorm1d-46            [-1, 256, 1024]             512
             ReLU-47            [-1, 256, 1024]               0
          Dropout-48            [-1, 256, 1024]               0
           Conv1d-49            [-1, 512, 1024]           4,608
  MyConv1dPadSame-50            [-1, 512, 1024]               0
      BatchNorm1d-51            [-1, 512, 1024]           1,024
             ReLU-52            [-1, 512, 1024]               0
          Dropout-53            [-1, 512, 1024]               0
           Conv1d-54            [-1, 512, 1024]           8,704
  MyConv1dPadSame-55            [-1, 512, 1024]               0
       Bottleneck-56            [-1, 512, 1024]               0
      BatchNorm1d-57            [-1, 512, 1024]           1,024
             ReLU-58            [-1, 512, 1024]               0
          Dropout-59            [-1, 512, 1024]               0
           Conv1d-60            [-1, 512, 1024]           8,704
  MyConv1dPadSame-61            [-1, 512, 1024]               0
      BatchNorm1d-62            [-1, 512, 1024]           1,024
             ReLU-63            [-1, 512, 1024]               0
          Dropout-64            [-1, 512, 1024]               0
           Conv1d-65            [-1, 512, 1024]           8,704
  MyConv1dPadSame-66            [-1, 512, 1024]               0
       Bottleneck-67            [-1, 512, 1024]               0
      BatchNorm1d-68            [-1, 512, 1024]           1,024
             ReLU-69            [-1, 512, 1024]               0
          Dropout-70            [-1, 512, 1024]               0
           Conv1d-71           [-1, 1024, 1024]          17,408
  MyConv1dPadSame-72           [-1, 1024, 1024]               0
      BatchNorm1d-73           [-1, 1024, 1024]           2,048
             ReLU-74           [-1, 1024, 1024]               0
          Dropout-75           [-1, 1024, 1024]               0
           Conv1d-76           [-1, 1024, 1024]          33,792
  MyConv1dPadSame-77           [-1, 1024, 1024]               0
       Bottleneck-78           [-1, 1024, 1024]               0
      BatchNorm1d-79           [-1, 1024, 1024]           2,048
             ReLU-80           [-1, 1024, 1024]               0
          Dropout-81           [-1, 1024, 1024]               0
           Conv1d-82           [-1, 1024, 1024]          33,792
  MyConv1dPadSame-83           [-1, 1024, 1024]               0
      BatchNorm1d-84           [-1, 1024, 1024]           2,048
             ReLU-85           [-1, 1024, 1024]               0
          Dropout-86           [-1, 1024, 1024]               0
           Conv1d-87           [-1, 1024, 1024]          33,792
  MyConv1dPadSame-88           [-1, 1024, 1024]               0
       Bottleneck-89           [-1, 1024, 1024]               0
      BatchNorm1d-90           [-1, 1024, 1024]           2,048
             ReLU-91           [-1, 1024, 1024]               0
           Linear-92                    [-1, 2]           2,050
================================================================
Total params: 178,562
Trainable params: 178,562
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 326.00
Params size (MB): 0.68
Estimated Total Size (MB): 326.69
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 128, kernel_size: 4, n_block: 16
************************************************************
************************************************************
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1            [-1, 128, 1024]             640
   MyConv1dPadSame-2            [-1, 128, 1024]               0
       BatchNorm1d-3            [-1, 128, 1024]             256
              ReLU-4            [-1, 128, 1024]               0
            Conv1d-5            [-1, 128, 1024]             640
   MyConv1dPadSame-6            [-1, 128, 1024]               0
       BatchNorm1d-7            [-1, 128, 1024]             256
              ReLU-8            [-1, 128, 1024]               0
           Dropout-9            [-1, 128, 1024]               0
           Conv1d-10            [-1, 128, 1024]             640
  MyConv1dPadSame-11            [-1, 128, 1024]               0
       Bottleneck-12            [-1, 128, 1024]               0
      BatchNorm1d-13            [-1, 128, 1024]             256
             ReLU-14            [-1, 128, 1024]               0
          Dropout-15            [-1, 128, 1024]               0
           Conv1d-16             [-1, 128, 512]             640
  MyConv1dPadSame-17             [-1, 128, 512]               0
      BatchNorm1d-18             [-1, 128, 512]             256
             ReLU-19             [-1, 128, 512]               0
          Dropout-20             [-1, 128, 512]               0
           Conv1d-21             [-1, 128, 512]             640
  MyConv1dPadSame-22             [-1, 128, 512]               0
        MaxPool1d-23             [-1, 128, 512]               0
MyMaxPool1dPadSame-24             [-1, 128, 512]               0
       Bottleneck-25             [-1, 128, 512]               0
      BatchNorm1d-26             [-1, 128, 512]             256
             ReLU-27             [-1, 128, 512]               0
          Dropout-28             [-1, 128, 512]               0
           Conv1d-29             [-1, 128, 512]             640
  MyConv1dPadSame-30             [-1, 128, 512]               0
      BatchNorm1d-31             [-1, 128, 512]             256
             ReLU-32             [-1, 128, 512]               0
          Dropout-33             [-1, 128, 512]               0
           Conv1d-34             [-1, 128, 512]             640
  MyConv1dPadSame-35             [-1, 128, 512]               0
       Bottleneck-36             [-1, 128, 512]               0
      BatchNorm1d-37             [-1, 128, 512]             256
             ReLU-38             [-1, 128, 512]               0
          Dropout-39             [-1, 128, 512]               0
           Conv1d-40             [-1, 128, 256]             640
  MyConv1dPadSame-41             [-1, 128, 256]               0
      BatchNorm1d-42             [-1, 128, 256]             256
             ReLU-43             [-1, 128, 256]               0
          Dropout-44             [-1, 128, 256]               0
           Conv1d-45             [-1, 128, 256]             640
  MyConv1dPadSame-46             [-1, 128, 256]               0
        MaxPool1d-47             [-1, 128, 256]               0
MyMaxPool1dPadSame-48             [-1, 128, 256]               0
       Bottleneck-49             [-1, 128, 256]               0
      BatchNorm1d-50             [-1, 128, 256]             256
             ReLU-51             [-1, 128, 256]               0
          Dropout-52             [-1, 128, 256]               0
           Conv1d-53             [-1, 256, 256]           1,280
  MyConv1dPadSame-54             [-1, 256, 256]               0
      BatchNorm1d-55             [-1, 256, 256]             512
             ReLU-56             [-1, 256, 256]               0
          Dropout-57             [-1, 256, 256]               0
           Conv1d-58             [-1, 256, 256]           2,304
  MyConv1dPadSame-59             [-1, 256, 256]               0
       Bottleneck-60             [-1, 256, 256]               0
      BatchNorm1d-61             [-1, 256, 256]             512
             ReLU-62             [-1, 256, 256]               0
          Dropout-63             [-1, 256, 256]               0
           Conv1d-64             [-1, 256, 128]           2,304
  MyConv1dPadSame-65             [-1, 256, 128]               0
      BatchNorm1d-66             [-1, 256, 128]             512
             ReLU-67             [-1, 256, 128]               0
          Dropout-68             [-1, 256, 128]               0
           Conv1d-69             [-1, 256, 128]           2,304
  MyConv1dPadSame-70             [-1, 256, 128]               0
        MaxPool1d-71             [-1, 256, 128]               0
MyMaxPool1dPadSame-72             [-1, 256, 128]               0
       Bottleneck-73             [-1, 256, 128]               0
      BatchNorm1d-74             [-1, 256, 128]             512
             ReLU-75             [-1, 256, 128]               0
          Dropout-76             [-1, 256, 128]               0
           Conv1d-77             [-1, 256, 128]           2,304
  MyConv1dPadSame-78             [-1, 256, 128]               0
      BatchNorm1d-79             [-1, 256, 128]             512
             ReLU-80             [-1, 256, 128]               0
          Dropout-81             [-1, 256, 128]               0
           Conv1d-82             [-1, 256, 128]           2,304
  MyConv1dPadSame-83             [-1, 256, 128]               0
       Bottleneck-84             [-1, 256, 128]               0
      BatchNorm1d-85             [-1, 256, 128]             512
             ReLU-86             [-1, 256, 128]               0
          Dropout-87             [-1, 256, 128]               0
           Conv1d-88              [-1, 256, 64]           2,304
  MyConv1dPadSame-89              [-1, 256, 64]               0
      BatchNorm1d-90              [-1, 256, 64]             512
             ReLU-91              [-1, 256, 64]               0
          Dropout-92              [-1, 256, 64]               0
           Conv1d-93              [-1, 256, 64]           2,304
  MyConv1dPadSame-94              [-1, 256, 64]               0
        MaxPool1d-95              [-1, 256, 64]               0
MyMaxPool1dPadSame-96              [-1, 256, 64]               0
       Bottleneck-97              [-1, 256, 64]               0
      BatchNorm1d-98              [-1, 256, 64]             512
             ReLU-99              [-1, 256, 64]               0
         Dropout-100              [-1, 256, 64]               0
          Conv1d-101              [-1, 512, 64]           4,608
 MyConv1dPadSame-102              [-1, 512, 64]               0
     BatchNorm1d-103              [-1, 512, 64]           1,024
            ReLU-104              [-1, 512, 64]               0
         Dropout-105              [-1, 512, 64]               0
          Conv1d-106              [-1, 512, 64]           8,704
 MyConv1dPadSame-107              [-1, 512, 64]               0
      Bottleneck-108              [-1, 512, 64]               0
     BatchNorm1d-109              [-1, 512, 64]           1,024
            ReLU-110              [-1, 512, 64]               0
         Dropout-111              [-1, 512, 64]               0
          Conv1d-112              [-1, 512, 32]           8,704
 MyConv1dPadSame-113              [-1, 512, 32]               0
     BatchNorm1d-114              [-1, 512, 32]           1,024
            ReLU-115              [-1, 512, 32]               0
         Dropout-116              [-1, 512, 32]               0
          Conv1d-117              [-1, 512, 32]           8,704
 MyConv1dPadSame-118              [-1, 512, 32]               0
       MaxPool1d-119              [-1, 512, 32]               0
MyMaxPool1dPadSame-120              [-1, 512, 32]               0
      Bottleneck-121              [-1, 512, 32]               0
     BatchNorm1d-122              [-1, 512, 32]           1,024
            ReLU-123              [-1, 512, 32]               0
         Dropout-124              [-1, 512, 32]               0
          Conv1d-125              [-1, 512, 32]           8,704
 MyConv1dPadSame-126              [-1, 512, 32]               0
     BatchNorm1d-127              [-1, 512, 32]           1,024
            ReLU-128              [-1, 512, 32]               0
         Dropout-129              [-1, 512, 32]               0
          Conv1d-130              [-1, 512, 32]           8,704
 MyConv1dPadSame-131              [-1, 512, 32]               0
      Bottleneck-132              [-1, 512, 32]               0
     BatchNorm1d-133              [-1, 512, 32]           1,024
            ReLU-134              [-1, 512, 32]               0
         Dropout-135              [-1, 512, 32]               0
          Conv1d-136              [-1, 512, 16]           8,704
 MyConv1dPadSame-137              [-1, 512, 16]               0
     BatchNorm1d-138              [-1, 512, 16]           1,024
            ReLU-139              [-1, 512, 16]               0
         Dropout-140              [-1, 512, 16]               0
          Conv1d-141              [-1, 512, 16]           8,704
 MyConv1dPadSame-142              [-1, 512, 16]               0
       MaxPool1d-143              [-1, 512, 16]               0
MyMaxPool1dPadSame-144              [-1, 512, 16]               0
      Bottleneck-145              [-1, 512, 16]               0
     BatchNorm1d-146              [-1, 512, 16]           1,024
            ReLU-147              [-1, 512, 16]               0
         Dropout-148              [-1, 512, 16]               0
          Conv1d-149             [-1, 1024, 16]          17,408
 MyConv1dPadSame-150             [-1, 1024, 16]               0
     BatchNorm1d-151             [-1, 1024, 16]           2,048
            ReLU-152             [-1, 1024, 16]               0
         Dropout-153             [-1, 1024, 16]               0
          Conv1d-154             [-1, 1024, 16]          33,792
 MyConv1dPadSame-155             [-1, 1024, 16]               0
      Bottleneck-156             [-1, 1024, 16]               0
     BatchNorm1d-157             [-1, 1024, 16]           2,048
            ReLU-158             [-1, 1024, 16]               0
         Dropout-159             [-1, 1024, 16]               0
          Conv1d-160              [-1, 1024, 8]          33,792
 MyConv1dPadSame-161              [-1, 1024, 8]               0
     BatchNorm1d-162              [-1, 1024, 8]           2,048
            ReLU-163              [-1, 1024, 8]               0
         Dropout-164              [-1, 1024, 8]               0
          Conv1d-165              [-1, 1024, 8]          33,792
 MyConv1dPadSame-166              [-1, 1024, 8]               0
       MaxPool1d-167              [-1, 1024, 8]               0
MyMaxPool1dPadSame-168              [-1, 1024, 8]               0
      Bottleneck-169              [-1, 1024, 8]               0
     BatchNorm1d-170              [-1, 1024, 8]           2,048
            ReLU-171              [-1, 1024, 8]               0
         Dropout-172              [-1, 1024, 8]               0
          Conv1d-173              [-1, 1024, 8]          33,792
 MyConv1dPadSame-174              [-1, 1024, 8]               0
     BatchNorm1d-175              [-1, 1024, 8]           2,048
            ReLU-176              [-1, 1024, 8]               0
         Dropout-177              [-1, 1024, 8]               0
          Conv1d-178              [-1, 1024, 8]          33,792
 MyConv1dPadSame-179              [-1, 1024, 8]               0
      Bottleneck-180              [-1, 1024, 8]               0
     BatchNorm1d-181              [-1, 1024, 8]           2,048
            ReLU-182              [-1, 1024, 8]               0
         Dropout-183              [-1, 1024, 8]               0
          Conv1d-184              [-1, 1024, 4]          33,792
 MyConv1dPadSame-185              [-1, 1024, 4]               0
     BatchNorm1d-186              [-1, 1024, 4]           2,048
            ReLU-187              [-1, 1024, 4]               0
         Dropout-188              [-1, 1024, 4]               0
          Conv1d-189              [-1, 1024, 4]          33,792
 MyConv1dPadSame-190              [-1, 1024, 4]               0
       MaxPool1d-191              [-1, 1024, 4]               0
MyMaxPool1dPadSame-192              [-1, 1024, 4]               0
      Bottleneck-193              [-1, 1024, 4]               0
     BatchNorm1d-194              [-1, 1024, 4]           2,048
            ReLU-195              [-1, 1024, 4]               0
          Linear-196                    [-1, 2]           2,050
================================================================
Total params: 375,682
Trainable params: 375,682
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 53.19
Params size (MB): 1.43
Estimated Total Size (MB): 54.62
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 128, kernel_size: 8, n_block: 2
************************************************************
************************************************************
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1            [-1, 128, 1024]           1,152
   MyConv1dPadSame-2            [-1, 128, 1024]               0
       BatchNorm1d-3            [-1, 128, 1024]             256
              ReLU-4            [-1, 128, 1024]               0
            Conv1d-5            [-1, 128, 1024]           1,152
   MyConv1dPadSame-6            [-1, 128, 1024]               0
       BatchNorm1d-7            [-1, 128, 1024]             256
              ReLU-8            [-1, 128, 1024]               0
           Dropout-9            [-1, 128, 1024]               0
           Conv1d-10            [-1, 128, 1024]           1,152
  MyConv1dPadSame-11            [-1, 128, 1024]               0
       Bottleneck-12            [-1, 128, 1024]               0
      BatchNorm1d-13            [-1, 128, 1024]             256
             ReLU-14            [-1, 128, 1024]               0
          Dropout-15            [-1, 128, 1024]               0
           Conv1d-16            [-1, 256, 1024]           2,304
  MyConv1dPadSame-17            [-1, 256, 1024]               0
      BatchNorm1d-18            [-1, 256, 1024]             512
             ReLU-19            [-1, 256, 1024]               0
          Dropout-20            [-1, 256, 1024]               0
           Conv1d-21            [-1, 256, 1024]           4,352
  MyConv1dPadSame-22            [-1, 256, 1024]               0
       Bottleneck-23            [-1, 256, 1024]               0
      BatchNorm1d-24            [-1, 256, 1024]             512
             ReLU-25            [-1, 256, 1024]               0
           Linear-26                    [-1, 2]             514
================================================================
Total params: 12,418
Trainable params: 12,418
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 35.00
Params size (MB): 0.05
Estimated Total Size (MB): 35.05
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 128, kernel_size: 8, n_block: 4
************************************************************
************************************************************
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1            [-1, 128, 1024]           1,152
   MyConv1dPadSame-2            [-1, 128, 1024]               0
       BatchNorm1d-3            [-1, 128, 1024]             256
              ReLU-4            [-1, 128, 1024]               0
            Conv1d-5            [-1, 128, 1024]           1,152
   MyConv1dPadSame-6            [-1, 128, 1024]               0
       BatchNorm1d-7            [-1, 128, 1024]             256
              ReLU-8            [-1, 128, 1024]               0
           Dropout-9            [-1, 128, 1024]               0
           Conv1d-10            [-1, 128, 1024]           1,152
  MyConv1dPadSame-11            [-1, 128, 1024]               0
       Bottleneck-12            [-1, 128, 1024]               0
      BatchNorm1d-13            [-1, 128, 1024]             256
             ReLU-14            [-1, 128, 1024]               0
          Dropout-15            [-1, 128, 1024]               0
           Conv1d-16            [-1, 256, 1024]           2,304
  MyConv1dPadSame-17            [-1, 256, 1024]               0
      BatchNorm1d-18            [-1, 256, 1024]             512
             ReLU-19            [-1, 256, 1024]               0
          Dropout-20            [-1, 256, 1024]               0
           Conv1d-21            [-1, 256, 1024]           4,352
  MyConv1dPadSame-22            [-1, 256, 1024]               0
       Bottleneck-23            [-1, 256, 1024]               0
      BatchNorm1d-24            [-1, 256, 1024]             512
             ReLU-25            [-1, 256, 1024]               0
          Dropout-26            [-1, 256, 1024]               0
           Conv1d-27            [-1, 512, 1024]           8,704
  MyConv1dPadSame-28            [-1, 512, 1024]               0
      BatchNorm1d-29            [-1, 512, 1024]           1,024
             ReLU-30            [-1, 512, 1024]               0
          Dropout-31            [-1, 512, 1024]               0
           Conv1d-32            [-1, 512, 1024]          16,896
  MyConv1dPadSame-33            [-1, 512, 1024]               0
       Bottleneck-34            [-1, 512, 1024]               0
      BatchNorm1d-35            [-1, 512, 1024]           1,024
             ReLU-36            [-1, 512, 1024]               0
          Dropout-37            [-1, 512, 1024]               0
           Conv1d-38           [-1, 1024, 1024]          33,792
  MyConv1dPadSame-39           [-1, 1024, 1024]               0
      BatchNorm1d-40           [-1, 1024, 1024]           2,048
             ReLU-41           [-1, 1024, 1024]               0
          Dropout-42           [-1, 1024, 1024]               0
           Conv1d-43           [-1, 1024, 1024]          66,560
  MyConv1dPadSame-44           [-1, 1024, 1024]               0
       Bottleneck-45           [-1, 1024, 1024]               0
      BatchNorm1d-46           [-1, 1024, 1024]           2,048
             ReLU-47           [-1, 1024, 1024]               0
           Linear-48                    [-1, 2]           2,050
================================================================
Total params: 146,050
Trainable params: 146,050
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 161.00
Params size (MB): 0.56
Estimated Total Size (MB): 161.56
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 128, kernel_size: 8, n_block: 8
************************************************************
************************************************************
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1            [-1, 128, 1024]           1,152
   MyConv1dPadSame-2            [-1, 128, 1024]               0
       BatchNorm1d-3            [-1, 128, 1024]             256
              ReLU-4            [-1, 128, 1024]               0
            Conv1d-5            [-1, 128, 1024]           1,152
   MyConv1dPadSame-6            [-1, 128, 1024]               0
       BatchNorm1d-7            [-1, 128, 1024]             256
              ReLU-8            [-1, 128, 1024]               0
           Dropout-9            [-1, 128, 1024]               0
           Conv1d-10            [-1, 128, 1024]           1,152
  MyConv1dPadSame-11            [-1, 128, 1024]               0
       Bottleneck-12            [-1, 128, 1024]               0
      BatchNorm1d-13            [-1, 128, 1024]             256
             ReLU-14            [-1, 128, 1024]               0
          Dropout-15            [-1, 128, 1024]               0
           Conv1d-16            [-1, 128, 1024]           1,152
  MyConv1dPadSame-17            [-1, 128, 1024]               0
      BatchNorm1d-18            [-1, 128, 1024]             256
             ReLU-19            [-1, 128, 1024]               0
          Dropout-20            [-1, 128, 1024]               0
           Conv1d-21            [-1, 128, 1024]           1,152
  MyConv1dPadSame-22            [-1, 128, 1024]               0
       Bottleneck-23            [-1, 128, 1024]               0
      BatchNorm1d-24            [-1, 128, 1024]             256
             ReLU-25            [-1, 128, 1024]               0
          Dropout-26            [-1, 128, 1024]               0
           Conv1d-27            [-1, 256, 1024]           2,304
  MyConv1dPadSame-28            [-1, 256, 1024]               0
      BatchNorm1d-29            [-1, 256, 1024]             512
             ReLU-30            [-1, 256, 1024]               0
          Dropout-31            [-1, 256, 1024]               0
           Conv1d-32            [-1, 256, 1024]           4,352
  MyConv1dPadSame-33            [-1, 256, 1024]               0
       Bottleneck-34            [-1, 256, 1024]               0
      BatchNorm1d-35            [-1, 256, 1024]             512
             ReLU-36            [-1, 256, 1024]               0
          Dropout-37            [-1, 256, 1024]               0
           Conv1d-38            [-1, 256, 1024]           4,352
  MyConv1dPadSame-39            [-1, 256, 1024]               0
      BatchNorm1d-40            [-1, 256, 1024]             512
             ReLU-41            [-1, 256, 1024]               0
          Dropout-42            [-1, 256, 1024]               0
           Conv1d-43            [-1, 256, 1024]           4,352
  MyConv1dPadSame-44            [-1, 256, 1024]               0
       Bottleneck-45            [-1, 256, 1024]               0
      BatchNorm1d-46            [-1, 256, 1024]             512
             ReLU-47            [-1, 256, 1024]               0
          Dropout-48            [-1, 256, 1024]               0
           Conv1d-49            [-1, 512, 1024]           8,704
  MyConv1dPadSame-50            [-1, 512, 1024]               0
      BatchNorm1d-51            [-1, 512, 1024]           1,024
             ReLU-52            [-1, 512, 1024]               0
          Dropout-53            [-1, 512, 1024]               0
           Conv1d-54            [-1, 512, 1024]          16,896
  MyConv1dPadSame-55            [-1, 512, 1024]               0
       Bottleneck-56            [-1, 512, 1024]               0
      BatchNorm1d-57            [-1, 512, 1024]           1,024
             ReLU-58            [-1, 512, 1024]               0
          Dropout-59            [-1, 512, 1024]               0
           Conv1d-60            [-1, 512, 1024]          16,896
  MyConv1dPadSame-61            [-1, 512, 1024]               0
      BatchNorm1d-62            [-1, 512, 1024]           1,024
             ReLU-63            [-1, 512, 1024]               0
          Dropout-64            [-1, 512, 1024]               0
           Conv1d-65            [-1, 512, 1024]          16,896
  MyConv1dPadSame-66            [-1, 512, 1024]               0
       Bottleneck-67            [-1, 512, 1024]               0
      BatchNorm1d-68            [-1, 512, 1024]           1,024
             ReLU-69            [-1, 512, 1024]               0
          Dropout-70            [-1, 512, 1024]               0
           Conv1d-71           [-1, 1024, 1024]          33,792
  MyConv1dPadSame-72           [-1, 1024, 1024]               0
      BatchNorm1d-73           [-1, 1024, 1024]           2,048
             ReLU-74           [-1, 1024, 1024]               0
          Dropout-75           [-1, 1024, 1024]               0
           Conv1d-76           [-1, 1024, 1024]          66,560
  MyConv1dPadSame-77           [-1, 1024, 1024]               0
       Bottleneck-78           [-1, 1024, 1024]               0
      BatchNorm1d-79           [-1, 1024, 1024]           2,048
             ReLU-80           [-1, 1024, 1024]               0
          Dropout-81           [-1, 1024, 1024]               0
           Conv1d-82           [-1, 1024, 1024]          66,560
  MyConv1dPadSame-83           [-1, 1024, 1024]               0
      BatchNorm1d-84           [-1, 1024, 1024]           2,048
             ReLU-85           [-1, 1024, 1024]               0
          Dropout-86           [-1, 1024, 1024]               0
           Conv1d-87           [-1, 1024, 1024]          66,560
  MyConv1dPadSame-88           [-1, 1024, 1024]               0
       Bottleneck-89           [-1, 1024, 1024]               0
      BatchNorm1d-90           [-1, 1024, 1024]           2,048
             ReLU-91           [-1, 1024, 1024]               0
           Linear-92                    [-1, 2]           2,050
================================================================
Total params: 331,650
Trainable params: 331,650
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 326.00
Params size (MB): 1.27
Estimated Total Size (MB): 327.27
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 128, kernel_size: 8, n_block: 16
************************************************************
************************************************************
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1            [-1, 128, 1024]           1,152
   MyConv1dPadSame-2            [-1, 128, 1024]               0
       BatchNorm1d-3            [-1, 128, 1024]             256
              ReLU-4            [-1, 128, 1024]               0
            Conv1d-5            [-1, 128, 1024]           1,152
   MyConv1dPadSame-6            [-1, 128, 1024]               0
       BatchNorm1d-7            [-1, 128, 1024]             256
              ReLU-8            [-1, 128, 1024]               0
           Dropout-9            [-1, 128, 1024]               0
           Conv1d-10            [-1, 128, 1024]           1,152
  MyConv1dPadSame-11            [-1, 128, 1024]               0
       Bottleneck-12            [-1, 128, 1024]               0
      BatchNorm1d-13            [-1, 128, 1024]             256
             ReLU-14            [-1, 128, 1024]               0
          Dropout-15            [-1, 128, 1024]               0
           Conv1d-16             [-1, 128, 512]           1,152
  MyConv1dPadSame-17             [-1, 128, 512]               0
      BatchNorm1d-18             [-1, 128, 512]             256
             ReLU-19             [-1, 128, 512]               0
          Dropout-20             [-1, 128, 512]               0
           Conv1d-21             [-1, 128, 512]           1,152
  MyConv1dPadSame-22             [-1, 128, 512]               0
        MaxPool1d-23             [-1, 128, 512]               0
MyMaxPool1dPadSame-24             [-1, 128, 512]               0
       Bottleneck-25             [-1, 128, 512]               0
      BatchNorm1d-26             [-1, 128, 512]             256
             ReLU-27             [-1, 128, 512]               0
          Dropout-28             [-1, 128, 512]               0
           Conv1d-29             [-1, 128, 512]           1,152
  MyConv1dPadSame-30             [-1, 128, 512]               0
      BatchNorm1d-31             [-1, 128, 512]             256
             ReLU-32             [-1, 128, 512]               0
          Dropout-33             [-1, 128, 512]               0
           Conv1d-34             [-1, 128, 512]           1,152
  MyConv1dPadSame-35             [-1, 128, 512]               0
       Bottleneck-36             [-1, 128, 512]               0
      BatchNorm1d-37             [-1, 128, 512]             256
             ReLU-38             [-1, 128, 512]               0
          Dropout-39             [-1, 128, 512]               0
           Conv1d-40             [-1, 128, 256]           1,152
  MyConv1dPadSame-41             [-1, 128, 256]               0
      BatchNorm1d-42             [-1, 128, 256]             256
             ReLU-43             [-1, 128, 256]               0
          Dropout-44             [-1, 128, 256]               0
           Conv1d-45             [-1, 128, 256]           1,152
  MyConv1dPadSame-46             [-1, 128, 256]               0
        MaxPool1d-47             [-1, 128, 256]               0
MyMaxPool1dPadSame-48             [-1, 128, 256]               0
       Bottleneck-49             [-1, 128, 256]               0
      BatchNorm1d-50             [-1, 128, 256]             256
             ReLU-51             [-1, 128, 256]               0
          Dropout-52             [-1, 128, 256]               0
           Conv1d-53             [-1, 256, 256]           2,304
  MyConv1dPadSame-54             [-1, 256, 256]               0
      BatchNorm1d-55             [-1, 256, 256]             512
             ReLU-56             [-1, 256, 256]               0
          Dropout-57             [-1, 256, 256]               0
           Conv1d-58             [-1, 256, 256]           4,352
  MyConv1dPadSame-59             [-1, 256, 256]               0
       Bottleneck-60             [-1, 256, 256]               0
      BatchNorm1d-61             [-1, 256, 256]             512
             ReLU-62             [-1, 256, 256]               0
          Dropout-63             [-1, 256, 256]               0
           Conv1d-64             [-1, 256, 128]           4,352
  MyConv1dPadSame-65             [-1, 256, 128]               0
      BatchNorm1d-66             [-1, 256, 128]             512
             ReLU-67             [-1, 256, 128]               0
          Dropout-68             [-1, 256, 128]               0
           Conv1d-69             [-1, 256, 128]           4,352
  MyConv1dPadSame-70             [-1, 256, 128]               0
        MaxPool1d-71             [-1, 256, 128]               0
MyMaxPool1dPadSame-72             [-1, 256, 128]               0
       Bottleneck-73             [-1, 256, 128]               0
      BatchNorm1d-74             [-1, 256, 128]             512
             ReLU-75             [-1, 256, 128]               0
          Dropout-76             [-1, 256, 128]               0
           Conv1d-77             [-1, 256, 128]           4,352
  MyConv1dPadSame-78             [-1, 256, 128]               0
      BatchNorm1d-79             [-1, 256, 128]             512
             ReLU-80             [-1, 256, 128]               0
          Dropout-81             [-1, 256, 128]               0
           Conv1d-82             [-1, 256, 128]           4,352
  MyConv1dPadSame-83             [-1, 256, 128]               0
       Bottleneck-84             [-1, 256, 128]               0
      BatchNorm1d-85             [-1, 256, 128]             512
             ReLU-86             [-1, 256, 128]               0
          Dropout-87             [-1, 256, 128]               0
           Conv1d-88              [-1, 256, 64]           4,352
  MyConv1dPadSame-89              [-1, 256, 64]               0
      BatchNorm1d-90              [-1, 256, 64]             512
             ReLU-91              [-1, 256, 64]               0
          Dropout-92              [-1, 256, 64]               0
           Conv1d-93              [-1, 256, 64]           4,352
  MyConv1dPadSame-94              [-1, 256, 64]               0
        MaxPool1d-95              [-1, 256, 64]               0
MyMaxPool1dPadSame-96              [-1, 256, 64]               0
       Bottleneck-97              [-1, 256, 64]               0
      BatchNorm1d-98              [-1, 256, 64]             512
             ReLU-99              [-1, 256, 64]               0
         Dropout-100              [-1, 256, 64]               0
          Conv1d-101              [-1, 512, 64]           8,704
 MyConv1dPadSame-102              [-1, 512, 64]               0
     BatchNorm1d-103              [-1, 512, 64]           1,024
            ReLU-104              [-1, 512, 64]               0
         Dropout-105              [-1, 512, 64]               0
          Conv1d-106              [-1, 512, 64]          16,896
 MyConv1dPadSame-107              [-1, 512, 64]               0
      Bottleneck-108              [-1, 512, 64]               0
     BatchNorm1d-109              [-1, 512, 64]           1,024
            ReLU-110              [-1, 512, 64]               0
         Dropout-111              [-1, 512, 64]               0
          Conv1d-112              [-1, 512, 32]          16,896
 MyConv1dPadSame-113              [-1, 512, 32]               0
     BatchNorm1d-114              [-1, 512, 32]           1,024
            ReLU-115              [-1, 512, 32]               0
         Dropout-116              [-1, 512, 32]               0
          Conv1d-117              [-1, 512, 32]          16,896
 MyConv1dPadSame-118              [-1, 512, 32]               0
       MaxPool1d-119              [-1, 512, 32]               0
MyMaxPool1dPadSame-120              [-1, 512, 32]               0
      Bottleneck-121              [-1, 512, 32]               0
     BatchNorm1d-122              [-1, 512, 32]           1,024
            ReLU-123              [-1, 512, 32]               0
         Dropout-124              [-1, 512, 32]               0
          Conv1d-125              [-1, 512, 32]          16,896
 MyConv1dPadSame-126              [-1, 512, 32]               0
     BatchNorm1d-127              [-1, 512, 32]           1,024
            ReLU-128              [-1, 512, 32]               0
         Dropout-129              [-1, 512, 32]               0
          Conv1d-130              [-1, 512, 32]          16,896
 MyConv1dPadSame-131              [-1, 512, 32]               0
      Bottleneck-132              [-1, 512, 32]               0
     BatchNorm1d-133              [-1, 512, 32]           1,024
            ReLU-134              [-1, 512, 32]               0
         Dropout-135              [-1, 512, 32]               0
          Conv1d-136              [-1, 512, 16]          16,896
 MyConv1dPadSame-137              [-1, 512, 16]               0
     BatchNorm1d-138              [-1, 512, 16]           1,024
            ReLU-139              [-1, 512, 16]               0
         Dropout-140              [-1, 512, 16]               0
          Conv1d-141              [-1, 512, 16]          16,896
 MyConv1dPadSame-142              [-1, 512, 16]               0
       MaxPool1d-143              [-1, 512, 16]               0
MyMaxPool1dPadSame-144              [-1, 512, 16]               0
      Bottleneck-145              [-1, 512, 16]               0
     BatchNorm1d-146              [-1, 512, 16]           1,024
            ReLU-147              [-1, 512, 16]               0
         Dropout-148              [-1, 512, 16]               0
          Conv1d-149             [-1, 1024, 16]          33,792
 MyConv1dPadSame-150             [-1, 1024, 16]               0
     BatchNorm1d-151             [-1, 1024, 16]           2,048
            ReLU-152             [-1, 1024, 16]               0
         Dropout-153             [-1, 1024, 16]               0
          Conv1d-154             [-1, 1024, 16]          66,560
 MyConv1dPadSame-155             [-1, 1024, 16]               0
      Bottleneck-156             [-1, 1024, 16]               0
     BatchNorm1d-157             [-1, 1024, 16]           2,048
            ReLU-158             [-1, 1024, 16]               0
         Dropout-159             [-1, 1024, 16]               0
          Conv1d-160              [-1, 1024, 8]          66,560
 MyConv1dPadSame-161              [-1, 1024, 8]               0
     BatchNorm1d-162              [-1, 1024, 8]           2,048
            ReLU-163              [-1, 1024, 8]               0
         Dropout-164              [-1, 1024, 8]               0
          Conv1d-165              [-1, 1024, 8]          66,560
 MyConv1dPadSame-166              [-1, 1024, 8]               0
       MaxPool1d-167              [-1, 1024, 8]               0
MyMaxPool1dPadSame-168              [-1, 1024, 8]               0
      Bottleneck-169              [-1, 1024, 8]               0
     BatchNorm1d-170              [-1, 1024, 8]           2,048
            ReLU-171              [-1, 1024, 8]               0
         Dropout-172              [-1, 1024, 8]               0
          Conv1d-173              [-1, 1024, 8]          66,560
 MyConv1dPadSame-174              [-1, 1024, 8]               0
     BatchNorm1d-175              [-1, 1024, 8]           2,048
            ReLU-176              [-1, 1024, 8]               0
         Dropout-177              [-1, 1024, 8]               0
          Conv1d-178              [-1, 1024, 8]          66,560
 MyConv1dPadSame-179              [-1, 1024, 8]               0
      Bottleneck-180              [-1, 1024, 8]               0
     BatchNorm1d-181              [-1, 1024, 8]           2,048
            ReLU-182              [-1, 1024, 8]               0
         Dropout-183              [-1, 1024, 8]               0
          Conv1d-184              [-1, 1024, 4]          66,560
 MyConv1dPadSame-185              [-1, 1024, 4]               0
     BatchNorm1d-186              [-1, 1024, 4]           2,048
            ReLU-187              [-1, 1024, 4]               0
         Dropout-188              [-1, 1024, 4]               0
          Conv1d-189              [-1, 1024, 4]          66,560
 MyConv1dPadSame-190              [-1, 1024, 4]               0
       MaxPool1d-191              [-1, 1024, 4]               0
MyMaxPool1dPadSame-192              [-1, 1024, 4]               0
      Bottleneck-193              [-1, 1024, 4]               0
     BatchNorm1d-194              [-1, 1024, 4]           2,048
            ReLU-195              [-1, 1024, 4]               0
          Linear-196                    [-1, 2]           2,050
================================================================
Total params: 702,850
Trainable params: 702,850
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 53.19
Params size (MB): 2.68
Estimated Total Size (MB): 55.87
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 128, kernel_size: 16, n_block: 2
************************************************************
************************************************************
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1            [-1, 128, 1024]           2,176
   MyConv1dPadSame-2            [-1, 128, 1024]               0
       BatchNorm1d-3            [-1, 128, 1024]             256
              ReLU-4            [-1, 128, 1024]               0
            Conv1d-5            [-1, 128, 1024]           2,176
   MyConv1dPadSame-6            [-1, 128, 1024]               0
       BatchNorm1d-7            [-1, 128, 1024]             256
              ReLU-8            [-1, 128, 1024]               0
           Dropout-9            [-1, 128, 1024]               0
           Conv1d-10            [-1, 128, 1024]           2,176
  MyConv1dPadSame-11            [-1, 128, 1024]               0
       Bottleneck-12            [-1, 128, 1024]               0
      BatchNorm1d-13            [-1, 128, 1024]             256
             ReLU-14            [-1, 128, 1024]               0
          Dropout-15            [-1, 128, 1024]               0
           Conv1d-16            [-1, 256, 1024]           4,352
  MyConv1dPadSame-17            [-1, 256, 1024]               0
      BatchNorm1d-18            [-1, 256, 1024]             512
             ReLU-19            [-1, 256, 1024]               0
          Dropout-20            [-1, 256, 1024]               0
           Conv1d-21            [-1, 256, 1024]           8,448
  MyConv1dPadSame-22            [-1, 256, 1024]               0
       Bottleneck-23            [-1, 256, 1024]               0
      BatchNorm1d-24            [-1, 256, 1024]             512
             ReLU-25            [-1, 256, 1024]               0
           Linear-26                    [-1, 2]             514
================================================================
Total params: 21,634
Trainable params: 21,634
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 35.00
Params size (MB): 0.08
Estimated Total Size (MB): 35.09
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 128, kernel_size: 16, n_block: 4
************************************************************
************************************************************
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1            [-1, 128, 1024]           2,176
   MyConv1dPadSame-2            [-1, 128, 1024]               0
       BatchNorm1d-3            [-1, 128, 1024]             256
              ReLU-4            [-1, 128, 1024]               0
            Conv1d-5            [-1, 128, 1024]           2,176
   MyConv1dPadSame-6            [-1, 128, 1024]               0
       BatchNorm1d-7            [-1, 128, 1024]             256
              ReLU-8            [-1, 128, 1024]               0
           Dropout-9            [-1, 128, 1024]               0
           Conv1d-10            [-1, 128, 1024]           2,176
  MyConv1dPadSame-11            [-1, 128, 1024]               0
       Bottleneck-12            [-1, 128, 1024]               0
      BatchNorm1d-13            [-1, 128, 1024]             256
             ReLU-14            [-1, 128, 1024]               0
          Dropout-15            [-1, 128, 1024]               0
           Conv1d-16            [-1, 256, 1024]           4,352
  MyConv1dPadSame-17            [-1, 256, 1024]               0
      BatchNorm1d-18            [-1, 256, 1024]             512
             ReLU-19            [-1, 256, 1024]               0
          Dropout-20            [-1, 256, 1024]               0
           Conv1d-21            [-1, 256, 1024]           8,448
  MyConv1dPadSame-22            [-1, 256, 1024]               0
       Bottleneck-23            [-1, 256, 1024]               0
      BatchNorm1d-24            [-1, 256, 1024]             512
             ReLU-25            [-1, 256, 1024]               0
          Dropout-26            [-1, 256, 1024]               0
           Conv1d-27            [-1, 512, 1024]          16,896
  MyConv1dPadSame-28            [-1, 512, 1024]               0
      BatchNorm1d-29            [-1, 512, 1024]           1,024
             ReLU-30            [-1, 512, 1024]               0
          Dropout-31            [-1, 512, 1024]               0
           Conv1d-32            [-1, 512, 1024]          33,280
  MyConv1dPadSame-33            [-1, 512, 1024]               0
       Bottleneck-34            [-1, 512, 1024]               0
      BatchNorm1d-35            [-1, 512, 1024]           1,024
             ReLU-36            [-1, 512, 1024]               0
          Dropout-37            [-1, 512, 1024]               0
           Conv1d-38           [-1, 1024, 1024]          66,560
  MyConv1dPadSame-39           [-1, 1024, 1024]               0
      BatchNorm1d-40           [-1, 1024, 1024]           2,048
             ReLU-41           [-1, 1024, 1024]               0
          Dropout-42           [-1, 1024, 1024]               0
           Conv1d-43           [-1, 1024, 1024]         132,096
  MyConv1dPadSame-44           [-1, 1024, 1024]               0
       Bottleneck-45           [-1, 1024, 1024]               0
      BatchNorm1d-46           [-1, 1024, 1024]           2,048
             ReLU-47           [-1, 1024, 1024]               0
           Linear-48                    [-1, 2]           2,050
================================================================
Total params: 278,146
Trainable params: 278,146
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 161.00
Params size (MB): 1.06
Estimated Total Size (MB): 162.06
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 128, kernel_size: 16, n_block: 8
************************************************************
************************************************************
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1            [-1, 128, 1024]           2,176
   MyConv1dPadSame-2            [-1, 128, 1024]               0
       BatchNorm1d-3            [-1, 128, 1024]             256
              ReLU-4            [-1, 128, 1024]               0
            Conv1d-5            [-1, 128, 1024]           2,176
   MyConv1dPadSame-6            [-1, 128, 1024]               0
       BatchNorm1d-7            [-1, 128, 1024]             256
              ReLU-8            [-1, 128, 1024]               0
           Dropout-9            [-1, 128, 1024]               0
           Conv1d-10            [-1, 128, 1024]           2,176
  MyConv1dPadSame-11            [-1, 128, 1024]               0
       Bottleneck-12            [-1, 128, 1024]               0
      BatchNorm1d-13            [-1, 128, 1024]             256
             ReLU-14            [-1, 128, 1024]               0
          Dropout-15            [-1, 128, 1024]               0
           Conv1d-16            [-1, 128, 1024]           2,176
  MyConv1dPadSame-17            [-1, 128, 1024]               0
      BatchNorm1d-18            [-1, 128, 1024]             256
             ReLU-19            [-1, 128, 1024]               0
          Dropout-20            [-1, 128, 1024]               0
           Conv1d-21            [-1, 128, 1024]           2,176
  MyConv1dPadSame-22            [-1, 128, 1024]               0
       Bottleneck-23            [-1, 128, 1024]               0
      BatchNorm1d-24            [-1, 128, 1024]             256
             ReLU-25            [-1, 128, 1024]               0
          Dropout-26            [-1, 128, 1024]               0
           Conv1d-27            [-1, 256, 1024]           4,352
  MyConv1dPadSame-28            [-1, 256, 1024]               0
      BatchNorm1d-29            [-1, 256, 1024]             512
             ReLU-30            [-1, 256, 1024]               0
          Dropout-31            [-1, 256, 1024]               0
           Conv1d-32            [-1, 256, 1024]           8,448
  MyConv1dPadSame-33            [-1, 256, 1024]               0
       Bottleneck-34            [-1, 256, 1024]               0
      BatchNorm1d-35            [-1, 256, 1024]             512
             ReLU-36            [-1, 256, 1024]               0
          Dropout-37            [-1, 256, 1024]               0
           Conv1d-38            [-1, 256, 1024]           8,448
  MyConv1dPadSame-39            [-1, 256, 1024]               0
      BatchNorm1d-40            [-1, 256, 1024]             512
             ReLU-41            [-1, 256, 1024]               0
          Dropout-42            [-1, 256, 1024]               0
           Conv1d-43            [-1, 256, 1024]           8,448
  MyConv1dPadSame-44            [-1, 256, 1024]               0
       Bottleneck-45            [-1, 256, 1024]               0
      BatchNorm1d-46            [-1, 256, 1024]             512
             ReLU-47            [-1, 256, 1024]               0
          Dropout-48            [-1, 256, 1024]               0
           Conv1d-49            [-1, 512, 1024]          16,896
  MyConv1dPadSame-50            [-1, 512, 1024]               0
      BatchNorm1d-51            [-1, 512, 1024]           1,024
             ReLU-52            [-1, 512, 1024]               0
          Dropout-53            [-1, 512, 1024]               0
           Conv1d-54            [-1, 512, 1024]          33,280
  MyConv1dPadSame-55            [-1, 512, 1024]               0
       Bottleneck-56            [-1, 512, 1024]               0
      BatchNorm1d-57            [-1, 512, 1024]           1,024
             ReLU-58            [-1, 512, 1024]               0
          Dropout-59            [-1, 512, 1024]               0
           Conv1d-60            [-1, 512, 1024]          33,280
  MyConv1dPadSame-61            [-1, 512, 1024]               0
      BatchNorm1d-62            [-1, 512, 1024]           1,024
             ReLU-63            [-1, 512, 1024]               0
          Dropout-64            [-1, 512, 1024]               0
           Conv1d-65            [-1, 512, 1024]          33,280
  MyConv1dPadSame-66            [-1, 512, 1024]               0
       Bottleneck-67            [-1, 512, 1024]               0
      BatchNorm1d-68            [-1, 512, 1024]           1,024
             ReLU-69            [-1, 512, 1024]               0
          Dropout-70            [-1, 512, 1024]               0
           Conv1d-71           [-1, 1024, 1024]          66,560
  MyConv1dPadSame-72           [-1, 1024, 1024]               0
      BatchNorm1d-73           [-1, 1024, 1024]           2,048
             ReLU-74           [-1, 1024, 1024]               0
          Dropout-75           [-1, 1024, 1024]               0
           Conv1d-76           [-1, 1024, 1024]         132,096
  MyConv1dPadSame-77           [-1, 1024, 1024]               0
       Bottleneck-78           [-1, 1024, 1024]               0
      BatchNorm1d-79           [-1, 1024, 1024]           2,048
             ReLU-80           [-1, 1024, 1024]               0
          Dropout-81           [-1, 1024, 1024]               0
           Conv1d-82           [-1, 1024, 1024]         132,096
  MyConv1dPadSame-83           [-1, 1024, 1024]               0
      BatchNorm1d-84           [-1, 1024, 1024]           2,048
             ReLU-85           [-1, 1024, 1024]               0
          Dropout-86           [-1, 1024, 1024]               0
           Conv1d-87           [-1, 1024, 1024]         132,096
  MyConv1dPadSame-88           [-1, 1024, 1024]               0
       Bottleneck-89           [-1, 1024, 1024]               0
      BatchNorm1d-90           [-1, 1024, 1024]           2,048
             ReLU-91           [-1, 1024, 1024]               0
           Linear-92                    [-1, 2]           2,050
================================================================
Total params: 637,826
Trainable params: 637,826
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 326.00
Params size (MB): 2.43
Estimated Total Size (MB): 328.44
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 1024, base_filters: 128, kernel_size: 16, n_block: 16
************************************************************
************************************************************
(2000, 1, 1024) Counter({0: 1000, 1: 1000})
(2000, 1, 1024) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1            [-1, 128, 1024]           2,176
   MyConv1dPadSame-2            [-1, 128, 1024]               0
       BatchNorm1d-3            [-1, 128, 1024]             256
              ReLU-4            [-1, 128, 1024]               0
            Conv1d-5            [-1, 128, 1024]           2,176
   MyConv1dPadSame-6            [-1, 128, 1024]               0
       BatchNorm1d-7            [-1, 128, 1024]             256
              ReLU-8            [-1, 128, 1024]               0
           Dropout-9            [-1, 128, 1024]               0
           Conv1d-10            [-1, 128, 1024]           2,176
  MyConv1dPadSame-11            [-1, 128, 1024]               0
       Bottleneck-12            [-1, 128, 1024]               0
      BatchNorm1d-13            [-1, 128, 1024]             256
             ReLU-14            [-1, 128, 1024]               0
          Dropout-15            [-1, 128, 1024]               0
           Conv1d-16             [-1, 128, 512]           2,176
  MyConv1dPadSame-17             [-1, 128, 512]               0
      BatchNorm1d-18             [-1, 128, 512]             256
             ReLU-19             [-1, 128, 512]               0
          Dropout-20             [-1, 128, 512]               0
           Conv1d-21             [-1, 128, 512]           2,176
  MyConv1dPadSame-22             [-1, 128, 512]               0
        MaxPool1d-23             [-1, 128, 512]               0
MyMaxPool1dPadSame-24             [-1, 128, 512]               0
       Bottleneck-25             [-1, 128, 512]               0
      BatchNorm1d-26             [-1, 128, 512]             256
             ReLU-27             [-1, 128, 512]               0
          Dropout-28             [-1, 128, 512]               0
           Conv1d-29             [-1, 128, 512]           2,176
  MyConv1dPadSame-30             [-1, 128, 512]               0
      BatchNorm1d-31             [-1, 128, 512]             256
             ReLU-32             [-1, 128, 512]               0
          Dropout-33             [-1, 128, 512]               0
           Conv1d-34             [-1, 128, 512]           2,176
  MyConv1dPadSame-35             [-1, 128, 512]               0
       Bottleneck-36             [-1, 128, 512]               0
      BatchNorm1d-37             [-1, 128, 512]             256
             ReLU-38             [-1, 128, 512]               0
          Dropout-39             [-1, 128, 512]               0
           Conv1d-40             [-1, 128, 256]           2,176
  MyConv1dPadSame-41             [-1, 128, 256]               0
      BatchNorm1d-42             [-1, 128, 256]             256
             ReLU-43             [-1, 128, 256]               0
          Dropout-44             [-1, 128, 256]               0
           Conv1d-45             [-1, 128, 256]           2,176
  MyConv1dPadSame-46             [-1, 128, 256]               0
        MaxPool1d-47             [-1, 128, 256]               0
MyMaxPool1dPadSame-48             [-1, 128, 256]               0
       Bottleneck-49             [-1, 128, 256]               0
      BatchNorm1d-50             [-1, 128, 256]             256
             ReLU-51             [-1, 128, 256]               0
          Dropout-52             [-1, 128, 256]               0
           Conv1d-53             [-1, 256, 256]           4,352
  MyConv1dPadSame-54             [-1, 256, 256]               0
      BatchNorm1d-55             [-1, 256, 256]             512
             ReLU-56             [-1, 256, 256]               0
          Dropout-57             [-1, 256, 256]               0
           Conv1d-58             [-1, 256, 256]           8,448
  MyConv1dPadSame-59             [-1, 256, 256]               0
       Bottleneck-60             [-1, 256, 256]               0
      BatchNorm1d-61             [-1, 256, 256]             512
             ReLU-62             [-1, 256, 256]               0
          Dropout-63             [-1, 256, 256]               0
           Conv1d-64             [-1, 256, 128]           8,448
  MyConv1dPadSame-65             [-1, 256, 128]               0
      BatchNorm1d-66             [-1, 256, 128]             512
             ReLU-67             [-1, 256, 128]               0
          Dropout-68             [-1, 256, 128]               0
           Conv1d-69             [-1, 256, 128]           8,448
  MyConv1dPadSame-70             [-1, 256, 128]               0
        MaxPool1d-71             [-1, 256, 128]               0
MyMaxPool1dPadSame-72             [-1, 256, 128]               0
       Bottleneck-73             [-1, 256, 128]               0
      BatchNorm1d-74             [-1, 256, 128]             512
             ReLU-75             [-1, 256, 128]               0
          Dropout-76             [-1, 256, 128]               0
           Conv1d-77             [-1, 256, 128]           8,448
  MyConv1dPadSame-78             [-1, 256, 128]               0
      BatchNorm1d-79             [-1, 256, 128]             512
             ReLU-80             [-1, 256, 128]               0
          Dropout-81             [-1, 256, 128]               0
           Conv1d-82             [-1, 256, 128]           8,448
  MyConv1dPadSame-83             [-1, 256, 128]               0
       Bottleneck-84             [-1, 256, 128]               0
      BatchNorm1d-85             [-1, 256, 128]             512
             ReLU-86             [-1, 256, 128]               0
          Dropout-87             [-1, 256, 128]               0
           Conv1d-88              [-1, 256, 64]           8,448
  MyConv1dPadSame-89              [-1, 256, 64]               0
      BatchNorm1d-90              [-1, 256, 64]             512
             ReLU-91              [-1, 256, 64]               0
          Dropout-92              [-1, 256, 64]               0
           Conv1d-93              [-1, 256, 64]           8,448
  MyConv1dPadSame-94              [-1, 256, 64]               0
        MaxPool1d-95              [-1, 256, 64]               0
MyMaxPool1dPadSame-96              [-1, 256, 64]               0
       Bottleneck-97              [-1, 256, 64]               0
      BatchNorm1d-98              [-1, 256, 64]             512
             ReLU-99              [-1, 256, 64]               0
         Dropout-100              [-1, 256, 64]               0
          Conv1d-101              [-1, 512, 64]          16,896
 MyConv1dPadSame-102              [-1, 512, 64]               0
     BatchNorm1d-103              [-1, 512, 64]           1,024
            ReLU-104              [-1, 512, 64]               0
         Dropout-105              [-1, 512, 64]               0
          Conv1d-106              [-1, 512, 64]          33,280
 MyConv1dPadSame-107              [-1, 512, 64]               0
      Bottleneck-108              [-1, 512, 64]               0
     BatchNorm1d-109              [-1, 512, 64]           1,024
            ReLU-110              [-1, 512, 64]               0
         Dropout-111              [-1, 512, 64]               0
          Conv1d-112              [-1, 512, 32]          33,280
 MyConv1dPadSame-113              [-1, 512, 32]               0
     BatchNorm1d-114              [-1, 512, 32]           1,024
            ReLU-115              [-1, 512, 32]               0
         Dropout-116              [-1, 512, 32]               0
          Conv1d-117              [-1, 512, 32]          33,280
 MyConv1dPadSame-118              [-1, 512, 32]               0
       MaxPool1d-119              [-1, 512, 32]               0
MyMaxPool1dPadSame-120              [-1, 512, 32]               0
      Bottleneck-121              [-1, 512, 32]               0
     BatchNorm1d-122              [-1, 512, 32]           1,024
            ReLU-123              [-1, 512, 32]               0
         Dropout-124              [-1, 512, 32]               0
          Conv1d-125              [-1, 512, 32]          33,280
 MyConv1dPadSame-126              [-1, 512, 32]               0
     BatchNorm1d-127              [-1, 512, 32]           1,024
            ReLU-128              [-1, 512, 32]               0
         Dropout-129              [-1, 512, 32]               0
          Conv1d-130              [-1, 512, 32]          33,280
 MyConv1dPadSame-131              [-1, 512, 32]               0
      Bottleneck-132              [-1, 512, 32]               0
     BatchNorm1d-133              [-1, 512, 32]           1,024
            ReLU-134              [-1, 512, 32]               0
         Dropout-135              [-1, 512, 32]               0
          Conv1d-136              [-1, 512, 16]          33,280
 MyConv1dPadSame-137              [-1, 512, 16]               0
     BatchNorm1d-138              [-1, 512, 16]           1,024
            ReLU-139              [-1, 512, 16]               0
         Dropout-140              [-1, 512, 16]               0
          Conv1d-141              [-1, 512, 16]          33,280
 MyConv1dPadSame-142              [-1, 512, 16]               0
       MaxPool1d-143              [-1, 512, 16]               0
MyMaxPool1dPadSame-144              [-1, 512, 16]               0
      Bottleneck-145              [-1, 512, 16]               0
     BatchNorm1d-146              [-1, 512, 16]           1,024
            ReLU-147              [-1, 512, 16]               0
         Dropout-148              [-1, 512, 16]               0
          Conv1d-149             [-1, 1024, 16]          66,560
 MyConv1dPadSame-150             [-1, 1024, 16]               0
     BatchNorm1d-151             [-1, 1024, 16]           2,048
            ReLU-152             [-1, 1024, 16]               0
         Dropout-153             [-1, 1024, 16]               0
          Conv1d-154             [-1, 1024, 16]         132,096
 MyConv1dPadSame-155             [-1, 1024, 16]               0
      Bottleneck-156             [-1, 1024, 16]               0
     BatchNorm1d-157             [-1, 1024, 16]           2,048
            ReLU-158             [-1, 1024, 16]               0
         Dropout-159             [-1, 1024, 16]               0
          Conv1d-160              [-1, 1024, 8]         132,096
 MyConv1dPadSame-161              [-1, 1024, 8]               0
     BatchNorm1d-162              [-1, 1024, 8]           2,048
            ReLU-163              [-1, 1024, 8]               0
         Dropout-164              [-1, 1024, 8]               0
          Conv1d-165              [-1, 1024, 8]         132,096
 MyConv1dPadSame-166              [-1, 1024, 8]               0
       MaxPool1d-167              [-1, 1024, 8]               0
MyMaxPool1dPadSame-168              [-1, 1024, 8]               0
      Bottleneck-169              [-1, 1024, 8]               0
     BatchNorm1d-170              [-1, 1024, 8]           2,048
            ReLU-171              [-1, 1024, 8]               0
         Dropout-172              [-1, 1024, 8]               0
          Conv1d-173              [-1, 1024, 8]         132,096
 MyConv1dPadSame-174              [-1, 1024, 8]               0
     BatchNorm1d-175              [-1, 1024, 8]           2,048
            ReLU-176              [-1, 1024, 8]               0
         Dropout-177              [-1, 1024, 8]               0
          Conv1d-178              [-1, 1024, 8]         132,096
 MyConv1dPadSame-179              [-1, 1024, 8]               0
      Bottleneck-180              [-1, 1024, 8]               0
     BatchNorm1d-181              [-1, 1024, 8]           2,048
            ReLU-182              [-1, 1024, 8]               0
         Dropout-183              [-1, 1024, 8]               0
          Conv1d-184              [-1, 1024, 4]         132,096
 MyConv1dPadSame-185              [-1, 1024, 4]               0
     BatchNorm1d-186              [-1, 1024, 4]           2,048
            ReLU-187              [-1, 1024, 4]               0
         Dropout-188              [-1, 1024, 4]               0
          Conv1d-189              [-1, 1024, 4]         132,096
 MyConv1dPadSame-190              [-1, 1024, 4]               0
       MaxPool1d-191              [-1, 1024, 4]               0
MyMaxPool1dPadSame-192              [-1, 1024, 4]               0
      Bottleneck-193              [-1, 1024, 4]               0
     BatchNorm1d-194              [-1, 1024, 4]           2,048
            ReLU-195              [-1, 1024, 4]               0
          Linear-196                    [-1, 2]           2,050
================================================================
Total params: 1,357,186
Trainable params: 1,357,186
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 53.19
Params size (MB): 5.18
Estimated Total Size (MB): 58.37
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 8, kernel_size: 2, n_block: 2
************************************************************
************************************************************
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 8, 4096]              24
   MyConv1dPadSame-2              [-1, 8, 4096]               0
       BatchNorm1d-3              [-1, 8, 4096]              16
              ReLU-4              [-1, 8, 4096]               0
            Conv1d-5              [-1, 8, 4096]              24
   MyConv1dPadSame-6              [-1, 8, 4096]               0
       BatchNorm1d-7              [-1, 8, 4096]              16
              ReLU-8              [-1, 8, 4096]               0
           Dropout-9              [-1, 8, 4096]               0
           Conv1d-10              [-1, 8, 4096]              24
  MyConv1dPadSame-11              [-1, 8, 4096]               0
       Bottleneck-12              [-1, 8, 4096]               0
      BatchNorm1d-13              [-1, 8, 4096]              16
             ReLU-14              [-1, 8, 4096]               0
          Dropout-15              [-1, 8, 4096]               0
           Conv1d-16             [-1, 16, 4096]              48
  MyConv1dPadSame-17             [-1, 16, 4096]               0
      BatchNorm1d-18             [-1, 16, 4096]              32
             ReLU-19             [-1, 16, 4096]               0
          Dropout-20             [-1, 16, 4096]               0
           Conv1d-21             [-1, 16, 4096]              80
  MyConv1dPadSame-22             [-1, 16, 4096]               0
       Bottleneck-23             [-1, 16, 4096]               0
      BatchNorm1d-24             [-1, 16, 4096]              32
             ReLU-25             [-1, 16, 4096]               0
           Linear-26                    [-1, 2]              34
================================================================
Total params: 346
Trainable params: 346
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 8.75
Params size (MB): 0.00
Estimated Total Size (MB): 8.77
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 8, kernel_size: 2, n_block: 4
************************************************************
************************************************************
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 8, 4096]              24
   MyConv1dPadSame-2              [-1, 8, 4096]               0
       BatchNorm1d-3              [-1, 8, 4096]              16
              ReLU-4              [-1, 8, 4096]               0
            Conv1d-5              [-1, 8, 4096]              24
   MyConv1dPadSame-6              [-1, 8, 4096]               0
       BatchNorm1d-7              [-1, 8, 4096]              16
              ReLU-8              [-1, 8, 4096]               0
           Dropout-9              [-1, 8, 4096]               0
           Conv1d-10              [-1, 8, 4096]              24
  MyConv1dPadSame-11              [-1, 8, 4096]               0
       Bottleneck-12              [-1, 8, 4096]               0
      BatchNorm1d-13              [-1, 8, 4096]              16
             ReLU-14              [-1, 8, 4096]               0
          Dropout-15              [-1, 8, 4096]               0
           Conv1d-16             [-1, 16, 4096]              48
  MyConv1dPadSame-17             [-1, 16, 4096]               0
      BatchNorm1d-18             [-1, 16, 4096]              32
             ReLU-19             [-1, 16, 4096]               0
          Dropout-20             [-1, 16, 4096]               0
           Conv1d-21             [-1, 16, 4096]              80
  MyConv1dPadSame-22             [-1, 16, 4096]               0
       Bottleneck-23             [-1, 16, 4096]               0
      BatchNorm1d-24             [-1, 16, 4096]              32
             ReLU-25             [-1, 16, 4096]               0
          Dropout-26             [-1, 16, 4096]               0
           Conv1d-27             [-1, 32, 4096]             160
  MyConv1dPadSame-28             [-1, 32, 4096]               0
      BatchNorm1d-29             [-1, 32, 4096]              64
             ReLU-30             [-1, 32, 4096]               0
          Dropout-31             [-1, 32, 4096]               0
           Conv1d-32             [-1, 32, 4096]             288
  MyConv1dPadSame-33             [-1, 32, 4096]               0
       Bottleneck-34             [-1, 32, 4096]               0
      BatchNorm1d-35             [-1, 32, 4096]              64
             ReLU-36             [-1, 32, 4096]               0
          Dropout-37             [-1, 32, 4096]               0
           Conv1d-38             [-1, 64, 4096]             576
  MyConv1dPadSame-39             [-1, 64, 4096]               0
      BatchNorm1d-40             [-1, 64, 4096]             128
             ReLU-41             [-1, 64, 4096]               0
          Dropout-42             [-1, 64, 4096]               0
           Conv1d-43             [-1, 64, 4096]           1,088
  MyConv1dPadSame-44             [-1, 64, 4096]               0
       Bottleneck-45             [-1, 64, 4096]               0
      BatchNorm1d-46             [-1, 64, 4096]             128
             ReLU-47             [-1, 64, 4096]               0
           Linear-48                    [-1, 2]             130
================================================================
Total params: 2,938
Trainable params: 2,938
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 40.25
Params size (MB): 0.01
Estimated Total Size (MB): 40.28
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 8, kernel_size: 2, n_block: 8
************************************************************
************************************************************
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 8, 4096]              24
   MyConv1dPadSame-2              [-1, 8, 4096]               0
       BatchNorm1d-3              [-1, 8, 4096]              16
              ReLU-4              [-1, 8, 4096]               0
            Conv1d-5              [-1, 8, 4096]              24
   MyConv1dPadSame-6              [-1, 8, 4096]               0
       BatchNorm1d-7              [-1, 8, 4096]              16
              ReLU-8              [-1, 8, 4096]               0
           Dropout-9              [-1, 8, 4096]               0
           Conv1d-10              [-1, 8, 4096]              24
  MyConv1dPadSame-11              [-1, 8, 4096]               0
       Bottleneck-12              [-1, 8, 4096]               0
      BatchNorm1d-13              [-1, 8, 4096]              16
             ReLU-14              [-1, 8, 4096]               0
          Dropout-15              [-1, 8, 4096]               0
           Conv1d-16              [-1, 8, 4096]              24
  MyConv1dPadSame-17              [-1, 8, 4096]               0
      BatchNorm1d-18              [-1, 8, 4096]              16
             ReLU-19              [-1, 8, 4096]               0
          Dropout-20              [-1, 8, 4096]               0
           Conv1d-21              [-1, 8, 4096]              24
  MyConv1dPadSame-22              [-1, 8, 4096]               0
       Bottleneck-23              [-1, 8, 4096]               0
      BatchNorm1d-24              [-1, 8, 4096]              16
             ReLU-25              [-1, 8, 4096]               0
          Dropout-26              [-1, 8, 4096]               0
           Conv1d-27             [-1, 16, 4096]              48
  MyConv1dPadSame-28             [-1, 16, 4096]               0
      BatchNorm1d-29             [-1, 16, 4096]              32
             ReLU-30             [-1, 16, 4096]               0
          Dropout-31             [-1, 16, 4096]               0
           Conv1d-32             [-1, 16, 4096]              80
  MyConv1dPadSame-33             [-1, 16, 4096]               0
       Bottleneck-34             [-1, 16, 4096]               0
      BatchNorm1d-35             [-1, 16, 4096]              32
             ReLU-36             [-1, 16, 4096]               0
          Dropout-37             [-1, 16, 4096]               0
           Conv1d-38             [-1, 16, 4096]              80
  MyConv1dPadSame-39             [-1, 16, 4096]               0
      BatchNorm1d-40             [-1, 16, 4096]              32
             ReLU-41             [-1, 16, 4096]               0
          Dropout-42             [-1, 16, 4096]               0
           Conv1d-43             [-1, 16, 4096]              80
  MyConv1dPadSame-44             [-1, 16, 4096]               0
       Bottleneck-45             [-1, 16, 4096]               0
      BatchNorm1d-46             [-1, 16, 4096]              32
             ReLU-47             [-1, 16, 4096]               0
          Dropout-48             [-1, 16, 4096]               0
           Conv1d-49             [-1, 32, 4096]             160
  MyConv1dPadSame-50             [-1, 32, 4096]               0
      BatchNorm1d-51             [-1, 32, 4096]              64
             ReLU-52             [-1, 32, 4096]               0
          Dropout-53             [-1, 32, 4096]               0
           Conv1d-54             [-1, 32, 4096]             288
  MyConv1dPadSame-55             [-1, 32, 4096]               0
       Bottleneck-56             [-1, 32, 4096]               0
      BatchNorm1d-57             [-1, 32, 4096]              64
             ReLU-58             [-1, 32, 4096]               0
          Dropout-59             [-1, 32, 4096]               0
           Conv1d-60             [-1, 32, 4096]             288
  MyConv1dPadSame-61             [-1, 32, 4096]               0
      BatchNorm1d-62             [-1, 32, 4096]              64
             ReLU-63             [-1, 32, 4096]               0
          Dropout-64             [-1, 32, 4096]               0
           Conv1d-65             [-1, 32, 4096]             288
  MyConv1dPadSame-66             [-1, 32, 4096]               0
       Bottleneck-67             [-1, 32, 4096]               0
      BatchNorm1d-68             [-1, 32, 4096]              64
             ReLU-69             [-1, 32, 4096]               0
          Dropout-70             [-1, 32, 4096]               0
           Conv1d-71             [-1, 64, 4096]             576
  MyConv1dPadSame-72             [-1, 64, 4096]               0
      BatchNorm1d-73             [-1, 64, 4096]             128
             ReLU-74             [-1, 64, 4096]               0
          Dropout-75             [-1, 64, 4096]               0
           Conv1d-76             [-1, 64, 4096]           1,088
  MyConv1dPadSame-77             [-1, 64, 4096]               0
       Bottleneck-78             [-1, 64, 4096]               0
      BatchNorm1d-79             [-1, 64, 4096]             128
             ReLU-80             [-1, 64, 4096]               0
          Dropout-81             [-1, 64, 4096]               0
           Conv1d-82             [-1, 64, 4096]           1,088
  MyConv1dPadSame-83             [-1, 64, 4096]               0
      BatchNorm1d-84             [-1, 64, 4096]             128
             ReLU-85             [-1, 64, 4096]               0
          Dropout-86             [-1, 64, 4096]               0
           Conv1d-87             [-1, 64, 4096]           1,088
  MyConv1dPadSame-88             [-1, 64, 4096]               0
       Bottleneck-89             [-1, 64, 4096]               0
      BatchNorm1d-90             [-1, 64, 4096]             128
             ReLU-91             [-1, 64, 4096]               0
           Linear-92                    [-1, 2]             130
================================================================
Total params: 6,378
Trainable params: 6,378
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 81.50
Params size (MB): 0.02
Estimated Total Size (MB): 81.54
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 8, kernel_size: 2, n_block: 16
************************************************************
************************************************************
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 8, 4096]              24
   MyConv1dPadSame-2              [-1, 8, 4096]               0
       BatchNorm1d-3              [-1, 8, 4096]              16
              ReLU-4              [-1, 8, 4096]               0
            Conv1d-5              [-1, 8, 4096]              24
   MyConv1dPadSame-6              [-1, 8, 4096]               0
       BatchNorm1d-7              [-1, 8, 4096]              16
              ReLU-8              [-1, 8, 4096]               0
           Dropout-9              [-1, 8, 4096]               0
           Conv1d-10              [-1, 8, 4096]              24
  MyConv1dPadSame-11              [-1, 8, 4096]               0
       Bottleneck-12              [-1, 8, 4096]               0
      BatchNorm1d-13              [-1, 8, 4096]              16
             ReLU-14              [-1, 8, 4096]               0
          Dropout-15              [-1, 8, 4096]               0
           Conv1d-16              [-1, 8, 2048]              24
  MyConv1dPadSame-17              [-1, 8, 2048]               0
      BatchNorm1d-18              [-1, 8, 2048]              16
             ReLU-19              [-1, 8, 2048]               0
          Dropout-20              [-1, 8, 2048]               0
           Conv1d-21              [-1, 8, 2048]              24
  MyConv1dPadSame-22              [-1, 8, 2048]               0
        MaxPool1d-23              [-1, 8, 2048]               0
MyMaxPool1dPadSame-24              [-1, 8, 2048]               0
       Bottleneck-25              [-1, 8, 2048]               0
      BatchNorm1d-26              [-1, 8, 2048]              16
             ReLU-27              [-1, 8, 2048]               0
          Dropout-28              [-1, 8, 2048]               0
           Conv1d-29              [-1, 8, 2048]              24
  MyConv1dPadSame-30              [-1, 8, 2048]               0
      BatchNorm1d-31              [-1, 8, 2048]              16
             ReLU-32              [-1, 8, 2048]               0
          Dropout-33              [-1, 8, 2048]               0
           Conv1d-34              [-1, 8, 2048]              24
  MyConv1dPadSame-35              [-1, 8, 2048]               0
       Bottleneck-36              [-1, 8, 2048]               0
      BatchNorm1d-37              [-1, 8, 2048]              16
             ReLU-38              [-1, 8, 2048]               0
          Dropout-39              [-1, 8, 2048]               0
           Conv1d-40              [-1, 8, 1024]              24
  MyConv1dPadSame-41              [-1, 8, 1024]               0
      BatchNorm1d-42              [-1, 8, 1024]              16
             ReLU-43              [-1, 8, 1024]               0
          Dropout-44              [-1, 8, 1024]               0
           Conv1d-45              [-1, 8, 1024]              24
  MyConv1dPadSame-46              [-1, 8, 1024]               0
        MaxPool1d-47              [-1, 8, 1024]               0
MyMaxPool1dPadSame-48              [-1, 8, 1024]               0
       Bottleneck-49              [-1, 8, 1024]               0
      BatchNorm1d-50              [-1, 8, 1024]              16
             ReLU-51              [-1, 8, 1024]               0
          Dropout-52              [-1, 8, 1024]               0
           Conv1d-53             [-1, 16, 1024]              48
  MyConv1dPadSame-54             [-1, 16, 1024]               0
      BatchNorm1d-55             [-1, 16, 1024]              32
             ReLU-56             [-1, 16, 1024]               0
          Dropout-57             [-1, 16, 1024]               0
           Conv1d-58             [-1, 16, 1024]              80
  MyConv1dPadSame-59             [-1, 16, 1024]               0
       Bottleneck-60             [-1, 16, 1024]               0
      BatchNorm1d-61             [-1, 16, 1024]              32
             ReLU-62             [-1, 16, 1024]               0
          Dropout-63             [-1, 16, 1024]               0
           Conv1d-64              [-1, 16, 512]              80
  MyConv1dPadSame-65              [-1, 16, 512]               0
      BatchNorm1d-66              [-1, 16, 512]              32
             ReLU-67              [-1, 16, 512]               0
          Dropout-68              [-1, 16, 512]               0
           Conv1d-69              [-1, 16, 512]              80
  MyConv1dPadSame-70              [-1, 16, 512]               0
        MaxPool1d-71              [-1, 16, 512]               0
MyMaxPool1dPadSame-72              [-1, 16, 512]               0
       Bottleneck-73              [-1, 16, 512]               0
      BatchNorm1d-74              [-1, 16, 512]              32
             ReLU-75              [-1, 16, 512]               0
          Dropout-76              [-1, 16, 512]               0
           Conv1d-77              [-1, 16, 512]              80
  MyConv1dPadSame-78              [-1, 16, 512]               0
      BatchNorm1d-79              [-1, 16, 512]              32
             ReLU-80              [-1, 16, 512]               0
          Dropout-81              [-1, 16, 512]               0
           Conv1d-82              [-1, 16, 512]              80
  MyConv1dPadSame-83              [-1, 16, 512]               0
       Bottleneck-84              [-1, 16, 512]               0
      BatchNorm1d-85              [-1, 16, 512]              32
             ReLU-86              [-1, 16, 512]               0
          Dropout-87              [-1, 16, 512]               0
           Conv1d-88              [-1, 16, 256]              80
  MyConv1dPadSame-89              [-1, 16, 256]               0
      BatchNorm1d-90              [-1, 16, 256]              32
             ReLU-91              [-1, 16, 256]               0
          Dropout-92              [-1, 16, 256]               0
           Conv1d-93              [-1, 16, 256]              80
  MyConv1dPadSame-94              [-1, 16, 256]               0
        MaxPool1d-95              [-1, 16, 256]               0
MyMaxPool1dPadSame-96              [-1, 16, 256]               0
       Bottleneck-97              [-1, 16, 256]               0
      BatchNorm1d-98              [-1, 16, 256]              32
             ReLU-99              [-1, 16, 256]               0
         Dropout-100              [-1, 16, 256]               0
          Conv1d-101              [-1, 32, 256]             160
 MyConv1dPadSame-102              [-1, 32, 256]               0
     BatchNorm1d-103              [-1, 32, 256]              64
            ReLU-104              [-1, 32, 256]               0
         Dropout-105              [-1, 32, 256]               0
          Conv1d-106              [-1, 32, 256]             288
 MyConv1dPadSame-107              [-1, 32, 256]               0
      Bottleneck-108              [-1, 32, 256]               0
     BatchNorm1d-109              [-1, 32, 256]              64
            ReLU-110              [-1, 32, 256]               0
         Dropout-111              [-1, 32, 256]               0
          Conv1d-112              [-1, 32, 128]             288
 MyConv1dPadSame-113              [-1, 32, 128]               0
     BatchNorm1d-114              [-1, 32, 128]              64
            ReLU-115              [-1, 32, 128]               0
         Dropout-116              [-1, 32, 128]               0
          Conv1d-117              [-1, 32, 128]             288
 MyConv1dPadSame-118              [-1, 32, 128]               0
       MaxPool1d-119              [-1, 32, 128]               0
MyMaxPool1dPadSame-120              [-1, 32, 128]               0
      Bottleneck-121              [-1, 32, 128]               0
     BatchNorm1d-122              [-1, 32, 128]              64
            ReLU-123              [-1, 32, 128]               0
         Dropout-124              [-1, 32, 128]               0
          Conv1d-125              [-1, 32, 128]             288
 MyConv1dPadSame-126              [-1, 32, 128]               0
     BatchNorm1d-127              [-1, 32, 128]              64
            ReLU-128              [-1, 32, 128]               0
         Dropout-129              [-1, 32, 128]               0
          Conv1d-130              [-1, 32, 128]             288
 MyConv1dPadSame-131              [-1, 32, 128]               0
      Bottleneck-132              [-1, 32, 128]               0
     BatchNorm1d-133              [-1, 32, 128]              64
            ReLU-134              [-1, 32, 128]               0
         Dropout-135              [-1, 32, 128]               0
          Conv1d-136               [-1, 32, 64]             288
 MyConv1dPadSame-137               [-1, 32, 64]               0
     BatchNorm1d-138               [-1, 32, 64]              64
            ReLU-139               [-1, 32, 64]               0
         Dropout-140               [-1, 32, 64]               0
          Conv1d-141               [-1, 32, 64]             288
 MyConv1dPadSame-142               [-1, 32, 64]               0
       MaxPool1d-143               [-1, 32, 64]               0
MyMaxPool1dPadSame-144               [-1, 32, 64]               0
      Bottleneck-145               [-1, 32, 64]               0
     BatchNorm1d-146               [-1, 32, 64]              64
            ReLU-147               [-1, 32, 64]               0
         Dropout-148               [-1, 32, 64]               0
          Conv1d-149               [-1, 64, 64]             576
 MyConv1dPadSame-150               [-1, 64, 64]               0
     BatchNorm1d-151               [-1, 64, 64]             128
            ReLU-152               [-1, 64, 64]               0
         Dropout-153               [-1, 64, 64]               0
          Conv1d-154               [-1, 64, 64]           1,088
 MyConv1dPadSame-155               [-1, 64, 64]               0
      Bottleneck-156               [-1, 64, 64]               0
     BatchNorm1d-157               [-1, 64, 64]             128
            ReLU-158               [-1, 64, 64]               0
         Dropout-159               [-1, 64, 64]               0
          Conv1d-160               [-1, 64, 32]           1,088
 MyConv1dPadSame-161               [-1, 64, 32]               0
     BatchNorm1d-162               [-1, 64, 32]             128
            ReLU-163               [-1, 64, 32]               0
         Dropout-164               [-1, 64, 32]               0
          Conv1d-165               [-1, 64, 32]           1,088
 MyConv1dPadSame-166               [-1, 64, 32]               0
       MaxPool1d-167               [-1, 64, 32]               0
MyMaxPool1dPadSame-168               [-1, 64, 32]               0
      Bottleneck-169               [-1, 64, 32]               0
     BatchNorm1d-170               [-1, 64, 32]             128
            ReLU-171               [-1, 64, 32]               0
         Dropout-172               [-1, 64, 32]               0
          Conv1d-173               [-1, 64, 32]           1,088
 MyConv1dPadSame-174               [-1, 64, 32]               0
     BatchNorm1d-175               [-1, 64, 32]             128
            ReLU-176               [-1, 64, 32]               0
         Dropout-177               [-1, 64, 32]               0
          Conv1d-178               [-1, 64, 32]           1,088
 MyConv1dPadSame-179               [-1, 64, 32]               0
      Bottleneck-180               [-1, 64, 32]               0
     BatchNorm1d-181               [-1, 64, 32]             128
            ReLU-182               [-1, 64, 32]               0
         Dropout-183               [-1, 64, 32]               0
          Conv1d-184               [-1, 64, 16]           1,088
 MyConv1dPadSame-185               [-1, 64, 16]               0
     BatchNorm1d-186               [-1, 64, 16]             128
            ReLU-187               [-1, 64, 16]               0
         Dropout-188               [-1, 64, 16]               0
          Conv1d-189               [-1, 64, 16]           1,088
 MyConv1dPadSame-190               [-1, 64, 16]               0
       MaxPool1d-191               [-1, 64, 16]               0
MyMaxPool1dPadSame-192               [-1, 64, 16]               0
      Bottleneck-193               [-1, 64, 16]               0
     BatchNorm1d-194               [-1, 64, 16]             128
            ReLU-195               [-1, 64, 16]               0
          Linear-196                    [-1, 2]             130
================================================================
Total params: 13,258
Trainable params: 13,258
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 13.30
Params size (MB): 0.05
Estimated Total Size (MB): 13.36
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 8, kernel_size: 4, n_block: 2
************************************************************
************************************************************
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 8, 4096]              40
   MyConv1dPadSame-2              [-1, 8, 4096]               0
       BatchNorm1d-3              [-1, 8, 4096]              16
              ReLU-4              [-1, 8, 4096]               0
            Conv1d-5              [-1, 8, 4096]              40
   MyConv1dPadSame-6              [-1, 8, 4096]               0
       BatchNorm1d-7              [-1, 8, 4096]              16
              ReLU-8              [-1, 8, 4096]               0
           Dropout-9              [-1, 8, 4096]               0
           Conv1d-10              [-1, 8, 4096]              40
  MyConv1dPadSame-11              [-1, 8, 4096]               0
       Bottleneck-12              [-1, 8, 4096]               0
      BatchNorm1d-13              [-1, 8, 4096]              16
             ReLU-14              [-1, 8, 4096]               0
          Dropout-15              [-1, 8, 4096]               0
           Conv1d-16             [-1, 16, 4096]              80
  MyConv1dPadSame-17             [-1, 16, 4096]               0
      BatchNorm1d-18             [-1, 16, 4096]              32
             ReLU-19             [-1, 16, 4096]               0
          Dropout-20             [-1, 16, 4096]               0
           Conv1d-21             [-1, 16, 4096]             144
  MyConv1dPadSame-22             [-1, 16, 4096]               0
       Bottleneck-23             [-1, 16, 4096]               0
      BatchNorm1d-24             [-1, 16, 4096]              32
             ReLU-25             [-1, 16, 4096]               0
           Linear-26                    [-1, 2]              34
================================================================
Total params: 490
Trainable params: 490
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 8.75
Params size (MB): 0.00
Estimated Total Size (MB): 8.77
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 8, kernel_size: 4, n_block: 4
************************************************************
************************************************************
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 8, 4096]              40
   MyConv1dPadSame-2              [-1, 8, 4096]               0
       BatchNorm1d-3              [-1, 8, 4096]              16
              ReLU-4              [-1, 8, 4096]               0
            Conv1d-5              [-1, 8, 4096]              40
   MyConv1dPadSame-6              [-1, 8, 4096]               0
       BatchNorm1d-7              [-1, 8, 4096]              16
              ReLU-8              [-1, 8, 4096]               0
           Dropout-9              [-1, 8, 4096]               0
           Conv1d-10              [-1, 8, 4096]              40
  MyConv1dPadSame-11              [-1, 8, 4096]               0
       Bottleneck-12              [-1, 8, 4096]               0
      BatchNorm1d-13              [-1, 8, 4096]              16
             ReLU-14              [-1, 8, 4096]               0
          Dropout-15              [-1, 8, 4096]               0
           Conv1d-16             [-1, 16, 4096]              80
  MyConv1dPadSame-17             [-1, 16, 4096]               0
      BatchNorm1d-18             [-1, 16, 4096]              32
             ReLU-19             [-1, 16, 4096]               0
          Dropout-20             [-1, 16, 4096]               0
           Conv1d-21             [-1, 16, 4096]             144
  MyConv1dPadSame-22             [-1, 16, 4096]               0
       Bottleneck-23             [-1, 16, 4096]               0
      BatchNorm1d-24             [-1, 16, 4096]              32
             ReLU-25             [-1, 16, 4096]               0
          Dropout-26             [-1, 16, 4096]               0
           Conv1d-27             [-1, 32, 4096]             288
  MyConv1dPadSame-28             [-1, 32, 4096]               0
      BatchNorm1d-29             [-1, 32, 4096]              64
             ReLU-30             [-1, 32, 4096]               0
          Dropout-31             [-1, 32, 4096]               0
           Conv1d-32             [-1, 32, 4096]             544
  MyConv1dPadSame-33             [-1, 32, 4096]               0
       Bottleneck-34             [-1, 32, 4096]               0
      BatchNorm1d-35             [-1, 32, 4096]              64
             ReLU-36             [-1, 32, 4096]               0
          Dropout-37             [-1, 32, 4096]               0
           Conv1d-38             [-1, 64, 4096]           1,088
  MyConv1dPadSame-39             [-1, 64, 4096]               0
      BatchNorm1d-40             [-1, 64, 4096]             128
             ReLU-41             [-1, 64, 4096]               0
          Dropout-42             [-1, 64, 4096]               0
           Conv1d-43             [-1, 64, 4096]           2,112
  MyConv1dPadSame-44             [-1, 64, 4096]               0
       Bottleneck-45             [-1, 64, 4096]               0
      BatchNorm1d-46             [-1, 64, 4096]             128
             ReLU-47             [-1, 64, 4096]               0
           Linear-48                    [-1, 2]             130
================================================================
Total params: 5,002
Trainable params: 5,002
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 40.25
Params size (MB): 0.02
Estimated Total Size (MB): 40.28
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 8, kernel_size: 4, n_block: 8
************************************************************
************************************************************
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 8, 4096]              40
   MyConv1dPadSame-2              [-1, 8, 4096]               0
       BatchNorm1d-3              [-1, 8, 4096]              16
              ReLU-4              [-1, 8, 4096]               0
            Conv1d-5              [-1, 8, 4096]              40
   MyConv1dPadSame-6              [-1, 8, 4096]               0
       BatchNorm1d-7              [-1, 8, 4096]              16
              ReLU-8              [-1, 8, 4096]               0
           Dropout-9              [-1, 8, 4096]               0
           Conv1d-10              [-1, 8, 4096]              40
  MyConv1dPadSame-11              [-1, 8, 4096]               0
       Bottleneck-12              [-1, 8, 4096]               0
      BatchNorm1d-13              [-1, 8, 4096]              16
             ReLU-14              [-1, 8, 4096]               0
          Dropout-15              [-1, 8, 4096]               0
           Conv1d-16              [-1, 8, 4096]              40
  MyConv1dPadSame-17              [-1, 8, 4096]               0
      BatchNorm1d-18              [-1, 8, 4096]              16
             ReLU-19              [-1, 8, 4096]               0
          Dropout-20              [-1, 8, 4096]               0
           Conv1d-21              [-1, 8, 4096]              40
  MyConv1dPadSame-22              [-1, 8, 4096]               0
       Bottleneck-23              [-1, 8, 4096]               0
      BatchNorm1d-24              [-1, 8, 4096]              16
             ReLU-25              [-1, 8, 4096]               0
          Dropout-26              [-1, 8, 4096]               0
           Conv1d-27             [-1, 16, 4096]              80
  MyConv1dPadSame-28             [-1, 16, 4096]               0
      BatchNorm1d-29             [-1, 16, 4096]              32
             ReLU-30             [-1, 16, 4096]               0
          Dropout-31             [-1, 16, 4096]               0
           Conv1d-32             [-1, 16, 4096]             144
  MyConv1dPadSame-33             [-1, 16, 4096]               0
       Bottleneck-34             [-1, 16, 4096]               0
      BatchNorm1d-35             [-1, 16, 4096]              32
             ReLU-36             [-1, 16, 4096]               0
          Dropout-37             [-1, 16, 4096]               0
           Conv1d-38             [-1, 16, 4096]             144
  MyConv1dPadSame-39             [-1, 16, 4096]               0
      BatchNorm1d-40             [-1, 16, 4096]              32
             ReLU-41             [-1, 16, 4096]               0
          Dropout-42             [-1, 16, 4096]               0
           Conv1d-43             [-1, 16, 4096]             144
  MyConv1dPadSame-44             [-1, 16, 4096]               0
       Bottleneck-45             [-1, 16, 4096]               0
      BatchNorm1d-46             [-1, 16, 4096]              32
             ReLU-47             [-1, 16, 4096]               0
          Dropout-48             [-1, 16, 4096]               0
           Conv1d-49             [-1, 32, 4096]             288
  MyConv1dPadSame-50             [-1, 32, 4096]               0
      BatchNorm1d-51             [-1, 32, 4096]              64
             ReLU-52             [-1, 32, 4096]               0
          Dropout-53             [-1, 32, 4096]               0
           Conv1d-54             [-1, 32, 4096]             544
  MyConv1dPadSame-55             [-1, 32, 4096]               0
       Bottleneck-56             [-1, 32, 4096]               0
      BatchNorm1d-57             [-1, 32, 4096]              64
             ReLU-58             [-1, 32, 4096]               0
          Dropout-59             [-1, 32, 4096]               0
           Conv1d-60             [-1, 32, 4096]             544
  MyConv1dPadSame-61             [-1, 32, 4096]               0
      BatchNorm1d-62             [-1, 32, 4096]              64
             ReLU-63             [-1, 32, 4096]               0
          Dropout-64             [-1, 32, 4096]               0
           Conv1d-65             [-1, 32, 4096]             544
  MyConv1dPadSame-66             [-1, 32, 4096]               0
       Bottleneck-67             [-1, 32, 4096]               0
      BatchNorm1d-68             [-1, 32, 4096]              64
             ReLU-69             [-1, 32, 4096]               0
          Dropout-70             [-1, 32, 4096]               0
           Conv1d-71             [-1, 64, 4096]           1,088
  MyConv1dPadSame-72             [-1, 64, 4096]               0
      BatchNorm1d-73             [-1, 64, 4096]             128
             ReLU-74             [-1, 64, 4096]               0
          Dropout-75             [-1, 64, 4096]               0
           Conv1d-76             [-1, 64, 4096]           2,112
  MyConv1dPadSame-77             [-1, 64, 4096]               0
       Bottleneck-78             [-1, 64, 4096]               0
      BatchNorm1d-79             [-1, 64, 4096]             128
             ReLU-80             [-1, 64, 4096]               0
          Dropout-81             [-1, 64, 4096]               0
           Conv1d-82             [-1, 64, 4096]           2,112
  MyConv1dPadSame-83             [-1, 64, 4096]               0
      BatchNorm1d-84             [-1, 64, 4096]             128
             ReLU-85             [-1, 64, 4096]               0
          Dropout-86             [-1, 64, 4096]               0
           Conv1d-87             [-1, 64, 4096]           2,112
  MyConv1dPadSame-88             [-1, 64, 4096]               0
       Bottleneck-89             [-1, 64, 4096]               0
      BatchNorm1d-90             [-1, 64, 4096]             128
             ReLU-91             [-1, 64, 4096]               0
           Linear-92                    [-1, 2]             130
================================================================
Total params: 11,162
Trainable params: 11,162
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 81.50
Params size (MB): 0.04
Estimated Total Size (MB): 81.56
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 8, kernel_size: 4, n_block: 16
************************************************************
************************************************************
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 8, 4096]              40
   MyConv1dPadSame-2              [-1, 8, 4096]               0
       BatchNorm1d-3              [-1, 8, 4096]              16
              ReLU-4              [-1, 8, 4096]               0
            Conv1d-5              [-1, 8, 4096]              40
   MyConv1dPadSame-6              [-1, 8, 4096]               0
       BatchNorm1d-7              [-1, 8, 4096]              16
              ReLU-8              [-1, 8, 4096]               0
           Dropout-9              [-1, 8, 4096]               0
           Conv1d-10              [-1, 8, 4096]              40
  MyConv1dPadSame-11              [-1, 8, 4096]               0
       Bottleneck-12              [-1, 8, 4096]               0
      BatchNorm1d-13              [-1, 8, 4096]              16
             ReLU-14              [-1, 8, 4096]               0
          Dropout-15              [-1, 8, 4096]               0
           Conv1d-16              [-1, 8, 2048]              40
  MyConv1dPadSame-17              [-1, 8, 2048]               0
      BatchNorm1d-18              [-1, 8, 2048]              16
             ReLU-19              [-1, 8, 2048]               0
          Dropout-20              [-1, 8, 2048]               0
           Conv1d-21              [-1, 8, 2048]              40
  MyConv1dPadSame-22              [-1, 8, 2048]               0
        MaxPool1d-23              [-1, 8, 2048]               0
MyMaxPool1dPadSame-24              [-1, 8, 2048]               0
       Bottleneck-25              [-1, 8, 2048]               0
      BatchNorm1d-26              [-1, 8, 2048]              16
             ReLU-27              [-1, 8, 2048]               0
          Dropout-28              [-1, 8, 2048]               0
           Conv1d-29              [-1, 8, 2048]              40
  MyConv1dPadSame-30              [-1, 8, 2048]               0
      BatchNorm1d-31              [-1, 8, 2048]              16
             ReLU-32              [-1, 8, 2048]               0
          Dropout-33              [-1, 8, 2048]               0
           Conv1d-34              [-1, 8, 2048]              40
  MyConv1dPadSame-35              [-1, 8, 2048]               0
       Bottleneck-36              [-1, 8, 2048]               0
      BatchNorm1d-37              [-1, 8, 2048]              16
             ReLU-38              [-1, 8, 2048]               0
          Dropout-39              [-1, 8, 2048]               0
           Conv1d-40              [-1, 8, 1024]              40
  MyConv1dPadSame-41              [-1, 8, 1024]               0
      BatchNorm1d-42              [-1, 8, 1024]              16
             ReLU-43              [-1, 8, 1024]               0
          Dropout-44              [-1, 8, 1024]               0
           Conv1d-45              [-1, 8, 1024]              40
  MyConv1dPadSame-46              [-1, 8, 1024]               0
        MaxPool1d-47              [-1, 8, 1024]               0
MyMaxPool1dPadSame-48              [-1, 8, 1024]               0
       Bottleneck-49              [-1, 8, 1024]               0
      BatchNorm1d-50              [-1, 8, 1024]              16
             ReLU-51              [-1, 8, 1024]               0
          Dropout-52              [-1, 8, 1024]               0
           Conv1d-53             [-1, 16, 1024]              80
  MyConv1dPadSame-54             [-1, 16, 1024]               0
      BatchNorm1d-55             [-1, 16, 1024]              32
             ReLU-56             [-1, 16, 1024]               0
          Dropout-57             [-1, 16, 1024]               0
           Conv1d-58             [-1, 16, 1024]             144
  MyConv1dPadSame-59             [-1, 16, 1024]               0
       Bottleneck-60             [-1, 16, 1024]               0
      BatchNorm1d-61             [-1, 16, 1024]              32
             ReLU-62             [-1, 16, 1024]               0
          Dropout-63             [-1, 16, 1024]               0
           Conv1d-64              [-1, 16, 512]             144
  MyConv1dPadSame-65              [-1, 16, 512]               0
      BatchNorm1d-66              [-1, 16, 512]              32
             ReLU-67              [-1, 16, 512]               0
          Dropout-68              [-1, 16, 512]               0
           Conv1d-69              [-1, 16, 512]             144
  MyConv1dPadSame-70              [-1, 16, 512]               0
        MaxPool1d-71              [-1, 16, 512]               0
MyMaxPool1dPadSame-72              [-1, 16, 512]               0
       Bottleneck-73              [-1, 16, 512]               0
      BatchNorm1d-74              [-1, 16, 512]              32
             ReLU-75              [-1, 16, 512]               0
          Dropout-76              [-1, 16, 512]               0
           Conv1d-77              [-1, 16, 512]             144
  MyConv1dPadSame-78              [-1, 16, 512]               0
      BatchNorm1d-79              [-1, 16, 512]              32
             ReLU-80              [-1, 16, 512]               0
          Dropout-81              [-1, 16, 512]               0
           Conv1d-82              [-1, 16, 512]             144
  MyConv1dPadSame-83              [-1, 16, 512]               0
       Bottleneck-84              [-1, 16, 512]               0
      BatchNorm1d-85              [-1, 16, 512]              32
             ReLU-86              [-1, 16, 512]               0
          Dropout-87              [-1, 16, 512]               0
           Conv1d-88              [-1, 16, 256]             144
  MyConv1dPadSame-89              [-1, 16, 256]               0
      BatchNorm1d-90              [-1, 16, 256]              32
             ReLU-91              [-1, 16, 256]               0
          Dropout-92              [-1, 16, 256]               0
           Conv1d-93              [-1, 16, 256]             144
  MyConv1dPadSame-94              [-1, 16, 256]               0
        MaxPool1d-95              [-1, 16, 256]               0
MyMaxPool1dPadSame-96              [-1, 16, 256]               0
       Bottleneck-97              [-1, 16, 256]               0
      BatchNorm1d-98              [-1, 16, 256]              32
             ReLU-99              [-1, 16, 256]               0
         Dropout-100              [-1, 16, 256]               0
          Conv1d-101              [-1, 32, 256]             288
 MyConv1dPadSame-102              [-1, 32, 256]               0
     BatchNorm1d-103              [-1, 32, 256]              64
            ReLU-104              [-1, 32, 256]               0
         Dropout-105              [-1, 32, 256]               0
          Conv1d-106              [-1, 32, 256]             544
 MyConv1dPadSame-107              [-1, 32, 256]               0
      Bottleneck-108              [-1, 32, 256]               0
     BatchNorm1d-109              [-1, 32, 256]              64
            ReLU-110              [-1, 32, 256]               0
         Dropout-111              [-1, 32, 256]               0
          Conv1d-112              [-1, 32, 128]             544
 MyConv1dPadSame-113              [-1, 32, 128]               0
     BatchNorm1d-114              [-1, 32, 128]              64
            ReLU-115              [-1, 32, 128]               0
         Dropout-116              [-1, 32, 128]               0
          Conv1d-117              [-1, 32, 128]             544
 MyConv1dPadSame-118              [-1, 32, 128]               0
       MaxPool1d-119              [-1, 32, 128]               0
MyMaxPool1dPadSame-120              [-1, 32, 128]               0
      Bottleneck-121              [-1, 32, 128]               0
     BatchNorm1d-122              [-1, 32, 128]              64
            ReLU-123              [-1, 32, 128]               0
         Dropout-124              [-1, 32, 128]               0
          Conv1d-125              [-1, 32, 128]             544
 MyConv1dPadSame-126              [-1, 32, 128]               0
     BatchNorm1d-127              [-1, 32, 128]              64
            ReLU-128              [-1, 32, 128]               0
         Dropout-129              [-1, 32, 128]               0
          Conv1d-130              [-1, 32, 128]             544
 MyConv1dPadSame-131              [-1, 32, 128]               0
      Bottleneck-132              [-1, 32, 128]               0
     BatchNorm1d-133              [-1, 32, 128]              64
            ReLU-134              [-1, 32, 128]               0
         Dropout-135              [-1, 32, 128]               0
          Conv1d-136               [-1, 32, 64]             544
 MyConv1dPadSame-137               [-1, 32, 64]               0
     BatchNorm1d-138               [-1, 32, 64]              64
            ReLU-139               [-1, 32, 64]               0
         Dropout-140               [-1, 32, 64]               0
          Conv1d-141               [-1, 32, 64]             544
 MyConv1dPadSame-142               [-1, 32, 64]               0
       MaxPool1d-143               [-1, 32, 64]               0
MyMaxPool1dPadSame-144               [-1, 32, 64]               0
      Bottleneck-145               [-1, 32, 64]               0
     BatchNorm1d-146               [-1, 32, 64]              64
            ReLU-147               [-1, 32, 64]               0
         Dropout-148               [-1, 32, 64]               0
          Conv1d-149               [-1, 64, 64]           1,088
 MyConv1dPadSame-150               [-1, 64, 64]               0
     BatchNorm1d-151               [-1, 64, 64]             128
            ReLU-152               [-1, 64, 64]               0
         Dropout-153               [-1, 64, 64]               0
          Conv1d-154               [-1, 64, 64]           2,112
 MyConv1dPadSame-155               [-1, 64, 64]               0
      Bottleneck-156               [-1, 64, 64]               0
     BatchNorm1d-157               [-1, 64, 64]             128
            ReLU-158               [-1, 64, 64]               0
         Dropout-159               [-1, 64, 64]               0
          Conv1d-160               [-1, 64, 32]           2,112
 MyConv1dPadSame-161               [-1, 64, 32]               0
     BatchNorm1d-162               [-1, 64, 32]             128
            ReLU-163               [-1, 64, 32]               0
         Dropout-164               [-1, 64, 32]               0
          Conv1d-165               [-1, 64, 32]           2,112
 MyConv1dPadSame-166               [-1, 64, 32]               0
       MaxPool1d-167               [-1, 64, 32]               0
MyMaxPool1dPadSame-168               [-1, 64, 32]               0
      Bottleneck-169               [-1, 64, 32]               0
     BatchNorm1d-170               [-1, 64, 32]             128
            ReLU-171               [-1, 64, 32]               0
         Dropout-172               [-1, 64, 32]               0
          Conv1d-173               [-1, 64, 32]           2,112
 MyConv1dPadSame-174               [-1, 64, 32]               0
     BatchNorm1d-175               [-1, 64, 32]             128
            ReLU-176               [-1, 64, 32]               0
         Dropout-177               [-1, 64, 32]               0
          Conv1d-178               [-1, 64, 32]           2,112
 MyConv1dPadSame-179               [-1, 64, 32]               0
      Bottleneck-180               [-1, 64, 32]               0
     BatchNorm1d-181               [-1, 64, 32]             128
            ReLU-182               [-1, 64, 32]               0
         Dropout-183               [-1, 64, 32]               0
          Conv1d-184               [-1, 64, 16]           2,112
 MyConv1dPadSame-185               [-1, 64, 16]               0
     BatchNorm1d-186               [-1, 64, 16]             128
            ReLU-187               [-1, 64, 16]               0
         Dropout-188               [-1, 64, 16]               0
          Conv1d-189               [-1, 64, 16]           2,112
 MyConv1dPadSame-190               [-1, 64, 16]               0
       MaxPool1d-191               [-1, 64, 16]               0
MyMaxPool1dPadSame-192               [-1, 64, 16]               0
      Bottleneck-193               [-1, 64, 16]               0
     BatchNorm1d-194               [-1, 64, 16]             128
            ReLU-195               [-1, 64, 16]               0
          Linear-196                    [-1, 2]             130
================================================================
Total params: 23,482
Trainable params: 23,482
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 13.30
Params size (MB): 0.09
Estimated Total Size (MB): 13.40
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 8, kernel_size: 8, n_block: 2
************************************************************
************************************************************
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 8, 4096]              72
   MyConv1dPadSame-2              [-1, 8, 4096]               0
       BatchNorm1d-3              [-1, 8, 4096]              16
              ReLU-4              [-1, 8, 4096]               0
            Conv1d-5              [-1, 8, 4096]              72
   MyConv1dPadSame-6              [-1, 8, 4096]               0
       BatchNorm1d-7              [-1, 8, 4096]              16
              ReLU-8              [-1, 8, 4096]               0
           Dropout-9              [-1, 8, 4096]               0
           Conv1d-10              [-1, 8, 4096]              72
  MyConv1dPadSame-11              [-1, 8, 4096]               0
       Bottleneck-12              [-1, 8, 4096]               0
      BatchNorm1d-13              [-1, 8, 4096]              16
             ReLU-14              [-1, 8, 4096]               0
          Dropout-15              [-1, 8, 4096]               0
           Conv1d-16             [-1, 16, 4096]             144
  MyConv1dPadSame-17             [-1, 16, 4096]               0
      BatchNorm1d-18             [-1, 16, 4096]              32
             ReLU-19             [-1, 16, 4096]               0
          Dropout-20             [-1, 16, 4096]               0
           Conv1d-21             [-1, 16, 4096]             272
  MyConv1dPadSame-22             [-1, 16, 4096]               0
       Bottleneck-23             [-1, 16, 4096]               0
      BatchNorm1d-24             [-1, 16, 4096]              32
             ReLU-25             [-1, 16, 4096]               0
           Linear-26                    [-1, 2]              34
================================================================
Total params: 778
Trainable params: 778
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 8.75
Params size (MB): 0.00
Estimated Total Size (MB): 8.77
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 8, kernel_size: 8, n_block: 4
************************************************************
************************************************************
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 8, 4096]              72
   MyConv1dPadSame-2              [-1, 8, 4096]               0
       BatchNorm1d-3              [-1, 8, 4096]              16
              ReLU-4              [-1, 8, 4096]               0
            Conv1d-5              [-1, 8, 4096]              72
   MyConv1dPadSame-6              [-1, 8, 4096]               0
       BatchNorm1d-7              [-1, 8, 4096]              16
              ReLU-8              [-1, 8, 4096]               0
           Dropout-9              [-1, 8, 4096]               0
           Conv1d-10              [-1, 8, 4096]              72
  MyConv1dPadSame-11              [-1, 8, 4096]               0
       Bottleneck-12              [-1, 8, 4096]               0
      BatchNorm1d-13              [-1, 8, 4096]              16
             ReLU-14              [-1, 8, 4096]               0
          Dropout-15              [-1, 8, 4096]               0
           Conv1d-16             [-1, 16, 4096]             144
  MyConv1dPadSame-17             [-1, 16, 4096]               0
      BatchNorm1d-18             [-1, 16, 4096]              32
             ReLU-19             [-1, 16, 4096]               0
          Dropout-20             [-1, 16, 4096]               0
           Conv1d-21             [-1, 16, 4096]             272
  MyConv1dPadSame-22             [-1, 16, 4096]               0
       Bottleneck-23             [-1, 16, 4096]               0
      BatchNorm1d-24             [-1, 16, 4096]              32
             ReLU-25             [-1, 16, 4096]               0
          Dropout-26             [-1, 16, 4096]               0
           Conv1d-27             [-1, 32, 4096]             544
  MyConv1dPadSame-28             [-1, 32, 4096]               0
      BatchNorm1d-29             [-1, 32, 4096]              64
             ReLU-30             [-1, 32, 4096]               0
          Dropout-31             [-1, 32, 4096]               0
           Conv1d-32             [-1, 32, 4096]           1,056
  MyConv1dPadSame-33             [-1, 32, 4096]               0
       Bottleneck-34             [-1, 32, 4096]               0
      BatchNorm1d-35             [-1, 32, 4096]              64
             ReLU-36             [-1, 32, 4096]               0
          Dropout-37             [-1, 32, 4096]               0
           Conv1d-38             [-1, 64, 4096]           2,112
  MyConv1dPadSame-39             [-1, 64, 4096]               0
      BatchNorm1d-40             [-1, 64, 4096]             128
             ReLU-41             [-1, 64, 4096]               0
          Dropout-42             [-1, 64, 4096]               0
           Conv1d-43             [-1, 64, 4096]           4,160
  MyConv1dPadSame-44             [-1, 64, 4096]               0
       Bottleneck-45             [-1, 64, 4096]               0
      BatchNorm1d-46             [-1, 64, 4096]             128
             ReLU-47             [-1, 64, 4096]               0
           Linear-48                    [-1, 2]             130
================================================================
Total params: 9,130
Trainable params: 9,130
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 40.25
Params size (MB): 0.03
Estimated Total Size (MB): 40.30
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 8, kernel_size: 8, n_block: 8
************************************************************
************************************************************
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 8, 4096]              72
   MyConv1dPadSame-2              [-1, 8, 4096]               0
       BatchNorm1d-3              [-1, 8, 4096]              16
              ReLU-4              [-1, 8, 4096]               0
            Conv1d-5              [-1, 8, 4096]              72
   MyConv1dPadSame-6              [-1, 8, 4096]               0
       BatchNorm1d-7              [-1, 8, 4096]              16
              ReLU-8              [-1, 8, 4096]               0
           Dropout-9              [-1, 8, 4096]               0
           Conv1d-10              [-1, 8, 4096]              72
  MyConv1dPadSame-11              [-1, 8, 4096]               0
       Bottleneck-12              [-1, 8, 4096]               0
      BatchNorm1d-13              [-1, 8, 4096]              16
             ReLU-14              [-1, 8, 4096]               0
          Dropout-15              [-1, 8, 4096]               0
           Conv1d-16              [-1, 8, 4096]              72
  MyConv1dPadSame-17              [-1, 8, 4096]               0
      BatchNorm1d-18              [-1, 8, 4096]              16
             ReLU-19              [-1, 8, 4096]               0
          Dropout-20              [-1, 8, 4096]               0
           Conv1d-21              [-1, 8, 4096]              72
  MyConv1dPadSame-22              [-1, 8, 4096]               0
       Bottleneck-23              [-1, 8, 4096]               0
      BatchNorm1d-24              [-1, 8, 4096]              16
             ReLU-25              [-1, 8, 4096]               0
          Dropout-26              [-1, 8, 4096]               0
           Conv1d-27             [-1, 16, 4096]             144
  MyConv1dPadSame-28             [-1, 16, 4096]               0
      BatchNorm1d-29             [-1, 16, 4096]              32
             ReLU-30             [-1, 16, 4096]               0
          Dropout-31             [-1, 16, 4096]               0
           Conv1d-32             [-1, 16, 4096]             272
  MyConv1dPadSame-33             [-1, 16, 4096]               0
       Bottleneck-34             [-1, 16, 4096]               0
      BatchNorm1d-35             [-1, 16, 4096]              32
             ReLU-36             [-1, 16, 4096]               0
          Dropout-37             [-1, 16, 4096]               0
           Conv1d-38             [-1, 16, 4096]             272
  MyConv1dPadSame-39             [-1, 16, 4096]               0
      BatchNorm1d-40             [-1, 16, 4096]              32
             ReLU-41             [-1, 16, 4096]               0
          Dropout-42             [-1, 16, 4096]               0
           Conv1d-43             [-1, 16, 4096]             272
  MyConv1dPadSame-44             [-1, 16, 4096]               0
       Bottleneck-45             [-1, 16, 4096]               0
      BatchNorm1d-46             [-1, 16, 4096]              32
             ReLU-47             [-1, 16, 4096]               0
          Dropout-48             [-1, 16, 4096]               0
           Conv1d-49             [-1, 32, 4096]             544
  MyConv1dPadSame-50             [-1, 32, 4096]               0
      BatchNorm1d-51             [-1, 32, 4096]              64
             ReLU-52             [-1, 32, 4096]               0
          Dropout-53             [-1, 32, 4096]               0
           Conv1d-54             [-1, 32, 4096]           1,056
  MyConv1dPadSame-55             [-1, 32, 4096]               0
       Bottleneck-56             [-1, 32, 4096]               0
      BatchNorm1d-57             [-1, 32, 4096]              64
             ReLU-58             [-1, 32, 4096]               0
          Dropout-59             [-1, 32, 4096]               0
           Conv1d-60             [-1, 32, 4096]           1,056
  MyConv1dPadSame-61             [-1, 32, 4096]               0
      BatchNorm1d-62             [-1, 32, 4096]              64
             ReLU-63             [-1, 32, 4096]               0
          Dropout-64             [-1, 32, 4096]               0
           Conv1d-65             [-1, 32, 4096]           1,056
  MyConv1dPadSame-66             [-1, 32, 4096]               0
       Bottleneck-67             [-1, 32, 4096]               0
      BatchNorm1d-68             [-1, 32, 4096]              64
             ReLU-69             [-1, 32, 4096]               0
          Dropout-70             [-1, 32, 4096]               0
           Conv1d-71             [-1, 64, 4096]           2,112
  MyConv1dPadSame-72             [-1, 64, 4096]               0
      BatchNorm1d-73             [-1, 64, 4096]             128
             ReLU-74             [-1, 64, 4096]               0
          Dropout-75             [-1, 64, 4096]               0
           Conv1d-76             [-1, 64, 4096]           4,160
  MyConv1dPadSame-77             [-1, 64, 4096]               0
       Bottleneck-78             [-1, 64, 4096]               0
      BatchNorm1d-79             [-1, 64, 4096]             128
             ReLU-80             [-1, 64, 4096]               0
          Dropout-81             [-1, 64, 4096]               0
           Conv1d-82             [-1, 64, 4096]           4,160
  MyConv1dPadSame-83             [-1, 64, 4096]               0
      BatchNorm1d-84             [-1, 64, 4096]             128
             ReLU-85             [-1, 64, 4096]               0
          Dropout-86             [-1, 64, 4096]               0
           Conv1d-87             [-1, 64, 4096]           4,160
  MyConv1dPadSame-88             [-1, 64, 4096]               0
       Bottleneck-89             [-1, 64, 4096]               0
      BatchNorm1d-90             [-1, 64, 4096]             128
             ReLU-91             [-1, 64, 4096]               0
           Linear-92                    [-1, 2]             130
================================================================
Total params: 20,730
Trainable params: 20,730
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 81.50
Params size (MB): 0.08
Estimated Total Size (MB): 81.59
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 8, kernel_size: 8, n_block: 16
************************************************************
************************************************************
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 8, 4096]              72
   MyConv1dPadSame-2              [-1, 8, 4096]               0
       BatchNorm1d-3              [-1, 8, 4096]              16
              ReLU-4              [-1, 8, 4096]               0
            Conv1d-5              [-1, 8, 4096]              72
   MyConv1dPadSame-6              [-1, 8, 4096]               0
       BatchNorm1d-7              [-1, 8, 4096]              16
              ReLU-8              [-1, 8, 4096]               0
           Dropout-9              [-1, 8, 4096]               0
           Conv1d-10              [-1, 8, 4096]              72
  MyConv1dPadSame-11              [-1, 8, 4096]               0
       Bottleneck-12              [-1, 8, 4096]               0
      BatchNorm1d-13              [-1, 8, 4096]              16
             ReLU-14              [-1, 8, 4096]               0
          Dropout-15              [-1, 8, 4096]               0
           Conv1d-16              [-1, 8, 2048]              72
  MyConv1dPadSame-17              [-1, 8, 2048]               0
      BatchNorm1d-18              [-1, 8, 2048]              16
             ReLU-19              [-1, 8, 2048]               0
          Dropout-20              [-1, 8, 2048]               0
           Conv1d-21              [-1, 8, 2048]              72
  MyConv1dPadSame-22              [-1, 8, 2048]               0
        MaxPool1d-23              [-1, 8, 2048]               0
MyMaxPool1dPadSame-24              [-1, 8, 2048]               0
       Bottleneck-25              [-1, 8, 2048]               0
      BatchNorm1d-26              [-1, 8, 2048]              16
             ReLU-27              [-1, 8, 2048]               0
          Dropout-28              [-1, 8, 2048]               0
           Conv1d-29              [-1, 8, 2048]              72
  MyConv1dPadSame-30              [-1, 8, 2048]               0
      BatchNorm1d-31              [-1, 8, 2048]              16
             ReLU-32              [-1, 8, 2048]               0
          Dropout-33              [-1, 8, 2048]               0
           Conv1d-34              [-1, 8, 2048]              72
  MyConv1dPadSame-35              [-1, 8, 2048]               0
       Bottleneck-36              [-1, 8, 2048]               0
      BatchNorm1d-37              [-1, 8, 2048]              16
             ReLU-38              [-1, 8, 2048]               0
          Dropout-39              [-1, 8, 2048]               0
           Conv1d-40              [-1, 8, 1024]              72
  MyConv1dPadSame-41              [-1, 8, 1024]               0
      BatchNorm1d-42              [-1, 8, 1024]              16
             ReLU-43              [-1, 8, 1024]               0
          Dropout-44              [-1, 8, 1024]               0
           Conv1d-45              [-1, 8, 1024]              72
  MyConv1dPadSame-46              [-1, 8, 1024]               0
        MaxPool1d-47              [-1, 8, 1024]               0
MyMaxPool1dPadSame-48              [-1, 8, 1024]               0
       Bottleneck-49              [-1, 8, 1024]               0
      BatchNorm1d-50              [-1, 8, 1024]              16
             ReLU-51              [-1, 8, 1024]               0
          Dropout-52              [-1, 8, 1024]               0
           Conv1d-53             [-1, 16, 1024]             144
  MyConv1dPadSame-54             [-1, 16, 1024]               0
      BatchNorm1d-55             [-1, 16, 1024]              32
             ReLU-56             [-1, 16, 1024]               0
          Dropout-57             [-1, 16, 1024]               0
           Conv1d-58             [-1, 16, 1024]             272
  MyConv1dPadSame-59             [-1, 16, 1024]               0
       Bottleneck-60             [-1, 16, 1024]               0
      BatchNorm1d-61             [-1, 16, 1024]              32
             ReLU-62             [-1, 16, 1024]               0
          Dropout-63             [-1, 16, 1024]               0
           Conv1d-64              [-1, 16, 512]             272
  MyConv1dPadSame-65              [-1, 16, 512]               0
      BatchNorm1d-66              [-1, 16, 512]              32
             ReLU-67              [-1, 16, 512]               0
          Dropout-68              [-1, 16, 512]               0
           Conv1d-69              [-1, 16, 512]             272
  MyConv1dPadSame-70              [-1, 16, 512]               0
        MaxPool1d-71              [-1, 16, 512]               0
MyMaxPool1dPadSame-72              [-1, 16, 512]               0
       Bottleneck-73              [-1, 16, 512]               0
      BatchNorm1d-74              [-1, 16, 512]              32
             ReLU-75              [-1, 16, 512]               0
          Dropout-76              [-1, 16, 512]               0
           Conv1d-77              [-1, 16, 512]             272
  MyConv1dPadSame-78              [-1, 16, 512]               0
      BatchNorm1d-79              [-1, 16, 512]              32
             ReLU-80              [-1, 16, 512]               0
          Dropout-81              [-1, 16, 512]               0
           Conv1d-82              [-1, 16, 512]             272
  MyConv1dPadSame-83              [-1, 16, 512]               0
       Bottleneck-84              [-1, 16, 512]               0
      BatchNorm1d-85              [-1, 16, 512]              32
             ReLU-86              [-1, 16, 512]               0
          Dropout-87              [-1, 16, 512]               0
           Conv1d-88              [-1, 16, 256]             272
  MyConv1dPadSame-89              [-1, 16, 256]               0
      BatchNorm1d-90              [-1, 16, 256]              32
             ReLU-91              [-1, 16, 256]               0
          Dropout-92              [-1, 16, 256]               0
           Conv1d-93              [-1, 16, 256]             272
  MyConv1dPadSame-94              [-1, 16, 256]               0
        MaxPool1d-95              [-1, 16, 256]               0
MyMaxPool1dPadSame-96              [-1, 16, 256]               0
       Bottleneck-97              [-1, 16, 256]               0
      BatchNorm1d-98              [-1, 16, 256]              32
             ReLU-99              [-1, 16, 256]               0
         Dropout-100              [-1, 16, 256]               0
          Conv1d-101              [-1, 32, 256]             544
 MyConv1dPadSame-102              [-1, 32, 256]               0
     BatchNorm1d-103              [-1, 32, 256]              64
            ReLU-104              [-1, 32, 256]               0
         Dropout-105              [-1, 32, 256]               0
          Conv1d-106              [-1, 32, 256]           1,056
 MyConv1dPadSame-107              [-1, 32, 256]               0
      Bottleneck-108              [-1, 32, 256]               0
     BatchNorm1d-109              [-1, 32, 256]              64
            ReLU-110              [-1, 32, 256]               0
         Dropout-111              [-1, 32, 256]               0
          Conv1d-112              [-1, 32, 128]           1,056
 MyConv1dPadSame-113              [-1, 32, 128]               0
     BatchNorm1d-114              [-1, 32, 128]              64
            ReLU-115              [-1, 32, 128]               0
         Dropout-116              [-1, 32, 128]               0
          Conv1d-117              [-1, 32, 128]           1,056
 MyConv1dPadSame-118              [-1, 32, 128]               0
       MaxPool1d-119              [-1, 32, 128]               0
MyMaxPool1dPadSame-120              [-1, 32, 128]               0
      Bottleneck-121              [-1, 32, 128]               0
     BatchNorm1d-122              [-1, 32, 128]              64
            ReLU-123              [-1, 32, 128]               0
         Dropout-124              [-1, 32, 128]               0
          Conv1d-125              [-1, 32, 128]           1,056
 MyConv1dPadSame-126              [-1, 32, 128]               0
     BatchNorm1d-127              [-1, 32, 128]              64
            ReLU-128              [-1, 32, 128]               0
         Dropout-129              [-1, 32, 128]               0
          Conv1d-130              [-1, 32, 128]           1,056
 MyConv1dPadSame-131              [-1, 32, 128]               0
      Bottleneck-132              [-1, 32, 128]               0
     BatchNorm1d-133              [-1, 32, 128]              64
            ReLU-134              [-1, 32, 128]               0
         Dropout-135              [-1, 32, 128]               0
          Conv1d-136               [-1, 32, 64]           1,056
 MyConv1dPadSame-137               [-1, 32, 64]               0
     BatchNorm1d-138               [-1, 32, 64]              64
            ReLU-139               [-1, 32, 64]               0
         Dropout-140               [-1, 32, 64]               0
          Conv1d-141               [-1, 32, 64]           1,056
 MyConv1dPadSame-142               [-1, 32, 64]               0
       MaxPool1d-143               [-1, 32, 64]               0
MyMaxPool1dPadSame-144               [-1, 32, 64]               0
      Bottleneck-145               [-1, 32, 64]               0
     BatchNorm1d-146               [-1, 32, 64]              64
            ReLU-147               [-1, 32, 64]               0
         Dropout-148               [-1, 32, 64]               0
          Conv1d-149               [-1, 64, 64]           2,112
 MyConv1dPadSame-150               [-1, 64, 64]               0
     BatchNorm1d-151               [-1, 64, 64]             128
            ReLU-152               [-1, 64, 64]               0
         Dropout-153               [-1, 64, 64]               0
          Conv1d-154               [-1, 64, 64]           4,160
 MyConv1dPadSame-155               [-1, 64, 64]               0
      Bottleneck-156               [-1, 64, 64]               0
     BatchNorm1d-157               [-1, 64, 64]             128
            ReLU-158               [-1, 64, 64]               0
         Dropout-159               [-1, 64, 64]               0
          Conv1d-160               [-1, 64, 32]           4,160
 MyConv1dPadSame-161               [-1, 64, 32]               0
     BatchNorm1d-162               [-1, 64, 32]             128
            ReLU-163               [-1, 64, 32]               0
         Dropout-164               [-1, 64, 32]               0
          Conv1d-165               [-1, 64, 32]           4,160
 MyConv1dPadSame-166               [-1, 64, 32]               0
       MaxPool1d-167               [-1, 64, 32]               0
MyMaxPool1dPadSame-168               [-1, 64, 32]               0
      Bottleneck-169               [-1, 64, 32]               0
     BatchNorm1d-170               [-1, 64, 32]             128
            ReLU-171               [-1, 64, 32]               0
         Dropout-172               [-1, 64, 32]               0
          Conv1d-173               [-1, 64, 32]           4,160
 MyConv1dPadSame-174               [-1, 64, 32]               0
     BatchNorm1d-175               [-1, 64, 32]             128
            ReLU-176               [-1, 64, 32]               0
         Dropout-177               [-1, 64, 32]               0
          Conv1d-178               [-1, 64, 32]           4,160
 MyConv1dPadSame-179               [-1, 64, 32]               0
      Bottleneck-180               [-1, 64, 32]               0
     BatchNorm1d-181               [-1, 64, 32]             128
            ReLU-182               [-1, 64, 32]               0
         Dropout-183               [-1, 64, 32]               0
          Conv1d-184               [-1, 64, 16]           4,160
 MyConv1dPadSame-185               [-1, 64, 16]               0
     BatchNorm1d-186               [-1, 64, 16]             128
            ReLU-187               [-1, 64, 16]               0
         Dropout-188               [-1, 64, 16]               0
          Conv1d-189               [-1, 64, 16]           4,160
 MyConv1dPadSame-190               [-1, 64, 16]               0
       MaxPool1d-191               [-1, 64, 16]               0
MyMaxPool1dPadSame-192               [-1, 64, 16]               0
      Bottleneck-193               [-1, 64, 16]               0
     BatchNorm1d-194               [-1, 64, 16]             128
            ReLU-195               [-1, 64, 16]               0
          Linear-196                    [-1, 2]             130
================================================================
Total params: 43,930
Trainable params: 43,930
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 13.30
Params size (MB): 0.17
Estimated Total Size (MB): 13.48
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 8, kernel_size: 16, n_block: 2
************************************************************
************************************************************
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 8, 4096]             136
   MyConv1dPadSame-2              [-1, 8, 4096]               0
       BatchNorm1d-3              [-1, 8, 4096]              16
              ReLU-4              [-1, 8, 4096]               0
            Conv1d-5              [-1, 8, 4096]             136
   MyConv1dPadSame-6              [-1, 8, 4096]               0
       BatchNorm1d-7              [-1, 8, 4096]              16
              ReLU-8              [-1, 8, 4096]               0
           Dropout-9              [-1, 8, 4096]               0
           Conv1d-10              [-1, 8, 4096]             136
  MyConv1dPadSame-11              [-1, 8, 4096]               0
       Bottleneck-12              [-1, 8, 4096]               0
      BatchNorm1d-13              [-1, 8, 4096]              16
             ReLU-14              [-1, 8, 4096]               0
          Dropout-15              [-1, 8, 4096]               0
           Conv1d-16             [-1, 16, 4096]             272
  MyConv1dPadSame-17             [-1, 16, 4096]               0
      BatchNorm1d-18             [-1, 16, 4096]              32
             ReLU-19             [-1, 16, 4096]               0
          Dropout-20             [-1, 16, 4096]               0
           Conv1d-21             [-1, 16, 4096]             528
  MyConv1dPadSame-22             [-1, 16, 4096]               0
       Bottleneck-23             [-1, 16, 4096]               0
      BatchNorm1d-24             [-1, 16, 4096]              32
             ReLU-25             [-1, 16, 4096]               0
           Linear-26                    [-1, 2]              34
================================================================
Total params: 1,354
Trainable params: 1,354
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 8.75
Params size (MB): 0.01
Estimated Total Size (MB): 8.77
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 8, kernel_size: 16, n_block: 4
************************************************************
************************************************************
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 8, 4096]             136
   MyConv1dPadSame-2              [-1, 8, 4096]               0
       BatchNorm1d-3              [-1, 8, 4096]              16
              ReLU-4              [-1, 8, 4096]               0
            Conv1d-5              [-1, 8, 4096]             136
   MyConv1dPadSame-6              [-1, 8, 4096]               0
       BatchNorm1d-7              [-1, 8, 4096]              16
              ReLU-8              [-1, 8, 4096]               0
           Dropout-9              [-1, 8, 4096]               0
           Conv1d-10              [-1, 8, 4096]             136
  MyConv1dPadSame-11              [-1, 8, 4096]               0
       Bottleneck-12              [-1, 8, 4096]               0
      BatchNorm1d-13              [-1, 8, 4096]              16
             ReLU-14              [-1, 8, 4096]               0
          Dropout-15              [-1, 8, 4096]               0
           Conv1d-16             [-1, 16, 4096]             272
  MyConv1dPadSame-17             [-1, 16, 4096]               0
      BatchNorm1d-18             [-1, 16, 4096]              32
             ReLU-19             [-1, 16, 4096]               0
          Dropout-20             [-1, 16, 4096]               0
           Conv1d-21             [-1, 16, 4096]             528
  MyConv1dPadSame-22             [-1, 16, 4096]               0
       Bottleneck-23             [-1, 16, 4096]               0
      BatchNorm1d-24             [-1, 16, 4096]              32
             ReLU-25             [-1, 16, 4096]               0
          Dropout-26             [-1, 16, 4096]               0
           Conv1d-27             [-1, 32, 4096]           1,056
  MyConv1dPadSame-28             [-1, 32, 4096]               0
      BatchNorm1d-29             [-1, 32, 4096]              64
             ReLU-30             [-1, 32, 4096]               0
          Dropout-31             [-1, 32, 4096]               0
           Conv1d-32             [-1, 32, 4096]           2,080
  MyConv1dPadSame-33             [-1, 32, 4096]               0
       Bottleneck-34             [-1, 32, 4096]               0
      BatchNorm1d-35             [-1, 32, 4096]              64
             ReLU-36             [-1, 32, 4096]               0
          Dropout-37             [-1, 32, 4096]               0
           Conv1d-38             [-1, 64, 4096]           4,160
  MyConv1dPadSame-39             [-1, 64, 4096]               0
      BatchNorm1d-40             [-1, 64, 4096]             128
             ReLU-41             [-1, 64, 4096]               0
          Dropout-42             [-1, 64, 4096]               0
           Conv1d-43             [-1, 64, 4096]           8,256
  MyConv1dPadSame-44             [-1, 64, 4096]               0
       Bottleneck-45             [-1, 64, 4096]               0
      BatchNorm1d-46             [-1, 64, 4096]             128
             ReLU-47             [-1, 64, 4096]               0
           Linear-48                    [-1, 2]             130
================================================================
Total params: 17,386
Trainable params: 17,386
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 40.25
Params size (MB): 0.07
Estimated Total Size (MB): 40.33
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 8, kernel_size: 16, n_block: 8
************************************************************
************************************************************
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 8, 4096]             136
   MyConv1dPadSame-2              [-1, 8, 4096]               0
       BatchNorm1d-3              [-1, 8, 4096]              16
              ReLU-4              [-1, 8, 4096]               0
            Conv1d-5              [-1, 8, 4096]             136
   MyConv1dPadSame-6              [-1, 8, 4096]               0
       BatchNorm1d-7              [-1, 8, 4096]              16
              ReLU-8              [-1, 8, 4096]               0
           Dropout-9              [-1, 8, 4096]               0
           Conv1d-10              [-1, 8, 4096]             136
  MyConv1dPadSame-11              [-1, 8, 4096]               0
       Bottleneck-12              [-1, 8, 4096]               0
      BatchNorm1d-13              [-1, 8, 4096]              16
             ReLU-14              [-1, 8, 4096]               0
          Dropout-15              [-1, 8, 4096]               0
           Conv1d-16              [-1, 8, 4096]             136
  MyConv1dPadSame-17              [-1, 8, 4096]               0
      BatchNorm1d-18              [-1, 8, 4096]              16
             ReLU-19              [-1, 8, 4096]               0
          Dropout-20              [-1, 8, 4096]               0
           Conv1d-21              [-1, 8, 4096]             136
  MyConv1dPadSame-22              [-1, 8, 4096]               0
       Bottleneck-23              [-1, 8, 4096]               0
      BatchNorm1d-24              [-1, 8, 4096]              16
             ReLU-25              [-1, 8, 4096]               0
          Dropout-26              [-1, 8, 4096]               0
           Conv1d-27             [-1, 16, 4096]             272
  MyConv1dPadSame-28             [-1, 16, 4096]               0
      BatchNorm1d-29             [-1, 16, 4096]              32
             ReLU-30             [-1, 16, 4096]               0
          Dropout-31             [-1, 16, 4096]               0
           Conv1d-32             [-1, 16, 4096]             528
  MyConv1dPadSame-33             [-1, 16, 4096]               0
       Bottleneck-34             [-1, 16, 4096]               0
      BatchNorm1d-35             [-1, 16, 4096]              32
             ReLU-36             [-1, 16, 4096]               0
          Dropout-37             [-1, 16, 4096]               0
           Conv1d-38             [-1, 16, 4096]             528
  MyConv1dPadSame-39             [-1, 16, 4096]               0
      BatchNorm1d-40             [-1, 16, 4096]              32
             ReLU-41             [-1, 16, 4096]               0
          Dropout-42             [-1, 16, 4096]               0
           Conv1d-43             [-1, 16, 4096]             528
  MyConv1dPadSame-44             [-1, 16, 4096]               0
       Bottleneck-45             [-1, 16, 4096]               0
      BatchNorm1d-46             [-1, 16, 4096]              32
             ReLU-47             [-1, 16, 4096]               0
          Dropout-48             [-1, 16, 4096]               0
           Conv1d-49             [-1, 32, 4096]           1,056
  MyConv1dPadSame-50             [-1, 32, 4096]               0
      BatchNorm1d-51             [-1, 32, 4096]              64
             ReLU-52             [-1, 32, 4096]               0
          Dropout-53             [-1, 32, 4096]               0
           Conv1d-54             [-1, 32, 4096]           2,080
  MyConv1dPadSame-55             [-1, 32, 4096]               0
       Bottleneck-56             [-1, 32, 4096]               0
      BatchNorm1d-57             [-1, 32, 4096]              64
             ReLU-58             [-1, 32, 4096]               0
          Dropout-59             [-1, 32, 4096]               0
           Conv1d-60             [-1, 32, 4096]           2,080
  MyConv1dPadSame-61             [-1, 32, 4096]               0
      BatchNorm1d-62             [-1, 32, 4096]              64
             ReLU-63             [-1, 32, 4096]               0
          Dropout-64             [-1, 32, 4096]               0
           Conv1d-65             [-1, 32, 4096]           2,080
  MyConv1dPadSame-66             [-1, 32, 4096]               0
       Bottleneck-67             [-1, 32, 4096]               0
      BatchNorm1d-68             [-1, 32, 4096]              64
             ReLU-69             [-1, 32, 4096]               0
          Dropout-70             [-1, 32, 4096]               0
           Conv1d-71             [-1, 64, 4096]           4,160
  MyConv1dPadSame-72             [-1, 64, 4096]               0
      BatchNorm1d-73             [-1, 64, 4096]             128
             ReLU-74             [-1, 64, 4096]               0
          Dropout-75             [-1, 64, 4096]               0
           Conv1d-76             [-1, 64, 4096]           8,256
  MyConv1dPadSame-77             [-1, 64, 4096]               0
       Bottleneck-78             [-1, 64, 4096]               0
      BatchNorm1d-79             [-1, 64, 4096]             128
             ReLU-80             [-1, 64, 4096]               0
          Dropout-81             [-1, 64, 4096]               0
           Conv1d-82             [-1, 64, 4096]           8,256
  MyConv1dPadSame-83             [-1, 64, 4096]               0
      BatchNorm1d-84             [-1, 64, 4096]             128
             ReLU-85             [-1, 64, 4096]               0
          Dropout-86             [-1, 64, 4096]               0
           Conv1d-87             [-1, 64, 4096]           8,256
  MyConv1dPadSame-88             [-1, 64, 4096]               0
       Bottleneck-89             [-1, 64, 4096]               0
      BatchNorm1d-90             [-1, 64, 4096]             128
             ReLU-91             [-1, 64, 4096]               0
           Linear-92                    [-1, 2]             130
================================================================
Total params: 39,866
Trainable params: 39,866
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 81.50
Params size (MB): 0.15
Estimated Total Size (MB): 81.67
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 8, kernel_size: 16, n_block: 16
************************************************************
************************************************************
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1              [-1, 8, 4096]             136
   MyConv1dPadSame-2              [-1, 8, 4096]               0
       BatchNorm1d-3              [-1, 8, 4096]              16
              ReLU-4              [-1, 8, 4096]               0
            Conv1d-5              [-1, 8, 4096]             136
   MyConv1dPadSame-6              [-1, 8, 4096]               0
       BatchNorm1d-7              [-1, 8, 4096]              16
              ReLU-8              [-1, 8, 4096]               0
           Dropout-9              [-1, 8, 4096]               0
           Conv1d-10              [-1, 8, 4096]             136
  MyConv1dPadSame-11              [-1, 8, 4096]               0
       Bottleneck-12              [-1, 8, 4096]               0
      BatchNorm1d-13              [-1, 8, 4096]              16
             ReLU-14              [-1, 8, 4096]               0
          Dropout-15              [-1, 8, 4096]               0
           Conv1d-16              [-1, 8, 2048]             136
  MyConv1dPadSame-17              [-1, 8, 2048]               0
      BatchNorm1d-18              [-1, 8, 2048]              16
             ReLU-19              [-1, 8, 2048]               0
          Dropout-20              [-1, 8, 2048]               0
           Conv1d-21              [-1, 8, 2048]             136
  MyConv1dPadSame-22              [-1, 8, 2048]               0
        MaxPool1d-23              [-1, 8, 2048]               0
MyMaxPool1dPadSame-24              [-1, 8, 2048]               0
       Bottleneck-25              [-1, 8, 2048]               0
      BatchNorm1d-26              [-1, 8, 2048]              16
             ReLU-27              [-1, 8, 2048]               0
          Dropout-28              [-1, 8, 2048]               0
           Conv1d-29              [-1, 8, 2048]             136
  MyConv1dPadSame-30              [-1, 8, 2048]               0
      BatchNorm1d-31              [-1, 8, 2048]              16
             ReLU-32              [-1, 8, 2048]               0
          Dropout-33              [-1, 8, 2048]               0
           Conv1d-34              [-1, 8, 2048]             136
  MyConv1dPadSame-35              [-1, 8, 2048]               0
       Bottleneck-36              [-1, 8, 2048]               0
      BatchNorm1d-37              [-1, 8, 2048]              16
             ReLU-38              [-1, 8, 2048]               0
          Dropout-39              [-1, 8, 2048]               0
           Conv1d-40              [-1, 8, 1024]             136
  MyConv1dPadSame-41              [-1, 8, 1024]               0
      BatchNorm1d-42              [-1, 8, 1024]              16
             ReLU-43              [-1, 8, 1024]               0
          Dropout-44              [-1, 8, 1024]               0
           Conv1d-45              [-1, 8, 1024]             136
  MyConv1dPadSame-46              [-1, 8, 1024]               0
        MaxPool1d-47              [-1, 8, 1024]               0
MyMaxPool1dPadSame-48              [-1, 8, 1024]               0
       Bottleneck-49              [-1, 8, 1024]               0
      BatchNorm1d-50              [-1, 8, 1024]              16
             ReLU-51              [-1, 8, 1024]               0
          Dropout-52              [-1, 8, 1024]               0
           Conv1d-53             [-1, 16, 1024]             272
  MyConv1dPadSame-54             [-1, 16, 1024]               0
      BatchNorm1d-55             [-1, 16, 1024]              32
             ReLU-56             [-1, 16, 1024]               0
          Dropout-57             [-1, 16, 1024]               0
           Conv1d-58             [-1, 16, 1024]             528
  MyConv1dPadSame-59             [-1, 16, 1024]               0
       Bottleneck-60             [-1, 16, 1024]               0
      BatchNorm1d-61             [-1, 16, 1024]              32
             ReLU-62             [-1, 16, 1024]               0
          Dropout-63             [-1, 16, 1024]               0
           Conv1d-64              [-1, 16, 512]             528
  MyConv1dPadSame-65              [-1, 16, 512]               0
      BatchNorm1d-66              [-1, 16, 512]              32
             ReLU-67              [-1, 16, 512]               0
          Dropout-68              [-1, 16, 512]               0
           Conv1d-69              [-1, 16, 512]             528
  MyConv1dPadSame-70              [-1, 16, 512]               0
        MaxPool1d-71              [-1, 16, 512]               0
MyMaxPool1dPadSame-72              [-1, 16, 512]               0
       Bottleneck-73              [-1, 16, 512]               0
      BatchNorm1d-74              [-1, 16, 512]              32
             ReLU-75              [-1, 16, 512]               0
          Dropout-76              [-1, 16, 512]               0
           Conv1d-77              [-1, 16, 512]             528
  MyConv1dPadSame-78              [-1, 16, 512]               0
      BatchNorm1d-79              [-1, 16, 512]              32
             ReLU-80              [-1, 16, 512]               0
          Dropout-81              [-1, 16, 512]               0
           Conv1d-82              [-1, 16, 512]             528
  MyConv1dPadSame-83              [-1, 16, 512]               0
       Bottleneck-84              [-1, 16, 512]               0
      BatchNorm1d-85              [-1, 16, 512]              32
             ReLU-86              [-1, 16, 512]               0
          Dropout-87              [-1, 16, 512]               0
           Conv1d-88              [-1, 16, 256]             528
  MyConv1dPadSame-89              [-1, 16, 256]               0
      BatchNorm1d-90              [-1, 16, 256]              32
             ReLU-91              [-1, 16, 256]               0
          Dropout-92              [-1, 16, 256]               0
           Conv1d-93              [-1, 16, 256]             528
  MyConv1dPadSame-94              [-1, 16, 256]               0
        MaxPool1d-95              [-1, 16, 256]               0
MyMaxPool1dPadSame-96              [-1, 16, 256]               0
       Bottleneck-97              [-1, 16, 256]               0
      BatchNorm1d-98              [-1, 16, 256]              32
             ReLU-99              [-1, 16, 256]               0
         Dropout-100              [-1, 16, 256]               0
          Conv1d-101              [-1, 32, 256]           1,056
 MyConv1dPadSame-102              [-1, 32, 256]               0
     BatchNorm1d-103              [-1, 32, 256]              64
            ReLU-104              [-1, 32, 256]               0
         Dropout-105              [-1, 32, 256]               0
          Conv1d-106              [-1, 32, 256]           2,080
 MyConv1dPadSame-107              [-1, 32, 256]               0
      Bottleneck-108              [-1, 32, 256]               0
     BatchNorm1d-109              [-1, 32, 256]              64
            ReLU-110              [-1, 32, 256]               0
         Dropout-111              [-1, 32, 256]               0
          Conv1d-112              [-1, 32, 128]           2,080
 MyConv1dPadSame-113              [-1, 32, 128]               0
     BatchNorm1d-114              [-1, 32, 128]              64
            ReLU-115              [-1, 32, 128]               0
         Dropout-116              [-1, 32, 128]               0
          Conv1d-117              [-1, 32, 128]           2,080
 MyConv1dPadSame-118              [-1, 32, 128]               0
       MaxPool1d-119              [-1, 32, 128]               0
MyMaxPool1dPadSame-120              [-1, 32, 128]               0
      Bottleneck-121              [-1, 32, 128]               0
     BatchNorm1d-122              [-1, 32, 128]              64
            ReLU-123              [-1, 32, 128]               0
         Dropout-124              [-1, 32, 128]               0
          Conv1d-125              [-1, 32, 128]           2,080
 MyConv1dPadSame-126              [-1, 32, 128]               0
     BatchNorm1d-127              [-1, 32, 128]              64
            ReLU-128              [-1, 32, 128]               0
         Dropout-129              [-1, 32, 128]               0
          Conv1d-130              [-1, 32, 128]           2,080
 MyConv1dPadSame-131              [-1, 32, 128]               0
      Bottleneck-132              [-1, 32, 128]               0
     BatchNorm1d-133              [-1, 32, 128]              64
            ReLU-134              [-1, 32, 128]               0
         Dropout-135              [-1, 32, 128]               0
          Conv1d-136               [-1, 32, 64]           2,080
 MyConv1dPadSame-137               [-1, 32, 64]               0
     BatchNorm1d-138               [-1, 32, 64]              64
            ReLU-139               [-1, 32, 64]               0
         Dropout-140               [-1, 32, 64]               0
          Conv1d-141               [-1, 32, 64]           2,080
 MyConv1dPadSame-142               [-1, 32, 64]               0
       MaxPool1d-143               [-1, 32, 64]               0
MyMaxPool1dPadSame-144               [-1, 32, 64]               0
      Bottleneck-145               [-1, 32, 64]               0
     BatchNorm1d-146               [-1, 32, 64]              64
            ReLU-147               [-1, 32, 64]               0
         Dropout-148               [-1, 32, 64]               0
          Conv1d-149               [-1, 64, 64]           4,160
 MyConv1dPadSame-150               [-1, 64, 64]               0
     BatchNorm1d-151               [-1, 64, 64]             128
            ReLU-152               [-1, 64, 64]               0
         Dropout-153               [-1, 64, 64]               0
          Conv1d-154               [-1, 64, 64]           8,256
 MyConv1dPadSame-155               [-1, 64, 64]               0
      Bottleneck-156               [-1, 64, 64]               0
     BatchNorm1d-157               [-1, 64, 64]             128
            ReLU-158               [-1, 64, 64]               0
         Dropout-159               [-1, 64, 64]               0
          Conv1d-160               [-1, 64, 32]           8,256
 MyConv1dPadSame-161               [-1, 64, 32]               0
     BatchNorm1d-162               [-1, 64, 32]             128
            ReLU-163               [-1, 64, 32]               0
         Dropout-164               [-1, 64, 32]               0
          Conv1d-165               [-1, 64, 32]           8,256
 MyConv1dPadSame-166               [-1, 64, 32]               0
       MaxPool1d-167               [-1, 64, 32]               0
MyMaxPool1dPadSame-168               [-1, 64, 32]               0
      Bottleneck-169               [-1, 64, 32]               0
     BatchNorm1d-170               [-1, 64, 32]             128
            ReLU-171               [-1, 64, 32]               0
         Dropout-172               [-1, 64, 32]               0
          Conv1d-173               [-1, 64, 32]           8,256
 MyConv1dPadSame-174               [-1, 64, 32]               0
     BatchNorm1d-175               [-1, 64, 32]             128
            ReLU-176               [-1, 64, 32]               0
         Dropout-177               [-1, 64, 32]               0
          Conv1d-178               [-1, 64, 32]           8,256
 MyConv1dPadSame-179               [-1, 64, 32]               0
      Bottleneck-180               [-1, 64, 32]               0
     BatchNorm1d-181               [-1, 64, 32]             128
            ReLU-182               [-1, 64, 32]               0
         Dropout-183               [-1, 64, 32]               0
          Conv1d-184               [-1, 64, 16]           8,256
 MyConv1dPadSame-185               [-1, 64, 16]               0
     BatchNorm1d-186               [-1, 64, 16]             128
            ReLU-187               [-1, 64, 16]               0
         Dropout-188               [-1, 64, 16]               0
          Conv1d-189               [-1, 64, 16]           8,256
 MyConv1dPadSame-190               [-1, 64, 16]               0
       MaxPool1d-191               [-1, 64, 16]               0
MyMaxPool1dPadSame-192               [-1, 64, 16]               0
      Bottleneck-193               [-1, 64, 16]               0
     BatchNorm1d-194               [-1, 64, 16]             128
            ReLU-195               [-1, 64, 16]               0
          Linear-196                    [-1, 2]             130
================================================================
Total params: 84,826
Trainable params: 84,826
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 13.30
Params size (MB): 0.32
Estimated Total Size (MB): 13.64
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 16, kernel_size: 2, n_block: 2
************************************************************
************************************************************
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 16, 4096]              48
   MyConv1dPadSame-2             [-1, 16, 4096]               0
       BatchNorm1d-3             [-1, 16, 4096]              32
              ReLU-4             [-1, 16, 4096]               0
            Conv1d-5             [-1, 16, 4096]              48
   MyConv1dPadSame-6             [-1, 16, 4096]               0
       BatchNorm1d-7             [-1, 16, 4096]              32
              ReLU-8             [-1, 16, 4096]               0
           Dropout-9             [-1, 16, 4096]               0
           Conv1d-10             [-1, 16, 4096]              48
  MyConv1dPadSame-11             [-1, 16, 4096]               0
       Bottleneck-12             [-1, 16, 4096]               0
      BatchNorm1d-13             [-1, 16, 4096]              32
             ReLU-14             [-1, 16, 4096]               0
          Dropout-15             [-1, 16, 4096]               0
           Conv1d-16             [-1, 32, 4096]              96
  MyConv1dPadSame-17             [-1, 32, 4096]               0
      BatchNorm1d-18             [-1, 32, 4096]              64
             ReLU-19             [-1, 32, 4096]               0
          Dropout-20             [-1, 32, 4096]               0
           Conv1d-21             [-1, 32, 4096]             160
  MyConv1dPadSame-22             [-1, 32, 4096]               0
       Bottleneck-23             [-1, 32, 4096]               0
      BatchNorm1d-24             [-1, 32, 4096]              64
             ReLU-25             [-1, 32, 4096]               0
           Linear-26                    [-1, 2]              66
================================================================
Total params: 690
Trainable params: 690
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 17.50
Params size (MB): 0.00
Estimated Total Size (MB): 17.52
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 16, kernel_size: 2, n_block: 4
************************************************************
************************************************************
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 16, 4096]              48
   MyConv1dPadSame-2             [-1, 16, 4096]               0
       BatchNorm1d-3             [-1, 16, 4096]              32
              ReLU-4             [-1, 16, 4096]               0
            Conv1d-5             [-1, 16, 4096]              48
   MyConv1dPadSame-6             [-1, 16, 4096]               0
       BatchNorm1d-7             [-1, 16, 4096]              32
              ReLU-8             [-1, 16, 4096]               0
           Dropout-9             [-1, 16, 4096]               0
           Conv1d-10             [-1, 16, 4096]              48
  MyConv1dPadSame-11             [-1, 16, 4096]               0
       Bottleneck-12             [-1, 16, 4096]               0
      BatchNorm1d-13             [-1, 16, 4096]              32
             ReLU-14             [-1, 16, 4096]               0
          Dropout-15             [-1, 16, 4096]               0
           Conv1d-16             [-1, 32, 4096]              96
  MyConv1dPadSame-17             [-1, 32, 4096]               0
      BatchNorm1d-18             [-1, 32, 4096]              64
             ReLU-19             [-1, 32, 4096]               0
          Dropout-20             [-1, 32, 4096]               0
           Conv1d-21             [-1, 32, 4096]             160
  MyConv1dPadSame-22             [-1, 32, 4096]               0
       Bottleneck-23             [-1, 32, 4096]               0
      BatchNorm1d-24             [-1, 32, 4096]              64
             ReLU-25             [-1, 32, 4096]               0
          Dropout-26             [-1, 32, 4096]               0
           Conv1d-27             [-1, 64, 4096]             320
  MyConv1dPadSame-28             [-1, 64, 4096]               0
      BatchNorm1d-29             [-1, 64, 4096]             128
             ReLU-30             [-1, 64, 4096]               0
          Dropout-31             [-1, 64, 4096]               0
           Conv1d-32             [-1, 64, 4096]             576
  MyConv1dPadSame-33             [-1, 64, 4096]               0
       Bottleneck-34             [-1, 64, 4096]               0
      BatchNorm1d-35             [-1, 64, 4096]             128
             ReLU-36             [-1, 64, 4096]               0
          Dropout-37             [-1, 64, 4096]               0
           Conv1d-38            [-1, 128, 4096]           1,152
  MyConv1dPadSame-39            [-1, 128, 4096]               0
      BatchNorm1d-40            [-1, 128, 4096]             256
             ReLU-41            [-1, 128, 4096]               0
          Dropout-42            [-1, 128, 4096]               0
           Conv1d-43            [-1, 128, 4096]           2,176
  MyConv1dPadSame-44            [-1, 128, 4096]               0
       Bottleneck-45            [-1, 128, 4096]               0
      BatchNorm1d-46            [-1, 128, 4096]             256
             ReLU-47            [-1, 128, 4096]               0
           Linear-48                    [-1, 2]             258
================================================================
Total params: 5,874
Trainable params: 5,874
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 80.50
Params size (MB): 0.02
Estimated Total Size (MB): 80.54
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 16, kernel_size: 2, n_block: 8
************************************************************
************************************************************
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 16, 4096]              48
   MyConv1dPadSame-2             [-1, 16, 4096]               0
       BatchNorm1d-3             [-1, 16, 4096]              32
              ReLU-4             [-1, 16, 4096]               0
            Conv1d-5             [-1, 16, 4096]              48
   MyConv1dPadSame-6             [-1, 16, 4096]               0
       BatchNorm1d-7             [-1, 16, 4096]              32
              ReLU-8             [-1, 16, 4096]               0
           Dropout-9             [-1, 16, 4096]               0
           Conv1d-10             [-1, 16, 4096]              48
  MyConv1dPadSame-11             [-1, 16, 4096]               0
       Bottleneck-12             [-1, 16, 4096]               0
      BatchNorm1d-13             [-1, 16, 4096]              32
             ReLU-14             [-1, 16, 4096]               0
          Dropout-15             [-1, 16, 4096]               0
           Conv1d-16             [-1, 16, 4096]              48
  MyConv1dPadSame-17             [-1, 16, 4096]               0
      BatchNorm1d-18             [-1, 16, 4096]              32
             ReLU-19             [-1, 16, 4096]               0
          Dropout-20             [-1, 16, 4096]               0
           Conv1d-21             [-1, 16, 4096]              48
  MyConv1dPadSame-22             [-1, 16, 4096]               0
       Bottleneck-23             [-1, 16, 4096]               0
      BatchNorm1d-24             [-1, 16, 4096]              32
             ReLU-25             [-1, 16, 4096]               0
          Dropout-26             [-1, 16, 4096]               0
           Conv1d-27             [-1, 32, 4096]              96
  MyConv1dPadSame-28             [-1, 32, 4096]               0
      BatchNorm1d-29             [-1, 32, 4096]              64
             ReLU-30             [-1, 32, 4096]               0
          Dropout-31             [-1, 32, 4096]               0
           Conv1d-32             [-1, 32, 4096]             160
  MyConv1dPadSame-33             [-1, 32, 4096]               0
       Bottleneck-34             [-1, 32, 4096]               0
      BatchNorm1d-35             [-1, 32, 4096]              64
             ReLU-36             [-1, 32, 4096]               0
          Dropout-37             [-1, 32, 4096]               0
           Conv1d-38             [-1, 32, 4096]             160
  MyConv1dPadSame-39             [-1, 32, 4096]               0
      BatchNorm1d-40             [-1, 32, 4096]              64
             ReLU-41             [-1, 32, 4096]               0
          Dropout-42             [-1, 32, 4096]               0
           Conv1d-43             [-1, 32, 4096]             160
  MyConv1dPadSame-44             [-1, 32, 4096]               0
       Bottleneck-45             [-1, 32, 4096]               0
      BatchNorm1d-46             [-1, 32, 4096]              64
             ReLU-47             [-1, 32, 4096]               0
          Dropout-48             [-1, 32, 4096]               0
           Conv1d-49             [-1, 64, 4096]             320
  MyConv1dPadSame-50             [-1, 64, 4096]               0
      BatchNorm1d-51             [-1, 64, 4096]             128
             ReLU-52             [-1, 64, 4096]               0
          Dropout-53             [-1, 64, 4096]               0
           Conv1d-54             [-1, 64, 4096]             576
  MyConv1dPadSame-55             [-1, 64, 4096]               0
       Bottleneck-56             [-1, 64, 4096]               0
      BatchNorm1d-57             [-1, 64, 4096]             128
             ReLU-58             [-1, 64, 4096]               0
          Dropout-59             [-1, 64, 4096]               0
           Conv1d-60             [-1, 64, 4096]             576
  MyConv1dPadSame-61             [-1, 64, 4096]               0
      BatchNorm1d-62             [-1, 64, 4096]             128
             ReLU-63             [-1, 64, 4096]               0
          Dropout-64             [-1, 64, 4096]               0
           Conv1d-65             [-1, 64, 4096]             576
  MyConv1dPadSame-66             [-1, 64, 4096]               0
       Bottleneck-67             [-1, 64, 4096]               0
      BatchNorm1d-68             [-1, 64, 4096]             128
             ReLU-69             [-1, 64, 4096]               0
          Dropout-70             [-1, 64, 4096]               0
           Conv1d-71            [-1, 128, 4096]           1,152
  MyConv1dPadSame-72            [-1, 128, 4096]               0
      BatchNorm1d-73            [-1, 128, 4096]             256
             ReLU-74            [-1, 128, 4096]               0
          Dropout-75            [-1, 128, 4096]               0
           Conv1d-76            [-1, 128, 4096]           2,176
  MyConv1dPadSame-77            [-1, 128, 4096]               0
       Bottleneck-78            [-1, 128, 4096]               0
      BatchNorm1d-79            [-1, 128, 4096]             256
             ReLU-80            [-1, 128, 4096]               0
          Dropout-81            [-1, 128, 4096]               0
           Conv1d-82            [-1, 128, 4096]           2,176
  MyConv1dPadSame-83            [-1, 128, 4096]               0
      BatchNorm1d-84            [-1, 128, 4096]             256
             ReLU-85            [-1, 128, 4096]               0
          Dropout-86            [-1, 128, 4096]               0
           Conv1d-87            [-1, 128, 4096]           2,176
  MyConv1dPadSame-88            [-1, 128, 4096]               0
       Bottleneck-89            [-1, 128, 4096]               0
      BatchNorm1d-90            [-1, 128, 4096]             256
             ReLU-91            [-1, 128, 4096]               0
           Linear-92                    [-1, 2]             258
================================================================
Total params: 12,754
Trainable params: 12,754
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 163.00
Params size (MB): 0.05
Estimated Total Size (MB): 163.06
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 16, kernel_size: 2, n_block: 16
************************************************************
************************************************************
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 16, 4096]              48
   MyConv1dPadSame-2             [-1, 16, 4096]               0
       BatchNorm1d-3             [-1, 16, 4096]              32
              ReLU-4             [-1, 16, 4096]               0
            Conv1d-5             [-1, 16, 4096]              48
   MyConv1dPadSame-6             [-1, 16, 4096]               0
       BatchNorm1d-7             [-1, 16, 4096]              32
              ReLU-8             [-1, 16, 4096]               0
           Dropout-9             [-1, 16, 4096]               0
           Conv1d-10             [-1, 16, 4096]              48
  MyConv1dPadSame-11             [-1, 16, 4096]               0
       Bottleneck-12             [-1, 16, 4096]               0
      BatchNorm1d-13             [-1, 16, 4096]              32
             ReLU-14             [-1, 16, 4096]               0
          Dropout-15             [-1, 16, 4096]               0
           Conv1d-16             [-1, 16, 2048]              48
  MyConv1dPadSame-17             [-1, 16, 2048]               0
      BatchNorm1d-18             [-1, 16, 2048]              32
             ReLU-19             [-1, 16, 2048]               0
          Dropout-20             [-1, 16, 2048]               0
           Conv1d-21             [-1, 16, 2048]              48
  MyConv1dPadSame-22             [-1, 16, 2048]               0
        MaxPool1d-23             [-1, 16, 2048]               0
MyMaxPool1dPadSame-24             [-1, 16, 2048]               0
       Bottleneck-25             [-1, 16, 2048]               0
      BatchNorm1d-26             [-1, 16, 2048]              32
             ReLU-27             [-1, 16, 2048]               0
          Dropout-28             [-1, 16, 2048]               0
           Conv1d-29             [-1, 16, 2048]              48
  MyConv1dPadSame-30             [-1, 16, 2048]               0
      BatchNorm1d-31             [-1, 16, 2048]              32
             ReLU-32             [-1, 16, 2048]               0
          Dropout-33             [-1, 16, 2048]               0
           Conv1d-34             [-1, 16, 2048]              48
  MyConv1dPadSame-35             [-1, 16, 2048]               0
       Bottleneck-36             [-1, 16, 2048]               0
      BatchNorm1d-37             [-1, 16, 2048]              32
             ReLU-38             [-1, 16, 2048]               0
          Dropout-39             [-1, 16, 2048]               0
           Conv1d-40             [-1, 16, 1024]              48
  MyConv1dPadSame-41             [-1, 16, 1024]               0
      BatchNorm1d-42             [-1, 16, 1024]              32
             ReLU-43             [-1, 16, 1024]               0
          Dropout-44             [-1, 16, 1024]               0
           Conv1d-45             [-1, 16, 1024]              48
  MyConv1dPadSame-46             [-1, 16, 1024]               0
        MaxPool1d-47             [-1, 16, 1024]               0
MyMaxPool1dPadSame-48             [-1, 16, 1024]               0
       Bottleneck-49             [-1, 16, 1024]               0
      BatchNorm1d-50             [-1, 16, 1024]              32
             ReLU-51             [-1, 16, 1024]               0
          Dropout-52             [-1, 16, 1024]               0
           Conv1d-53             [-1, 32, 1024]              96
  MyConv1dPadSame-54             [-1, 32, 1024]               0
      BatchNorm1d-55             [-1, 32, 1024]              64
             ReLU-56             [-1, 32, 1024]               0
          Dropout-57             [-1, 32, 1024]               0
           Conv1d-58             [-1, 32, 1024]             160
  MyConv1dPadSame-59             [-1, 32, 1024]               0
       Bottleneck-60             [-1, 32, 1024]               0
      BatchNorm1d-61             [-1, 32, 1024]              64
             ReLU-62             [-1, 32, 1024]               0
          Dropout-63             [-1, 32, 1024]               0
           Conv1d-64              [-1, 32, 512]             160
  MyConv1dPadSame-65              [-1, 32, 512]               0
      BatchNorm1d-66              [-1, 32, 512]              64
             ReLU-67              [-1, 32, 512]               0
          Dropout-68              [-1, 32, 512]               0
           Conv1d-69              [-1, 32, 512]             160
  MyConv1dPadSame-70              [-1, 32, 512]               0
        MaxPool1d-71              [-1, 32, 512]               0
MyMaxPool1dPadSame-72              [-1, 32, 512]               0
       Bottleneck-73              [-1, 32, 512]               0
      BatchNorm1d-74              [-1, 32, 512]              64
             ReLU-75              [-1, 32, 512]               0
          Dropout-76              [-1, 32, 512]               0
           Conv1d-77              [-1, 32, 512]             160
  MyConv1dPadSame-78              [-1, 32, 512]               0
      BatchNorm1d-79              [-1, 32, 512]              64
             ReLU-80              [-1, 32, 512]               0
          Dropout-81              [-1, 32, 512]               0
           Conv1d-82              [-1, 32, 512]             160
  MyConv1dPadSame-83              [-1, 32, 512]               0
       Bottleneck-84              [-1, 32, 512]               0
      BatchNorm1d-85              [-1, 32, 512]              64
             ReLU-86              [-1, 32, 512]               0
          Dropout-87              [-1, 32, 512]               0
           Conv1d-88              [-1, 32, 256]             160
  MyConv1dPadSame-89              [-1, 32, 256]               0
      BatchNorm1d-90              [-1, 32, 256]              64
             ReLU-91              [-1, 32, 256]               0
          Dropout-92              [-1, 32, 256]               0
           Conv1d-93              [-1, 32, 256]             160
  MyConv1dPadSame-94              [-1, 32, 256]               0
        MaxPool1d-95              [-1, 32, 256]               0
MyMaxPool1dPadSame-96              [-1, 32, 256]               0
       Bottleneck-97              [-1, 32, 256]               0
      BatchNorm1d-98              [-1, 32, 256]              64
             ReLU-99              [-1, 32, 256]               0
         Dropout-100              [-1, 32, 256]               0
          Conv1d-101              [-1, 64, 256]             320
 MyConv1dPadSame-102              [-1, 64, 256]               0
     BatchNorm1d-103              [-1, 64, 256]             128
            ReLU-104              [-1, 64, 256]               0
         Dropout-105              [-1, 64, 256]               0
          Conv1d-106              [-1, 64, 256]             576
 MyConv1dPadSame-107              [-1, 64, 256]               0
      Bottleneck-108              [-1, 64, 256]               0
     BatchNorm1d-109              [-1, 64, 256]             128
            ReLU-110              [-1, 64, 256]               0
         Dropout-111              [-1, 64, 256]               0
          Conv1d-112              [-1, 64, 128]             576
 MyConv1dPadSame-113              [-1, 64, 128]               0
     BatchNorm1d-114              [-1, 64, 128]             128
            ReLU-115              [-1, 64, 128]               0
         Dropout-116              [-1, 64, 128]               0
          Conv1d-117              [-1, 64, 128]             576
 MyConv1dPadSame-118              [-1, 64, 128]               0
       MaxPool1d-119              [-1, 64, 128]               0
MyMaxPool1dPadSame-120              [-1, 64, 128]               0
      Bottleneck-121              [-1, 64, 128]               0
     BatchNorm1d-122              [-1, 64, 128]             128
            ReLU-123              [-1, 64, 128]               0
         Dropout-124              [-1, 64, 128]               0
          Conv1d-125              [-1, 64, 128]             576
 MyConv1dPadSame-126              [-1, 64, 128]               0
     BatchNorm1d-127              [-1, 64, 128]             128
            ReLU-128              [-1, 64, 128]               0
         Dropout-129              [-1, 64, 128]               0
          Conv1d-130              [-1, 64, 128]             576
 MyConv1dPadSame-131              [-1, 64, 128]               0
      Bottleneck-132              [-1, 64, 128]               0
     BatchNorm1d-133              [-1, 64, 128]             128
            ReLU-134              [-1, 64, 128]               0
         Dropout-135              [-1, 64, 128]               0
          Conv1d-136               [-1, 64, 64]             576
 MyConv1dPadSame-137               [-1, 64, 64]               0
     BatchNorm1d-138               [-1, 64, 64]             128
            ReLU-139               [-1, 64, 64]               0
         Dropout-140               [-1, 64, 64]               0
          Conv1d-141               [-1, 64, 64]             576
 MyConv1dPadSame-142               [-1, 64, 64]               0
       MaxPool1d-143               [-1, 64, 64]               0
MyMaxPool1dPadSame-144               [-1, 64, 64]               0
      Bottleneck-145               [-1, 64, 64]               0
     BatchNorm1d-146               [-1, 64, 64]             128
            ReLU-147               [-1, 64, 64]               0
         Dropout-148               [-1, 64, 64]               0
          Conv1d-149              [-1, 128, 64]           1,152
 MyConv1dPadSame-150              [-1, 128, 64]               0
     BatchNorm1d-151              [-1, 128, 64]             256
            ReLU-152              [-1, 128, 64]               0
         Dropout-153              [-1, 128, 64]               0
          Conv1d-154              [-1, 128, 64]           2,176
 MyConv1dPadSame-155              [-1, 128, 64]               0
      Bottleneck-156              [-1, 128, 64]               0
     BatchNorm1d-157              [-1, 128, 64]             256
            ReLU-158              [-1, 128, 64]               0
         Dropout-159              [-1, 128, 64]               0
          Conv1d-160              [-1, 128, 32]           2,176
 MyConv1dPadSame-161              [-1, 128, 32]               0
     BatchNorm1d-162              [-1, 128, 32]             256
            ReLU-163              [-1, 128, 32]               0
         Dropout-164              [-1, 128, 32]               0
          Conv1d-165              [-1, 128, 32]           2,176
 MyConv1dPadSame-166              [-1, 128, 32]               0
       MaxPool1d-167              [-1, 128, 32]               0
MyMaxPool1dPadSame-168              [-1, 128, 32]               0
      Bottleneck-169              [-1, 128, 32]               0
     BatchNorm1d-170              [-1, 128, 32]             256
            ReLU-171              [-1, 128, 32]               0
         Dropout-172              [-1, 128, 32]               0
          Conv1d-173              [-1, 128, 32]           2,176
 MyConv1dPadSame-174              [-1, 128, 32]               0
     BatchNorm1d-175              [-1, 128, 32]             256
            ReLU-176              [-1, 128, 32]               0
         Dropout-177              [-1, 128, 32]               0
          Conv1d-178              [-1, 128, 32]           2,176
 MyConv1dPadSame-179              [-1, 128, 32]               0
      Bottleneck-180              [-1, 128, 32]               0
     BatchNorm1d-181              [-1, 128, 32]             256
            ReLU-182              [-1, 128, 32]               0
         Dropout-183              [-1, 128, 32]               0
          Conv1d-184              [-1, 128, 16]           2,176
 MyConv1dPadSame-185              [-1, 128, 16]               0
     BatchNorm1d-186              [-1, 128, 16]             256
            ReLU-187              [-1, 128, 16]               0
         Dropout-188              [-1, 128, 16]               0
          Conv1d-189              [-1, 128, 16]           2,176
 MyConv1dPadSame-190              [-1, 128, 16]               0
       MaxPool1d-191              [-1, 128, 16]               0
MyMaxPool1dPadSame-192              [-1, 128, 16]               0
      Bottleneck-193              [-1, 128, 16]               0
     BatchNorm1d-194              [-1, 128, 16]             256
            ReLU-195              [-1, 128, 16]               0
          Linear-196                    [-1, 2]             258
================================================================
Total params: 26,514
Trainable params: 26,514
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 26.59
Params size (MB): 0.10
Estimated Total Size (MB): 26.71
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 16, kernel_size: 4, n_block: 2
************************************************************
************************************************************
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 16, 4096]              80
   MyConv1dPadSame-2             [-1, 16, 4096]               0
       BatchNorm1d-3             [-1, 16, 4096]              32
              ReLU-4             [-1, 16, 4096]               0
            Conv1d-5             [-1, 16, 4096]              80
   MyConv1dPadSame-6             [-1, 16, 4096]               0
       BatchNorm1d-7             [-1, 16, 4096]              32
              ReLU-8             [-1, 16, 4096]               0
           Dropout-9             [-1, 16, 4096]               0
           Conv1d-10             [-1, 16, 4096]              80
  MyConv1dPadSame-11             [-1, 16, 4096]               0
       Bottleneck-12             [-1, 16, 4096]               0
      BatchNorm1d-13             [-1, 16, 4096]              32
             ReLU-14             [-1, 16, 4096]               0
          Dropout-15             [-1, 16, 4096]               0
           Conv1d-16             [-1, 32, 4096]             160
  MyConv1dPadSame-17             [-1, 32, 4096]               0
      BatchNorm1d-18             [-1, 32, 4096]              64
             ReLU-19             [-1, 32, 4096]               0
          Dropout-20             [-1, 32, 4096]               0
           Conv1d-21             [-1, 32, 4096]             288
  MyConv1dPadSame-22             [-1, 32, 4096]               0
       Bottleneck-23             [-1, 32, 4096]               0
      BatchNorm1d-24             [-1, 32, 4096]              64
             ReLU-25             [-1, 32, 4096]               0
           Linear-26                    [-1, 2]              66
================================================================
Total params: 978
Trainable params: 978
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 17.50
Params size (MB): 0.00
Estimated Total Size (MB): 17.52
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 16, kernel_size: 4, n_block: 4
************************************************************
************************************************************
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 16, 4096]              80
   MyConv1dPadSame-2             [-1, 16, 4096]               0
       BatchNorm1d-3             [-1, 16, 4096]              32
              ReLU-4             [-1, 16, 4096]               0
            Conv1d-5             [-1, 16, 4096]              80
   MyConv1dPadSame-6             [-1, 16, 4096]               0
       BatchNorm1d-7             [-1, 16, 4096]              32
              ReLU-8             [-1, 16, 4096]               0
           Dropout-9             [-1, 16, 4096]               0
           Conv1d-10             [-1, 16, 4096]              80
  MyConv1dPadSame-11             [-1, 16, 4096]               0
       Bottleneck-12             [-1, 16, 4096]               0
      BatchNorm1d-13             [-1, 16, 4096]              32
             ReLU-14             [-1, 16, 4096]               0
          Dropout-15             [-1, 16, 4096]               0
           Conv1d-16             [-1, 32, 4096]             160
  MyConv1dPadSame-17             [-1, 32, 4096]               0
      BatchNorm1d-18             [-1, 32, 4096]              64
             ReLU-19             [-1, 32, 4096]               0
          Dropout-20             [-1, 32, 4096]               0
           Conv1d-21             [-1, 32, 4096]             288
  MyConv1dPadSame-22             [-1, 32, 4096]               0
       Bottleneck-23             [-1, 32, 4096]               0
      BatchNorm1d-24             [-1, 32, 4096]              64
             ReLU-25             [-1, 32, 4096]               0
          Dropout-26             [-1, 32, 4096]               0
           Conv1d-27             [-1, 64, 4096]             576
  MyConv1dPadSame-28             [-1, 64, 4096]               0
      BatchNorm1d-29             [-1, 64, 4096]             128
             ReLU-30             [-1, 64, 4096]               0
          Dropout-31             [-1, 64, 4096]               0
           Conv1d-32             [-1, 64, 4096]           1,088
  MyConv1dPadSame-33             [-1, 64, 4096]               0
       Bottleneck-34             [-1, 64, 4096]               0
      BatchNorm1d-35             [-1, 64, 4096]             128
             ReLU-36             [-1, 64, 4096]               0
          Dropout-37             [-1, 64, 4096]               0
           Conv1d-38            [-1, 128, 4096]           2,176
  MyConv1dPadSame-39            [-1, 128, 4096]               0
      BatchNorm1d-40            [-1, 128, 4096]             256
             ReLU-41            [-1, 128, 4096]               0
          Dropout-42            [-1, 128, 4096]               0
           Conv1d-43            [-1, 128, 4096]           4,224
  MyConv1dPadSame-44            [-1, 128, 4096]               0
       Bottleneck-45            [-1, 128, 4096]               0
      BatchNorm1d-46            [-1, 128, 4096]             256
             ReLU-47            [-1, 128, 4096]               0
           Linear-48                    [-1, 2]             258
================================================================
Total params: 10,002
Trainable params: 10,002
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 80.50
Params size (MB): 0.04
Estimated Total Size (MB): 80.55
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 16, kernel_size: 4, n_block: 8
************************************************************
************************************************************
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 16, 4096]              80
   MyConv1dPadSame-2             [-1, 16, 4096]               0
       BatchNorm1d-3             [-1, 16, 4096]              32
              ReLU-4             [-1, 16, 4096]               0
            Conv1d-5             [-1, 16, 4096]              80
   MyConv1dPadSame-6             [-1, 16, 4096]               0
       BatchNorm1d-7             [-1, 16, 4096]              32
              ReLU-8             [-1, 16, 4096]               0
           Dropout-9             [-1, 16, 4096]               0
           Conv1d-10             [-1, 16, 4096]              80
  MyConv1dPadSame-11             [-1, 16, 4096]               0
       Bottleneck-12             [-1, 16, 4096]               0
      BatchNorm1d-13             [-1, 16, 4096]              32
             ReLU-14             [-1, 16, 4096]               0
          Dropout-15             [-1, 16, 4096]               0
           Conv1d-16             [-1, 16, 4096]              80
  MyConv1dPadSame-17             [-1, 16, 4096]               0
      BatchNorm1d-18             [-1, 16, 4096]              32
             ReLU-19             [-1, 16, 4096]               0
          Dropout-20             [-1, 16, 4096]               0
           Conv1d-21             [-1, 16, 4096]              80
  MyConv1dPadSame-22             [-1, 16, 4096]               0
       Bottleneck-23             [-1, 16, 4096]               0
      BatchNorm1d-24             [-1, 16, 4096]              32
             ReLU-25             [-1, 16, 4096]               0
          Dropout-26             [-1, 16, 4096]               0
           Conv1d-27             [-1, 32, 4096]             160
  MyConv1dPadSame-28             [-1, 32, 4096]               0
      BatchNorm1d-29             [-1, 32, 4096]              64
             ReLU-30             [-1, 32, 4096]               0
          Dropout-31             [-1, 32, 4096]               0
           Conv1d-32             [-1, 32, 4096]             288
  MyConv1dPadSame-33             [-1, 32, 4096]               0
       Bottleneck-34             [-1, 32, 4096]               0
      BatchNorm1d-35             [-1, 32, 4096]              64
             ReLU-36             [-1, 32, 4096]               0
          Dropout-37             [-1, 32, 4096]               0
           Conv1d-38             [-1, 32, 4096]             288
  MyConv1dPadSame-39             [-1, 32, 4096]               0
      BatchNorm1d-40             [-1, 32, 4096]              64
             ReLU-41             [-1, 32, 4096]               0
          Dropout-42             [-1, 32, 4096]               0
           Conv1d-43             [-1, 32, 4096]             288
  MyConv1dPadSame-44             [-1, 32, 4096]               0
       Bottleneck-45             [-1, 32, 4096]               0
      BatchNorm1d-46             [-1, 32, 4096]              64
             ReLU-47             [-1, 32, 4096]               0
          Dropout-48             [-1, 32, 4096]               0
           Conv1d-49             [-1, 64, 4096]             576
  MyConv1dPadSame-50             [-1, 64, 4096]               0
      BatchNorm1d-51             [-1, 64, 4096]             128
             ReLU-52             [-1, 64, 4096]               0
          Dropout-53             [-1, 64, 4096]               0
           Conv1d-54             [-1, 64, 4096]           1,088
  MyConv1dPadSame-55             [-1, 64, 4096]               0
       Bottleneck-56             [-1, 64, 4096]               0
      BatchNorm1d-57             [-1, 64, 4096]             128
             ReLU-58             [-1, 64, 4096]               0
          Dropout-59             [-1, 64, 4096]               0
           Conv1d-60             [-1, 64, 4096]           1,088
  MyConv1dPadSame-61             [-1, 64, 4096]               0
      BatchNorm1d-62             [-1, 64, 4096]             128
             ReLU-63             [-1, 64, 4096]               0
          Dropout-64             [-1, 64, 4096]               0
           Conv1d-65             [-1, 64, 4096]           1,088
  MyConv1dPadSame-66             [-1, 64, 4096]               0
       Bottleneck-67             [-1, 64, 4096]               0
      BatchNorm1d-68             [-1, 64, 4096]             128
             ReLU-69             [-1, 64, 4096]               0
          Dropout-70             [-1, 64, 4096]               0
           Conv1d-71            [-1, 128, 4096]           2,176
  MyConv1dPadSame-72            [-1, 128, 4096]               0
      BatchNorm1d-73            [-1, 128, 4096]             256
             ReLU-74            [-1, 128, 4096]               0
          Dropout-75            [-1, 128, 4096]               0
           Conv1d-76            [-1, 128, 4096]           4,224
  MyConv1dPadSame-77            [-1, 128, 4096]               0
       Bottleneck-78            [-1, 128, 4096]               0
      BatchNorm1d-79            [-1, 128, 4096]             256
             ReLU-80            [-1, 128, 4096]               0
          Dropout-81            [-1, 128, 4096]               0
           Conv1d-82            [-1, 128, 4096]           4,224
  MyConv1dPadSame-83            [-1, 128, 4096]               0
      BatchNorm1d-84            [-1, 128, 4096]             256
             ReLU-85            [-1, 128, 4096]               0
          Dropout-86            [-1, 128, 4096]               0
           Conv1d-87            [-1, 128, 4096]           4,224
  MyConv1dPadSame-88            [-1, 128, 4096]               0
       Bottleneck-89            [-1, 128, 4096]               0
      BatchNorm1d-90            [-1, 128, 4096]             256
             ReLU-91            [-1, 128, 4096]               0
           Linear-92                    [-1, 2]             258
================================================================
Total params: 22,322
Trainable params: 22,322
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 163.00
Params size (MB): 0.09
Estimated Total Size (MB): 163.10
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 16, kernel_size: 4, n_block: 16
************************************************************
************************************************************
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 16, 4096]              80
   MyConv1dPadSame-2             [-1, 16, 4096]               0
       BatchNorm1d-3             [-1, 16, 4096]              32
              ReLU-4             [-1, 16, 4096]               0
            Conv1d-5             [-1, 16, 4096]              80
   MyConv1dPadSame-6             [-1, 16, 4096]               0
       BatchNorm1d-7             [-1, 16, 4096]              32
              ReLU-8             [-1, 16, 4096]               0
           Dropout-9             [-1, 16, 4096]               0
           Conv1d-10             [-1, 16, 4096]              80
  MyConv1dPadSame-11             [-1, 16, 4096]               0
       Bottleneck-12             [-1, 16, 4096]               0
      BatchNorm1d-13             [-1, 16, 4096]              32
             ReLU-14             [-1, 16, 4096]               0
          Dropout-15             [-1, 16, 4096]               0
           Conv1d-16             [-1, 16, 2048]              80
  MyConv1dPadSame-17             [-1, 16, 2048]               0
      BatchNorm1d-18             [-1, 16, 2048]              32
             ReLU-19             [-1, 16, 2048]               0
          Dropout-20             [-1, 16, 2048]               0
           Conv1d-21             [-1, 16, 2048]              80
  MyConv1dPadSame-22             [-1, 16, 2048]               0
        MaxPool1d-23             [-1, 16, 2048]               0
MyMaxPool1dPadSame-24             [-1, 16, 2048]               0
       Bottleneck-25             [-1, 16, 2048]               0
      BatchNorm1d-26             [-1, 16, 2048]              32
             ReLU-27             [-1, 16, 2048]               0
          Dropout-28             [-1, 16, 2048]               0
           Conv1d-29             [-1, 16, 2048]              80
  MyConv1dPadSame-30             [-1, 16, 2048]               0
      BatchNorm1d-31             [-1, 16, 2048]              32
             ReLU-32             [-1, 16, 2048]               0
          Dropout-33             [-1, 16, 2048]               0
           Conv1d-34             [-1, 16, 2048]              80
  MyConv1dPadSame-35             [-1, 16, 2048]               0
       Bottleneck-36             [-1, 16, 2048]               0
      BatchNorm1d-37             [-1, 16, 2048]              32
             ReLU-38             [-1, 16, 2048]               0
          Dropout-39             [-1, 16, 2048]               0
           Conv1d-40             [-1, 16, 1024]              80
  MyConv1dPadSame-41             [-1, 16, 1024]               0
      BatchNorm1d-42             [-1, 16, 1024]              32
             ReLU-43             [-1, 16, 1024]               0
          Dropout-44             [-1, 16, 1024]               0
           Conv1d-45             [-1, 16, 1024]              80
  MyConv1dPadSame-46             [-1, 16, 1024]               0
        MaxPool1d-47             [-1, 16, 1024]               0
MyMaxPool1dPadSame-48             [-1, 16, 1024]               0
       Bottleneck-49             [-1, 16, 1024]               0
      BatchNorm1d-50             [-1, 16, 1024]              32
             ReLU-51             [-1, 16, 1024]               0
          Dropout-52             [-1, 16, 1024]               0
           Conv1d-53             [-1, 32, 1024]             160
  MyConv1dPadSame-54             [-1, 32, 1024]               0
      BatchNorm1d-55             [-1, 32, 1024]              64
             ReLU-56             [-1, 32, 1024]               0
          Dropout-57             [-1, 32, 1024]               0
           Conv1d-58             [-1, 32, 1024]             288
  MyConv1dPadSame-59             [-1, 32, 1024]               0
       Bottleneck-60             [-1, 32, 1024]               0
      BatchNorm1d-61             [-1, 32, 1024]              64
             ReLU-62             [-1, 32, 1024]               0
          Dropout-63             [-1, 32, 1024]               0
           Conv1d-64              [-1, 32, 512]             288
  MyConv1dPadSame-65              [-1, 32, 512]               0
      BatchNorm1d-66              [-1, 32, 512]              64
             ReLU-67              [-1, 32, 512]               0
          Dropout-68              [-1, 32, 512]               0
           Conv1d-69              [-1, 32, 512]             288
  MyConv1dPadSame-70              [-1, 32, 512]               0
        MaxPool1d-71              [-1, 32, 512]               0
MyMaxPool1dPadSame-72              [-1, 32, 512]               0
       Bottleneck-73              [-1, 32, 512]               0
      BatchNorm1d-74              [-1, 32, 512]              64
             ReLU-75              [-1, 32, 512]               0
          Dropout-76              [-1, 32, 512]               0
           Conv1d-77              [-1, 32, 512]             288
  MyConv1dPadSame-78              [-1, 32, 512]               0
      BatchNorm1d-79              [-1, 32, 512]              64
             ReLU-80              [-1, 32, 512]               0
          Dropout-81              [-1, 32, 512]               0
           Conv1d-82              [-1, 32, 512]             288
  MyConv1dPadSame-83              [-1, 32, 512]               0
       Bottleneck-84              [-1, 32, 512]               0
      BatchNorm1d-85              [-1, 32, 512]              64
             ReLU-86              [-1, 32, 512]               0
          Dropout-87              [-1, 32, 512]               0
           Conv1d-88              [-1, 32, 256]             288
  MyConv1dPadSame-89              [-1, 32, 256]               0
      BatchNorm1d-90              [-1, 32, 256]              64
             ReLU-91              [-1, 32, 256]               0
          Dropout-92              [-1, 32, 256]               0
           Conv1d-93              [-1, 32, 256]             288
  MyConv1dPadSame-94              [-1, 32, 256]               0
        MaxPool1d-95              [-1, 32, 256]               0
MyMaxPool1dPadSame-96              [-1, 32, 256]               0
       Bottleneck-97              [-1, 32, 256]               0
      BatchNorm1d-98              [-1, 32, 256]              64
             ReLU-99              [-1, 32, 256]               0
         Dropout-100              [-1, 32, 256]               0
          Conv1d-101              [-1, 64, 256]             576
 MyConv1dPadSame-102              [-1, 64, 256]               0
     BatchNorm1d-103              [-1, 64, 256]             128
            ReLU-104              [-1, 64, 256]               0
         Dropout-105              [-1, 64, 256]               0
          Conv1d-106              [-1, 64, 256]           1,088
 MyConv1dPadSame-107              [-1, 64, 256]               0
      Bottleneck-108              [-1, 64, 256]               0
     BatchNorm1d-109              [-1, 64, 256]             128
            ReLU-110              [-1, 64, 256]               0
         Dropout-111              [-1, 64, 256]               0
          Conv1d-112              [-1, 64, 128]           1,088
 MyConv1dPadSame-113              [-1, 64, 128]               0
     BatchNorm1d-114              [-1, 64, 128]             128
            ReLU-115              [-1, 64, 128]               0
         Dropout-116              [-1, 64, 128]               0
          Conv1d-117              [-1, 64, 128]           1,088
 MyConv1dPadSame-118              [-1, 64, 128]               0
       MaxPool1d-119              [-1, 64, 128]               0
MyMaxPool1dPadSame-120              [-1, 64, 128]               0
      Bottleneck-121              [-1, 64, 128]               0
     BatchNorm1d-122              [-1, 64, 128]             128
            ReLU-123              [-1, 64, 128]               0
         Dropout-124              [-1, 64, 128]               0
          Conv1d-125              [-1, 64, 128]           1,088
 MyConv1dPadSame-126              [-1, 64, 128]               0
     BatchNorm1d-127              [-1, 64, 128]             128
            ReLU-128              [-1, 64, 128]               0
         Dropout-129              [-1, 64, 128]               0
          Conv1d-130              [-1, 64, 128]           1,088
 MyConv1dPadSame-131              [-1, 64, 128]               0
      Bottleneck-132              [-1, 64, 128]               0
     BatchNorm1d-133              [-1, 64, 128]             128
            ReLU-134              [-1, 64, 128]               0
         Dropout-135              [-1, 64, 128]               0
          Conv1d-136               [-1, 64, 64]           1,088
 MyConv1dPadSame-137               [-1, 64, 64]               0
     BatchNorm1d-138               [-1, 64, 64]             128
            ReLU-139               [-1, 64, 64]               0
         Dropout-140               [-1, 64, 64]               0
          Conv1d-141               [-1, 64, 64]           1,088
 MyConv1dPadSame-142               [-1, 64, 64]               0
       MaxPool1d-143               [-1, 64, 64]               0
MyMaxPool1dPadSame-144               [-1, 64, 64]               0
      Bottleneck-145               [-1, 64, 64]               0
     BatchNorm1d-146               [-1, 64, 64]             128
            ReLU-147               [-1, 64, 64]               0
         Dropout-148               [-1, 64, 64]               0
          Conv1d-149              [-1, 128, 64]           2,176
 MyConv1dPadSame-150              [-1, 128, 64]               0
     BatchNorm1d-151              [-1, 128, 64]             256
            ReLU-152              [-1, 128, 64]               0
         Dropout-153              [-1, 128, 64]               0
          Conv1d-154              [-1, 128, 64]           4,224
 MyConv1dPadSame-155              [-1, 128, 64]               0
      Bottleneck-156              [-1, 128, 64]               0
     BatchNorm1d-157              [-1, 128, 64]             256
            ReLU-158              [-1, 128, 64]               0
         Dropout-159              [-1, 128, 64]               0
          Conv1d-160              [-1, 128, 32]           4,224
 MyConv1dPadSame-161              [-1, 128, 32]               0
     BatchNorm1d-162              [-1, 128, 32]             256
            ReLU-163              [-1, 128, 32]               0
         Dropout-164              [-1, 128, 32]               0
          Conv1d-165              [-1, 128, 32]           4,224
 MyConv1dPadSame-166              [-1, 128, 32]               0
       MaxPool1d-167              [-1, 128, 32]               0
MyMaxPool1dPadSame-168              [-1, 128, 32]               0
      Bottleneck-169              [-1, 128, 32]               0
     BatchNorm1d-170              [-1, 128, 32]             256
            ReLU-171              [-1, 128, 32]               0
         Dropout-172              [-1, 128, 32]               0
          Conv1d-173              [-1, 128, 32]           4,224
 MyConv1dPadSame-174              [-1, 128, 32]               0
     BatchNorm1d-175              [-1, 128, 32]             256
            ReLU-176              [-1, 128, 32]               0
         Dropout-177              [-1, 128, 32]               0
          Conv1d-178              [-1, 128, 32]           4,224
 MyConv1dPadSame-179              [-1, 128, 32]               0
      Bottleneck-180              [-1, 128, 32]               0
     BatchNorm1d-181              [-1, 128, 32]             256
            ReLU-182              [-1, 128, 32]               0
         Dropout-183              [-1, 128, 32]               0
          Conv1d-184              [-1, 128, 16]           4,224
 MyConv1dPadSame-185              [-1, 128, 16]               0
     BatchNorm1d-186              [-1, 128, 16]             256
            ReLU-187              [-1, 128, 16]               0
         Dropout-188              [-1, 128, 16]               0
          Conv1d-189              [-1, 128, 16]           4,224
 MyConv1dPadSame-190              [-1, 128, 16]               0
       MaxPool1d-191              [-1, 128, 16]               0
MyMaxPool1dPadSame-192              [-1, 128, 16]               0
      Bottleneck-193              [-1, 128, 16]               0
     BatchNorm1d-194              [-1, 128, 16]             256
            ReLU-195              [-1, 128, 16]               0
          Linear-196                    [-1, 2]             258
================================================================
Total params: 46,962
Trainable params: 46,962
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 26.59
Params size (MB): 0.18
Estimated Total Size (MB): 26.79
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 16, kernel_size: 8, n_block: 2
************************************************************
************************************************************
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 16, 4096]             144
   MyConv1dPadSame-2             [-1, 16, 4096]               0
       BatchNorm1d-3             [-1, 16, 4096]              32
              ReLU-4             [-1, 16, 4096]               0
            Conv1d-5             [-1, 16, 4096]             144
   MyConv1dPadSame-6             [-1, 16, 4096]               0
       BatchNorm1d-7             [-1, 16, 4096]              32
              ReLU-8             [-1, 16, 4096]               0
           Dropout-9             [-1, 16, 4096]               0
           Conv1d-10             [-1, 16, 4096]             144
  MyConv1dPadSame-11             [-1, 16, 4096]               0
       Bottleneck-12             [-1, 16, 4096]               0
      BatchNorm1d-13             [-1, 16, 4096]              32
             ReLU-14             [-1, 16, 4096]               0
          Dropout-15             [-1, 16, 4096]               0
           Conv1d-16             [-1, 32, 4096]             288
  MyConv1dPadSame-17             [-1, 32, 4096]               0
      BatchNorm1d-18             [-1, 32, 4096]              64
             ReLU-19             [-1, 32, 4096]               0
          Dropout-20             [-1, 32, 4096]               0
           Conv1d-21             [-1, 32, 4096]             544
  MyConv1dPadSame-22             [-1, 32, 4096]               0
       Bottleneck-23             [-1, 32, 4096]               0
      BatchNorm1d-24             [-1, 32, 4096]              64
             ReLU-25             [-1, 32, 4096]               0
           Linear-26                    [-1, 2]              66
================================================================
Total params: 1,554
Trainable params: 1,554
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 17.50
Params size (MB): 0.01
Estimated Total Size (MB): 17.52
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 16, kernel_size: 8, n_block: 4
************************************************************
************************************************************
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 16, 4096]             144
   MyConv1dPadSame-2             [-1, 16, 4096]               0
       BatchNorm1d-3             [-1, 16, 4096]              32
              ReLU-4             [-1, 16, 4096]               0
            Conv1d-5             [-1, 16, 4096]             144
   MyConv1dPadSame-6             [-1, 16, 4096]               0
       BatchNorm1d-7             [-1, 16, 4096]              32
              ReLU-8             [-1, 16, 4096]               0
           Dropout-9             [-1, 16, 4096]               0
           Conv1d-10             [-1, 16, 4096]             144
  MyConv1dPadSame-11             [-1, 16, 4096]               0
       Bottleneck-12             [-1, 16, 4096]               0
      BatchNorm1d-13             [-1, 16, 4096]              32
             ReLU-14             [-1, 16, 4096]               0
          Dropout-15             [-1, 16, 4096]               0
           Conv1d-16             [-1, 32, 4096]             288
  MyConv1dPadSame-17             [-1, 32, 4096]               0
      BatchNorm1d-18             [-1, 32, 4096]              64
             ReLU-19             [-1, 32, 4096]               0
          Dropout-20             [-1, 32, 4096]               0
           Conv1d-21             [-1, 32, 4096]             544
  MyConv1dPadSame-22             [-1, 32, 4096]               0
       Bottleneck-23             [-1, 32, 4096]               0
      BatchNorm1d-24             [-1, 32, 4096]              64
             ReLU-25             [-1, 32, 4096]               0
          Dropout-26             [-1, 32, 4096]               0
           Conv1d-27             [-1, 64, 4096]           1,088
  MyConv1dPadSame-28             [-1, 64, 4096]               0
      BatchNorm1d-29             [-1, 64, 4096]             128
             ReLU-30             [-1, 64, 4096]               0
          Dropout-31             [-1, 64, 4096]               0
           Conv1d-32             [-1, 64, 4096]           2,112
  MyConv1dPadSame-33             [-1, 64, 4096]               0
       Bottleneck-34             [-1, 64, 4096]               0
      BatchNorm1d-35             [-1, 64, 4096]             128
             ReLU-36             [-1, 64, 4096]               0
          Dropout-37             [-1, 64, 4096]               0
           Conv1d-38            [-1, 128, 4096]           4,224
  MyConv1dPadSame-39            [-1, 128, 4096]               0
      BatchNorm1d-40            [-1, 128, 4096]             256
             ReLU-41            [-1, 128, 4096]               0
          Dropout-42            [-1, 128, 4096]               0
           Conv1d-43            [-1, 128, 4096]           8,320
  MyConv1dPadSame-44            [-1, 128, 4096]               0
       Bottleneck-45            [-1, 128, 4096]               0
      BatchNorm1d-46            [-1, 128, 4096]             256
             ReLU-47            [-1, 128, 4096]               0
           Linear-48                    [-1, 2]             258
================================================================
Total params: 18,258
Trainable params: 18,258
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 80.50
Params size (MB): 0.07
Estimated Total Size (MB): 80.59
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 16, kernel_size: 8, n_block: 8
************************************************************
************************************************************
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 16, 4096]             144
   MyConv1dPadSame-2             [-1, 16, 4096]               0
       BatchNorm1d-3             [-1, 16, 4096]              32
              ReLU-4             [-1, 16, 4096]               0
            Conv1d-5             [-1, 16, 4096]             144
   MyConv1dPadSame-6             [-1, 16, 4096]               0
       BatchNorm1d-7             [-1, 16, 4096]              32
              ReLU-8             [-1, 16, 4096]               0
           Dropout-9             [-1, 16, 4096]               0
           Conv1d-10             [-1, 16, 4096]             144
  MyConv1dPadSame-11             [-1, 16, 4096]               0
       Bottleneck-12             [-1, 16, 4096]               0
      BatchNorm1d-13             [-1, 16, 4096]              32
             ReLU-14             [-1, 16, 4096]               0
          Dropout-15             [-1, 16, 4096]               0
           Conv1d-16             [-1, 16, 4096]             144
  MyConv1dPadSame-17             [-1, 16, 4096]               0
      BatchNorm1d-18             [-1, 16, 4096]              32
             ReLU-19             [-1, 16, 4096]               0
          Dropout-20             [-1, 16, 4096]               0
           Conv1d-21             [-1, 16, 4096]             144
  MyConv1dPadSame-22             [-1, 16, 4096]               0
       Bottleneck-23             [-1, 16, 4096]               0
      BatchNorm1d-24             [-1, 16, 4096]              32
             ReLU-25             [-1, 16, 4096]               0
          Dropout-26             [-1, 16, 4096]               0
           Conv1d-27             [-1, 32, 4096]             288
  MyConv1dPadSame-28             [-1, 32, 4096]               0
      BatchNorm1d-29             [-1, 32, 4096]              64
             ReLU-30             [-1, 32, 4096]               0
          Dropout-31             [-1, 32, 4096]               0
           Conv1d-32             [-1, 32, 4096]             544
  MyConv1dPadSame-33             [-1, 32, 4096]               0
       Bottleneck-34             [-1, 32, 4096]               0
      BatchNorm1d-35             [-1, 32, 4096]              64
             ReLU-36             [-1, 32, 4096]               0
          Dropout-37             [-1, 32, 4096]               0
           Conv1d-38             [-1, 32, 4096]             544
  MyConv1dPadSame-39             [-1, 32, 4096]               0
      BatchNorm1d-40             [-1, 32, 4096]              64
             ReLU-41             [-1, 32, 4096]               0
          Dropout-42             [-1, 32, 4096]               0
           Conv1d-43             [-1, 32, 4096]             544
  MyConv1dPadSame-44             [-1, 32, 4096]               0
       Bottleneck-45             [-1, 32, 4096]               0
      BatchNorm1d-46             [-1, 32, 4096]              64
             ReLU-47             [-1, 32, 4096]               0
          Dropout-48             [-1, 32, 4096]               0
           Conv1d-49             [-1, 64, 4096]           1,088
  MyConv1dPadSame-50             [-1, 64, 4096]               0
      BatchNorm1d-51             [-1, 64, 4096]             128
             ReLU-52             [-1, 64, 4096]               0
          Dropout-53             [-1, 64, 4096]               0
           Conv1d-54             [-1, 64, 4096]           2,112
  MyConv1dPadSame-55             [-1, 64, 4096]               0
       Bottleneck-56             [-1, 64, 4096]               0
      BatchNorm1d-57             [-1, 64, 4096]             128
             ReLU-58             [-1, 64, 4096]               0
          Dropout-59             [-1, 64, 4096]               0
           Conv1d-60             [-1, 64, 4096]           2,112
  MyConv1dPadSame-61             [-1, 64, 4096]               0
      BatchNorm1d-62             [-1, 64, 4096]             128
             ReLU-63             [-1, 64, 4096]               0
          Dropout-64             [-1, 64, 4096]               0
           Conv1d-65             [-1, 64, 4096]           2,112
  MyConv1dPadSame-66             [-1, 64, 4096]               0
       Bottleneck-67             [-1, 64, 4096]               0
      BatchNorm1d-68             [-1, 64, 4096]             128
             ReLU-69             [-1, 64, 4096]               0
          Dropout-70             [-1, 64, 4096]               0
           Conv1d-71            [-1, 128, 4096]           4,224
  MyConv1dPadSame-72            [-1, 128, 4096]               0
      BatchNorm1d-73            [-1, 128, 4096]             256
             ReLU-74            [-1, 128, 4096]               0
          Dropout-75            [-1, 128, 4096]               0
           Conv1d-76            [-1, 128, 4096]           8,320
  MyConv1dPadSame-77            [-1, 128, 4096]               0
       Bottleneck-78            [-1, 128, 4096]               0
      BatchNorm1d-79            [-1, 128, 4096]             256
             ReLU-80            [-1, 128, 4096]               0
          Dropout-81            [-1, 128, 4096]               0
           Conv1d-82            [-1, 128, 4096]           8,320
  MyConv1dPadSame-83            [-1, 128, 4096]               0
      BatchNorm1d-84            [-1, 128, 4096]             256
             ReLU-85            [-1, 128, 4096]               0
          Dropout-86            [-1, 128, 4096]               0
           Conv1d-87            [-1, 128, 4096]           8,320
  MyConv1dPadSame-88            [-1, 128, 4096]               0
       Bottleneck-89            [-1, 128, 4096]               0
      BatchNorm1d-90            [-1, 128, 4096]             256
             ReLU-91            [-1, 128, 4096]               0
           Linear-92                    [-1, 2]             258
================================================================
Total params: 41,458
Trainable params: 41,458
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 163.00
Params size (MB): 0.16
Estimated Total Size (MB): 163.17
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 16, kernel_size: 8, n_block: 16
************************************************************
************************************************************
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 16, 4096]             144
   MyConv1dPadSame-2             [-1, 16, 4096]               0
       BatchNorm1d-3             [-1, 16, 4096]              32
              ReLU-4             [-1, 16, 4096]               0
            Conv1d-5             [-1, 16, 4096]             144
   MyConv1dPadSame-6             [-1, 16, 4096]               0
       BatchNorm1d-7             [-1, 16, 4096]              32
              ReLU-8             [-1, 16, 4096]               0
           Dropout-9             [-1, 16, 4096]               0
           Conv1d-10             [-1, 16, 4096]             144
  MyConv1dPadSame-11             [-1, 16, 4096]               0
       Bottleneck-12             [-1, 16, 4096]               0
      BatchNorm1d-13             [-1, 16, 4096]              32
             ReLU-14             [-1, 16, 4096]               0
          Dropout-15             [-1, 16, 4096]               0
           Conv1d-16             [-1, 16, 2048]             144
  MyConv1dPadSame-17             [-1, 16, 2048]               0
      BatchNorm1d-18             [-1, 16, 2048]              32
             ReLU-19             [-1, 16, 2048]               0
          Dropout-20             [-1, 16, 2048]               0
           Conv1d-21             [-1, 16, 2048]             144
  MyConv1dPadSame-22             [-1, 16, 2048]               0
        MaxPool1d-23             [-1, 16, 2048]               0
MyMaxPool1dPadSame-24             [-1, 16, 2048]               0
       Bottleneck-25             [-1, 16, 2048]               0
      BatchNorm1d-26             [-1, 16, 2048]              32
             ReLU-27             [-1, 16, 2048]               0
          Dropout-28             [-1, 16, 2048]               0
           Conv1d-29             [-1, 16, 2048]             144
  MyConv1dPadSame-30             [-1, 16, 2048]               0
      BatchNorm1d-31             [-1, 16, 2048]              32
             ReLU-32             [-1, 16, 2048]               0
          Dropout-33             [-1, 16, 2048]               0
           Conv1d-34             [-1, 16, 2048]             144
  MyConv1dPadSame-35             [-1, 16, 2048]               0
       Bottleneck-36             [-1, 16, 2048]               0
      BatchNorm1d-37             [-1, 16, 2048]              32
             ReLU-38             [-1, 16, 2048]               0
          Dropout-39             [-1, 16, 2048]               0
           Conv1d-40             [-1, 16, 1024]             144
  MyConv1dPadSame-41             [-1, 16, 1024]               0
      BatchNorm1d-42             [-1, 16, 1024]              32
             ReLU-43             [-1, 16, 1024]               0
          Dropout-44             [-1, 16, 1024]               0
           Conv1d-45             [-1, 16, 1024]             144
  MyConv1dPadSame-46             [-1, 16, 1024]               0
        MaxPool1d-47             [-1, 16, 1024]               0
MyMaxPool1dPadSame-48             [-1, 16, 1024]               0
       Bottleneck-49             [-1, 16, 1024]               0
      BatchNorm1d-50             [-1, 16, 1024]              32
             ReLU-51             [-1, 16, 1024]               0
          Dropout-52             [-1, 16, 1024]               0
           Conv1d-53             [-1, 32, 1024]             288
  MyConv1dPadSame-54             [-1, 32, 1024]               0
      BatchNorm1d-55             [-1, 32, 1024]              64
             ReLU-56             [-1, 32, 1024]               0
          Dropout-57             [-1, 32, 1024]               0
           Conv1d-58             [-1, 32, 1024]             544
  MyConv1dPadSame-59             [-1, 32, 1024]               0
       Bottleneck-60             [-1, 32, 1024]               0
      BatchNorm1d-61             [-1, 32, 1024]              64
             ReLU-62             [-1, 32, 1024]               0
          Dropout-63             [-1, 32, 1024]               0
           Conv1d-64              [-1, 32, 512]             544
  MyConv1dPadSame-65              [-1, 32, 512]               0
      BatchNorm1d-66              [-1, 32, 512]              64
             ReLU-67              [-1, 32, 512]               0
          Dropout-68              [-1, 32, 512]               0
           Conv1d-69              [-1, 32, 512]             544
  MyConv1dPadSame-70              [-1, 32, 512]               0
        MaxPool1d-71              [-1, 32, 512]               0
MyMaxPool1dPadSame-72              [-1, 32, 512]               0
       Bottleneck-73              [-1, 32, 512]               0
      BatchNorm1d-74              [-1, 32, 512]              64
             ReLU-75              [-1, 32, 512]               0
          Dropout-76              [-1, 32, 512]               0
           Conv1d-77              [-1, 32, 512]             544
  MyConv1dPadSame-78              [-1, 32, 512]               0
      BatchNorm1d-79              [-1, 32, 512]              64
             ReLU-80              [-1, 32, 512]               0
          Dropout-81              [-1, 32, 512]               0
           Conv1d-82              [-1, 32, 512]             544
  MyConv1dPadSame-83              [-1, 32, 512]               0
       Bottleneck-84              [-1, 32, 512]               0
      BatchNorm1d-85              [-1, 32, 512]              64
             ReLU-86              [-1, 32, 512]               0
          Dropout-87              [-1, 32, 512]               0
           Conv1d-88              [-1, 32, 256]             544
  MyConv1dPadSame-89              [-1, 32, 256]               0
      BatchNorm1d-90              [-1, 32, 256]              64
             ReLU-91              [-1, 32, 256]               0
          Dropout-92              [-1, 32, 256]               0
           Conv1d-93              [-1, 32, 256]             544
  MyConv1dPadSame-94              [-1, 32, 256]               0
        MaxPool1d-95              [-1, 32, 256]               0
MyMaxPool1dPadSame-96              [-1, 32, 256]               0
       Bottleneck-97              [-1, 32, 256]               0
      BatchNorm1d-98              [-1, 32, 256]              64
             ReLU-99              [-1, 32, 256]               0
         Dropout-100              [-1, 32, 256]               0
          Conv1d-101              [-1, 64, 256]           1,088
 MyConv1dPadSame-102              [-1, 64, 256]               0
     BatchNorm1d-103              [-1, 64, 256]             128
            ReLU-104              [-1, 64, 256]               0
         Dropout-105              [-1, 64, 256]               0
          Conv1d-106              [-1, 64, 256]           2,112
 MyConv1dPadSame-107              [-1, 64, 256]               0
      Bottleneck-108              [-1, 64, 256]               0
     BatchNorm1d-109              [-1, 64, 256]             128
            ReLU-110              [-1, 64, 256]               0
         Dropout-111              [-1, 64, 256]               0
          Conv1d-112              [-1, 64, 128]           2,112
 MyConv1dPadSame-113              [-1, 64, 128]               0
     BatchNorm1d-114              [-1, 64, 128]             128
            ReLU-115              [-1, 64, 128]               0
         Dropout-116              [-1, 64, 128]               0
          Conv1d-117              [-1, 64, 128]           2,112
 MyConv1dPadSame-118              [-1, 64, 128]               0
       MaxPool1d-119              [-1, 64, 128]               0
MyMaxPool1dPadSame-120              [-1, 64, 128]               0
      Bottleneck-121              [-1, 64, 128]               0
     BatchNorm1d-122              [-1, 64, 128]             128
            ReLU-123              [-1, 64, 128]               0
         Dropout-124              [-1, 64, 128]               0
          Conv1d-125              [-1, 64, 128]           2,112
 MyConv1dPadSame-126              [-1, 64, 128]               0
     BatchNorm1d-127              [-1, 64, 128]             128
            ReLU-128              [-1, 64, 128]               0
         Dropout-129              [-1, 64, 128]               0
          Conv1d-130              [-1, 64, 128]           2,112
 MyConv1dPadSame-131              [-1, 64, 128]               0
      Bottleneck-132              [-1, 64, 128]               0
     BatchNorm1d-133              [-1, 64, 128]             128
            ReLU-134              [-1, 64, 128]               0
         Dropout-135              [-1, 64, 128]               0
          Conv1d-136               [-1, 64, 64]           2,112
 MyConv1dPadSame-137               [-1, 64, 64]               0
     BatchNorm1d-138               [-1, 64, 64]             128
            ReLU-139               [-1, 64, 64]               0
         Dropout-140               [-1, 64, 64]               0
          Conv1d-141               [-1, 64, 64]           2,112
 MyConv1dPadSame-142               [-1, 64, 64]               0
       MaxPool1d-143               [-1, 64, 64]               0
MyMaxPool1dPadSame-144               [-1, 64, 64]               0
      Bottleneck-145               [-1, 64, 64]               0
     BatchNorm1d-146               [-1, 64, 64]             128
            ReLU-147               [-1, 64, 64]               0
         Dropout-148               [-1, 64, 64]               0
          Conv1d-149              [-1, 128, 64]           4,224
 MyConv1dPadSame-150              [-1, 128, 64]               0
     BatchNorm1d-151              [-1, 128, 64]             256
            ReLU-152              [-1, 128, 64]               0
         Dropout-153              [-1, 128, 64]               0
          Conv1d-154              [-1, 128, 64]           8,320
 MyConv1dPadSame-155              [-1, 128, 64]               0
      Bottleneck-156              [-1, 128, 64]               0
     BatchNorm1d-157              [-1, 128, 64]             256
            ReLU-158              [-1, 128, 64]               0
         Dropout-159              [-1, 128, 64]               0
          Conv1d-160              [-1, 128, 32]           8,320
 MyConv1dPadSame-161              [-1, 128, 32]               0
     BatchNorm1d-162              [-1, 128, 32]             256
            ReLU-163              [-1, 128, 32]               0
         Dropout-164              [-1, 128, 32]               0
          Conv1d-165              [-1, 128, 32]           8,320
 MyConv1dPadSame-166              [-1, 128, 32]               0
       MaxPool1d-167              [-1, 128, 32]               0
MyMaxPool1dPadSame-168              [-1, 128, 32]               0
      Bottleneck-169              [-1, 128, 32]               0
     BatchNorm1d-170              [-1, 128, 32]             256
            ReLU-171              [-1, 128, 32]               0
         Dropout-172              [-1, 128, 32]               0
          Conv1d-173              [-1, 128, 32]           8,320
 MyConv1dPadSame-174              [-1, 128, 32]               0
     BatchNorm1d-175              [-1, 128, 32]             256
            ReLU-176              [-1, 128, 32]               0
         Dropout-177              [-1, 128, 32]               0
          Conv1d-178              [-1, 128, 32]           8,320
 MyConv1dPadSame-179              [-1, 128, 32]               0
      Bottleneck-180              [-1, 128, 32]               0
     BatchNorm1d-181              [-1, 128, 32]             256
            ReLU-182              [-1, 128, 32]               0
         Dropout-183              [-1, 128, 32]               0
          Conv1d-184              [-1, 128, 16]           8,320
 MyConv1dPadSame-185              [-1, 128, 16]               0
     BatchNorm1d-186              [-1, 128, 16]             256
            ReLU-187              [-1, 128, 16]               0
         Dropout-188              [-1, 128, 16]               0
          Conv1d-189              [-1, 128, 16]           8,320
 MyConv1dPadSame-190              [-1, 128, 16]               0
       MaxPool1d-191              [-1, 128, 16]               0
MyMaxPool1dPadSame-192              [-1, 128, 16]               0
      Bottleneck-193              [-1, 128, 16]               0
     BatchNorm1d-194              [-1, 128, 16]             256
            ReLU-195              [-1, 128, 16]               0
          Linear-196                    [-1, 2]             258
================================================================
Total params: 87,858
Trainable params: 87,858
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 26.59
Params size (MB): 0.34
Estimated Total Size (MB): 26.94
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 16, kernel_size: 16, n_block: 2
************************************************************
************************************************************
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 16, 4096]             272
   MyConv1dPadSame-2             [-1, 16, 4096]               0
       BatchNorm1d-3             [-1, 16, 4096]              32
              ReLU-4             [-1, 16, 4096]               0
            Conv1d-5             [-1, 16, 4096]             272
   MyConv1dPadSame-6             [-1, 16, 4096]               0
       BatchNorm1d-7             [-1, 16, 4096]              32
              ReLU-8             [-1, 16, 4096]               0
           Dropout-9             [-1, 16, 4096]               0
           Conv1d-10             [-1, 16, 4096]             272
  MyConv1dPadSame-11             [-1, 16, 4096]               0
       Bottleneck-12             [-1, 16, 4096]               0
      BatchNorm1d-13             [-1, 16, 4096]              32
             ReLU-14             [-1, 16, 4096]               0
          Dropout-15             [-1, 16, 4096]               0
           Conv1d-16             [-1, 32, 4096]             544
  MyConv1dPadSame-17             [-1, 32, 4096]               0
      BatchNorm1d-18             [-1, 32, 4096]              64
             ReLU-19             [-1, 32, 4096]               0
          Dropout-20             [-1, 32, 4096]               0
           Conv1d-21             [-1, 32, 4096]           1,056
  MyConv1dPadSame-22             [-1, 32, 4096]               0
       Bottleneck-23             [-1, 32, 4096]               0
      BatchNorm1d-24             [-1, 32, 4096]              64
             ReLU-25             [-1, 32, 4096]               0
           Linear-26                    [-1, 2]              66
================================================================
Total params: 2,706
Trainable params: 2,706
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 17.50
Params size (MB): 0.01
Estimated Total Size (MB): 17.53
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 16, kernel_size: 16, n_block: 4
************************************************************
************************************************************
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 16, 4096]             272
   MyConv1dPadSame-2             [-1, 16, 4096]               0
       BatchNorm1d-3             [-1, 16, 4096]              32
              ReLU-4             [-1, 16, 4096]               0
            Conv1d-5             [-1, 16, 4096]             272
   MyConv1dPadSame-6             [-1, 16, 4096]               0
       BatchNorm1d-7             [-1, 16, 4096]              32
              ReLU-8             [-1, 16, 4096]               0
           Dropout-9             [-1, 16, 4096]               0
           Conv1d-10             [-1, 16, 4096]             272
  MyConv1dPadSame-11             [-1, 16, 4096]               0
       Bottleneck-12             [-1, 16, 4096]               0
      BatchNorm1d-13             [-1, 16, 4096]              32
             ReLU-14             [-1, 16, 4096]               0
          Dropout-15             [-1, 16, 4096]               0
           Conv1d-16             [-1, 32, 4096]             544
  MyConv1dPadSame-17             [-1, 32, 4096]               0
      BatchNorm1d-18             [-1, 32, 4096]              64
             ReLU-19             [-1, 32, 4096]               0
          Dropout-20             [-1, 32, 4096]               0
           Conv1d-21             [-1, 32, 4096]           1,056
  MyConv1dPadSame-22             [-1, 32, 4096]               0
       Bottleneck-23             [-1, 32, 4096]               0
      BatchNorm1d-24             [-1, 32, 4096]              64
             ReLU-25             [-1, 32, 4096]               0
          Dropout-26             [-1, 32, 4096]               0
           Conv1d-27             [-1, 64, 4096]           2,112
  MyConv1dPadSame-28             [-1, 64, 4096]               0
      BatchNorm1d-29             [-1, 64, 4096]             128
             ReLU-30             [-1, 64, 4096]               0
          Dropout-31             [-1, 64, 4096]               0
           Conv1d-32             [-1, 64, 4096]           4,160
  MyConv1dPadSame-33             [-1, 64, 4096]               0
       Bottleneck-34             [-1, 64, 4096]               0
      BatchNorm1d-35             [-1, 64, 4096]             128
             ReLU-36             [-1, 64, 4096]               0
          Dropout-37             [-1, 64, 4096]               0
           Conv1d-38            [-1, 128, 4096]           8,320
  MyConv1dPadSame-39            [-1, 128, 4096]               0
      BatchNorm1d-40            [-1, 128, 4096]             256
             ReLU-41            [-1, 128, 4096]               0
          Dropout-42            [-1, 128, 4096]               0
           Conv1d-43            [-1, 128, 4096]          16,512
  MyConv1dPadSame-44            [-1, 128, 4096]               0
       Bottleneck-45            [-1, 128, 4096]               0
      BatchNorm1d-46            [-1, 128, 4096]             256
             ReLU-47            [-1, 128, 4096]               0
           Linear-48                    [-1, 2]             258
================================================================
Total params: 34,770
Trainable params: 34,770
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 80.50
Params size (MB): 0.13
Estimated Total Size (MB): 80.65
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 16, kernel_size: 16, n_block: 8
************************************************************
************************************************************
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 16, 4096]             272
   MyConv1dPadSame-2             [-1, 16, 4096]               0
       BatchNorm1d-3             [-1, 16, 4096]              32
              ReLU-4             [-1, 16, 4096]               0
            Conv1d-5             [-1, 16, 4096]             272
   MyConv1dPadSame-6             [-1, 16, 4096]               0
       BatchNorm1d-7             [-1, 16, 4096]              32
              ReLU-8             [-1, 16, 4096]               0
           Dropout-9             [-1, 16, 4096]               0
           Conv1d-10             [-1, 16, 4096]             272
  MyConv1dPadSame-11             [-1, 16, 4096]               0
       Bottleneck-12             [-1, 16, 4096]               0
      BatchNorm1d-13             [-1, 16, 4096]              32
             ReLU-14             [-1, 16, 4096]               0
          Dropout-15             [-1, 16, 4096]               0
           Conv1d-16             [-1, 16, 4096]             272
  MyConv1dPadSame-17             [-1, 16, 4096]               0
      BatchNorm1d-18             [-1, 16, 4096]              32
             ReLU-19             [-1, 16, 4096]               0
          Dropout-20             [-1, 16, 4096]               0
           Conv1d-21             [-1, 16, 4096]             272
  MyConv1dPadSame-22             [-1, 16, 4096]               0
       Bottleneck-23             [-1, 16, 4096]               0
      BatchNorm1d-24             [-1, 16, 4096]              32
             ReLU-25             [-1, 16, 4096]               0
          Dropout-26             [-1, 16, 4096]               0
           Conv1d-27             [-1, 32, 4096]             544
  MyConv1dPadSame-28             [-1, 32, 4096]               0
      BatchNorm1d-29             [-1, 32, 4096]              64
             ReLU-30             [-1, 32, 4096]               0
          Dropout-31             [-1, 32, 4096]               0
           Conv1d-32             [-1, 32, 4096]           1,056
  MyConv1dPadSame-33             [-1, 32, 4096]               0
       Bottleneck-34             [-1, 32, 4096]               0
      BatchNorm1d-35             [-1, 32, 4096]              64
             ReLU-36             [-1, 32, 4096]               0
          Dropout-37             [-1, 32, 4096]               0
           Conv1d-38             [-1, 32, 4096]           1,056
  MyConv1dPadSame-39             [-1, 32, 4096]               0
      BatchNorm1d-40             [-1, 32, 4096]              64
             ReLU-41             [-1, 32, 4096]               0
          Dropout-42             [-1, 32, 4096]               0
           Conv1d-43             [-1, 32, 4096]           1,056
  MyConv1dPadSame-44             [-1, 32, 4096]               0
       Bottleneck-45             [-1, 32, 4096]               0
      BatchNorm1d-46             [-1, 32, 4096]              64
             ReLU-47             [-1, 32, 4096]               0
          Dropout-48             [-1, 32, 4096]               0
           Conv1d-49             [-1, 64, 4096]           2,112
  MyConv1dPadSame-50             [-1, 64, 4096]               0
      BatchNorm1d-51             [-1, 64, 4096]             128
             ReLU-52             [-1, 64, 4096]               0
          Dropout-53             [-1, 64, 4096]               0
           Conv1d-54             [-1, 64, 4096]           4,160
  MyConv1dPadSame-55             [-1, 64, 4096]               0
       Bottleneck-56             [-1, 64, 4096]               0
      BatchNorm1d-57             [-1, 64, 4096]             128
             ReLU-58             [-1, 64, 4096]               0
          Dropout-59             [-1, 64, 4096]               0
           Conv1d-60             [-1, 64, 4096]           4,160
  MyConv1dPadSame-61             [-1, 64, 4096]               0
      BatchNorm1d-62             [-1, 64, 4096]             128
             ReLU-63             [-1, 64, 4096]               0
          Dropout-64             [-1, 64, 4096]               0
           Conv1d-65             [-1, 64, 4096]           4,160
  MyConv1dPadSame-66             [-1, 64, 4096]               0
       Bottleneck-67             [-1, 64, 4096]               0
      BatchNorm1d-68             [-1, 64, 4096]             128
             ReLU-69             [-1, 64, 4096]               0
          Dropout-70             [-1, 64, 4096]               0
           Conv1d-71            [-1, 128, 4096]           8,320
  MyConv1dPadSame-72            [-1, 128, 4096]               0
      BatchNorm1d-73            [-1, 128, 4096]             256
             ReLU-74            [-1, 128, 4096]               0
          Dropout-75            [-1, 128, 4096]               0
           Conv1d-76            [-1, 128, 4096]          16,512
  MyConv1dPadSame-77            [-1, 128, 4096]               0
       Bottleneck-78            [-1, 128, 4096]               0
      BatchNorm1d-79            [-1, 128, 4096]             256
             ReLU-80            [-1, 128, 4096]               0
          Dropout-81            [-1, 128, 4096]               0
           Conv1d-82            [-1, 128, 4096]          16,512
  MyConv1dPadSame-83            [-1, 128, 4096]               0
      BatchNorm1d-84            [-1, 128, 4096]             256
             ReLU-85            [-1, 128, 4096]               0
          Dropout-86            [-1, 128, 4096]               0
           Conv1d-87            [-1, 128, 4096]          16,512
  MyConv1dPadSame-88            [-1, 128, 4096]               0
       Bottleneck-89            [-1, 128, 4096]               0
      BatchNorm1d-90            [-1, 128, 4096]             256
             ReLU-91            [-1, 128, 4096]               0
           Linear-92                    [-1, 2]             258
================================================================
Total params: 79,730
Trainable params: 79,730
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 163.00
Params size (MB): 0.30
Estimated Total Size (MB): 163.32
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 16, kernel_size: 16, n_block: 16
************************************************************
************************************************************
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 16, 4096]             272
   MyConv1dPadSame-2             [-1, 16, 4096]               0
       BatchNorm1d-3             [-1, 16, 4096]              32
              ReLU-4             [-1, 16, 4096]               0
            Conv1d-5             [-1, 16, 4096]             272
   MyConv1dPadSame-6             [-1, 16, 4096]               0
       BatchNorm1d-7             [-1, 16, 4096]              32
              ReLU-8             [-1, 16, 4096]               0
           Dropout-9             [-1, 16, 4096]               0
           Conv1d-10             [-1, 16, 4096]             272
  MyConv1dPadSame-11             [-1, 16, 4096]               0
       Bottleneck-12             [-1, 16, 4096]               0
      BatchNorm1d-13             [-1, 16, 4096]              32
             ReLU-14             [-1, 16, 4096]               0
          Dropout-15             [-1, 16, 4096]               0
           Conv1d-16             [-1, 16, 2048]             272
  MyConv1dPadSame-17             [-1, 16, 2048]               0
      BatchNorm1d-18             [-1, 16, 2048]              32
             ReLU-19             [-1, 16, 2048]               0
          Dropout-20             [-1, 16, 2048]               0
           Conv1d-21             [-1, 16, 2048]             272
  MyConv1dPadSame-22             [-1, 16, 2048]               0
        MaxPool1d-23             [-1, 16, 2048]               0
MyMaxPool1dPadSame-24             [-1, 16, 2048]               0
       Bottleneck-25             [-1, 16, 2048]               0
      BatchNorm1d-26             [-1, 16, 2048]              32
             ReLU-27             [-1, 16, 2048]               0
          Dropout-28             [-1, 16, 2048]               0
           Conv1d-29             [-1, 16, 2048]             272
  MyConv1dPadSame-30             [-1, 16, 2048]               0
      BatchNorm1d-31             [-1, 16, 2048]              32
             ReLU-32             [-1, 16, 2048]               0
          Dropout-33             [-1, 16, 2048]               0
           Conv1d-34             [-1, 16, 2048]             272
  MyConv1dPadSame-35             [-1, 16, 2048]               0
       Bottleneck-36             [-1, 16, 2048]               0
      BatchNorm1d-37             [-1, 16, 2048]              32
             ReLU-38             [-1, 16, 2048]               0
          Dropout-39             [-1, 16, 2048]               0
           Conv1d-40             [-1, 16, 1024]             272
  MyConv1dPadSame-41             [-1, 16, 1024]               0
      BatchNorm1d-42             [-1, 16, 1024]              32
             ReLU-43             [-1, 16, 1024]               0
          Dropout-44             [-1, 16, 1024]               0
           Conv1d-45             [-1, 16, 1024]             272
  MyConv1dPadSame-46             [-1, 16, 1024]               0
        MaxPool1d-47             [-1, 16, 1024]               0
MyMaxPool1dPadSame-48             [-1, 16, 1024]               0
       Bottleneck-49             [-1, 16, 1024]               0
      BatchNorm1d-50             [-1, 16, 1024]              32
             ReLU-51             [-1, 16, 1024]               0
          Dropout-52             [-1, 16, 1024]               0
           Conv1d-53             [-1, 32, 1024]             544
  MyConv1dPadSame-54             [-1, 32, 1024]               0
      BatchNorm1d-55             [-1, 32, 1024]              64
             ReLU-56             [-1, 32, 1024]               0
          Dropout-57             [-1, 32, 1024]               0
           Conv1d-58             [-1, 32, 1024]           1,056
  MyConv1dPadSame-59             [-1, 32, 1024]               0
       Bottleneck-60             [-1, 32, 1024]               0
      BatchNorm1d-61             [-1, 32, 1024]              64
             ReLU-62             [-1, 32, 1024]               0
          Dropout-63             [-1, 32, 1024]               0
           Conv1d-64              [-1, 32, 512]           1,056
  MyConv1dPadSame-65              [-1, 32, 512]               0
      BatchNorm1d-66              [-1, 32, 512]              64
             ReLU-67              [-1, 32, 512]               0
          Dropout-68              [-1, 32, 512]               0
           Conv1d-69              [-1, 32, 512]           1,056
  MyConv1dPadSame-70              [-1, 32, 512]               0
        MaxPool1d-71              [-1, 32, 512]               0
MyMaxPool1dPadSame-72              [-1, 32, 512]               0
       Bottleneck-73              [-1, 32, 512]               0
      BatchNorm1d-74              [-1, 32, 512]              64
             ReLU-75              [-1, 32, 512]               0
          Dropout-76              [-1, 32, 512]               0
           Conv1d-77              [-1, 32, 512]           1,056
  MyConv1dPadSame-78              [-1, 32, 512]               0
      BatchNorm1d-79              [-1, 32, 512]              64
             ReLU-80              [-1, 32, 512]               0
          Dropout-81              [-1, 32, 512]               0
           Conv1d-82              [-1, 32, 512]           1,056
  MyConv1dPadSame-83              [-1, 32, 512]               0
       Bottleneck-84              [-1, 32, 512]               0
      BatchNorm1d-85              [-1, 32, 512]              64
             ReLU-86              [-1, 32, 512]               0
          Dropout-87              [-1, 32, 512]               0
           Conv1d-88              [-1, 32, 256]           1,056
  MyConv1dPadSame-89              [-1, 32, 256]               0
      BatchNorm1d-90              [-1, 32, 256]              64
             ReLU-91              [-1, 32, 256]               0
          Dropout-92              [-1, 32, 256]               0
           Conv1d-93              [-1, 32, 256]           1,056
  MyConv1dPadSame-94              [-1, 32, 256]               0
        MaxPool1d-95              [-1, 32, 256]               0
MyMaxPool1dPadSame-96              [-1, 32, 256]               0
       Bottleneck-97              [-1, 32, 256]               0
      BatchNorm1d-98              [-1, 32, 256]              64
             ReLU-99              [-1, 32, 256]               0
         Dropout-100              [-1, 32, 256]               0
          Conv1d-101              [-1, 64, 256]           2,112
 MyConv1dPadSame-102              [-1, 64, 256]               0
     BatchNorm1d-103              [-1, 64, 256]             128
            ReLU-104              [-1, 64, 256]               0
         Dropout-105              [-1, 64, 256]               0
          Conv1d-106              [-1, 64, 256]           4,160
 MyConv1dPadSame-107              [-1, 64, 256]               0
      Bottleneck-108              [-1, 64, 256]               0
     BatchNorm1d-109              [-1, 64, 256]             128
            ReLU-110              [-1, 64, 256]               0
         Dropout-111              [-1, 64, 256]               0
          Conv1d-112              [-1, 64, 128]           4,160
 MyConv1dPadSame-113              [-1, 64, 128]               0
     BatchNorm1d-114              [-1, 64, 128]             128
            ReLU-115              [-1, 64, 128]               0
         Dropout-116              [-1, 64, 128]               0
          Conv1d-117              [-1, 64, 128]           4,160
 MyConv1dPadSame-118              [-1, 64, 128]               0
       MaxPool1d-119              [-1, 64, 128]               0
MyMaxPool1dPadSame-120              [-1, 64, 128]               0
      Bottleneck-121              [-1, 64, 128]               0
     BatchNorm1d-122              [-1, 64, 128]             128
            ReLU-123              [-1, 64, 128]               0
         Dropout-124              [-1, 64, 128]               0
          Conv1d-125              [-1, 64, 128]           4,160
 MyConv1dPadSame-126              [-1, 64, 128]               0
     BatchNorm1d-127              [-1, 64, 128]             128
            ReLU-128              [-1, 64, 128]               0
         Dropout-129              [-1, 64, 128]               0
          Conv1d-130              [-1, 64, 128]           4,160
 MyConv1dPadSame-131              [-1, 64, 128]               0
      Bottleneck-132              [-1, 64, 128]               0
     BatchNorm1d-133              [-1, 64, 128]             128
            ReLU-134              [-1, 64, 128]               0
         Dropout-135              [-1, 64, 128]               0
          Conv1d-136               [-1, 64, 64]           4,160
 MyConv1dPadSame-137               [-1, 64, 64]               0
     BatchNorm1d-138               [-1, 64, 64]             128
            ReLU-139               [-1, 64, 64]               0
         Dropout-140               [-1, 64, 64]               0
          Conv1d-141               [-1, 64, 64]           4,160
 MyConv1dPadSame-142               [-1, 64, 64]               0
       MaxPool1d-143               [-1, 64, 64]               0
MyMaxPool1dPadSame-144               [-1, 64, 64]               0
      Bottleneck-145               [-1, 64, 64]               0
     BatchNorm1d-146               [-1, 64, 64]             128
            ReLU-147               [-1, 64, 64]               0
         Dropout-148               [-1, 64, 64]               0
          Conv1d-149              [-1, 128, 64]           8,320
 MyConv1dPadSame-150              [-1, 128, 64]               0
     BatchNorm1d-151              [-1, 128, 64]             256
            ReLU-152              [-1, 128, 64]               0
         Dropout-153              [-1, 128, 64]               0
          Conv1d-154              [-1, 128, 64]          16,512
 MyConv1dPadSame-155              [-1, 128, 64]               0
      Bottleneck-156              [-1, 128, 64]               0
     BatchNorm1d-157              [-1, 128, 64]             256
            ReLU-158              [-1, 128, 64]               0
         Dropout-159              [-1, 128, 64]               0
          Conv1d-160              [-1, 128, 32]          16,512
 MyConv1dPadSame-161              [-1, 128, 32]               0
     BatchNorm1d-162              [-1, 128, 32]             256
            ReLU-163              [-1, 128, 32]               0
         Dropout-164              [-1, 128, 32]               0
          Conv1d-165              [-1, 128, 32]          16,512
 MyConv1dPadSame-166              [-1, 128, 32]               0
       MaxPool1d-167              [-1, 128, 32]               0
MyMaxPool1dPadSame-168              [-1, 128, 32]               0
      Bottleneck-169              [-1, 128, 32]               0
     BatchNorm1d-170              [-1, 128, 32]             256
            ReLU-171              [-1, 128, 32]               0
         Dropout-172              [-1, 128, 32]               0
          Conv1d-173              [-1, 128, 32]          16,512
 MyConv1dPadSame-174              [-1, 128, 32]               0
     BatchNorm1d-175              [-1, 128, 32]             256
            ReLU-176              [-1, 128, 32]               0
         Dropout-177              [-1, 128, 32]               0
          Conv1d-178              [-1, 128, 32]          16,512
 MyConv1dPadSame-179              [-1, 128, 32]               0
      Bottleneck-180              [-1, 128, 32]               0
     BatchNorm1d-181              [-1, 128, 32]             256
            ReLU-182              [-1, 128, 32]               0
         Dropout-183              [-1, 128, 32]               0
          Conv1d-184              [-1, 128, 16]          16,512
 MyConv1dPadSame-185              [-1, 128, 16]               0
     BatchNorm1d-186              [-1, 128, 16]             256
            ReLU-187              [-1, 128, 16]               0
         Dropout-188              [-1, 128, 16]               0
          Conv1d-189              [-1, 128, 16]          16,512
 MyConv1dPadSame-190              [-1, 128, 16]               0
       MaxPool1d-191              [-1, 128, 16]               0
MyMaxPool1dPadSame-192              [-1, 128, 16]               0
      Bottleneck-193              [-1, 128, 16]               0
     BatchNorm1d-194              [-1, 128, 16]             256
            ReLU-195              [-1, 128, 16]               0
          Linear-196                    [-1, 2]             258
================================================================
Total params: 169,650
Trainable params: 169,650
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 26.59
Params size (MB): 0.65
Estimated Total Size (MB): 27.26
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 32, kernel_size: 2, n_block: 2
************************************************************
************************************************************
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 32, 4096]              96
   MyConv1dPadSame-2             [-1, 32, 4096]               0
       BatchNorm1d-3             [-1, 32, 4096]              64
              ReLU-4             [-1, 32, 4096]               0
            Conv1d-5             [-1, 32, 4096]              96
   MyConv1dPadSame-6             [-1, 32, 4096]               0
       BatchNorm1d-7             [-1, 32, 4096]              64
              ReLU-8             [-1, 32, 4096]               0
           Dropout-9             [-1, 32, 4096]               0
           Conv1d-10             [-1, 32, 4096]              96
  MyConv1dPadSame-11             [-1, 32, 4096]               0
       Bottleneck-12             [-1, 32, 4096]               0
      BatchNorm1d-13             [-1, 32, 4096]              64
             ReLU-14             [-1, 32, 4096]               0
          Dropout-15             [-1, 32, 4096]               0
           Conv1d-16             [-1, 64, 4096]             192
  MyConv1dPadSame-17             [-1, 64, 4096]               0
      BatchNorm1d-18             [-1, 64, 4096]             128
             ReLU-19             [-1, 64, 4096]               0
          Dropout-20             [-1, 64, 4096]               0
           Conv1d-21             [-1, 64, 4096]             320
  MyConv1dPadSame-22             [-1, 64, 4096]               0
       Bottleneck-23             [-1, 64, 4096]               0
      BatchNorm1d-24             [-1, 64, 4096]             128
             ReLU-25             [-1, 64, 4096]               0
           Linear-26                    [-1, 2]             130
================================================================
Total params: 1,378
Trainable params: 1,378
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 35.00
Params size (MB): 0.01
Estimated Total Size (MB): 35.02
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 32, kernel_size: 2, n_block: 4
************************************************************
************************************************************
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 32, 4096]              96
   MyConv1dPadSame-2             [-1, 32, 4096]               0
       BatchNorm1d-3             [-1, 32, 4096]              64
              ReLU-4             [-1, 32, 4096]               0
            Conv1d-5             [-1, 32, 4096]              96
   MyConv1dPadSame-6             [-1, 32, 4096]               0
       BatchNorm1d-7             [-1, 32, 4096]              64
              ReLU-8             [-1, 32, 4096]               0
           Dropout-9             [-1, 32, 4096]               0
           Conv1d-10             [-1, 32, 4096]              96
  MyConv1dPadSame-11             [-1, 32, 4096]               0
       Bottleneck-12             [-1, 32, 4096]               0
      BatchNorm1d-13             [-1, 32, 4096]              64
             ReLU-14             [-1, 32, 4096]               0
          Dropout-15             [-1, 32, 4096]               0
           Conv1d-16             [-1, 64, 4096]             192
  MyConv1dPadSame-17             [-1, 64, 4096]               0
      BatchNorm1d-18             [-1, 64, 4096]             128
             ReLU-19             [-1, 64, 4096]               0
          Dropout-20             [-1, 64, 4096]               0
           Conv1d-21             [-1, 64, 4096]             320
  MyConv1dPadSame-22             [-1, 64, 4096]               0
       Bottleneck-23             [-1, 64, 4096]               0
      BatchNorm1d-24             [-1, 64, 4096]             128
             ReLU-25             [-1, 64, 4096]               0
          Dropout-26             [-1, 64, 4096]               0
           Conv1d-27            [-1, 128, 4096]             640
  MyConv1dPadSame-28            [-1, 128, 4096]               0
      BatchNorm1d-29            [-1, 128, 4096]             256
             ReLU-30            [-1, 128, 4096]               0
          Dropout-31            [-1, 128, 4096]               0
           Conv1d-32            [-1, 128, 4096]           1,152
  MyConv1dPadSame-33            [-1, 128, 4096]               0
       Bottleneck-34            [-1, 128, 4096]               0
      BatchNorm1d-35            [-1, 128, 4096]             256
             ReLU-36            [-1, 128, 4096]               0
          Dropout-37            [-1, 128, 4096]               0
           Conv1d-38            [-1, 256, 4096]           2,304
  MyConv1dPadSame-39            [-1, 256, 4096]               0
      BatchNorm1d-40            [-1, 256, 4096]             512
             ReLU-41            [-1, 256, 4096]               0
          Dropout-42            [-1, 256, 4096]               0
           Conv1d-43            [-1, 256, 4096]           4,352
  MyConv1dPadSame-44            [-1, 256, 4096]               0
       Bottleneck-45            [-1, 256, 4096]               0
      BatchNorm1d-46            [-1, 256, 4096]             512
             ReLU-47            [-1, 256, 4096]               0
           Linear-48                    [-1, 2]             514
================================================================
Total params: 11,746
Trainable params: 11,746
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 161.00
Params size (MB): 0.04
Estimated Total Size (MB): 161.06
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 32, kernel_size: 2, n_block: 8
************************************************************
************************************************************
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 32, 4096]              96
   MyConv1dPadSame-2             [-1, 32, 4096]               0
       BatchNorm1d-3             [-1, 32, 4096]              64
              ReLU-4             [-1, 32, 4096]               0
            Conv1d-5             [-1, 32, 4096]              96
   MyConv1dPadSame-6             [-1, 32, 4096]               0
       BatchNorm1d-7             [-1, 32, 4096]              64
              ReLU-8             [-1, 32, 4096]               0
           Dropout-9             [-1, 32, 4096]               0
           Conv1d-10             [-1, 32, 4096]              96
  MyConv1dPadSame-11             [-1, 32, 4096]               0
       Bottleneck-12             [-1, 32, 4096]               0
      BatchNorm1d-13             [-1, 32, 4096]              64
             ReLU-14             [-1, 32, 4096]               0
          Dropout-15             [-1, 32, 4096]               0
           Conv1d-16             [-1, 32, 4096]              96
  MyConv1dPadSame-17             [-1, 32, 4096]               0
      BatchNorm1d-18             [-1, 32, 4096]              64
             ReLU-19             [-1, 32, 4096]               0
          Dropout-20             [-1, 32, 4096]               0
           Conv1d-21             [-1, 32, 4096]              96
  MyConv1dPadSame-22             [-1, 32, 4096]               0
       Bottleneck-23             [-1, 32, 4096]               0
      BatchNorm1d-24             [-1, 32, 4096]              64
             ReLU-25             [-1, 32, 4096]               0
          Dropout-26             [-1, 32, 4096]               0
           Conv1d-27             [-1, 64, 4096]             192
  MyConv1dPadSame-28             [-1, 64, 4096]               0
      BatchNorm1d-29             [-1, 64, 4096]             128
             ReLU-30             [-1, 64, 4096]               0
          Dropout-31             [-1, 64, 4096]               0
           Conv1d-32             [-1, 64, 4096]             320
  MyConv1dPadSame-33             [-1, 64, 4096]               0
       Bottleneck-34             [-1, 64, 4096]               0
      BatchNorm1d-35             [-1, 64, 4096]             128
             ReLU-36             [-1, 64, 4096]               0
          Dropout-37             [-1, 64, 4096]               0
           Conv1d-38             [-1, 64, 4096]             320
  MyConv1dPadSame-39             [-1, 64, 4096]               0
      BatchNorm1d-40             [-1, 64, 4096]             128
             ReLU-41             [-1, 64, 4096]               0
          Dropout-42             [-1, 64, 4096]               0
           Conv1d-43             [-1, 64, 4096]             320
  MyConv1dPadSame-44             [-1, 64, 4096]               0
       Bottleneck-45             [-1, 64, 4096]               0
      BatchNorm1d-46             [-1, 64, 4096]             128
             ReLU-47             [-1, 64, 4096]               0
          Dropout-48             [-1, 64, 4096]               0
           Conv1d-49            [-1, 128, 4096]             640
  MyConv1dPadSame-50            [-1, 128, 4096]               0
      BatchNorm1d-51            [-1, 128, 4096]             256
             ReLU-52            [-1, 128, 4096]               0
          Dropout-53            [-1, 128, 4096]               0
           Conv1d-54            [-1, 128, 4096]           1,152
  MyConv1dPadSame-55            [-1, 128, 4096]               0
       Bottleneck-56            [-1, 128, 4096]               0
      BatchNorm1d-57            [-1, 128, 4096]             256
             ReLU-58            [-1, 128, 4096]               0
          Dropout-59            [-1, 128, 4096]               0
           Conv1d-60            [-1, 128, 4096]           1,152
  MyConv1dPadSame-61            [-1, 128, 4096]               0
      BatchNorm1d-62            [-1, 128, 4096]             256
             ReLU-63            [-1, 128, 4096]               0
          Dropout-64            [-1, 128, 4096]               0
           Conv1d-65            [-1, 128, 4096]           1,152
  MyConv1dPadSame-66            [-1, 128, 4096]               0
       Bottleneck-67            [-1, 128, 4096]               0
      BatchNorm1d-68            [-1, 128, 4096]             256
             ReLU-69            [-1, 128, 4096]               0
          Dropout-70            [-1, 128, 4096]               0
           Conv1d-71            [-1, 256, 4096]           2,304
  MyConv1dPadSame-72            [-1, 256, 4096]               0
      BatchNorm1d-73            [-1, 256, 4096]             512
             ReLU-74            [-1, 256, 4096]               0
          Dropout-75            [-1, 256, 4096]               0
           Conv1d-76            [-1, 256, 4096]           4,352
  MyConv1dPadSame-77            [-1, 256, 4096]               0
       Bottleneck-78            [-1, 256, 4096]               0
      BatchNorm1d-79            [-1, 256, 4096]             512
             ReLU-80            [-1, 256, 4096]               0
          Dropout-81            [-1, 256, 4096]               0
           Conv1d-82            [-1, 256, 4096]           4,352
  MyConv1dPadSame-83            [-1, 256, 4096]               0
      BatchNorm1d-84            [-1, 256, 4096]             512
             ReLU-85            [-1, 256, 4096]               0
          Dropout-86            [-1, 256, 4096]               0
           Conv1d-87            [-1, 256, 4096]           4,352
  MyConv1dPadSame-88            [-1, 256, 4096]               0
       Bottleneck-89            [-1, 256, 4096]               0
      BatchNorm1d-90            [-1, 256, 4096]             512
             ReLU-91            [-1, 256, 4096]               0
           Linear-92                    [-1, 2]             514
================================================================
Total params: 25,506
Trainable params: 25,506
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 326.00
Params size (MB): 0.10
Estimated Total Size (MB): 326.11
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 32, kernel_size: 2, n_block: 16
************************************************************
************************************************************
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 32, 4096]              96
   MyConv1dPadSame-2             [-1, 32, 4096]               0
       BatchNorm1d-3             [-1, 32, 4096]              64
              ReLU-4             [-1, 32, 4096]               0
            Conv1d-5             [-1, 32, 4096]              96
   MyConv1dPadSame-6             [-1, 32, 4096]               0
       BatchNorm1d-7             [-1, 32, 4096]              64
              ReLU-8             [-1, 32, 4096]               0
           Dropout-9             [-1, 32, 4096]               0
           Conv1d-10             [-1, 32, 4096]              96
  MyConv1dPadSame-11             [-1, 32, 4096]               0
       Bottleneck-12             [-1, 32, 4096]               0
      BatchNorm1d-13             [-1, 32, 4096]              64
             ReLU-14             [-1, 32, 4096]               0
          Dropout-15             [-1, 32, 4096]               0
           Conv1d-16             [-1, 32, 2048]              96
  MyConv1dPadSame-17             [-1, 32, 2048]               0
      BatchNorm1d-18             [-1, 32, 2048]              64
             ReLU-19             [-1, 32, 2048]               0
          Dropout-20             [-1, 32, 2048]               0
           Conv1d-21             [-1, 32, 2048]              96
  MyConv1dPadSame-22             [-1, 32, 2048]               0
        MaxPool1d-23             [-1, 32, 2048]               0
MyMaxPool1dPadSame-24             [-1, 32, 2048]               0
       Bottleneck-25             [-1, 32, 2048]               0
      BatchNorm1d-26             [-1, 32, 2048]              64
             ReLU-27             [-1, 32, 2048]               0
          Dropout-28             [-1, 32, 2048]               0
           Conv1d-29             [-1, 32, 2048]              96
  MyConv1dPadSame-30             [-1, 32, 2048]               0
      BatchNorm1d-31             [-1, 32, 2048]              64
             ReLU-32             [-1, 32, 2048]               0
          Dropout-33             [-1, 32, 2048]               0
           Conv1d-34             [-1, 32, 2048]              96
  MyConv1dPadSame-35             [-1, 32, 2048]               0
       Bottleneck-36             [-1, 32, 2048]               0
      BatchNorm1d-37             [-1, 32, 2048]              64
             ReLU-38             [-1, 32, 2048]               0
          Dropout-39             [-1, 32, 2048]               0
           Conv1d-40             [-1, 32, 1024]              96
  MyConv1dPadSame-41             [-1, 32, 1024]               0
      BatchNorm1d-42             [-1, 32, 1024]              64
             ReLU-43             [-1, 32, 1024]               0
          Dropout-44             [-1, 32, 1024]               0
           Conv1d-45             [-1, 32, 1024]              96
  MyConv1dPadSame-46             [-1, 32, 1024]               0
        MaxPool1d-47             [-1, 32, 1024]               0
MyMaxPool1dPadSame-48             [-1, 32, 1024]               0
       Bottleneck-49             [-1, 32, 1024]               0
      BatchNorm1d-50             [-1, 32, 1024]              64
             ReLU-51             [-1, 32, 1024]               0
          Dropout-52             [-1, 32, 1024]               0
           Conv1d-53             [-1, 64, 1024]             192
  MyConv1dPadSame-54             [-1, 64, 1024]               0
      BatchNorm1d-55             [-1, 64, 1024]             128
             ReLU-56             [-1, 64, 1024]               0
          Dropout-57             [-1, 64, 1024]               0
           Conv1d-58             [-1, 64, 1024]             320
  MyConv1dPadSame-59             [-1, 64, 1024]               0
       Bottleneck-60             [-1, 64, 1024]               0
      BatchNorm1d-61             [-1, 64, 1024]             128
             ReLU-62             [-1, 64, 1024]               0
          Dropout-63             [-1, 64, 1024]               0
           Conv1d-64              [-1, 64, 512]             320
  MyConv1dPadSame-65              [-1, 64, 512]               0
      BatchNorm1d-66              [-1, 64, 512]             128
             ReLU-67              [-1, 64, 512]               0
          Dropout-68              [-1, 64, 512]               0
           Conv1d-69              [-1, 64, 512]             320
  MyConv1dPadSame-70              [-1, 64, 512]               0
        MaxPool1d-71              [-1, 64, 512]               0
MyMaxPool1dPadSame-72              [-1, 64, 512]               0
       Bottleneck-73              [-1, 64, 512]               0
      BatchNorm1d-74              [-1, 64, 512]             128
             ReLU-75              [-1, 64, 512]               0
          Dropout-76              [-1, 64, 512]               0
           Conv1d-77              [-1, 64, 512]             320
  MyConv1dPadSame-78              [-1, 64, 512]               0
      BatchNorm1d-79              [-1, 64, 512]             128
             ReLU-80              [-1, 64, 512]               0
          Dropout-81              [-1, 64, 512]               0
           Conv1d-82              [-1, 64, 512]             320
  MyConv1dPadSame-83              [-1, 64, 512]               0
       Bottleneck-84              [-1, 64, 512]               0
      BatchNorm1d-85              [-1, 64, 512]             128
             ReLU-86              [-1, 64, 512]               0
          Dropout-87              [-1, 64, 512]               0
           Conv1d-88              [-1, 64, 256]             320
  MyConv1dPadSame-89              [-1, 64, 256]               0
      BatchNorm1d-90              [-1, 64, 256]             128
             ReLU-91              [-1, 64, 256]               0
          Dropout-92              [-1, 64, 256]               0
           Conv1d-93              [-1, 64, 256]             320
  MyConv1dPadSame-94              [-1, 64, 256]               0
        MaxPool1d-95              [-1, 64, 256]               0
MyMaxPool1dPadSame-96              [-1, 64, 256]               0
       Bottleneck-97              [-1, 64, 256]               0
      BatchNorm1d-98              [-1, 64, 256]             128
             ReLU-99              [-1, 64, 256]               0
         Dropout-100              [-1, 64, 256]               0
          Conv1d-101             [-1, 128, 256]             640
 MyConv1dPadSame-102             [-1, 128, 256]               0
     BatchNorm1d-103             [-1, 128, 256]             256
            ReLU-104             [-1, 128, 256]               0
         Dropout-105             [-1, 128, 256]               0
          Conv1d-106             [-1, 128, 256]           1,152
 MyConv1dPadSame-107             [-1, 128, 256]               0
      Bottleneck-108             [-1, 128, 256]               0
     BatchNorm1d-109             [-1, 128, 256]             256
            ReLU-110             [-1, 128, 256]               0
         Dropout-111             [-1, 128, 256]               0
          Conv1d-112             [-1, 128, 128]           1,152
 MyConv1dPadSame-113             [-1, 128, 128]               0
     BatchNorm1d-114             [-1, 128, 128]             256
            ReLU-115             [-1, 128, 128]               0
         Dropout-116             [-1, 128, 128]               0
          Conv1d-117             [-1, 128, 128]           1,152
 MyConv1dPadSame-118             [-1, 128, 128]               0
       MaxPool1d-119             [-1, 128, 128]               0
MyMaxPool1dPadSame-120             [-1, 128, 128]               0
      Bottleneck-121             [-1, 128, 128]               0
     BatchNorm1d-122             [-1, 128, 128]             256
            ReLU-123             [-1, 128, 128]               0
         Dropout-124             [-1, 128, 128]               0
          Conv1d-125             [-1, 128, 128]           1,152
 MyConv1dPadSame-126             [-1, 128, 128]               0
     BatchNorm1d-127             [-1, 128, 128]             256
            ReLU-128             [-1, 128, 128]               0
         Dropout-129             [-1, 128, 128]               0
          Conv1d-130             [-1, 128, 128]           1,152
 MyConv1dPadSame-131             [-1, 128, 128]               0
      Bottleneck-132             [-1, 128, 128]               0
     BatchNorm1d-133             [-1, 128, 128]             256
            ReLU-134             [-1, 128, 128]               0
         Dropout-135             [-1, 128, 128]               0
          Conv1d-136              [-1, 128, 64]           1,152
 MyConv1dPadSame-137              [-1, 128, 64]               0
     BatchNorm1d-138              [-1, 128, 64]             256
            ReLU-139              [-1, 128, 64]               0
         Dropout-140              [-1, 128, 64]               0
          Conv1d-141              [-1, 128, 64]           1,152
 MyConv1dPadSame-142              [-1, 128, 64]               0
       MaxPool1d-143              [-1, 128, 64]               0
MyMaxPool1dPadSame-144              [-1, 128, 64]               0
      Bottleneck-145              [-1, 128, 64]               0
     BatchNorm1d-146              [-1, 128, 64]             256
            ReLU-147              [-1, 128, 64]               0
         Dropout-148              [-1, 128, 64]               0
          Conv1d-149              [-1, 256, 64]           2,304
 MyConv1dPadSame-150              [-1, 256, 64]               0
     BatchNorm1d-151              [-1, 256, 64]             512
            ReLU-152              [-1, 256, 64]               0
         Dropout-153              [-1, 256, 64]               0
          Conv1d-154              [-1, 256, 64]           4,352
 MyConv1dPadSame-155              [-1, 256, 64]               0
      Bottleneck-156              [-1, 256, 64]               0
     BatchNorm1d-157              [-1, 256, 64]             512
            ReLU-158              [-1, 256, 64]               0
         Dropout-159              [-1, 256, 64]               0
          Conv1d-160              [-1, 256, 32]           4,352
 MyConv1dPadSame-161              [-1, 256, 32]               0
     BatchNorm1d-162              [-1, 256, 32]             512
            ReLU-163              [-1, 256, 32]               0
         Dropout-164              [-1, 256, 32]               0
          Conv1d-165              [-1, 256, 32]           4,352
 MyConv1dPadSame-166              [-1, 256, 32]               0
       MaxPool1d-167              [-1, 256, 32]               0
MyMaxPool1dPadSame-168              [-1, 256, 32]               0
      Bottleneck-169              [-1, 256, 32]               0
     BatchNorm1d-170              [-1, 256, 32]             512
            ReLU-171              [-1, 256, 32]               0
         Dropout-172              [-1, 256, 32]               0
          Conv1d-173              [-1, 256, 32]           4,352
 MyConv1dPadSame-174              [-1, 256, 32]               0
     BatchNorm1d-175              [-1, 256, 32]             512
            ReLU-176              [-1, 256, 32]               0
         Dropout-177              [-1, 256, 32]               0
          Conv1d-178              [-1, 256, 32]           4,352
 MyConv1dPadSame-179              [-1, 256, 32]               0
      Bottleneck-180              [-1, 256, 32]               0
     BatchNorm1d-181              [-1, 256, 32]             512
            ReLU-182              [-1, 256, 32]               0
         Dropout-183              [-1, 256, 32]               0
          Conv1d-184              [-1, 256, 16]           4,352
 MyConv1dPadSame-185              [-1, 256, 16]               0
     BatchNorm1d-186              [-1, 256, 16]             512
            ReLU-187              [-1, 256, 16]               0
         Dropout-188              [-1, 256, 16]               0
          Conv1d-189              [-1, 256, 16]           4,352
 MyConv1dPadSame-190              [-1, 256, 16]               0
       MaxPool1d-191              [-1, 256, 16]               0
MyMaxPool1dPadSame-192              [-1, 256, 16]               0
      Bottleneck-193              [-1, 256, 16]               0
     BatchNorm1d-194              [-1, 256, 16]             512
            ReLU-195              [-1, 256, 16]               0
          Linear-196                    [-1, 2]             514
================================================================
Total params: 53,026
Trainable params: 53,026
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 53.19
Params size (MB): 0.20
Estimated Total Size (MB): 53.41
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 32, kernel_size: 4, n_block: 2
************************************************************
************************************************************
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 32, 4096]             160
   MyConv1dPadSame-2             [-1, 32, 4096]               0
       BatchNorm1d-3             [-1, 32, 4096]              64
              ReLU-4             [-1, 32, 4096]               0
            Conv1d-5             [-1, 32, 4096]             160
   MyConv1dPadSame-6             [-1, 32, 4096]               0
       BatchNorm1d-7             [-1, 32, 4096]              64
              ReLU-8             [-1, 32, 4096]               0
           Dropout-9             [-1, 32, 4096]               0
           Conv1d-10             [-1, 32, 4096]             160
  MyConv1dPadSame-11             [-1, 32, 4096]               0
       Bottleneck-12             [-1, 32, 4096]               0
      BatchNorm1d-13             [-1, 32, 4096]              64
             ReLU-14             [-1, 32, 4096]               0
          Dropout-15             [-1, 32, 4096]               0
           Conv1d-16             [-1, 64, 4096]             320
  MyConv1dPadSame-17             [-1, 64, 4096]               0
      BatchNorm1d-18             [-1, 64, 4096]             128
             ReLU-19             [-1, 64, 4096]               0
          Dropout-20             [-1, 64, 4096]               0
           Conv1d-21             [-1, 64, 4096]             576
  MyConv1dPadSame-22             [-1, 64, 4096]               0
       Bottleneck-23             [-1, 64, 4096]               0
      BatchNorm1d-24             [-1, 64, 4096]             128
             ReLU-25             [-1, 64, 4096]               0
           Linear-26                    [-1, 2]             130
================================================================
Total params: 1,954
Trainable params: 1,954
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 35.00
Params size (MB): 0.01
Estimated Total Size (MB): 35.02
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 32, kernel_size: 4, n_block: 4
************************************************************
************************************************************
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 32, 4096]             160
   MyConv1dPadSame-2             [-1, 32, 4096]               0
       BatchNorm1d-3             [-1, 32, 4096]              64
              ReLU-4             [-1, 32, 4096]               0
            Conv1d-5             [-1, 32, 4096]             160
   MyConv1dPadSame-6             [-1, 32, 4096]               0
       BatchNorm1d-7             [-1, 32, 4096]              64
              ReLU-8             [-1, 32, 4096]               0
           Dropout-9             [-1, 32, 4096]               0
           Conv1d-10             [-1, 32, 4096]             160
  MyConv1dPadSame-11             [-1, 32, 4096]               0
       Bottleneck-12             [-1, 32, 4096]               0
      BatchNorm1d-13             [-1, 32, 4096]              64
             ReLU-14             [-1, 32, 4096]               0
          Dropout-15             [-1, 32, 4096]               0
           Conv1d-16             [-1, 64, 4096]             320
  MyConv1dPadSame-17             [-1, 64, 4096]               0
      BatchNorm1d-18             [-1, 64, 4096]             128
             ReLU-19             [-1, 64, 4096]               0
          Dropout-20             [-1, 64, 4096]               0
           Conv1d-21             [-1, 64, 4096]             576
  MyConv1dPadSame-22             [-1, 64, 4096]               0
       Bottleneck-23             [-1, 64, 4096]               0
      BatchNorm1d-24             [-1, 64, 4096]             128
             ReLU-25             [-1, 64, 4096]               0
          Dropout-26             [-1, 64, 4096]               0
           Conv1d-27            [-1, 128, 4096]           1,152
  MyConv1dPadSame-28            [-1, 128, 4096]               0
      BatchNorm1d-29            [-1, 128, 4096]             256
             ReLU-30            [-1, 128, 4096]               0
          Dropout-31            [-1, 128, 4096]               0
           Conv1d-32            [-1, 128, 4096]           2,176
  MyConv1dPadSame-33            [-1, 128, 4096]               0
       Bottleneck-34            [-1, 128, 4096]               0
      BatchNorm1d-35            [-1, 128, 4096]             256
             ReLU-36            [-1, 128, 4096]               0
          Dropout-37            [-1, 128, 4096]               0
           Conv1d-38            [-1, 256, 4096]           4,352
  MyConv1dPadSame-39            [-1, 256, 4096]               0
      BatchNorm1d-40            [-1, 256, 4096]             512
             ReLU-41            [-1, 256, 4096]               0
          Dropout-42            [-1, 256, 4096]               0
           Conv1d-43            [-1, 256, 4096]           8,448
  MyConv1dPadSame-44            [-1, 256, 4096]               0
       Bottleneck-45            [-1, 256, 4096]               0
      BatchNorm1d-46            [-1, 256, 4096]             512
             ReLU-47            [-1, 256, 4096]               0
           Linear-48                    [-1, 2]             514
================================================================
Total params: 20,002
Trainable params: 20,002
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 161.00
Params size (MB): 0.08
Estimated Total Size (MB): 161.09
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 32, kernel_size: 4, n_block: 8
************************************************************
************************************************************
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 32, 4096]             160
   MyConv1dPadSame-2             [-1, 32, 4096]               0
       BatchNorm1d-3             [-1, 32, 4096]              64
              ReLU-4             [-1, 32, 4096]               0
            Conv1d-5             [-1, 32, 4096]             160
   MyConv1dPadSame-6             [-1, 32, 4096]               0
       BatchNorm1d-7             [-1, 32, 4096]              64
              ReLU-8             [-1, 32, 4096]               0
           Dropout-9             [-1, 32, 4096]               0
           Conv1d-10             [-1, 32, 4096]             160
  MyConv1dPadSame-11             [-1, 32, 4096]               0
       Bottleneck-12             [-1, 32, 4096]               0
      BatchNorm1d-13             [-1, 32, 4096]              64
             ReLU-14             [-1, 32, 4096]               0
          Dropout-15             [-1, 32, 4096]               0
           Conv1d-16             [-1, 32, 4096]             160
  MyConv1dPadSame-17             [-1, 32, 4096]               0
      BatchNorm1d-18             [-1, 32, 4096]              64
             ReLU-19             [-1, 32, 4096]               0
          Dropout-20             [-1, 32, 4096]               0
           Conv1d-21             [-1, 32, 4096]             160
  MyConv1dPadSame-22             [-1, 32, 4096]               0
       Bottleneck-23             [-1, 32, 4096]               0
      BatchNorm1d-24             [-1, 32, 4096]              64
             ReLU-25             [-1, 32, 4096]               0
          Dropout-26             [-1, 32, 4096]               0
           Conv1d-27             [-1, 64, 4096]             320
  MyConv1dPadSame-28             [-1, 64, 4096]               0
      BatchNorm1d-29             [-1, 64, 4096]             128
             ReLU-30             [-1, 64, 4096]               0
          Dropout-31             [-1, 64, 4096]               0
           Conv1d-32             [-1, 64, 4096]             576
  MyConv1dPadSame-33             [-1, 64, 4096]               0
       Bottleneck-34             [-1, 64, 4096]               0
      BatchNorm1d-35             [-1, 64, 4096]             128
             ReLU-36             [-1, 64, 4096]               0
          Dropout-37             [-1, 64, 4096]               0
           Conv1d-38             [-1, 64, 4096]             576
  MyConv1dPadSame-39             [-1, 64, 4096]               0
      BatchNorm1d-40             [-1, 64, 4096]             128
             ReLU-41             [-1, 64, 4096]               0
          Dropout-42             [-1, 64, 4096]               0
           Conv1d-43             [-1, 64, 4096]             576
  MyConv1dPadSame-44             [-1, 64, 4096]               0
       Bottleneck-45             [-1, 64, 4096]               0
      BatchNorm1d-46             [-1, 64, 4096]             128
             ReLU-47             [-1, 64, 4096]               0
          Dropout-48             [-1, 64, 4096]               0
           Conv1d-49            [-1, 128, 4096]           1,152
  MyConv1dPadSame-50            [-1, 128, 4096]               0
      BatchNorm1d-51            [-1, 128, 4096]             256
             ReLU-52            [-1, 128, 4096]               0
          Dropout-53            [-1, 128, 4096]               0
           Conv1d-54            [-1, 128, 4096]           2,176
  MyConv1dPadSame-55            [-1, 128, 4096]               0
       Bottleneck-56            [-1, 128, 4096]               0
      BatchNorm1d-57            [-1, 128, 4096]             256
             ReLU-58            [-1, 128, 4096]               0
          Dropout-59            [-1, 128, 4096]               0
           Conv1d-60            [-1, 128, 4096]           2,176
  MyConv1dPadSame-61            [-1, 128, 4096]               0
      BatchNorm1d-62            [-1, 128, 4096]             256
             ReLU-63            [-1, 128, 4096]               0
          Dropout-64            [-1, 128, 4096]               0
           Conv1d-65            [-1, 128, 4096]           2,176
  MyConv1dPadSame-66            [-1, 128, 4096]               0
       Bottleneck-67            [-1, 128, 4096]               0
      BatchNorm1d-68            [-1, 128, 4096]             256
             ReLU-69            [-1, 128, 4096]               0
          Dropout-70            [-1, 128, 4096]               0
           Conv1d-71            [-1, 256, 4096]           4,352
  MyConv1dPadSame-72            [-1, 256, 4096]               0
      BatchNorm1d-73            [-1, 256, 4096]             512
             ReLU-74            [-1, 256, 4096]               0
          Dropout-75            [-1, 256, 4096]               0
           Conv1d-76            [-1, 256, 4096]           8,448
  MyConv1dPadSame-77            [-1, 256, 4096]               0
       Bottleneck-78            [-1, 256, 4096]               0
      BatchNorm1d-79            [-1, 256, 4096]             512
             ReLU-80            [-1, 256, 4096]               0
          Dropout-81            [-1, 256, 4096]               0
           Conv1d-82            [-1, 256, 4096]           8,448
  MyConv1dPadSame-83            [-1, 256, 4096]               0
      BatchNorm1d-84            [-1, 256, 4096]             512
             ReLU-85            [-1, 256, 4096]               0
          Dropout-86            [-1, 256, 4096]               0
           Conv1d-87            [-1, 256, 4096]           8,448
  MyConv1dPadSame-88            [-1, 256, 4096]               0
       Bottleneck-89            [-1, 256, 4096]               0
      BatchNorm1d-90            [-1, 256, 4096]             512
             ReLU-91            [-1, 256, 4096]               0
           Linear-92                    [-1, 2]             514
================================================================
Total params: 44,642
Trainable params: 44,642
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 326.00
Params size (MB): 0.17
Estimated Total Size (MB): 326.19
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 32, kernel_size: 4, n_block: 16
************************************************************
************************************************************
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 32, 4096]             160
   MyConv1dPadSame-2             [-1, 32, 4096]               0
       BatchNorm1d-3             [-1, 32, 4096]              64
              ReLU-4             [-1, 32, 4096]               0
            Conv1d-5             [-1, 32, 4096]             160
   MyConv1dPadSame-6             [-1, 32, 4096]               0
       BatchNorm1d-7             [-1, 32, 4096]              64
              ReLU-8             [-1, 32, 4096]               0
           Dropout-9             [-1, 32, 4096]               0
           Conv1d-10             [-1, 32, 4096]             160
  MyConv1dPadSame-11             [-1, 32, 4096]               0
       Bottleneck-12             [-1, 32, 4096]               0
      BatchNorm1d-13             [-1, 32, 4096]              64
             ReLU-14             [-1, 32, 4096]               0
          Dropout-15             [-1, 32, 4096]               0
           Conv1d-16             [-1, 32, 2048]             160
  MyConv1dPadSame-17             [-1, 32, 2048]               0
      BatchNorm1d-18             [-1, 32, 2048]              64
             ReLU-19             [-1, 32, 2048]               0
          Dropout-20             [-1, 32, 2048]               0
           Conv1d-21             [-1, 32, 2048]             160
  MyConv1dPadSame-22             [-1, 32, 2048]               0
        MaxPool1d-23             [-1, 32, 2048]               0
MyMaxPool1dPadSame-24             [-1, 32, 2048]               0
       Bottleneck-25             [-1, 32, 2048]               0
      BatchNorm1d-26             [-1, 32, 2048]              64
             ReLU-27             [-1, 32, 2048]               0
          Dropout-28             [-1, 32, 2048]               0
           Conv1d-29             [-1, 32, 2048]             160
  MyConv1dPadSame-30             [-1, 32, 2048]               0
      BatchNorm1d-31             [-1, 32, 2048]              64
             ReLU-32             [-1, 32, 2048]               0
          Dropout-33             [-1, 32, 2048]               0
           Conv1d-34             [-1, 32, 2048]             160
  MyConv1dPadSame-35             [-1, 32, 2048]               0
       Bottleneck-36             [-1, 32, 2048]               0
      BatchNorm1d-37             [-1, 32, 2048]              64
             ReLU-38             [-1, 32, 2048]               0
          Dropout-39             [-1, 32, 2048]               0
           Conv1d-40             [-1, 32, 1024]             160
  MyConv1dPadSame-41             [-1, 32, 1024]               0
      BatchNorm1d-42             [-1, 32, 1024]              64
             ReLU-43             [-1, 32, 1024]               0
          Dropout-44             [-1, 32, 1024]               0
           Conv1d-45             [-1, 32, 1024]             160
  MyConv1dPadSame-46             [-1, 32, 1024]               0
        MaxPool1d-47             [-1, 32, 1024]               0
MyMaxPool1dPadSame-48             [-1, 32, 1024]               0
       Bottleneck-49             [-1, 32, 1024]               0
      BatchNorm1d-50             [-1, 32, 1024]              64
             ReLU-51             [-1, 32, 1024]               0
          Dropout-52             [-1, 32, 1024]               0
           Conv1d-53             [-1, 64, 1024]             320
  MyConv1dPadSame-54             [-1, 64, 1024]               0
      BatchNorm1d-55             [-1, 64, 1024]             128
             ReLU-56             [-1, 64, 1024]               0
          Dropout-57             [-1, 64, 1024]               0
           Conv1d-58             [-1, 64, 1024]             576
  MyConv1dPadSame-59             [-1, 64, 1024]               0
       Bottleneck-60             [-1, 64, 1024]               0
      BatchNorm1d-61             [-1, 64, 1024]             128
             ReLU-62             [-1, 64, 1024]               0
          Dropout-63             [-1, 64, 1024]               0
           Conv1d-64              [-1, 64, 512]             576
  MyConv1dPadSame-65              [-1, 64, 512]               0
      BatchNorm1d-66              [-1, 64, 512]             128
             ReLU-67              [-1, 64, 512]               0
          Dropout-68              [-1, 64, 512]               0
           Conv1d-69              [-1, 64, 512]             576
  MyConv1dPadSame-70              [-1, 64, 512]               0
        MaxPool1d-71              [-1, 64, 512]               0
MyMaxPool1dPadSame-72              [-1, 64, 512]               0
       Bottleneck-73              [-1, 64, 512]               0
      BatchNorm1d-74              [-1, 64, 512]             128
             ReLU-75              [-1, 64, 512]               0
          Dropout-76              [-1, 64, 512]               0
           Conv1d-77              [-1, 64, 512]             576
  MyConv1dPadSame-78              [-1, 64, 512]               0
      BatchNorm1d-79              [-1, 64, 512]             128
             ReLU-80              [-1, 64, 512]               0
          Dropout-81              [-1, 64, 512]               0
           Conv1d-82              [-1, 64, 512]             576
  MyConv1dPadSame-83              [-1, 64, 512]               0
       Bottleneck-84              [-1, 64, 512]               0
      BatchNorm1d-85              [-1, 64, 512]             128
             ReLU-86              [-1, 64, 512]               0
          Dropout-87              [-1, 64, 512]               0
           Conv1d-88              [-1, 64, 256]             576
  MyConv1dPadSame-89              [-1, 64, 256]               0
      BatchNorm1d-90              [-1, 64, 256]             128
             ReLU-91              [-1, 64, 256]               0
          Dropout-92              [-1, 64, 256]               0
           Conv1d-93              [-1, 64, 256]             576
  MyConv1dPadSame-94              [-1, 64, 256]               0
        MaxPool1d-95              [-1, 64, 256]               0
MyMaxPool1dPadSame-96              [-1, 64, 256]               0
       Bottleneck-97              [-1, 64, 256]               0
      BatchNorm1d-98              [-1, 64, 256]             128
             ReLU-99              [-1, 64, 256]               0
         Dropout-100              [-1, 64, 256]               0
          Conv1d-101             [-1, 128, 256]           1,152
 MyConv1dPadSame-102             [-1, 128, 256]               0
     BatchNorm1d-103             [-1, 128, 256]             256
            ReLU-104             [-1, 128, 256]               0
         Dropout-105             [-1, 128, 256]               0
          Conv1d-106             [-1, 128, 256]           2,176
 MyConv1dPadSame-107             [-1, 128, 256]               0
      Bottleneck-108             [-1, 128, 256]               0
     BatchNorm1d-109             [-1, 128, 256]             256
            ReLU-110             [-1, 128, 256]               0
         Dropout-111             [-1, 128, 256]               0
          Conv1d-112             [-1, 128, 128]           2,176
 MyConv1dPadSame-113             [-1, 128, 128]               0
     BatchNorm1d-114             [-1, 128, 128]             256
            ReLU-115             [-1, 128, 128]               0
         Dropout-116             [-1, 128, 128]               0
          Conv1d-117             [-1, 128, 128]           2,176
 MyConv1dPadSame-118             [-1, 128, 128]               0
       MaxPool1d-119             [-1, 128, 128]               0
MyMaxPool1dPadSame-120             [-1, 128, 128]               0
      Bottleneck-121             [-1, 128, 128]               0
     BatchNorm1d-122             [-1, 128, 128]             256
            ReLU-123             [-1, 128, 128]               0
         Dropout-124             [-1, 128, 128]               0
          Conv1d-125             [-1, 128, 128]           2,176
 MyConv1dPadSame-126             [-1, 128, 128]               0
     BatchNorm1d-127             [-1, 128, 128]             256
            ReLU-128             [-1, 128, 128]               0
         Dropout-129             [-1, 128, 128]               0
          Conv1d-130             [-1, 128, 128]           2,176
 MyConv1dPadSame-131             [-1, 128, 128]               0
      Bottleneck-132             [-1, 128, 128]               0
     BatchNorm1d-133             [-1, 128, 128]             256
            ReLU-134             [-1, 128, 128]               0
         Dropout-135             [-1, 128, 128]               0
          Conv1d-136              [-1, 128, 64]           2,176
 MyConv1dPadSame-137              [-1, 128, 64]               0
     BatchNorm1d-138              [-1, 128, 64]             256
            ReLU-139              [-1, 128, 64]               0
         Dropout-140              [-1, 128, 64]               0
          Conv1d-141              [-1, 128, 64]           2,176
 MyConv1dPadSame-142              [-1, 128, 64]               0
       MaxPool1d-143              [-1, 128, 64]               0
MyMaxPool1dPadSame-144              [-1, 128, 64]               0
      Bottleneck-145              [-1, 128, 64]               0
     BatchNorm1d-146              [-1, 128, 64]             256
            ReLU-147              [-1, 128, 64]               0
         Dropout-148              [-1, 128, 64]               0
          Conv1d-149              [-1, 256, 64]           4,352
 MyConv1dPadSame-150              [-1, 256, 64]               0
     BatchNorm1d-151              [-1, 256, 64]             512
            ReLU-152              [-1, 256, 64]               0
         Dropout-153              [-1, 256, 64]               0
          Conv1d-154              [-1, 256, 64]           8,448
 MyConv1dPadSame-155              [-1, 256, 64]               0
      Bottleneck-156              [-1, 256, 64]               0
     BatchNorm1d-157              [-1, 256, 64]             512
            ReLU-158              [-1, 256, 64]               0
         Dropout-159              [-1, 256, 64]               0
          Conv1d-160              [-1, 256, 32]           8,448
 MyConv1dPadSame-161              [-1, 256, 32]               0
     BatchNorm1d-162              [-1, 256, 32]             512
            ReLU-163              [-1, 256, 32]               0
         Dropout-164              [-1, 256, 32]               0
          Conv1d-165              [-1, 256, 32]           8,448
 MyConv1dPadSame-166              [-1, 256, 32]               0
       MaxPool1d-167              [-1, 256, 32]               0
MyMaxPool1dPadSame-168              [-1, 256, 32]               0
      Bottleneck-169              [-1, 256, 32]               0
     BatchNorm1d-170              [-1, 256, 32]             512
            ReLU-171              [-1, 256, 32]               0
         Dropout-172              [-1, 256, 32]               0
          Conv1d-173              [-1, 256, 32]           8,448
 MyConv1dPadSame-174              [-1, 256, 32]               0
     BatchNorm1d-175              [-1, 256, 32]             512
            ReLU-176              [-1, 256, 32]               0
         Dropout-177              [-1, 256, 32]               0
          Conv1d-178              [-1, 256, 32]           8,448
 MyConv1dPadSame-179              [-1, 256, 32]               0
      Bottleneck-180              [-1, 256, 32]               0
     BatchNorm1d-181              [-1, 256, 32]             512
            ReLU-182              [-1, 256, 32]               0
         Dropout-183              [-1, 256, 32]               0
          Conv1d-184              [-1, 256, 16]           8,448
 MyConv1dPadSame-185              [-1, 256, 16]               0
     BatchNorm1d-186              [-1, 256, 16]             512
            ReLU-187              [-1, 256, 16]               0
         Dropout-188              [-1, 256, 16]               0
          Conv1d-189              [-1, 256, 16]           8,448
 MyConv1dPadSame-190              [-1, 256, 16]               0
       MaxPool1d-191              [-1, 256, 16]               0
MyMaxPool1dPadSame-192              [-1, 256, 16]               0
      Bottleneck-193              [-1, 256, 16]               0
     BatchNorm1d-194              [-1, 256, 16]             512
            ReLU-195              [-1, 256, 16]               0
          Linear-196                    [-1, 2]             514
================================================================
Total params: 93,922
Trainable params: 93,922
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 53.19
Params size (MB): 0.36
Estimated Total Size (MB): 53.56
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 32, kernel_size: 8, n_block: 2
************************************************************
************************************************************
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 32, 4096]             288
   MyConv1dPadSame-2             [-1, 32, 4096]               0
       BatchNorm1d-3             [-1, 32, 4096]              64
              ReLU-4             [-1, 32, 4096]               0
            Conv1d-5             [-1, 32, 4096]             288
   MyConv1dPadSame-6             [-1, 32, 4096]               0
       BatchNorm1d-7             [-1, 32, 4096]              64
              ReLU-8             [-1, 32, 4096]               0
           Dropout-9             [-1, 32, 4096]               0
           Conv1d-10             [-1, 32, 4096]             288
  MyConv1dPadSame-11             [-1, 32, 4096]               0
       Bottleneck-12             [-1, 32, 4096]               0
      BatchNorm1d-13             [-1, 32, 4096]              64
             ReLU-14             [-1, 32, 4096]               0
          Dropout-15             [-1, 32, 4096]               0
           Conv1d-16             [-1, 64, 4096]             576
  MyConv1dPadSame-17             [-1, 64, 4096]               0
      BatchNorm1d-18             [-1, 64, 4096]             128
             ReLU-19             [-1, 64, 4096]               0
          Dropout-20             [-1, 64, 4096]               0
           Conv1d-21             [-1, 64, 4096]           1,088
  MyConv1dPadSame-22             [-1, 64, 4096]               0
       Bottleneck-23             [-1, 64, 4096]               0
      BatchNorm1d-24             [-1, 64, 4096]             128
             ReLU-25             [-1, 64, 4096]               0
           Linear-26                    [-1, 2]             130
================================================================
Total params: 3,106
Trainable params: 3,106
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 35.00
Params size (MB): 0.01
Estimated Total Size (MB): 35.03
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 32, kernel_size: 8, n_block: 4
************************************************************
************************************************************
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 32, 4096]             288
   MyConv1dPadSame-2             [-1, 32, 4096]               0
       BatchNorm1d-3             [-1, 32, 4096]              64
              ReLU-4             [-1, 32, 4096]               0
            Conv1d-5             [-1, 32, 4096]             288
   MyConv1dPadSame-6             [-1, 32, 4096]               0
       BatchNorm1d-7             [-1, 32, 4096]              64
              ReLU-8             [-1, 32, 4096]               0
           Dropout-9             [-1, 32, 4096]               0
           Conv1d-10             [-1, 32, 4096]             288
  MyConv1dPadSame-11             [-1, 32, 4096]               0
       Bottleneck-12             [-1, 32, 4096]               0
      BatchNorm1d-13             [-1, 32, 4096]              64
             ReLU-14             [-1, 32, 4096]               0
          Dropout-15             [-1, 32, 4096]               0
           Conv1d-16             [-1, 64, 4096]             576
  MyConv1dPadSame-17             [-1, 64, 4096]               0
      BatchNorm1d-18             [-1, 64, 4096]             128
             ReLU-19             [-1, 64, 4096]               0
          Dropout-20             [-1, 64, 4096]               0
           Conv1d-21             [-1, 64, 4096]           1,088
  MyConv1dPadSame-22             [-1, 64, 4096]               0
       Bottleneck-23             [-1, 64, 4096]               0
      BatchNorm1d-24             [-1, 64, 4096]             128
             ReLU-25             [-1, 64, 4096]               0
          Dropout-26             [-1, 64, 4096]               0
           Conv1d-27            [-1, 128, 4096]           2,176
  MyConv1dPadSame-28            [-1, 128, 4096]               0
      BatchNorm1d-29            [-1, 128, 4096]             256
             ReLU-30            [-1, 128, 4096]               0
          Dropout-31            [-1, 128, 4096]               0
           Conv1d-32            [-1, 128, 4096]           4,224
  MyConv1dPadSame-33            [-1, 128, 4096]               0
       Bottleneck-34            [-1, 128, 4096]               0
      BatchNorm1d-35            [-1, 128, 4096]             256
             ReLU-36            [-1, 128, 4096]               0
          Dropout-37            [-1, 128, 4096]               0
           Conv1d-38            [-1, 256, 4096]           8,448
  MyConv1dPadSame-39            [-1, 256, 4096]               0
      BatchNorm1d-40            [-1, 256, 4096]             512
             ReLU-41            [-1, 256, 4096]               0
          Dropout-42            [-1, 256, 4096]               0
           Conv1d-43            [-1, 256, 4096]          16,640
  MyConv1dPadSame-44            [-1, 256, 4096]               0
       Bottleneck-45            [-1, 256, 4096]               0
      BatchNorm1d-46            [-1, 256, 4096]             512
             ReLU-47            [-1, 256, 4096]               0
           Linear-48                    [-1, 2]             514
================================================================
Total params: 36,514
Trainable params: 36,514
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 161.00
Params size (MB): 0.14
Estimated Total Size (MB): 161.15
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 32, kernel_size: 8, n_block: 8
************************************************************
************************************************************
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 32, 4096]             288
   MyConv1dPadSame-2             [-1, 32, 4096]               0
       BatchNorm1d-3             [-1, 32, 4096]              64
              ReLU-4             [-1, 32, 4096]               0
            Conv1d-5             [-1, 32, 4096]             288
   MyConv1dPadSame-6             [-1, 32, 4096]               0
       BatchNorm1d-7             [-1, 32, 4096]              64
              ReLU-8             [-1, 32, 4096]               0
           Dropout-9             [-1, 32, 4096]               0
           Conv1d-10             [-1, 32, 4096]             288
  MyConv1dPadSame-11             [-1, 32, 4096]               0
       Bottleneck-12             [-1, 32, 4096]               0
      BatchNorm1d-13             [-1, 32, 4096]              64
             ReLU-14             [-1, 32, 4096]               0
          Dropout-15             [-1, 32, 4096]               0
           Conv1d-16             [-1, 32, 4096]             288
  MyConv1dPadSame-17             [-1, 32, 4096]               0
      BatchNorm1d-18             [-1, 32, 4096]              64
             ReLU-19             [-1, 32, 4096]               0
          Dropout-20             [-1, 32, 4096]               0
           Conv1d-21             [-1, 32, 4096]             288
  MyConv1dPadSame-22             [-1, 32, 4096]               0
       Bottleneck-23             [-1, 32, 4096]               0
      BatchNorm1d-24             [-1, 32, 4096]              64
             ReLU-25             [-1, 32, 4096]               0
          Dropout-26             [-1, 32, 4096]               0
           Conv1d-27             [-1, 64, 4096]             576
  MyConv1dPadSame-28             [-1, 64, 4096]               0
      BatchNorm1d-29             [-1, 64, 4096]             128
             ReLU-30             [-1, 64, 4096]               0
          Dropout-31             [-1, 64, 4096]               0
           Conv1d-32             [-1, 64, 4096]           1,088
  MyConv1dPadSame-33             [-1, 64, 4096]               0
       Bottleneck-34             [-1, 64, 4096]               0
      BatchNorm1d-35             [-1, 64, 4096]             128
             ReLU-36             [-1, 64, 4096]               0
          Dropout-37             [-1, 64, 4096]               0
           Conv1d-38             [-1, 64, 4096]           1,088
  MyConv1dPadSame-39             [-1, 64, 4096]               0
      BatchNorm1d-40             [-1, 64, 4096]             128
             ReLU-41             [-1, 64, 4096]               0
          Dropout-42             [-1, 64, 4096]               0
           Conv1d-43             [-1, 64, 4096]           1,088
  MyConv1dPadSame-44             [-1, 64, 4096]               0
       Bottleneck-45             [-1, 64, 4096]               0
      BatchNorm1d-46             [-1, 64, 4096]             128
             ReLU-47             [-1, 64, 4096]               0
          Dropout-48             [-1, 64, 4096]               0
           Conv1d-49            [-1, 128, 4096]           2,176
  MyConv1dPadSame-50            [-1, 128, 4096]               0
      BatchNorm1d-51            [-1, 128, 4096]             256
             ReLU-52            [-1, 128, 4096]               0
          Dropout-53            [-1, 128, 4096]               0
           Conv1d-54            [-1, 128, 4096]           4,224
  MyConv1dPadSame-55            [-1, 128, 4096]               0
       Bottleneck-56            [-1, 128, 4096]               0
      BatchNorm1d-57            [-1, 128, 4096]             256
             ReLU-58            [-1, 128, 4096]               0
          Dropout-59            [-1, 128, 4096]               0
           Conv1d-60            [-1, 128, 4096]           4,224
  MyConv1dPadSame-61            [-1, 128, 4096]               0
      BatchNorm1d-62            [-1, 128, 4096]             256
             ReLU-63            [-1, 128, 4096]               0
          Dropout-64            [-1, 128, 4096]               0
           Conv1d-65            [-1, 128, 4096]           4,224
  MyConv1dPadSame-66            [-1, 128, 4096]               0
       Bottleneck-67            [-1, 128, 4096]               0
      BatchNorm1d-68            [-1, 128, 4096]             256
             ReLU-69            [-1, 128, 4096]               0
          Dropout-70            [-1, 128, 4096]               0
           Conv1d-71            [-1, 256, 4096]           8,448
  MyConv1dPadSame-72            [-1, 256, 4096]               0
      BatchNorm1d-73            [-1, 256, 4096]             512
             ReLU-74            [-1, 256, 4096]               0
          Dropout-75            [-1, 256, 4096]               0
           Conv1d-76            [-1, 256, 4096]          16,640
  MyConv1dPadSame-77            [-1, 256, 4096]               0
       Bottleneck-78            [-1, 256, 4096]               0
      BatchNorm1d-79            [-1, 256, 4096]             512
             ReLU-80            [-1, 256, 4096]               0
          Dropout-81            [-1, 256, 4096]               0
           Conv1d-82            [-1, 256, 4096]          16,640
  MyConv1dPadSame-83            [-1, 256, 4096]               0
      BatchNorm1d-84            [-1, 256, 4096]             512
             ReLU-85            [-1, 256, 4096]               0
          Dropout-86            [-1, 256, 4096]               0
           Conv1d-87            [-1, 256, 4096]          16,640
  MyConv1dPadSame-88            [-1, 256, 4096]               0
       Bottleneck-89            [-1, 256, 4096]               0
      BatchNorm1d-90            [-1, 256, 4096]             512
             ReLU-91            [-1, 256, 4096]               0
           Linear-92                    [-1, 2]             514
================================================================
Total params: 82,914
Trainable params: 82,914
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 326.00
Params size (MB): 0.32
Estimated Total Size (MB): 326.33
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 32, kernel_size: 8, n_block: 16
************************************************************
************************************************************
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 32, 4096]             288
   MyConv1dPadSame-2             [-1, 32, 4096]               0
       BatchNorm1d-3             [-1, 32, 4096]              64
              ReLU-4             [-1, 32, 4096]               0
            Conv1d-5             [-1, 32, 4096]             288
   MyConv1dPadSame-6             [-1, 32, 4096]               0
       BatchNorm1d-7             [-1, 32, 4096]              64
              ReLU-8             [-1, 32, 4096]               0
           Dropout-9             [-1, 32, 4096]               0
           Conv1d-10             [-1, 32, 4096]             288
  MyConv1dPadSame-11             [-1, 32, 4096]               0
       Bottleneck-12             [-1, 32, 4096]               0
      BatchNorm1d-13             [-1, 32, 4096]              64
             ReLU-14             [-1, 32, 4096]               0
          Dropout-15             [-1, 32, 4096]               0
           Conv1d-16             [-1, 32, 2048]             288
  MyConv1dPadSame-17             [-1, 32, 2048]               0
      BatchNorm1d-18             [-1, 32, 2048]              64
             ReLU-19             [-1, 32, 2048]               0
          Dropout-20             [-1, 32, 2048]               0
           Conv1d-21             [-1, 32, 2048]             288
  MyConv1dPadSame-22             [-1, 32, 2048]               0
        MaxPool1d-23             [-1, 32, 2048]               0
MyMaxPool1dPadSame-24             [-1, 32, 2048]               0
       Bottleneck-25             [-1, 32, 2048]               0
      BatchNorm1d-26             [-1, 32, 2048]              64
             ReLU-27             [-1, 32, 2048]               0
          Dropout-28             [-1, 32, 2048]               0
           Conv1d-29             [-1, 32, 2048]             288
  MyConv1dPadSame-30             [-1, 32, 2048]               0
      BatchNorm1d-31             [-1, 32, 2048]              64
             ReLU-32             [-1, 32, 2048]               0
          Dropout-33             [-1, 32, 2048]               0
           Conv1d-34             [-1, 32, 2048]             288
  MyConv1dPadSame-35             [-1, 32, 2048]               0
       Bottleneck-36             [-1, 32, 2048]               0
      BatchNorm1d-37             [-1, 32, 2048]              64
             ReLU-38             [-1, 32, 2048]               0
          Dropout-39             [-1, 32, 2048]               0
           Conv1d-40             [-1, 32, 1024]             288
  MyConv1dPadSame-41             [-1, 32, 1024]               0
      BatchNorm1d-42             [-1, 32, 1024]              64
             ReLU-43             [-1, 32, 1024]               0
          Dropout-44             [-1, 32, 1024]               0
           Conv1d-45             [-1, 32, 1024]             288
  MyConv1dPadSame-46             [-1, 32, 1024]               0
        MaxPool1d-47             [-1, 32, 1024]               0
MyMaxPool1dPadSame-48             [-1, 32, 1024]               0
       Bottleneck-49             [-1, 32, 1024]               0
      BatchNorm1d-50             [-1, 32, 1024]              64
             ReLU-51             [-1, 32, 1024]               0
          Dropout-52             [-1, 32, 1024]               0
           Conv1d-53             [-1, 64, 1024]             576
  MyConv1dPadSame-54             [-1, 64, 1024]               0
      BatchNorm1d-55             [-1, 64, 1024]             128
             ReLU-56             [-1, 64, 1024]               0
          Dropout-57             [-1, 64, 1024]               0
           Conv1d-58             [-1, 64, 1024]           1,088
  MyConv1dPadSame-59             [-1, 64, 1024]               0
       Bottleneck-60             [-1, 64, 1024]               0
      BatchNorm1d-61             [-1, 64, 1024]             128
             ReLU-62             [-1, 64, 1024]               0
          Dropout-63             [-1, 64, 1024]               0
           Conv1d-64              [-1, 64, 512]           1,088
  MyConv1dPadSame-65              [-1, 64, 512]               0
      BatchNorm1d-66              [-1, 64, 512]             128
             ReLU-67              [-1, 64, 512]               0
          Dropout-68              [-1, 64, 512]               0
           Conv1d-69              [-1, 64, 512]           1,088
  MyConv1dPadSame-70              [-1, 64, 512]               0
        MaxPool1d-71              [-1, 64, 512]               0
MyMaxPool1dPadSame-72              [-1, 64, 512]               0
       Bottleneck-73              [-1, 64, 512]               0
      BatchNorm1d-74              [-1, 64, 512]             128
             ReLU-75              [-1, 64, 512]               0
          Dropout-76              [-1, 64, 512]               0
           Conv1d-77              [-1, 64, 512]           1,088
  MyConv1dPadSame-78              [-1, 64, 512]               0
      BatchNorm1d-79              [-1, 64, 512]             128
             ReLU-80              [-1, 64, 512]               0
          Dropout-81              [-1, 64, 512]               0
           Conv1d-82              [-1, 64, 512]           1,088
  MyConv1dPadSame-83              [-1, 64, 512]               0
       Bottleneck-84              [-1, 64, 512]               0
      BatchNorm1d-85              [-1, 64, 512]             128
             ReLU-86              [-1, 64, 512]               0
          Dropout-87              [-1, 64, 512]               0
           Conv1d-88              [-1, 64, 256]           1,088
  MyConv1dPadSame-89              [-1, 64, 256]               0
      BatchNorm1d-90              [-1, 64, 256]             128
             ReLU-91              [-1, 64, 256]               0
          Dropout-92              [-1, 64, 256]               0
           Conv1d-93              [-1, 64, 256]           1,088
  MyConv1dPadSame-94              [-1, 64, 256]               0
        MaxPool1d-95              [-1, 64, 256]               0
MyMaxPool1dPadSame-96              [-1, 64, 256]               0
       Bottleneck-97              [-1, 64, 256]               0
      BatchNorm1d-98              [-1, 64, 256]             128
             ReLU-99              [-1, 64, 256]               0
         Dropout-100              [-1, 64, 256]               0
          Conv1d-101             [-1, 128, 256]           2,176
 MyConv1dPadSame-102             [-1, 128, 256]               0
     BatchNorm1d-103             [-1, 128, 256]             256
            ReLU-104             [-1, 128, 256]               0
         Dropout-105             [-1, 128, 256]               0
          Conv1d-106             [-1, 128, 256]           4,224
 MyConv1dPadSame-107             [-1, 128, 256]               0
      Bottleneck-108             [-1, 128, 256]               0
     BatchNorm1d-109             [-1, 128, 256]             256
            ReLU-110             [-1, 128, 256]               0
         Dropout-111             [-1, 128, 256]               0
          Conv1d-112             [-1, 128, 128]           4,224
 MyConv1dPadSame-113             [-1, 128, 128]               0
     BatchNorm1d-114             [-1, 128, 128]             256
            ReLU-115             [-1, 128, 128]               0
         Dropout-116             [-1, 128, 128]               0
          Conv1d-117             [-1, 128, 128]           4,224
 MyConv1dPadSame-118             [-1, 128, 128]               0
       MaxPool1d-119             [-1, 128, 128]               0
MyMaxPool1dPadSame-120             [-1, 128, 128]               0
      Bottleneck-121             [-1, 128, 128]               0
     BatchNorm1d-122             [-1, 128, 128]             256
            ReLU-123             [-1, 128, 128]               0
         Dropout-124             [-1, 128, 128]               0
          Conv1d-125             [-1, 128, 128]           4,224
 MyConv1dPadSame-126             [-1, 128, 128]               0
     BatchNorm1d-127             [-1, 128, 128]             256
            ReLU-128             [-1, 128, 128]               0
         Dropout-129             [-1, 128, 128]               0
          Conv1d-130             [-1, 128, 128]           4,224
 MyConv1dPadSame-131             [-1, 128, 128]               0
      Bottleneck-132             [-1, 128, 128]               0
     BatchNorm1d-133             [-1, 128, 128]             256
            ReLU-134             [-1, 128, 128]               0
         Dropout-135             [-1, 128, 128]               0
          Conv1d-136              [-1, 128, 64]           4,224
 MyConv1dPadSame-137              [-1, 128, 64]               0
     BatchNorm1d-138              [-1, 128, 64]             256
            ReLU-139              [-1, 128, 64]               0
         Dropout-140              [-1, 128, 64]               0
          Conv1d-141              [-1, 128, 64]           4,224
 MyConv1dPadSame-142              [-1, 128, 64]               0
       MaxPool1d-143              [-1, 128, 64]               0
MyMaxPool1dPadSame-144              [-1, 128, 64]               0
      Bottleneck-145              [-1, 128, 64]               0
     BatchNorm1d-146              [-1, 128, 64]             256
            ReLU-147              [-1, 128, 64]               0
         Dropout-148              [-1, 128, 64]               0
          Conv1d-149              [-1, 256, 64]           8,448
 MyConv1dPadSame-150              [-1, 256, 64]               0
     BatchNorm1d-151              [-1, 256, 64]             512
            ReLU-152              [-1, 256, 64]               0
         Dropout-153              [-1, 256, 64]               0
          Conv1d-154              [-1, 256, 64]          16,640
 MyConv1dPadSame-155              [-1, 256, 64]               0
      Bottleneck-156              [-1, 256, 64]               0
     BatchNorm1d-157              [-1, 256, 64]             512
            ReLU-158              [-1, 256, 64]               0
         Dropout-159              [-1, 256, 64]               0
          Conv1d-160              [-1, 256, 32]          16,640
 MyConv1dPadSame-161              [-1, 256, 32]               0
     BatchNorm1d-162              [-1, 256, 32]             512
            ReLU-163              [-1, 256, 32]               0
         Dropout-164              [-1, 256, 32]               0
          Conv1d-165              [-1, 256, 32]          16,640
 MyConv1dPadSame-166              [-1, 256, 32]               0
       MaxPool1d-167              [-1, 256, 32]               0
MyMaxPool1dPadSame-168              [-1, 256, 32]               0
      Bottleneck-169              [-1, 256, 32]               0
     BatchNorm1d-170              [-1, 256, 32]             512
            ReLU-171              [-1, 256, 32]               0
         Dropout-172              [-1, 256, 32]               0
          Conv1d-173              [-1, 256, 32]          16,640
 MyConv1dPadSame-174              [-1, 256, 32]               0
     BatchNorm1d-175              [-1, 256, 32]             512
            ReLU-176              [-1, 256, 32]               0
         Dropout-177              [-1, 256, 32]               0
          Conv1d-178              [-1, 256, 32]          16,640
 MyConv1dPadSame-179              [-1, 256, 32]               0
      Bottleneck-180              [-1, 256, 32]               0
     BatchNorm1d-181              [-1, 256, 32]             512
            ReLU-182              [-1, 256, 32]               0
         Dropout-183              [-1, 256, 32]               0
          Conv1d-184              [-1, 256, 16]          16,640
 MyConv1dPadSame-185              [-1, 256, 16]               0
     BatchNorm1d-186              [-1, 256, 16]             512
            ReLU-187              [-1, 256, 16]               0
         Dropout-188              [-1, 256, 16]               0
          Conv1d-189              [-1, 256, 16]          16,640
 MyConv1dPadSame-190              [-1, 256, 16]               0
       MaxPool1d-191              [-1, 256, 16]               0
MyMaxPool1dPadSame-192              [-1, 256, 16]               0
      Bottleneck-193              [-1, 256, 16]               0
     BatchNorm1d-194              [-1, 256, 16]             512
            ReLU-195              [-1, 256, 16]               0
          Linear-196                    [-1, 2]             514
================================================================
Total params: 175,714
Trainable params: 175,714
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 53.19
Params size (MB): 0.67
Estimated Total Size (MB): 53.87
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 32, kernel_size: 16, n_block: 2
************************************************************
************************************************************
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 32, 4096]             544
   MyConv1dPadSame-2             [-1, 32, 4096]               0
       BatchNorm1d-3             [-1, 32, 4096]              64
              ReLU-4             [-1, 32, 4096]               0
            Conv1d-5             [-1, 32, 4096]             544
   MyConv1dPadSame-6             [-1, 32, 4096]               0
       BatchNorm1d-7             [-1, 32, 4096]              64
              ReLU-8             [-1, 32, 4096]               0
           Dropout-9             [-1, 32, 4096]               0
           Conv1d-10             [-1, 32, 4096]             544
  MyConv1dPadSame-11             [-1, 32, 4096]               0
       Bottleneck-12             [-1, 32, 4096]               0
      BatchNorm1d-13             [-1, 32, 4096]              64
             ReLU-14             [-1, 32, 4096]               0
          Dropout-15             [-1, 32, 4096]               0
           Conv1d-16             [-1, 64, 4096]           1,088
  MyConv1dPadSame-17             [-1, 64, 4096]               0
      BatchNorm1d-18             [-1, 64, 4096]             128
             ReLU-19             [-1, 64, 4096]               0
          Dropout-20             [-1, 64, 4096]               0
           Conv1d-21             [-1, 64, 4096]           2,112
  MyConv1dPadSame-22             [-1, 64, 4096]               0
       Bottleneck-23             [-1, 64, 4096]               0
      BatchNorm1d-24             [-1, 64, 4096]             128
             ReLU-25             [-1, 64, 4096]               0
           Linear-26                    [-1, 2]             130
================================================================
Total params: 5,410
Trainable params: 5,410
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 35.00
Params size (MB): 0.02
Estimated Total Size (MB): 35.04
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 32, kernel_size: 16, n_block: 4
************************************************************
************************************************************
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 32, 4096]             544
   MyConv1dPadSame-2             [-1, 32, 4096]               0
       BatchNorm1d-3             [-1, 32, 4096]              64
              ReLU-4             [-1, 32, 4096]               0
            Conv1d-5             [-1, 32, 4096]             544
   MyConv1dPadSame-6             [-1, 32, 4096]               0
       BatchNorm1d-7             [-1, 32, 4096]              64
              ReLU-8             [-1, 32, 4096]               0
           Dropout-9             [-1, 32, 4096]               0
           Conv1d-10             [-1, 32, 4096]             544
  MyConv1dPadSame-11             [-1, 32, 4096]               0
       Bottleneck-12             [-1, 32, 4096]               0
      BatchNorm1d-13             [-1, 32, 4096]              64
             ReLU-14             [-1, 32, 4096]               0
          Dropout-15             [-1, 32, 4096]               0
           Conv1d-16             [-1, 64, 4096]           1,088
  MyConv1dPadSame-17             [-1, 64, 4096]               0
      BatchNorm1d-18             [-1, 64, 4096]             128
             ReLU-19             [-1, 64, 4096]               0
          Dropout-20             [-1, 64, 4096]               0
           Conv1d-21             [-1, 64, 4096]           2,112
  MyConv1dPadSame-22             [-1, 64, 4096]               0
       Bottleneck-23             [-1, 64, 4096]               0
      BatchNorm1d-24             [-1, 64, 4096]             128
             ReLU-25             [-1, 64, 4096]               0
          Dropout-26             [-1, 64, 4096]               0
           Conv1d-27            [-1, 128, 4096]           4,224
  MyConv1dPadSame-28            [-1, 128, 4096]               0
      BatchNorm1d-29            [-1, 128, 4096]             256
             ReLU-30            [-1, 128, 4096]               0
          Dropout-31            [-1, 128, 4096]               0
           Conv1d-32            [-1, 128, 4096]           8,320
  MyConv1dPadSame-33            [-1, 128, 4096]               0
       Bottleneck-34            [-1, 128, 4096]               0
      BatchNorm1d-35            [-1, 128, 4096]             256
             ReLU-36            [-1, 128, 4096]               0
          Dropout-37            [-1, 128, 4096]               0
           Conv1d-38            [-1, 256, 4096]          16,640
  MyConv1dPadSame-39            [-1, 256, 4096]               0
      BatchNorm1d-40            [-1, 256, 4096]             512
             ReLU-41            [-1, 256, 4096]               0
          Dropout-42            [-1, 256, 4096]               0
           Conv1d-43            [-1, 256, 4096]          33,024
  MyConv1dPadSame-44            [-1, 256, 4096]               0
       Bottleneck-45            [-1, 256, 4096]               0
      BatchNorm1d-46            [-1, 256, 4096]             512
             ReLU-47            [-1, 256, 4096]               0
           Linear-48                    [-1, 2]             514
================================================================
Total params: 69,538
Trainable params: 69,538
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 161.00
Params size (MB): 0.27
Estimated Total Size (MB): 161.28
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 32, kernel_size: 16, n_block: 8
************************************************************
************************************************************
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 32, 4096]             544
   MyConv1dPadSame-2             [-1, 32, 4096]               0
       BatchNorm1d-3             [-1, 32, 4096]              64
              ReLU-4             [-1, 32, 4096]               0
            Conv1d-5             [-1, 32, 4096]             544
   MyConv1dPadSame-6             [-1, 32, 4096]               0
       BatchNorm1d-7             [-1, 32, 4096]              64
              ReLU-8             [-1, 32, 4096]               0
           Dropout-9             [-1, 32, 4096]               0
           Conv1d-10             [-1, 32, 4096]             544
  MyConv1dPadSame-11             [-1, 32, 4096]               0
       Bottleneck-12             [-1, 32, 4096]               0
      BatchNorm1d-13             [-1, 32, 4096]              64
             ReLU-14             [-1, 32, 4096]               0
          Dropout-15             [-1, 32, 4096]               0
           Conv1d-16             [-1, 32, 4096]             544
  MyConv1dPadSame-17             [-1, 32, 4096]               0
      BatchNorm1d-18             [-1, 32, 4096]              64
             ReLU-19             [-1, 32, 4096]               0
          Dropout-20             [-1, 32, 4096]               0
           Conv1d-21             [-1, 32, 4096]             544
  MyConv1dPadSame-22             [-1, 32, 4096]               0
       Bottleneck-23             [-1, 32, 4096]               0
      BatchNorm1d-24             [-1, 32, 4096]              64
             ReLU-25             [-1, 32, 4096]               0
          Dropout-26             [-1, 32, 4096]               0
           Conv1d-27             [-1, 64, 4096]           1,088
  MyConv1dPadSame-28             [-1, 64, 4096]               0
      BatchNorm1d-29             [-1, 64, 4096]             128
             ReLU-30             [-1, 64, 4096]               0
          Dropout-31             [-1, 64, 4096]               0
           Conv1d-32             [-1, 64, 4096]           2,112
  MyConv1dPadSame-33             [-1, 64, 4096]               0
       Bottleneck-34             [-1, 64, 4096]               0
      BatchNorm1d-35             [-1, 64, 4096]             128
             ReLU-36             [-1, 64, 4096]               0
          Dropout-37             [-1, 64, 4096]               0
           Conv1d-38             [-1, 64, 4096]           2,112
  MyConv1dPadSame-39             [-1, 64, 4096]               0
      BatchNorm1d-40             [-1, 64, 4096]             128
             ReLU-41             [-1, 64, 4096]               0
          Dropout-42             [-1, 64, 4096]               0
           Conv1d-43             [-1, 64, 4096]           2,112
  MyConv1dPadSame-44             [-1, 64, 4096]               0
       Bottleneck-45             [-1, 64, 4096]               0
      BatchNorm1d-46             [-1, 64, 4096]             128
             ReLU-47             [-1, 64, 4096]               0
          Dropout-48             [-1, 64, 4096]               0
           Conv1d-49            [-1, 128, 4096]           4,224
  MyConv1dPadSame-50            [-1, 128, 4096]               0
      BatchNorm1d-51            [-1, 128, 4096]             256
             ReLU-52            [-1, 128, 4096]               0
          Dropout-53            [-1, 128, 4096]               0
           Conv1d-54            [-1, 128, 4096]           8,320
  MyConv1dPadSame-55            [-1, 128, 4096]               0
       Bottleneck-56            [-1, 128, 4096]               0
      BatchNorm1d-57            [-1, 128, 4096]             256
             ReLU-58            [-1, 128, 4096]               0
          Dropout-59            [-1, 128, 4096]               0
           Conv1d-60            [-1, 128, 4096]           8,320
  MyConv1dPadSame-61            [-1, 128, 4096]               0
      BatchNorm1d-62            [-1, 128, 4096]             256
             ReLU-63            [-1, 128, 4096]               0
          Dropout-64            [-1, 128, 4096]               0
           Conv1d-65            [-1, 128, 4096]           8,320
  MyConv1dPadSame-66            [-1, 128, 4096]               0
       Bottleneck-67            [-1, 128, 4096]               0
      BatchNorm1d-68            [-1, 128, 4096]             256
             ReLU-69            [-1, 128, 4096]               0
          Dropout-70            [-1, 128, 4096]               0
           Conv1d-71            [-1, 256, 4096]          16,640
  MyConv1dPadSame-72            [-1, 256, 4096]               0
      BatchNorm1d-73            [-1, 256, 4096]             512
             ReLU-74            [-1, 256, 4096]               0
          Dropout-75            [-1, 256, 4096]               0
           Conv1d-76            [-1, 256, 4096]          33,024
  MyConv1dPadSame-77            [-1, 256, 4096]               0
       Bottleneck-78            [-1, 256, 4096]               0
      BatchNorm1d-79            [-1, 256, 4096]             512
             ReLU-80            [-1, 256, 4096]               0
          Dropout-81            [-1, 256, 4096]               0
           Conv1d-82            [-1, 256, 4096]          33,024
  MyConv1dPadSame-83            [-1, 256, 4096]               0
      BatchNorm1d-84            [-1, 256, 4096]             512
             ReLU-85            [-1, 256, 4096]               0
          Dropout-86            [-1, 256, 4096]               0
           Conv1d-87            [-1, 256, 4096]          33,024
  MyConv1dPadSame-88            [-1, 256, 4096]               0
       Bottleneck-89            [-1, 256, 4096]               0
      BatchNorm1d-90            [-1, 256, 4096]             512
             ReLU-91            [-1, 256, 4096]               0
           Linear-92                    [-1, 2]             514
================================================================
Total params: 159,458
Trainable params: 159,458
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 326.00
Params size (MB): 0.61
Estimated Total Size (MB): 326.62
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 32, kernel_size: 16, n_block: 16
************************************************************
************************************************************
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 32, 4096]             544
   MyConv1dPadSame-2             [-1, 32, 4096]               0
       BatchNorm1d-3             [-1, 32, 4096]              64
              ReLU-4             [-1, 32, 4096]               0
            Conv1d-5             [-1, 32, 4096]             544
   MyConv1dPadSame-6             [-1, 32, 4096]               0
       BatchNorm1d-7             [-1, 32, 4096]              64
              ReLU-8             [-1, 32, 4096]               0
           Dropout-9             [-1, 32, 4096]               0
           Conv1d-10             [-1, 32, 4096]             544
  MyConv1dPadSame-11             [-1, 32, 4096]               0
       Bottleneck-12             [-1, 32, 4096]               0
      BatchNorm1d-13             [-1, 32, 4096]              64
             ReLU-14             [-1, 32, 4096]               0
          Dropout-15             [-1, 32, 4096]               0
           Conv1d-16             [-1, 32, 2048]             544
  MyConv1dPadSame-17             [-1, 32, 2048]               0
      BatchNorm1d-18             [-1, 32, 2048]              64
             ReLU-19             [-1, 32, 2048]               0
          Dropout-20             [-1, 32, 2048]               0
           Conv1d-21             [-1, 32, 2048]             544
  MyConv1dPadSame-22             [-1, 32, 2048]               0
        MaxPool1d-23             [-1, 32, 2048]               0
MyMaxPool1dPadSame-24             [-1, 32, 2048]               0
       Bottleneck-25             [-1, 32, 2048]               0
      BatchNorm1d-26             [-1, 32, 2048]              64
             ReLU-27             [-1, 32, 2048]               0
          Dropout-28             [-1, 32, 2048]               0
           Conv1d-29             [-1, 32, 2048]             544
  MyConv1dPadSame-30             [-1, 32, 2048]               0
      BatchNorm1d-31             [-1, 32, 2048]              64
             ReLU-32             [-1, 32, 2048]               0
          Dropout-33             [-1, 32, 2048]               0
           Conv1d-34             [-1, 32, 2048]             544
  MyConv1dPadSame-35             [-1, 32, 2048]               0
       Bottleneck-36             [-1, 32, 2048]               0
      BatchNorm1d-37             [-1, 32, 2048]              64
             ReLU-38             [-1, 32, 2048]               0
          Dropout-39             [-1, 32, 2048]               0
           Conv1d-40             [-1, 32, 1024]             544
  MyConv1dPadSame-41             [-1, 32, 1024]               0
      BatchNorm1d-42             [-1, 32, 1024]              64
             ReLU-43             [-1, 32, 1024]               0
          Dropout-44             [-1, 32, 1024]               0
           Conv1d-45             [-1, 32, 1024]             544
  MyConv1dPadSame-46             [-1, 32, 1024]               0
        MaxPool1d-47             [-1, 32, 1024]               0
MyMaxPool1dPadSame-48             [-1, 32, 1024]               0
       Bottleneck-49             [-1, 32, 1024]               0
      BatchNorm1d-50             [-1, 32, 1024]              64
             ReLU-51             [-1, 32, 1024]               0
          Dropout-52             [-1, 32, 1024]               0
           Conv1d-53             [-1, 64, 1024]           1,088
  MyConv1dPadSame-54             [-1, 64, 1024]               0
      BatchNorm1d-55             [-1, 64, 1024]             128
             ReLU-56             [-1, 64, 1024]               0
          Dropout-57             [-1, 64, 1024]               0
           Conv1d-58             [-1, 64, 1024]           2,112
  MyConv1dPadSame-59             [-1, 64, 1024]               0
       Bottleneck-60             [-1, 64, 1024]               0
      BatchNorm1d-61             [-1, 64, 1024]             128
             ReLU-62             [-1, 64, 1024]               0
          Dropout-63             [-1, 64, 1024]               0
           Conv1d-64              [-1, 64, 512]           2,112
  MyConv1dPadSame-65              [-1, 64, 512]               0
      BatchNorm1d-66              [-1, 64, 512]             128
             ReLU-67              [-1, 64, 512]               0
          Dropout-68              [-1, 64, 512]               0
           Conv1d-69              [-1, 64, 512]           2,112
  MyConv1dPadSame-70              [-1, 64, 512]               0
        MaxPool1d-71              [-1, 64, 512]               0
MyMaxPool1dPadSame-72              [-1, 64, 512]               0
       Bottleneck-73              [-1, 64, 512]               0
      BatchNorm1d-74              [-1, 64, 512]             128
             ReLU-75              [-1, 64, 512]               0
          Dropout-76              [-1, 64, 512]               0
           Conv1d-77              [-1, 64, 512]           2,112
  MyConv1dPadSame-78              [-1, 64, 512]               0
      BatchNorm1d-79              [-1, 64, 512]             128
             ReLU-80              [-1, 64, 512]               0
          Dropout-81              [-1, 64, 512]               0
           Conv1d-82              [-1, 64, 512]           2,112
  MyConv1dPadSame-83              [-1, 64, 512]               0
       Bottleneck-84              [-1, 64, 512]               0
      BatchNorm1d-85              [-1, 64, 512]             128
             ReLU-86              [-1, 64, 512]               0
          Dropout-87              [-1, 64, 512]               0
           Conv1d-88              [-1, 64, 256]           2,112
  MyConv1dPadSame-89              [-1, 64, 256]               0
      BatchNorm1d-90              [-1, 64, 256]             128
             ReLU-91              [-1, 64, 256]               0
          Dropout-92              [-1, 64, 256]               0
           Conv1d-93              [-1, 64, 256]           2,112
  MyConv1dPadSame-94              [-1, 64, 256]               0
        MaxPool1d-95              [-1, 64, 256]               0
MyMaxPool1dPadSame-96              [-1, 64, 256]               0
       Bottleneck-97              [-1, 64, 256]               0
      BatchNorm1d-98              [-1, 64, 256]             128
             ReLU-99              [-1, 64, 256]               0
         Dropout-100              [-1, 64, 256]               0
          Conv1d-101             [-1, 128, 256]           4,224
 MyConv1dPadSame-102             [-1, 128, 256]               0
     BatchNorm1d-103             [-1, 128, 256]             256
            ReLU-104             [-1, 128, 256]               0
         Dropout-105             [-1, 128, 256]               0
          Conv1d-106             [-1, 128, 256]           8,320
 MyConv1dPadSame-107             [-1, 128, 256]               0
      Bottleneck-108             [-1, 128, 256]               0
     BatchNorm1d-109             [-1, 128, 256]             256
            ReLU-110             [-1, 128, 256]               0
         Dropout-111             [-1, 128, 256]               0
          Conv1d-112             [-1, 128, 128]           8,320
 MyConv1dPadSame-113             [-1, 128, 128]               0
     BatchNorm1d-114             [-1, 128, 128]             256
            ReLU-115             [-1, 128, 128]               0
         Dropout-116             [-1, 128, 128]               0
          Conv1d-117             [-1, 128, 128]           8,320
 MyConv1dPadSame-118             [-1, 128, 128]               0
       MaxPool1d-119             [-1, 128, 128]               0
MyMaxPool1dPadSame-120             [-1, 128, 128]               0
      Bottleneck-121             [-1, 128, 128]               0
     BatchNorm1d-122             [-1, 128, 128]             256
            ReLU-123             [-1, 128, 128]               0
         Dropout-124             [-1, 128, 128]               0
          Conv1d-125             [-1, 128, 128]           8,320
 MyConv1dPadSame-126             [-1, 128, 128]               0
     BatchNorm1d-127             [-1, 128, 128]             256
            ReLU-128             [-1, 128, 128]               0
         Dropout-129             [-1, 128, 128]               0
          Conv1d-130             [-1, 128, 128]           8,320
 MyConv1dPadSame-131             [-1, 128, 128]               0
      Bottleneck-132             [-1, 128, 128]               0
     BatchNorm1d-133             [-1, 128, 128]             256
            ReLU-134             [-1, 128, 128]               0
         Dropout-135             [-1, 128, 128]               0
          Conv1d-136              [-1, 128, 64]           8,320
 MyConv1dPadSame-137              [-1, 128, 64]               0
     BatchNorm1d-138              [-1, 128, 64]             256
            ReLU-139              [-1, 128, 64]               0
         Dropout-140              [-1, 128, 64]               0
          Conv1d-141              [-1, 128, 64]           8,320
 MyConv1dPadSame-142              [-1, 128, 64]               0
       MaxPool1d-143              [-1, 128, 64]               0
MyMaxPool1dPadSame-144              [-1, 128, 64]               0
      Bottleneck-145              [-1, 128, 64]               0
     BatchNorm1d-146              [-1, 128, 64]             256
            ReLU-147              [-1, 128, 64]               0
         Dropout-148              [-1, 128, 64]               0
          Conv1d-149              [-1, 256, 64]          16,640
 MyConv1dPadSame-150              [-1, 256, 64]               0
     BatchNorm1d-151              [-1, 256, 64]             512
            ReLU-152              [-1, 256, 64]               0
         Dropout-153              [-1, 256, 64]               0
          Conv1d-154              [-1, 256, 64]          33,024
 MyConv1dPadSame-155              [-1, 256, 64]               0
      Bottleneck-156              [-1, 256, 64]               0
     BatchNorm1d-157              [-1, 256, 64]             512
            ReLU-158              [-1, 256, 64]               0
         Dropout-159              [-1, 256, 64]               0
          Conv1d-160              [-1, 256, 32]          33,024
 MyConv1dPadSame-161              [-1, 256, 32]               0
     BatchNorm1d-162              [-1, 256, 32]             512
            ReLU-163              [-1, 256, 32]               0
         Dropout-164              [-1, 256, 32]               0
          Conv1d-165              [-1, 256, 32]          33,024
 MyConv1dPadSame-166              [-1, 256, 32]               0
       MaxPool1d-167              [-1, 256, 32]               0
MyMaxPool1dPadSame-168              [-1, 256, 32]               0
      Bottleneck-169              [-1, 256, 32]               0
     BatchNorm1d-170              [-1, 256, 32]             512
            ReLU-171              [-1, 256, 32]               0
         Dropout-172              [-1, 256, 32]               0
          Conv1d-173              [-1, 256, 32]          33,024
 MyConv1dPadSame-174              [-1, 256, 32]               0
     BatchNorm1d-175              [-1, 256, 32]             512
            ReLU-176              [-1, 256, 32]               0
         Dropout-177              [-1, 256, 32]               0
          Conv1d-178              [-1, 256, 32]          33,024
 MyConv1dPadSame-179              [-1, 256, 32]               0
      Bottleneck-180              [-1, 256, 32]               0
     BatchNorm1d-181              [-1, 256, 32]             512
            ReLU-182              [-1, 256, 32]               0
         Dropout-183              [-1, 256, 32]               0
          Conv1d-184              [-1, 256, 16]          33,024
 MyConv1dPadSame-185              [-1, 256, 16]               0
     BatchNorm1d-186              [-1, 256, 16]             512
            ReLU-187              [-1, 256, 16]               0
         Dropout-188              [-1, 256, 16]               0
          Conv1d-189              [-1, 256, 16]          33,024
 MyConv1dPadSame-190              [-1, 256, 16]               0
       MaxPool1d-191              [-1, 256, 16]               0
MyMaxPool1dPadSame-192              [-1, 256, 16]               0
      Bottleneck-193              [-1, 256, 16]               0
     BatchNorm1d-194              [-1, 256, 16]             512
            ReLU-195              [-1, 256, 16]               0
          Linear-196                    [-1, 2]             514
================================================================
Total params: 339,298
Trainable params: 339,298
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 53.19
Params size (MB): 1.29
Estimated Total Size (MB): 54.50
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 64, kernel_size: 2, n_block: 2
************************************************************
************************************************************
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 64, 4096]             192
   MyConv1dPadSame-2             [-1, 64, 4096]               0
       BatchNorm1d-3             [-1, 64, 4096]             128
              ReLU-4             [-1, 64, 4096]               0
            Conv1d-5             [-1, 64, 4096]             192
   MyConv1dPadSame-6             [-1, 64, 4096]               0
       BatchNorm1d-7             [-1, 64, 4096]             128
              ReLU-8             [-1, 64, 4096]               0
           Dropout-9             [-1, 64, 4096]               0
           Conv1d-10             [-1, 64, 4096]             192
  MyConv1dPadSame-11             [-1, 64, 4096]               0
       Bottleneck-12             [-1, 64, 4096]               0
      BatchNorm1d-13             [-1, 64, 4096]             128
             ReLU-14             [-1, 64, 4096]               0
          Dropout-15             [-1, 64, 4096]               0
           Conv1d-16            [-1, 128, 4096]             384
  MyConv1dPadSame-17            [-1, 128, 4096]               0
      BatchNorm1d-18            [-1, 128, 4096]             256
             ReLU-19            [-1, 128, 4096]               0
          Dropout-20            [-1, 128, 4096]               0
           Conv1d-21            [-1, 128, 4096]             640
  MyConv1dPadSame-22            [-1, 128, 4096]               0
       Bottleneck-23            [-1, 128, 4096]               0
      BatchNorm1d-24            [-1, 128, 4096]             256
             ReLU-25            [-1, 128, 4096]               0
           Linear-26                    [-1, 2]             258
================================================================
Total params: 2,754
Trainable params: 2,754
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 70.00
Params size (MB): 0.01
Estimated Total Size (MB): 70.03
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 64, kernel_size: 2, n_block: 4
************************************************************
************************************************************
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 64, 4096]             192
   MyConv1dPadSame-2             [-1, 64, 4096]               0
       BatchNorm1d-3             [-1, 64, 4096]             128
              ReLU-4             [-1, 64, 4096]               0
            Conv1d-5             [-1, 64, 4096]             192
   MyConv1dPadSame-6             [-1, 64, 4096]               0
       BatchNorm1d-7             [-1, 64, 4096]             128
              ReLU-8             [-1, 64, 4096]               0
           Dropout-9             [-1, 64, 4096]               0
           Conv1d-10             [-1, 64, 4096]             192
  MyConv1dPadSame-11             [-1, 64, 4096]               0
       Bottleneck-12             [-1, 64, 4096]               0
      BatchNorm1d-13             [-1, 64, 4096]             128
             ReLU-14             [-1, 64, 4096]               0
          Dropout-15             [-1, 64, 4096]               0
           Conv1d-16            [-1, 128, 4096]             384
  MyConv1dPadSame-17            [-1, 128, 4096]               0
      BatchNorm1d-18            [-1, 128, 4096]             256
             ReLU-19            [-1, 128, 4096]               0
          Dropout-20            [-1, 128, 4096]               0
           Conv1d-21            [-1, 128, 4096]             640
  MyConv1dPadSame-22            [-1, 128, 4096]               0
       Bottleneck-23            [-1, 128, 4096]               0
      BatchNorm1d-24            [-1, 128, 4096]             256
             ReLU-25            [-1, 128, 4096]               0
          Dropout-26            [-1, 128, 4096]               0
           Conv1d-27            [-1, 256, 4096]           1,280
  MyConv1dPadSame-28            [-1, 256, 4096]               0
      BatchNorm1d-29            [-1, 256, 4096]             512
             ReLU-30            [-1, 256, 4096]               0
          Dropout-31            [-1, 256, 4096]               0
           Conv1d-32            [-1, 256, 4096]           2,304
  MyConv1dPadSame-33            [-1, 256, 4096]               0
       Bottleneck-34            [-1, 256, 4096]               0
      BatchNorm1d-35            [-1, 256, 4096]             512
             ReLU-36            [-1, 256, 4096]               0
          Dropout-37            [-1, 256, 4096]               0
           Conv1d-38            [-1, 512, 4096]           4,608
  MyConv1dPadSame-39            [-1, 512, 4096]               0
      BatchNorm1d-40            [-1, 512, 4096]           1,024
             ReLU-41            [-1, 512, 4096]               0
          Dropout-42            [-1, 512, 4096]               0
           Conv1d-43            [-1, 512, 4096]           8,704
  MyConv1dPadSame-44            [-1, 512, 4096]               0
       Bottleneck-45            [-1, 512, 4096]               0
      BatchNorm1d-46            [-1, 512, 4096]           1,024
             ReLU-47            [-1, 512, 4096]               0
           Linear-48                    [-1, 2]           1,026
================================================================
Total params: 23,490
Trainable params: 23,490
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 322.00
Params size (MB): 0.09
Estimated Total Size (MB): 322.11
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 64, kernel_size: 2, n_block: 8
************************************************************
************************************************************
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 64, 4096]             192
   MyConv1dPadSame-2             [-1, 64, 4096]               0
       BatchNorm1d-3             [-1, 64, 4096]             128
              ReLU-4             [-1, 64, 4096]               0
            Conv1d-5             [-1, 64, 4096]             192
   MyConv1dPadSame-6             [-1, 64, 4096]               0
       BatchNorm1d-7             [-1, 64, 4096]             128
              ReLU-8             [-1, 64, 4096]               0
           Dropout-9             [-1, 64, 4096]               0
           Conv1d-10             [-1, 64, 4096]             192
  MyConv1dPadSame-11             [-1, 64, 4096]               0
       Bottleneck-12             [-1, 64, 4096]               0
      BatchNorm1d-13             [-1, 64, 4096]             128
             ReLU-14             [-1, 64, 4096]               0
          Dropout-15             [-1, 64, 4096]               0
           Conv1d-16             [-1, 64, 4096]             192
  MyConv1dPadSame-17             [-1, 64, 4096]               0
      BatchNorm1d-18             [-1, 64, 4096]             128
             ReLU-19             [-1, 64, 4096]               0
          Dropout-20             [-1, 64, 4096]               0
           Conv1d-21             [-1, 64, 4096]             192
  MyConv1dPadSame-22             [-1, 64, 4096]               0
       Bottleneck-23             [-1, 64, 4096]               0
      BatchNorm1d-24             [-1, 64, 4096]             128
             ReLU-25             [-1, 64, 4096]               0
          Dropout-26             [-1, 64, 4096]               0
           Conv1d-27            [-1, 128, 4096]             384
  MyConv1dPadSame-28            [-1, 128, 4096]               0
      BatchNorm1d-29            [-1, 128, 4096]             256
             ReLU-30            [-1, 128, 4096]               0
          Dropout-31            [-1, 128, 4096]               0
           Conv1d-32            [-1, 128, 4096]             640
  MyConv1dPadSame-33            [-1, 128, 4096]               0
       Bottleneck-34            [-1, 128, 4096]               0
      BatchNorm1d-35            [-1, 128, 4096]             256
             ReLU-36            [-1, 128, 4096]               0
          Dropout-37            [-1, 128, 4096]               0
           Conv1d-38            [-1, 128, 4096]             640
  MyConv1dPadSame-39            [-1, 128, 4096]               0
      BatchNorm1d-40            [-1, 128, 4096]             256
             ReLU-41            [-1, 128, 4096]               0
          Dropout-42            [-1, 128, 4096]               0
           Conv1d-43            [-1, 128, 4096]             640
  MyConv1dPadSame-44            [-1, 128, 4096]               0
       Bottleneck-45            [-1, 128, 4096]               0
      BatchNorm1d-46            [-1, 128, 4096]             256
             ReLU-47            [-1, 128, 4096]               0
          Dropout-48            [-1, 128, 4096]               0
           Conv1d-49            [-1, 256, 4096]           1,280
  MyConv1dPadSame-50            [-1, 256, 4096]               0
      BatchNorm1d-51            [-1, 256, 4096]             512
             ReLU-52            [-1, 256, 4096]               0
          Dropout-53            [-1, 256, 4096]               0
           Conv1d-54            [-1, 256, 4096]           2,304
  MyConv1dPadSame-55            [-1, 256, 4096]               0
       Bottleneck-56            [-1, 256, 4096]               0
      BatchNorm1d-57            [-1, 256, 4096]             512
             ReLU-58            [-1, 256, 4096]               0
          Dropout-59            [-1, 256, 4096]               0
           Conv1d-60            [-1, 256, 4096]           2,304
  MyConv1dPadSame-61            [-1, 256, 4096]               0
      BatchNorm1d-62            [-1, 256, 4096]             512
             ReLU-63            [-1, 256, 4096]               0
          Dropout-64            [-1, 256, 4096]               0
           Conv1d-65            [-1, 256, 4096]           2,304
  MyConv1dPadSame-66            [-1, 256, 4096]               0
       Bottleneck-67            [-1, 256, 4096]               0
      BatchNorm1d-68            [-1, 256, 4096]             512
             ReLU-69            [-1, 256, 4096]               0
          Dropout-70            [-1, 256, 4096]               0
           Conv1d-71            [-1, 512, 4096]           4,608
  MyConv1dPadSame-72            [-1, 512, 4096]               0
      BatchNorm1d-73            [-1, 512, 4096]           1,024
             ReLU-74            [-1, 512, 4096]               0
          Dropout-75            [-1, 512, 4096]               0
           Conv1d-76            [-1, 512, 4096]           8,704
  MyConv1dPadSame-77            [-1, 512, 4096]               0
       Bottleneck-78            [-1, 512, 4096]               0
      BatchNorm1d-79            [-1, 512, 4096]           1,024
             ReLU-80            [-1, 512, 4096]               0
          Dropout-81            [-1, 512, 4096]               0
           Conv1d-82            [-1, 512, 4096]           8,704
  MyConv1dPadSame-83            [-1, 512, 4096]               0
      BatchNorm1d-84            [-1, 512, 4096]           1,024
             ReLU-85            [-1, 512, 4096]               0
          Dropout-86            [-1, 512, 4096]               0
           Conv1d-87            [-1, 512, 4096]           8,704
  MyConv1dPadSame-88            [-1, 512, 4096]               0
       Bottleneck-89            [-1, 512, 4096]               0
      BatchNorm1d-90            [-1, 512, 4096]           1,024
             ReLU-91            [-1, 512, 4096]               0
           Linear-92                    [-1, 2]           1,026
================================================================
Total params: 51,010
Trainable params: 51,010
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 652.00
Params size (MB): 0.19
Estimated Total Size (MB): 652.21
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 64, kernel_size: 2, n_block: 16
************************************************************
************************************************************
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 64, 4096]             192
   MyConv1dPadSame-2             [-1, 64, 4096]               0
       BatchNorm1d-3             [-1, 64, 4096]             128
              ReLU-4             [-1, 64, 4096]               0
            Conv1d-5             [-1, 64, 4096]             192
   MyConv1dPadSame-6             [-1, 64, 4096]               0
       BatchNorm1d-7             [-1, 64, 4096]             128
              ReLU-8             [-1, 64, 4096]               0
           Dropout-9             [-1, 64, 4096]               0
           Conv1d-10             [-1, 64, 4096]             192
  MyConv1dPadSame-11             [-1, 64, 4096]               0
       Bottleneck-12             [-1, 64, 4096]               0
      BatchNorm1d-13             [-1, 64, 4096]             128
             ReLU-14             [-1, 64, 4096]               0
          Dropout-15             [-1, 64, 4096]               0
           Conv1d-16             [-1, 64, 2048]             192
  MyConv1dPadSame-17             [-1, 64, 2048]               0
      BatchNorm1d-18             [-1, 64, 2048]             128
             ReLU-19             [-1, 64, 2048]               0
          Dropout-20             [-1, 64, 2048]               0
           Conv1d-21             [-1, 64, 2048]             192
  MyConv1dPadSame-22             [-1, 64, 2048]               0
        MaxPool1d-23             [-1, 64, 2048]               0
MyMaxPool1dPadSame-24             [-1, 64, 2048]               0
       Bottleneck-25             [-1, 64, 2048]               0
      BatchNorm1d-26             [-1, 64, 2048]             128
             ReLU-27             [-1, 64, 2048]               0
          Dropout-28             [-1, 64, 2048]               0
           Conv1d-29             [-1, 64, 2048]             192
  MyConv1dPadSame-30             [-1, 64, 2048]               0
      BatchNorm1d-31             [-1, 64, 2048]             128
             ReLU-32             [-1, 64, 2048]               0
          Dropout-33             [-1, 64, 2048]               0
           Conv1d-34             [-1, 64, 2048]             192
  MyConv1dPadSame-35             [-1, 64, 2048]               0
       Bottleneck-36             [-1, 64, 2048]               0
      BatchNorm1d-37             [-1, 64, 2048]             128
             ReLU-38             [-1, 64, 2048]               0
          Dropout-39             [-1, 64, 2048]               0
           Conv1d-40             [-1, 64, 1024]             192
  MyConv1dPadSame-41             [-1, 64, 1024]               0
      BatchNorm1d-42             [-1, 64, 1024]             128
             ReLU-43             [-1, 64, 1024]               0
          Dropout-44             [-1, 64, 1024]               0
           Conv1d-45             [-1, 64, 1024]             192
  MyConv1dPadSame-46             [-1, 64, 1024]               0
        MaxPool1d-47             [-1, 64, 1024]               0
MyMaxPool1dPadSame-48             [-1, 64, 1024]               0
       Bottleneck-49             [-1, 64, 1024]               0
      BatchNorm1d-50             [-1, 64, 1024]             128
             ReLU-51             [-1, 64, 1024]               0
          Dropout-52             [-1, 64, 1024]               0
           Conv1d-53            [-1, 128, 1024]             384
  MyConv1dPadSame-54            [-1, 128, 1024]               0
      BatchNorm1d-55            [-1, 128, 1024]             256
             ReLU-56            [-1, 128, 1024]               0
          Dropout-57            [-1, 128, 1024]               0
           Conv1d-58            [-1, 128, 1024]             640
  MyConv1dPadSame-59            [-1, 128, 1024]               0
       Bottleneck-60            [-1, 128, 1024]               0
      BatchNorm1d-61            [-1, 128, 1024]             256
             ReLU-62            [-1, 128, 1024]               0
          Dropout-63            [-1, 128, 1024]               0
           Conv1d-64             [-1, 128, 512]             640
  MyConv1dPadSame-65             [-1, 128, 512]               0
      BatchNorm1d-66             [-1, 128, 512]             256
             ReLU-67             [-1, 128, 512]               0
          Dropout-68             [-1, 128, 512]               0
           Conv1d-69             [-1, 128, 512]             640
  MyConv1dPadSame-70             [-1, 128, 512]               0
        MaxPool1d-71             [-1, 128, 512]               0
MyMaxPool1dPadSame-72             [-1, 128, 512]               0
       Bottleneck-73             [-1, 128, 512]               0
      BatchNorm1d-74             [-1, 128, 512]             256
             ReLU-75             [-1, 128, 512]               0
          Dropout-76             [-1, 128, 512]               0
           Conv1d-77             [-1, 128, 512]             640
  MyConv1dPadSame-78             [-1, 128, 512]               0
      BatchNorm1d-79             [-1, 128, 512]             256
             ReLU-80             [-1, 128, 512]               0
          Dropout-81             [-1, 128, 512]               0
           Conv1d-82             [-1, 128, 512]             640
  MyConv1dPadSame-83             [-1, 128, 512]               0
       Bottleneck-84             [-1, 128, 512]               0
      BatchNorm1d-85             [-1, 128, 512]             256
             ReLU-86             [-1, 128, 512]               0
          Dropout-87             [-1, 128, 512]               0
           Conv1d-88             [-1, 128, 256]             640
  MyConv1dPadSame-89             [-1, 128, 256]               0
      BatchNorm1d-90             [-1, 128, 256]             256
             ReLU-91             [-1, 128, 256]               0
          Dropout-92             [-1, 128, 256]               0
           Conv1d-93             [-1, 128, 256]             640
  MyConv1dPadSame-94             [-1, 128, 256]               0
        MaxPool1d-95             [-1, 128, 256]               0
MyMaxPool1dPadSame-96             [-1, 128, 256]               0
       Bottleneck-97             [-1, 128, 256]               0
      BatchNorm1d-98             [-1, 128, 256]             256
             ReLU-99             [-1, 128, 256]               0
         Dropout-100             [-1, 128, 256]               0
          Conv1d-101             [-1, 256, 256]           1,280
 MyConv1dPadSame-102             [-1, 256, 256]               0
     BatchNorm1d-103             [-1, 256, 256]             512
            ReLU-104             [-1, 256, 256]               0
         Dropout-105             [-1, 256, 256]               0
          Conv1d-106             [-1, 256, 256]           2,304
 MyConv1dPadSame-107             [-1, 256, 256]               0
      Bottleneck-108             [-1, 256, 256]               0
     BatchNorm1d-109             [-1, 256, 256]             512
            ReLU-110             [-1, 256, 256]               0
         Dropout-111             [-1, 256, 256]               0
          Conv1d-112             [-1, 256, 128]           2,304
 MyConv1dPadSame-113             [-1, 256, 128]               0
     BatchNorm1d-114             [-1, 256, 128]             512
            ReLU-115             [-1, 256, 128]               0
         Dropout-116             [-1, 256, 128]               0
          Conv1d-117             [-1, 256, 128]           2,304
 MyConv1dPadSame-118             [-1, 256, 128]               0
       MaxPool1d-119             [-1, 256, 128]               0
MyMaxPool1dPadSame-120             [-1, 256, 128]               0
      Bottleneck-121             [-1, 256, 128]               0
     BatchNorm1d-122             [-1, 256, 128]             512
            ReLU-123             [-1, 256, 128]               0
         Dropout-124             [-1, 256, 128]               0
          Conv1d-125             [-1, 256, 128]           2,304
 MyConv1dPadSame-126             [-1, 256, 128]               0
     BatchNorm1d-127             [-1, 256, 128]             512
            ReLU-128             [-1, 256, 128]               0
         Dropout-129             [-1, 256, 128]               0
          Conv1d-130             [-1, 256, 128]           2,304
 MyConv1dPadSame-131             [-1, 256, 128]               0
      Bottleneck-132             [-1, 256, 128]               0
     BatchNorm1d-133             [-1, 256, 128]             512
            ReLU-134             [-1, 256, 128]               0
         Dropout-135             [-1, 256, 128]               0
          Conv1d-136              [-1, 256, 64]           2,304
 MyConv1dPadSame-137              [-1, 256, 64]               0
     BatchNorm1d-138              [-1, 256, 64]             512
            ReLU-139              [-1, 256, 64]               0
         Dropout-140              [-1, 256, 64]               0
          Conv1d-141              [-1, 256, 64]           2,304
 MyConv1dPadSame-142              [-1, 256, 64]               0
       MaxPool1d-143              [-1, 256, 64]               0
MyMaxPool1dPadSame-144              [-1, 256, 64]               0
      Bottleneck-145              [-1, 256, 64]               0
     BatchNorm1d-146              [-1, 256, 64]             512
            ReLU-147              [-1, 256, 64]               0
         Dropout-148              [-1, 256, 64]               0
          Conv1d-149              [-1, 512, 64]           4,608
 MyConv1dPadSame-150              [-1, 512, 64]               0
     BatchNorm1d-151              [-1, 512, 64]           1,024
            ReLU-152              [-1, 512, 64]               0
         Dropout-153              [-1, 512, 64]               0
          Conv1d-154              [-1, 512, 64]           8,704
 MyConv1dPadSame-155              [-1, 512, 64]               0
      Bottleneck-156              [-1, 512, 64]               0
     BatchNorm1d-157              [-1, 512, 64]           1,024
            ReLU-158              [-1, 512, 64]               0
         Dropout-159              [-1, 512, 64]               0
          Conv1d-160              [-1, 512, 32]           8,704
 MyConv1dPadSame-161              [-1, 512, 32]               0
     BatchNorm1d-162              [-1, 512, 32]           1,024
            ReLU-163              [-1, 512, 32]               0
         Dropout-164              [-1, 512, 32]               0
          Conv1d-165              [-1, 512, 32]           8,704
 MyConv1dPadSame-166              [-1, 512, 32]               0
       MaxPool1d-167              [-1, 512, 32]               0
MyMaxPool1dPadSame-168              [-1, 512, 32]               0
      Bottleneck-169              [-1, 512, 32]               0
     BatchNorm1d-170              [-1, 512, 32]           1,024
            ReLU-171              [-1, 512, 32]               0
         Dropout-172              [-1, 512, 32]               0
          Conv1d-173              [-1, 512, 32]           8,704
 MyConv1dPadSame-174              [-1, 512, 32]               0
     BatchNorm1d-175              [-1, 512, 32]           1,024
            ReLU-176              [-1, 512, 32]               0
         Dropout-177              [-1, 512, 32]               0
          Conv1d-178              [-1, 512, 32]           8,704
 MyConv1dPadSame-179              [-1, 512, 32]               0
      Bottleneck-180              [-1, 512, 32]               0
     BatchNorm1d-181              [-1, 512, 32]           1,024
            ReLU-182              [-1, 512, 32]               0
         Dropout-183              [-1, 512, 32]               0
          Conv1d-184              [-1, 512, 16]           8,704
 MyConv1dPadSame-185              [-1, 512, 16]               0
     BatchNorm1d-186              [-1, 512, 16]           1,024
            ReLU-187              [-1, 512, 16]               0
         Dropout-188              [-1, 512, 16]               0
          Conv1d-189              [-1, 512, 16]           8,704
 MyConv1dPadSame-190              [-1, 512, 16]               0
       MaxPool1d-191              [-1, 512, 16]               0
MyMaxPool1dPadSame-192              [-1, 512, 16]               0
      Bottleneck-193              [-1, 512, 16]               0
     BatchNorm1d-194              [-1, 512, 16]           1,024
            ReLU-195              [-1, 512, 16]               0
          Linear-196                    [-1, 2]           1,026
================================================================
Total params: 106,050
Trainable params: 106,050
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 106.38
Params size (MB): 0.40
Estimated Total Size (MB): 106.80
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 64, kernel_size: 4, n_block: 2
************************************************************
************************************************************
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 64, 4096]             320
   MyConv1dPadSame-2             [-1, 64, 4096]               0
       BatchNorm1d-3             [-1, 64, 4096]             128
              ReLU-4             [-1, 64, 4096]               0
            Conv1d-5             [-1, 64, 4096]             320
   MyConv1dPadSame-6             [-1, 64, 4096]               0
       BatchNorm1d-7             [-1, 64, 4096]             128
              ReLU-8             [-1, 64, 4096]               0
           Dropout-9             [-1, 64, 4096]               0
           Conv1d-10             [-1, 64, 4096]             320
  MyConv1dPadSame-11             [-1, 64, 4096]               0
       Bottleneck-12             [-1, 64, 4096]               0
      BatchNorm1d-13             [-1, 64, 4096]             128
             ReLU-14             [-1, 64, 4096]               0
          Dropout-15             [-1, 64, 4096]               0
           Conv1d-16            [-1, 128, 4096]             640
  MyConv1dPadSame-17            [-1, 128, 4096]               0
      BatchNorm1d-18            [-1, 128, 4096]             256
             ReLU-19            [-1, 128, 4096]               0
          Dropout-20            [-1, 128, 4096]               0
           Conv1d-21            [-1, 128, 4096]           1,152
  MyConv1dPadSame-22            [-1, 128, 4096]               0
       Bottleneck-23            [-1, 128, 4096]               0
      BatchNorm1d-24            [-1, 128, 4096]             256
             ReLU-25            [-1, 128, 4096]               0
           Linear-26                    [-1, 2]             258
================================================================
Total params: 3,906
Trainable params: 3,906
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 70.00
Params size (MB): 0.01
Estimated Total Size (MB): 70.03
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 64, kernel_size: 4, n_block: 4
************************************************************
************************************************************
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 64, 4096]             320
   MyConv1dPadSame-2             [-1, 64, 4096]               0
       BatchNorm1d-3             [-1, 64, 4096]             128
              ReLU-4             [-1, 64, 4096]               0
            Conv1d-5             [-1, 64, 4096]             320
   MyConv1dPadSame-6             [-1, 64, 4096]               0
       BatchNorm1d-7             [-1, 64, 4096]             128
              ReLU-8             [-1, 64, 4096]               0
           Dropout-9             [-1, 64, 4096]               0
           Conv1d-10             [-1, 64, 4096]             320
  MyConv1dPadSame-11             [-1, 64, 4096]               0
       Bottleneck-12             [-1, 64, 4096]               0
      BatchNorm1d-13             [-1, 64, 4096]             128
             ReLU-14             [-1, 64, 4096]               0
          Dropout-15             [-1, 64, 4096]               0
           Conv1d-16            [-1, 128, 4096]             640
  MyConv1dPadSame-17            [-1, 128, 4096]               0
      BatchNorm1d-18            [-1, 128, 4096]             256
             ReLU-19            [-1, 128, 4096]               0
          Dropout-20            [-1, 128, 4096]               0
           Conv1d-21            [-1, 128, 4096]           1,152
  MyConv1dPadSame-22            [-1, 128, 4096]               0
       Bottleneck-23            [-1, 128, 4096]               0
      BatchNorm1d-24            [-1, 128, 4096]             256
             ReLU-25            [-1, 128, 4096]               0
          Dropout-26            [-1, 128, 4096]               0
           Conv1d-27            [-1, 256, 4096]           2,304
  MyConv1dPadSame-28            [-1, 256, 4096]               0
      BatchNorm1d-29            [-1, 256, 4096]             512
             ReLU-30            [-1, 256, 4096]               0
          Dropout-31            [-1, 256, 4096]               0
           Conv1d-32            [-1, 256, 4096]           4,352
  MyConv1dPadSame-33            [-1, 256, 4096]               0
       Bottleneck-34            [-1, 256, 4096]               0
      BatchNorm1d-35            [-1, 256, 4096]             512
             ReLU-36            [-1, 256, 4096]               0
          Dropout-37            [-1, 256, 4096]               0
           Conv1d-38            [-1, 512, 4096]           8,704
  MyConv1dPadSame-39            [-1, 512, 4096]               0
      BatchNorm1d-40            [-1, 512, 4096]           1,024
             ReLU-41            [-1, 512, 4096]               0
          Dropout-42            [-1, 512, 4096]               0
           Conv1d-43            [-1, 512, 4096]          16,896
  MyConv1dPadSame-44            [-1, 512, 4096]               0
       Bottleneck-45            [-1, 512, 4096]               0
      BatchNorm1d-46            [-1, 512, 4096]           1,024
             ReLU-47            [-1, 512, 4096]               0
           Linear-48                    [-1, 2]           1,026
================================================================
Total params: 40,002
Trainable params: 40,002
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 322.00
Params size (MB): 0.15
Estimated Total Size (MB): 322.17
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 64, kernel_size: 4, n_block: 8
************************************************************
************************************************************
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 64, 4096]             320
   MyConv1dPadSame-2             [-1, 64, 4096]               0
       BatchNorm1d-3             [-1, 64, 4096]             128
              ReLU-4             [-1, 64, 4096]               0
            Conv1d-5             [-1, 64, 4096]             320
   MyConv1dPadSame-6             [-1, 64, 4096]               0
       BatchNorm1d-7             [-1, 64, 4096]             128
              ReLU-8             [-1, 64, 4096]               0
           Dropout-9             [-1, 64, 4096]               0
           Conv1d-10             [-1, 64, 4096]             320
  MyConv1dPadSame-11             [-1, 64, 4096]               0
       Bottleneck-12             [-1, 64, 4096]               0
      BatchNorm1d-13             [-1, 64, 4096]             128
             ReLU-14             [-1, 64, 4096]               0
          Dropout-15             [-1, 64, 4096]               0
           Conv1d-16             [-1, 64, 4096]             320
  MyConv1dPadSame-17             [-1, 64, 4096]               0
      BatchNorm1d-18             [-1, 64, 4096]             128
             ReLU-19             [-1, 64, 4096]               0
          Dropout-20             [-1, 64, 4096]               0
           Conv1d-21             [-1, 64, 4096]             320
  MyConv1dPadSame-22             [-1, 64, 4096]               0
       Bottleneck-23             [-1, 64, 4096]               0
      BatchNorm1d-24             [-1, 64, 4096]             128
             ReLU-25             [-1, 64, 4096]               0
          Dropout-26             [-1, 64, 4096]               0
           Conv1d-27            [-1, 128, 4096]             640
  MyConv1dPadSame-28            [-1, 128, 4096]               0
      BatchNorm1d-29            [-1, 128, 4096]             256
             ReLU-30            [-1, 128, 4096]               0
          Dropout-31            [-1, 128, 4096]               0
           Conv1d-32            [-1, 128, 4096]           1,152
  MyConv1dPadSame-33            [-1, 128, 4096]               0
       Bottleneck-34            [-1, 128, 4096]               0
      BatchNorm1d-35            [-1, 128, 4096]             256
             ReLU-36            [-1, 128, 4096]               0
          Dropout-37            [-1, 128, 4096]               0
           Conv1d-38            [-1, 128, 4096]           1,152
  MyConv1dPadSame-39            [-1, 128, 4096]               0
      BatchNorm1d-40            [-1, 128, 4096]             256
             ReLU-41            [-1, 128, 4096]               0
          Dropout-42            [-1, 128, 4096]               0
           Conv1d-43            [-1, 128, 4096]           1,152
  MyConv1dPadSame-44            [-1, 128, 4096]               0
       Bottleneck-45            [-1, 128, 4096]               0
      BatchNorm1d-46            [-1, 128, 4096]             256
             ReLU-47            [-1, 128, 4096]               0
          Dropout-48            [-1, 128, 4096]               0
           Conv1d-49            [-1, 256, 4096]           2,304
  MyConv1dPadSame-50            [-1, 256, 4096]               0
      BatchNorm1d-51            [-1, 256, 4096]             512
             ReLU-52            [-1, 256, 4096]               0
          Dropout-53            [-1, 256, 4096]               0
           Conv1d-54            [-1, 256, 4096]           4,352
  MyConv1dPadSame-55            [-1, 256, 4096]               0
       Bottleneck-56            [-1, 256, 4096]               0
      BatchNorm1d-57            [-1, 256, 4096]             512
             ReLU-58            [-1, 256, 4096]               0
          Dropout-59            [-1, 256, 4096]               0
           Conv1d-60            [-1, 256, 4096]           4,352
  MyConv1dPadSame-61            [-1, 256, 4096]               0
      BatchNorm1d-62            [-1, 256, 4096]             512
             ReLU-63            [-1, 256, 4096]               0
          Dropout-64            [-1, 256, 4096]               0
           Conv1d-65            [-1, 256, 4096]           4,352
  MyConv1dPadSame-66            [-1, 256, 4096]               0
       Bottleneck-67            [-1, 256, 4096]               0
      BatchNorm1d-68            [-1, 256, 4096]             512
             ReLU-69            [-1, 256, 4096]               0
          Dropout-70            [-1, 256, 4096]               0
           Conv1d-71            [-1, 512, 4096]           8,704
  MyConv1dPadSame-72            [-1, 512, 4096]               0
      BatchNorm1d-73            [-1, 512, 4096]           1,024
             ReLU-74            [-1, 512, 4096]               0
          Dropout-75            [-1, 512, 4096]               0
           Conv1d-76            [-1, 512, 4096]          16,896
  MyConv1dPadSame-77            [-1, 512, 4096]               0
       Bottleneck-78            [-1, 512, 4096]               0
      BatchNorm1d-79            [-1, 512, 4096]           1,024
             ReLU-80            [-1, 512, 4096]               0
          Dropout-81            [-1, 512, 4096]               0
           Conv1d-82            [-1, 512, 4096]          16,896
  MyConv1dPadSame-83            [-1, 512, 4096]               0
      BatchNorm1d-84            [-1, 512, 4096]           1,024
             ReLU-85            [-1, 512, 4096]               0
          Dropout-86            [-1, 512, 4096]               0
           Conv1d-87            [-1, 512, 4096]          16,896
  MyConv1dPadSame-88            [-1, 512, 4096]               0
       Bottleneck-89            [-1, 512, 4096]               0
      BatchNorm1d-90            [-1, 512, 4096]           1,024
             ReLU-91            [-1, 512, 4096]               0
           Linear-92                    [-1, 2]           1,026
================================================================
Total params: 89,282
Trainable params: 89,282
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 652.00
Params size (MB): 0.34
Estimated Total Size (MB): 652.36
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 64, kernel_size: 4, n_block: 16
************************************************************
************************************************************
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 64, 4096]             320
   MyConv1dPadSame-2             [-1, 64, 4096]               0
       BatchNorm1d-3             [-1, 64, 4096]             128
              ReLU-4             [-1, 64, 4096]               0
            Conv1d-5             [-1, 64, 4096]             320
   MyConv1dPadSame-6             [-1, 64, 4096]               0
       BatchNorm1d-7             [-1, 64, 4096]             128
              ReLU-8             [-1, 64, 4096]               0
           Dropout-9             [-1, 64, 4096]               0
           Conv1d-10             [-1, 64, 4096]             320
  MyConv1dPadSame-11             [-1, 64, 4096]               0
       Bottleneck-12             [-1, 64, 4096]               0
      BatchNorm1d-13             [-1, 64, 4096]             128
             ReLU-14             [-1, 64, 4096]               0
          Dropout-15             [-1, 64, 4096]               0
           Conv1d-16             [-1, 64, 2048]             320
  MyConv1dPadSame-17             [-1, 64, 2048]               0
      BatchNorm1d-18             [-1, 64, 2048]             128
             ReLU-19             [-1, 64, 2048]               0
          Dropout-20             [-1, 64, 2048]               0
           Conv1d-21             [-1, 64, 2048]             320
  MyConv1dPadSame-22             [-1, 64, 2048]               0
        MaxPool1d-23             [-1, 64, 2048]               0
MyMaxPool1dPadSame-24             [-1, 64, 2048]               0
       Bottleneck-25             [-1, 64, 2048]               0
      BatchNorm1d-26             [-1, 64, 2048]             128
             ReLU-27             [-1, 64, 2048]               0
          Dropout-28             [-1, 64, 2048]               0
           Conv1d-29             [-1, 64, 2048]             320
  MyConv1dPadSame-30             [-1, 64, 2048]               0
      BatchNorm1d-31             [-1, 64, 2048]             128
             ReLU-32             [-1, 64, 2048]               0
          Dropout-33             [-1, 64, 2048]               0
           Conv1d-34             [-1, 64, 2048]             320
  MyConv1dPadSame-35             [-1, 64, 2048]               0
       Bottleneck-36             [-1, 64, 2048]               0
      BatchNorm1d-37             [-1, 64, 2048]             128
             ReLU-38             [-1, 64, 2048]               0
          Dropout-39             [-1, 64, 2048]               0
           Conv1d-40             [-1, 64, 1024]             320
  MyConv1dPadSame-41             [-1, 64, 1024]               0
      BatchNorm1d-42             [-1, 64, 1024]             128
             ReLU-43             [-1, 64, 1024]               0
          Dropout-44             [-1, 64, 1024]               0
           Conv1d-45             [-1, 64, 1024]             320
  MyConv1dPadSame-46             [-1, 64, 1024]               0
        MaxPool1d-47             [-1, 64, 1024]               0
MyMaxPool1dPadSame-48             [-1, 64, 1024]               0
       Bottleneck-49             [-1, 64, 1024]               0
      BatchNorm1d-50             [-1, 64, 1024]             128
             ReLU-51             [-1, 64, 1024]               0
          Dropout-52             [-1, 64, 1024]               0
           Conv1d-53            [-1, 128, 1024]             640
  MyConv1dPadSame-54            [-1, 128, 1024]               0
      BatchNorm1d-55            [-1, 128, 1024]             256
             ReLU-56            [-1, 128, 1024]               0
          Dropout-57            [-1, 128, 1024]               0
           Conv1d-58            [-1, 128, 1024]           1,152
  MyConv1dPadSame-59            [-1, 128, 1024]               0
       Bottleneck-60            [-1, 128, 1024]               0
      BatchNorm1d-61            [-1, 128, 1024]             256
             ReLU-62            [-1, 128, 1024]               0
          Dropout-63            [-1, 128, 1024]               0
           Conv1d-64             [-1, 128, 512]           1,152
  MyConv1dPadSame-65             [-1, 128, 512]               0
      BatchNorm1d-66             [-1, 128, 512]             256
             ReLU-67             [-1, 128, 512]               0
          Dropout-68             [-1, 128, 512]               0
           Conv1d-69             [-1, 128, 512]           1,152
  MyConv1dPadSame-70             [-1, 128, 512]               0
        MaxPool1d-71             [-1, 128, 512]               0
MyMaxPool1dPadSame-72             [-1, 128, 512]               0
       Bottleneck-73             [-1, 128, 512]               0
      BatchNorm1d-74             [-1, 128, 512]             256
             ReLU-75             [-1, 128, 512]               0
          Dropout-76             [-1, 128, 512]               0
           Conv1d-77             [-1, 128, 512]           1,152
  MyConv1dPadSame-78             [-1, 128, 512]               0
      BatchNorm1d-79             [-1, 128, 512]             256
             ReLU-80             [-1, 128, 512]               0
          Dropout-81             [-1, 128, 512]               0
           Conv1d-82             [-1, 128, 512]           1,152
  MyConv1dPadSame-83             [-1, 128, 512]               0
       Bottleneck-84             [-1, 128, 512]               0
      BatchNorm1d-85             [-1, 128, 512]             256
             ReLU-86             [-1, 128, 512]               0
          Dropout-87             [-1, 128, 512]               0
           Conv1d-88             [-1, 128, 256]           1,152
  MyConv1dPadSame-89             [-1, 128, 256]               0
      BatchNorm1d-90             [-1, 128, 256]             256
             ReLU-91             [-1, 128, 256]               0
          Dropout-92             [-1, 128, 256]               0
           Conv1d-93             [-1, 128, 256]           1,152
  MyConv1dPadSame-94             [-1, 128, 256]               0
        MaxPool1d-95             [-1, 128, 256]               0
MyMaxPool1dPadSame-96             [-1, 128, 256]               0
       Bottleneck-97             [-1, 128, 256]               0
      BatchNorm1d-98             [-1, 128, 256]             256
             ReLU-99             [-1, 128, 256]               0
         Dropout-100             [-1, 128, 256]               0
          Conv1d-101             [-1, 256, 256]           2,304
 MyConv1dPadSame-102             [-1, 256, 256]               0
     BatchNorm1d-103             [-1, 256, 256]             512
            ReLU-104             [-1, 256, 256]               0
         Dropout-105             [-1, 256, 256]               0
          Conv1d-106             [-1, 256, 256]           4,352
 MyConv1dPadSame-107             [-1, 256, 256]               0
      Bottleneck-108             [-1, 256, 256]               0
     BatchNorm1d-109             [-1, 256, 256]             512
            ReLU-110             [-1, 256, 256]               0
         Dropout-111             [-1, 256, 256]               0
          Conv1d-112             [-1, 256, 128]           4,352
 MyConv1dPadSame-113             [-1, 256, 128]               0
     BatchNorm1d-114             [-1, 256, 128]             512
            ReLU-115             [-1, 256, 128]               0
         Dropout-116             [-1, 256, 128]               0
          Conv1d-117             [-1, 256, 128]           4,352
 MyConv1dPadSame-118             [-1, 256, 128]               0
       MaxPool1d-119             [-1, 256, 128]               0
MyMaxPool1dPadSame-120             [-1, 256, 128]               0
      Bottleneck-121             [-1, 256, 128]               0
     BatchNorm1d-122             [-1, 256, 128]             512
            ReLU-123             [-1, 256, 128]               0
         Dropout-124             [-1, 256, 128]               0
          Conv1d-125             [-1, 256, 128]           4,352
 MyConv1dPadSame-126             [-1, 256, 128]               0
     BatchNorm1d-127             [-1, 256, 128]             512
            ReLU-128             [-1, 256, 128]               0
         Dropout-129             [-1, 256, 128]               0
          Conv1d-130             [-1, 256, 128]           4,352
 MyConv1dPadSame-131             [-1, 256, 128]               0
      Bottleneck-132             [-1, 256, 128]               0
     BatchNorm1d-133             [-1, 256, 128]             512
            ReLU-134             [-1, 256, 128]               0
         Dropout-135             [-1, 256, 128]               0
          Conv1d-136              [-1, 256, 64]           4,352
 MyConv1dPadSame-137              [-1, 256, 64]               0
     BatchNorm1d-138              [-1, 256, 64]             512
            ReLU-139              [-1, 256, 64]               0
         Dropout-140              [-1, 256, 64]               0
          Conv1d-141              [-1, 256, 64]           4,352
 MyConv1dPadSame-142              [-1, 256, 64]               0
       MaxPool1d-143              [-1, 256, 64]               0
MyMaxPool1dPadSame-144              [-1, 256, 64]               0
      Bottleneck-145              [-1, 256, 64]               0
     BatchNorm1d-146              [-1, 256, 64]             512
            ReLU-147              [-1, 256, 64]               0
         Dropout-148              [-1, 256, 64]               0
          Conv1d-149              [-1, 512, 64]           8,704
 MyConv1dPadSame-150              [-1, 512, 64]               0
     BatchNorm1d-151              [-1, 512, 64]           1,024
            ReLU-152              [-1, 512, 64]               0
         Dropout-153              [-1, 512, 64]               0
          Conv1d-154              [-1, 512, 64]          16,896
 MyConv1dPadSame-155              [-1, 512, 64]               0
      Bottleneck-156              [-1, 512, 64]               0
     BatchNorm1d-157              [-1, 512, 64]           1,024
            ReLU-158              [-1, 512, 64]               0
         Dropout-159              [-1, 512, 64]               0
          Conv1d-160              [-1, 512, 32]          16,896
 MyConv1dPadSame-161              [-1, 512, 32]               0
     BatchNorm1d-162              [-1, 512, 32]           1,024
            ReLU-163              [-1, 512, 32]               0
         Dropout-164              [-1, 512, 32]               0
          Conv1d-165              [-1, 512, 32]          16,896
 MyConv1dPadSame-166              [-1, 512, 32]               0
       MaxPool1d-167              [-1, 512, 32]               0
MyMaxPool1dPadSame-168              [-1, 512, 32]               0
      Bottleneck-169              [-1, 512, 32]               0
     BatchNorm1d-170              [-1, 512, 32]           1,024
            ReLU-171              [-1, 512, 32]               0
         Dropout-172              [-1, 512, 32]               0
          Conv1d-173              [-1, 512, 32]          16,896
 MyConv1dPadSame-174              [-1, 512, 32]               0
     BatchNorm1d-175              [-1, 512, 32]           1,024
            ReLU-176              [-1, 512, 32]               0
         Dropout-177              [-1, 512, 32]               0
          Conv1d-178              [-1, 512, 32]          16,896
 MyConv1dPadSame-179              [-1, 512, 32]               0
      Bottleneck-180              [-1, 512, 32]               0
     BatchNorm1d-181              [-1, 512, 32]           1,024
            ReLU-182              [-1, 512, 32]               0
         Dropout-183              [-1, 512, 32]               0
          Conv1d-184              [-1, 512, 16]          16,896
 MyConv1dPadSame-185              [-1, 512, 16]               0
     BatchNorm1d-186              [-1, 512, 16]           1,024
            ReLU-187              [-1, 512, 16]               0
         Dropout-188              [-1, 512, 16]               0
          Conv1d-189              [-1, 512, 16]          16,896
 MyConv1dPadSame-190              [-1, 512, 16]               0
       MaxPool1d-191              [-1, 512, 16]               0
MyMaxPool1dPadSame-192              [-1, 512, 16]               0
      Bottleneck-193              [-1, 512, 16]               0
     BatchNorm1d-194              [-1, 512, 16]           1,024
            ReLU-195              [-1, 512, 16]               0
          Linear-196                    [-1, 2]           1,026
================================================================
Total params: 187,842
Trainable params: 187,842
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 106.38
Params size (MB): 0.72
Estimated Total Size (MB): 107.11
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 64, kernel_size: 8, n_block: 2
************************************************************
************************************************************
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 64, 4096]             576
   MyConv1dPadSame-2             [-1, 64, 4096]               0
       BatchNorm1d-3             [-1, 64, 4096]             128
              ReLU-4             [-1, 64, 4096]               0
            Conv1d-5             [-1, 64, 4096]             576
   MyConv1dPadSame-6             [-1, 64, 4096]               0
       BatchNorm1d-7             [-1, 64, 4096]             128
              ReLU-8             [-1, 64, 4096]               0
           Dropout-9             [-1, 64, 4096]               0
           Conv1d-10             [-1, 64, 4096]             576
  MyConv1dPadSame-11             [-1, 64, 4096]               0
       Bottleneck-12             [-1, 64, 4096]               0
      BatchNorm1d-13             [-1, 64, 4096]             128
             ReLU-14             [-1, 64, 4096]               0
          Dropout-15             [-1, 64, 4096]               0
           Conv1d-16            [-1, 128, 4096]           1,152
  MyConv1dPadSame-17            [-1, 128, 4096]               0
      BatchNorm1d-18            [-1, 128, 4096]             256
             ReLU-19            [-1, 128, 4096]               0
          Dropout-20            [-1, 128, 4096]               0
           Conv1d-21            [-1, 128, 4096]           2,176
  MyConv1dPadSame-22            [-1, 128, 4096]               0
       Bottleneck-23            [-1, 128, 4096]               0
      BatchNorm1d-24            [-1, 128, 4096]             256
             ReLU-25            [-1, 128, 4096]               0
           Linear-26                    [-1, 2]             258
================================================================
Total params: 6,210
Trainable params: 6,210
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 70.00
Params size (MB): 0.02
Estimated Total Size (MB): 70.04
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 64, kernel_size: 8, n_block: 4
************************************************************
************************************************************
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 64, 4096]             576
   MyConv1dPadSame-2             [-1, 64, 4096]               0
       BatchNorm1d-3             [-1, 64, 4096]             128
              ReLU-4             [-1, 64, 4096]               0
            Conv1d-5             [-1, 64, 4096]             576
   MyConv1dPadSame-6             [-1, 64, 4096]               0
       BatchNorm1d-7             [-1, 64, 4096]             128
              ReLU-8             [-1, 64, 4096]               0
           Dropout-9             [-1, 64, 4096]               0
           Conv1d-10             [-1, 64, 4096]             576
  MyConv1dPadSame-11             [-1, 64, 4096]               0
       Bottleneck-12             [-1, 64, 4096]               0
      BatchNorm1d-13             [-1, 64, 4096]             128
             ReLU-14             [-1, 64, 4096]               0
          Dropout-15             [-1, 64, 4096]               0
           Conv1d-16            [-1, 128, 4096]           1,152
  MyConv1dPadSame-17            [-1, 128, 4096]               0
      BatchNorm1d-18            [-1, 128, 4096]             256
             ReLU-19            [-1, 128, 4096]               0
          Dropout-20            [-1, 128, 4096]               0
           Conv1d-21            [-1, 128, 4096]           2,176
  MyConv1dPadSame-22            [-1, 128, 4096]               0
       Bottleneck-23            [-1, 128, 4096]               0
      BatchNorm1d-24            [-1, 128, 4096]             256
             ReLU-25            [-1, 128, 4096]               0
          Dropout-26            [-1, 128, 4096]               0
           Conv1d-27            [-1, 256, 4096]           4,352
  MyConv1dPadSame-28            [-1, 256, 4096]               0
      BatchNorm1d-29            [-1, 256, 4096]             512
             ReLU-30            [-1, 256, 4096]               0
          Dropout-31            [-1, 256, 4096]               0
           Conv1d-32            [-1, 256, 4096]           8,448
  MyConv1dPadSame-33            [-1, 256, 4096]               0
       Bottleneck-34            [-1, 256, 4096]               0
      BatchNorm1d-35            [-1, 256, 4096]             512
             ReLU-36            [-1, 256, 4096]               0
          Dropout-37            [-1, 256, 4096]               0
           Conv1d-38            [-1, 512, 4096]          16,896
  MyConv1dPadSame-39            [-1, 512, 4096]               0
      BatchNorm1d-40            [-1, 512, 4096]           1,024
             ReLU-41            [-1, 512, 4096]               0
          Dropout-42            [-1, 512, 4096]               0
           Conv1d-43            [-1, 512, 4096]          33,280
  MyConv1dPadSame-44            [-1, 512, 4096]               0
       Bottleneck-45            [-1, 512, 4096]               0
      BatchNorm1d-46            [-1, 512, 4096]           1,024
             ReLU-47            [-1, 512, 4096]               0
           Linear-48                    [-1, 2]           1,026
================================================================
Total params: 73,026
Trainable params: 73,026
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 322.00
Params size (MB): 0.28
Estimated Total Size (MB): 322.29
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 64, kernel_size: 8, n_block: 8
************************************************************
************************************************************
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 64, 4096]             576
   MyConv1dPadSame-2             [-1, 64, 4096]               0
       BatchNorm1d-3             [-1, 64, 4096]             128
              ReLU-4             [-1, 64, 4096]               0
            Conv1d-5             [-1, 64, 4096]             576
   MyConv1dPadSame-6             [-1, 64, 4096]               0
       BatchNorm1d-7             [-1, 64, 4096]             128
              ReLU-8             [-1, 64, 4096]               0
           Dropout-9             [-1, 64, 4096]               0
           Conv1d-10             [-1, 64, 4096]             576
  MyConv1dPadSame-11             [-1, 64, 4096]               0
       Bottleneck-12             [-1, 64, 4096]               0
      BatchNorm1d-13             [-1, 64, 4096]             128
             ReLU-14             [-1, 64, 4096]               0
          Dropout-15             [-1, 64, 4096]               0
           Conv1d-16             [-1, 64, 4096]             576
  MyConv1dPadSame-17             [-1, 64, 4096]               0
      BatchNorm1d-18             [-1, 64, 4096]             128
             ReLU-19             [-1, 64, 4096]               0
          Dropout-20             [-1, 64, 4096]               0
           Conv1d-21             [-1, 64, 4096]             576
  MyConv1dPadSame-22             [-1, 64, 4096]               0
       Bottleneck-23             [-1, 64, 4096]               0
      BatchNorm1d-24             [-1, 64, 4096]             128
             ReLU-25             [-1, 64, 4096]               0
          Dropout-26             [-1, 64, 4096]               0
           Conv1d-27            [-1, 128, 4096]           1,152
  MyConv1dPadSame-28            [-1, 128, 4096]               0
      BatchNorm1d-29            [-1, 128, 4096]             256
             ReLU-30            [-1, 128, 4096]               0
          Dropout-31            [-1, 128, 4096]               0
           Conv1d-32            [-1, 128, 4096]           2,176
  MyConv1dPadSame-33            [-1, 128, 4096]               0
       Bottleneck-34            [-1, 128, 4096]               0
      BatchNorm1d-35            [-1, 128, 4096]             256
             ReLU-36            [-1, 128, 4096]               0
          Dropout-37            [-1, 128, 4096]               0
           Conv1d-38            [-1, 128, 4096]           2,176
  MyConv1dPadSame-39            [-1, 128, 4096]               0
      BatchNorm1d-40            [-1, 128, 4096]             256
             ReLU-41            [-1, 128, 4096]               0
          Dropout-42            [-1, 128, 4096]               0
           Conv1d-43            [-1, 128, 4096]           2,176
  MyConv1dPadSame-44            [-1, 128, 4096]               0
       Bottleneck-45            [-1, 128, 4096]               0
      BatchNorm1d-46            [-1, 128, 4096]             256
             ReLU-47            [-1, 128, 4096]               0
          Dropout-48            [-1, 128, 4096]               0
           Conv1d-49            [-1, 256, 4096]           4,352
  MyConv1dPadSame-50            [-1, 256, 4096]               0
      BatchNorm1d-51            [-1, 256, 4096]             512
             ReLU-52            [-1, 256, 4096]               0
          Dropout-53            [-1, 256, 4096]               0
           Conv1d-54            [-1, 256, 4096]           8,448
  MyConv1dPadSame-55            [-1, 256, 4096]               0
       Bottleneck-56            [-1, 256, 4096]               0
      BatchNorm1d-57            [-1, 256, 4096]             512
             ReLU-58            [-1, 256, 4096]               0
          Dropout-59            [-1, 256, 4096]               0
           Conv1d-60            [-1, 256, 4096]           8,448
  MyConv1dPadSame-61            [-1, 256, 4096]               0
      BatchNorm1d-62            [-1, 256, 4096]             512
             ReLU-63            [-1, 256, 4096]               0
          Dropout-64            [-1, 256, 4096]               0
           Conv1d-65            [-1, 256, 4096]           8,448
  MyConv1dPadSame-66            [-1, 256, 4096]               0
       Bottleneck-67            [-1, 256, 4096]               0
      BatchNorm1d-68            [-1, 256, 4096]             512
             ReLU-69            [-1, 256, 4096]               0
          Dropout-70            [-1, 256, 4096]               0
           Conv1d-71            [-1, 512, 4096]          16,896
  MyConv1dPadSame-72            [-1, 512, 4096]               0
      BatchNorm1d-73            [-1, 512, 4096]           1,024
             ReLU-74            [-1, 512, 4096]               0
          Dropout-75            [-1, 512, 4096]               0
           Conv1d-76            [-1, 512, 4096]          33,280
  MyConv1dPadSame-77            [-1, 512, 4096]               0
       Bottleneck-78            [-1, 512, 4096]               0
      BatchNorm1d-79            [-1, 512, 4096]           1,024
             ReLU-80            [-1, 512, 4096]               0
          Dropout-81            [-1, 512, 4096]               0
           Conv1d-82            [-1, 512, 4096]          33,280
  MyConv1dPadSame-83            [-1, 512, 4096]               0
      BatchNorm1d-84            [-1, 512, 4096]           1,024
             ReLU-85            [-1, 512, 4096]               0
          Dropout-86            [-1, 512, 4096]               0
           Conv1d-87            [-1, 512, 4096]          33,280
  MyConv1dPadSame-88            [-1, 512, 4096]               0
       Bottleneck-89            [-1, 512, 4096]               0
      BatchNorm1d-90            [-1, 512, 4096]           1,024
             ReLU-91            [-1, 512, 4096]               0
           Linear-92                    [-1, 2]           1,026
================================================================
Total params: 165,826
Trainable params: 165,826
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 652.00
Params size (MB): 0.63
Estimated Total Size (MB): 652.65
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 64, kernel_size: 8, n_block: 16
************************************************************
************************************************************
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 64, 4096]             576
   MyConv1dPadSame-2             [-1, 64, 4096]               0
       BatchNorm1d-3             [-1, 64, 4096]             128
              ReLU-4             [-1, 64, 4096]               0
            Conv1d-5             [-1, 64, 4096]             576
   MyConv1dPadSame-6             [-1, 64, 4096]               0
       BatchNorm1d-7             [-1, 64, 4096]             128
              ReLU-8             [-1, 64, 4096]               0
           Dropout-9             [-1, 64, 4096]               0
           Conv1d-10             [-1, 64, 4096]             576
  MyConv1dPadSame-11             [-1, 64, 4096]               0
       Bottleneck-12             [-1, 64, 4096]               0
      BatchNorm1d-13             [-1, 64, 4096]             128
             ReLU-14             [-1, 64, 4096]               0
          Dropout-15             [-1, 64, 4096]               0
           Conv1d-16             [-1, 64, 2048]             576
  MyConv1dPadSame-17             [-1, 64, 2048]               0
      BatchNorm1d-18             [-1, 64, 2048]             128
             ReLU-19             [-1, 64, 2048]               0
          Dropout-20             [-1, 64, 2048]               0
           Conv1d-21             [-1, 64, 2048]             576
  MyConv1dPadSame-22             [-1, 64, 2048]               0
        MaxPool1d-23             [-1, 64, 2048]               0
MyMaxPool1dPadSame-24             [-1, 64, 2048]               0
       Bottleneck-25             [-1, 64, 2048]               0
      BatchNorm1d-26             [-1, 64, 2048]             128
             ReLU-27             [-1, 64, 2048]               0
          Dropout-28             [-1, 64, 2048]               0
           Conv1d-29             [-1, 64, 2048]             576
  MyConv1dPadSame-30             [-1, 64, 2048]               0
      BatchNorm1d-31             [-1, 64, 2048]             128
             ReLU-32             [-1, 64, 2048]               0
          Dropout-33             [-1, 64, 2048]               0
           Conv1d-34             [-1, 64, 2048]             576
  MyConv1dPadSame-35             [-1, 64, 2048]               0
       Bottleneck-36             [-1, 64, 2048]               0
      BatchNorm1d-37             [-1, 64, 2048]             128
             ReLU-38             [-1, 64, 2048]               0
          Dropout-39             [-1, 64, 2048]               0
           Conv1d-40             [-1, 64, 1024]             576
  MyConv1dPadSame-41             [-1, 64, 1024]               0
      BatchNorm1d-42             [-1, 64, 1024]             128
             ReLU-43             [-1, 64, 1024]               0
          Dropout-44             [-1, 64, 1024]               0
           Conv1d-45             [-1, 64, 1024]             576
  MyConv1dPadSame-46             [-1, 64, 1024]               0
        MaxPool1d-47             [-1, 64, 1024]               0
MyMaxPool1dPadSame-48             [-1, 64, 1024]               0
       Bottleneck-49             [-1, 64, 1024]               0
      BatchNorm1d-50             [-1, 64, 1024]             128
             ReLU-51             [-1, 64, 1024]               0
          Dropout-52             [-1, 64, 1024]               0
           Conv1d-53            [-1, 128, 1024]           1,152
  MyConv1dPadSame-54            [-1, 128, 1024]               0
      BatchNorm1d-55            [-1, 128, 1024]             256
             ReLU-56            [-1, 128, 1024]               0
          Dropout-57            [-1, 128, 1024]               0
           Conv1d-58            [-1, 128, 1024]           2,176
  MyConv1dPadSame-59            [-1, 128, 1024]               0
       Bottleneck-60            [-1, 128, 1024]               0
      BatchNorm1d-61            [-1, 128, 1024]             256
             ReLU-62            [-1, 128, 1024]               0
          Dropout-63            [-1, 128, 1024]               0
           Conv1d-64             [-1, 128, 512]           2,176
  MyConv1dPadSame-65             [-1, 128, 512]               0
      BatchNorm1d-66             [-1, 128, 512]             256
             ReLU-67             [-1, 128, 512]               0
          Dropout-68             [-1, 128, 512]               0
           Conv1d-69             [-1, 128, 512]           2,176
  MyConv1dPadSame-70             [-1, 128, 512]               0
        MaxPool1d-71             [-1, 128, 512]               0
MyMaxPool1dPadSame-72             [-1, 128, 512]               0
       Bottleneck-73             [-1, 128, 512]               0
      BatchNorm1d-74             [-1, 128, 512]             256
             ReLU-75             [-1, 128, 512]               0
          Dropout-76             [-1, 128, 512]               0
           Conv1d-77             [-1, 128, 512]           2,176
  MyConv1dPadSame-78             [-1, 128, 512]               0
      BatchNorm1d-79             [-1, 128, 512]             256
             ReLU-80             [-1, 128, 512]               0
          Dropout-81             [-1, 128, 512]               0
           Conv1d-82             [-1, 128, 512]           2,176
  MyConv1dPadSame-83             [-1, 128, 512]               0
       Bottleneck-84             [-1, 128, 512]               0
      BatchNorm1d-85             [-1, 128, 512]             256
             ReLU-86             [-1, 128, 512]               0
          Dropout-87             [-1, 128, 512]               0
           Conv1d-88             [-1, 128, 256]           2,176
  MyConv1dPadSame-89             [-1, 128, 256]               0
      BatchNorm1d-90             [-1, 128, 256]             256
             ReLU-91             [-1, 128, 256]               0
          Dropout-92             [-1, 128, 256]               0
           Conv1d-93             [-1, 128, 256]           2,176
  MyConv1dPadSame-94             [-1, 128, 256]               0
        MaxPool1d-95             [-1, 128, 256]               0
MyMaxPool1dPadSame-96             [-1, 128, 256]               0
       Bottleneck-97             [-1, 128, 256]               0
      BatchNorm1d-98             [-1, 128, 256]             256
             ReLU-99             [-1, 128, 256]               0
         Dropout-100             [-1, 128, 256]               0
          Conv1d-101             [-1, 256, 256]           4,352
 MyConv1dPadSame-102             [-1, 256, 256]               0
     BatchNorm1d-103             [-1, 256, 256]             512
            ReLU-104             [-1, 256, 256]               0
         Dropout-105             [-1, 256, 256]               0
          Conv1d-106             [-1, 256, 256]           8,448
 MyConv1dPadSame-107             [-1, 256, 256]               0
      Bottleneck-108             [-1, 256, 256]               0
     BatchNorm1d-109             [-1, 256, 256]             512
            ReLU-110             [-1, 256, 256]               0
         Dropout-111             [-1, 256, 256]               0
          Conv1d-112             [-1, 256, 128]           8,448
 MyConv1dPadSame-113             [-1, 256, 128]               0
     BatchNorm1d-114             [-1, 256, 128]             512
            ReLU-115             [-1, 256, 128]               0
         Dropout-116             [-1, 256, 128]               0
          Conv1d-117             [-1, 256, 128]           8,448
 MyConv1dPadSame-118             [-1, 256, 128]               0
       MaxPool1d-119             [-1, 256, 128]               0
MyMaxPool1dPadSame-120             [-1, 256, 128]               0
      Bottleneck-121             [-1, 256, 128]               0
     BatchNorm1d-122             [-1, 256, 128]             512
            ReLU-123             [-1, 256, 128]               0
         Dropout-124             [-1, 256, 128]               0
          Conv1d-125             [-1, 256, 128]           8,448
 MyConv1dPadSame-126             [-1, 256, 128]               0
     BatchNorm1d-127             [-1, 256, 128]             512
            ReLU-128             [-1, 256, 128]               0
         Dropout-129             [-1, 256, 128]               0
          Conv1d-130             [-1, 256, 128]           8,448
 MyConv1dPadSame-131             [-1, 256, 128]               0
      Bottleneck-132             [-1, 256, 128]               0
     BatchNorm1d-133             [-1, 256, 128]             512
            ReLU-134             [-1, 256, 128]               0
         Dropout-135             [-1, 256, 128]               0
          Conv1d-136              [-1, 256, 64]           8,448
 MyConv1dPadSame-137              [-1, 256, 64]               0
     BatchNorm1d-138              [-1, 256, 64]             512
            ReLU-139              [-1, 256, 64]               0
         Dropout-140              [-1, 256, 64]               0
          Conv1d-141              [-1, 256, 64]           8,448
 MyConv1dPadSame-142              [-1, 256, 64]               0
       MaxPool1d-143              [-1, 256, 64]               0
MyMaxPool1dPadSame-144              [-1, 256, 64]               0
      Bottleneck-145              [-1, 256, 64]               0
     BatchNorm1d-146              [-1, 256, 64]             512
            ReLU-147              [-1, 256, 64]               0
         Dropout-148              [-1, 256, 64]               0
          Conv1d-149              [-1, 512, 64]          16,896
 MyConv1dPadSame-150              [-1, 512, 64]               0
     BatchNorm1d-151              [-1, 512, 64]           1,024
            ReLU-152              [-1, 512, 64]               0
         Dropout-153              [-1, 512, 64]               0
          Conv1d-154              [-1, 512, 64]          33,280
 MyConv1dPadSame-155              [-1, 512, 64]               0
      Bottleneck-156              [-1, 512, 64]               0
     BatchNorm1d-157              [-1, 512, 64]           1,024
            ReLU-158              [-1, 512, 64]               0
         Dropout-159              [-1, 512, 64]               0
          Conv1d-160              [-1, 512, 32]          33,280
 MyConv1dPadSame-161              [-1, 512, 32]               0
     BatchNorm1d-162              [-1, 512, 32]           1,024
            ReLU-163              [-1, 512, 32]               0
         Dropout-164              [-1, 512, 32]               0
          Conv1d-165              [-1, 512, 32]          33,280
 MyConv1dPadSame-166              [-1, 512, 32]               0
       MaxPool1d-167              [-1, 512, 32]               0
MyMaxPool1dPadSame-168              [-1, 512, 32]               0
      Bottleneck-169              [-1, 512, 32]               0
     BatchNorm1d-170              [-1, 512, 32]           1,024
            ReLU-171              [-1, 512, 32]               0
         Dropout-172              [-1, 512, 32]               0
          Conv1d-173              [-1, 512, 32]          33,280
 MyConv1dPadSame-174              [-1, 512, 32]               0
     BatchNorm1d-175              [-1, 512, 32]           1,024
            ReLU-176              [-1, 512, 32]               0
         Dropout-177              [-1, 512, 32]               0
          Conv1d-178              [-1, 512, 32]          33,280
 MyConv1dPadSame-179              [-1, 512, 32]               0
      Bottleneck-180              [-1, 512, 32]               0
     BatchNorm1d-181              [-1, 512, 32]           1,024
            ReLU-182              [-1, 512, 32]               0
         Dropout-183              [-1, 512, 32]               0
          Conv1d-184              [-1, 512, 16]          33,280
 MyConv1dPadSame-185              [-1, 512, 16]               0
     BatchNorm1d-186              [-1, 512, 16]           1,024
            ReLU-187              [-1, 512, 16]               0
         Dropout-188              [-1, 512, 16]               0
          Conv1d-189              [-1, 512, 16]          33,280
 MyConv1dPadSame-190              [-1, 512, 16]               0
       MaxPool1d-191              [-1, 512, 16]               0
MyMaxPool1dPadSame-192              [-1, 512, 16]               0
      Bottleneck-193              [-1, 512, 16]               0
     BatchNorm1d-194              [-1, 512, 16]           1,024
            ReLU-195              [-1, 512, 16]               0
          Linear-196                    [-1, 2]           1,026
================================================================
Total params: 351,426
Trainable params: 351,426
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 106.38
Params size (MB): 1.34
Estimated Total Size (MB): 107.73
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 64, kernel_size: 16, n_block: 2
************************************************************
************************************************************
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 64, 4096]           1,088
   MyConv1dPadSame-2             [-1, 64, 4096]               0
       BatchNorm1d-3             [-1, 64, 4096]             128
              ReLU-4             [-1, 64, 4096]               0
            Conv1d-5             [-1, 64, 4096]           1,088
   MyConv1dPadSame-6             [-1, 64, 4096]               0
       BatchNorm1d-7             [-1, 64, 4096]             128
              ReLU-8             [-1, 64, 4096]               0
           Dropout-9             [-1, 64, 4096]               0
           Conv1d-10             [-1, 64, 4096]           1,088
  MyConv1dPadSame-11             [-1, 64, 4096]               0
       Bottleneck-12             [-1, 64, 4096]               0
      BatchNorm1d-13             [-1, 64, 4096]             128
             ReLU-14             [-1, 64, 4096]               0
          Dropout-15             [-1, 64, 4096]               0
           Conv1d-16            [-1, 128, 4096]           2,176
  MyConv1dPadSame-17            [-1, 128, 4096]               0
      BatchNorm1d-18            [-1, 128, 4096]             256
             ReLU-19            [-1, 128, 4096]               0
          Dropout-20            [-1, 128, 4096]               0
           Conv1d-21            [-1, 128, 4096]           4,224
  MyConv1dPadSame-22            [-1, 128, 4096]               0
       Bottleneck-23            [-1, 128, 4096]               0
      BatchNorm1d-24            [-1, 128, 4096]             256
             ReLU-25            [-1, 128, 4096]               0
           Linear-26                    [-1, 2]             258
================================================================
Total params: 10,818
Trainable params: 10,818
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 70.00
Params size (MB): 0.04
Estimated Total Size (MB): 70.06
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 64, kernel_size: 16, n_block: 4
************************************************************
************************************************************
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 64, 4096]           1,088
   MyConv1dPadSame-2             [-1, 64, 4096]               0
       BatchNorm1d-3             [-1, 64, 4096]             128
              ReLU-4             [-1, 64, 4096]               0
            Conv1d-5             [-1, 64, 4096]           1,088
   MyConv1dPadSame-6             [-1, 64, 4096]               0
       BatchNorm1d-7             [-1, 64, 4096]             128
              ReLU-8             [-1, 64, 4096]               0
           Dropout-9             [-1, 64, 4096]               0
           Conv1d-10             [-1, 64, 4096]           1,088
  MyConv1dPadSame-11             [-1, 64, 4096]               0
       Bottleneck-12             [-1, 64, 4096]               0
      BatchNorm1d-13             [-1, 64, 4096]             128
             ReLU-14             [-1, 64, 4096]               0
          Dropout-15             [-1, 64, 4096]               0
           Conv1d-16            [-1, 128, 4096]           2,176
  MyConv1dPadSame-17            [-1, 128, 4096]               0
      BatchNorm1d-18            [-1, 128, 4096]             256
             ReLU-19            [-1, 128, 4096]               0
          Dropout-20            [-1, 128, 4096]               0
           Conv1d-21            [-1, 128, 4096]           4,224
  MyConv1dPadSame-22            [-1, 128, 4096]               0
       Bottleneck-23            [-1, 128, 4096]               0
      BatchNorm1d-24            [-1, 128, 4096]             256
             ReLU-25            [-1, 128, 4096]               0
          Dropout-26            [-1, 128, 4096]               0
           Conv1d-27            [-1, 256, 4096]           8,448
  MyConv1dPadSame-28            [-1, 256, 4096]               0
      BatchNorm1d-29            [-1, 256, 4096]             512
             ReLU-30            [-1, 256, 4096]               0
          Dropout-31            [-1, 256, 4096]               0
           Conv1d-32            [-1, 256, 4096]          16,640
  MyConv1dPadSame-33            [-1, 256, 4096]               0
       Bottleneck-34            [-1, 256, 4096]               0
      BatchNorm1d-35            [-1, 256, 4096]             512
             ReLU-36            [-1, 256, 4096]               0
          Dropout-37            [-1, 256, 4096]               0
           Conv1d-38            [-1, 512, 4096]          33,280
  MyConv1dPadSame-39            [-1, 512, 4096]               0
      BatchNorm1d-40            [-1, 512, 4096]           1,024
             ReLU-41            [-1, 512, 4096]               0
          Dropout-42            [-1, 512, 4096]               0
           Conv1d-43            [-1, 512, 4096]          66,048
  MyConv1dPadSame-44            [-1, 512, 4096]               0
       Bottleneck-45            [-1, 512, 4096]               0
      BatchNorm1d-46            [-1, 512, 4096]           1,024
             ReLU-47            [-1, 512, 4096]               0
           Linear-48                    [-1, 2]           1,026
================================================================
Total params: 139,074
Trainable params: 139,074
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 322.00
Params size (MB): 0.53
Estimated Total Size (MB): 322.55
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 64, kernel_size: 16, n_block: 8
************************************************************
************************************************************
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 64, 4096]           1,088
   MyConv1dPadSame-2             [-1, 64, 4096]               0
       BatchNorm1d-3             [-1, 64, 4096]             128
              ReLU-4             [-1, 64, 4096]               0
            Conv1d-5             [-1, 64, 4096]           1,088
   MyConv1dPadSame-6             [-1, 64, 4096]               0
       BatchNorm1d-7             [-1, 64, 4096]             128
              ReLU-8             [-1, 64, 4096]               0
           Dropout-9             [-1, 64, 4096]               0
           Conv1d-10             [-1, 64, 4096]           1,088
  MyConv1dPadSame-11             [-1, 64, 4096]               0
       Bottleneck-12             [-1, 64, 4096]               0
      BatchNorm1d-13             [-1, 64, 4096]             128
             ReLU-14             [-1, 64, 4096]               0
          Dropout-15             [-1, 64, 4096]               0
           Conv1d-16             [-1, 64, 4096]           1,088
  MyConv1dPadSame-17             [-1, 64, 4096]               0
      BatchNorm1d-18             [-1, 64, 4096]             128
             ReLU-19             [-1, 64, 4096]               0
          Dropout-20             [-1, 64, 4096]               0
           Conv1d-21             [-1, 64, 4096]           1,088
  MyConv1dPadSame-22             [-1, 64, 4096]               0
       Bottleneck-23             [-1, 64, 4096]               0
      BatchNorm1d-24             [-1, 64, 4096]             128
             ReLU-25             [-1, 64, 4096]               0
          Dropout-26             [-1, 64, 4096]               0
           Conv1d-27            [-1, 128, 4096]           2,176
  MyConv1dPadSame-28            [-1, 128, 4096]               0
      BatchNorm1d-29            [-1, 128, 4096]             256
             ReLU-30            [-1, 128, 4096]               0
          Dropout-31            [-1, 128, 4096]               0
           Conv1d-32            [-1, 128, 4096]           4,224
  MyConv1dPadSame-33            [-1, 128, 4096]               0
       Bottleneck-34            [-1, 128, 4096]               0
      BatchNorm1d-35            [-1, 128, 4096]             256
             ReLU-36            [-1, 128, 4096]               0
          Dropout-37            [-1, 128, 4096]               0
           Conv1d-38            [-1, 128, 4096]           4,224
  MyConv1dPadSame-39            [-1, 128, 4096]               0
      BatchNorm1d-40            [-1, 128, 4096]             256
             ReLU-41            [-1, 128, 4096]               0
          Dropout-42            [-1, 128, 4096]               0
           Conv1d-43            [-1, 128, 4096]           4,224
  MyConv1dPadSame-44            [-1, 128, 4096]               0
       Bottleneck-45            [-1, 128, 4096]               0
      BatchNorm1d-46            [-1, 128, 4096]             256
             ReLU-47            [-1, 128, 4096]               0
          Dropout-48            [-1, 128, 4096]               0
           Conv1d-49            [-1, 256, 4096]           8,448
  MyConv1dPadSame-50            [-1, 256, 4096]               0
      BatchNorm1d-51            [-1, 256, 4096]             512
             ReLU-52            [-1, 256, 4096]               0
          Dropout-53            [-1, 256, 4096]               0
           Conv1d-54            [-1, 256, 4096]          16,640
  MyConv1dPadSame-55            [-1, 256, 4096]               0
       Bottleneck-56            [-1, 256, 4096]               0
      BatchNorm1d-57            [-1, 256, 4096]             512
             ReLU-58            [-1, 256, 4096]               0
          Dropout-59            [-1, 256, 4096]               0
           Conv1d-60            [-1, 256, 4096]          16,640
  MyConv1dPadSame-61            [-1, 256, 4096]               0
      BatchNorm1d-62            [-1, 256, 4096]             512
             ReLU-63            [-1, 256, 4096]               0
          Dropout-64            [-1, 256, 4096]               0
           Conv1d-65            [-1, 256, 4096]          16,640
  MyConv1dPadSame-66            [-1, 256, 4096]               0
       Bottleneck-67            [-1, 256, 4096]               0
      BatchNorm1d-68            [-1, 256, 4096]             512
             ReLU-69            [-1, 256, 4096]               0
          Dropout-70            [-1, 256, 4096]               0
           Conv1d-71            [-1, 512, 4096]          33,280
  MyConv1dPadSame-72            [-1, 512, 4096]               0
      BatchNorm1d-73            [-1, 512, 4096]           1,024
             ReLU-74            [-1, 512, 4096]               0
          Dropout-75            [-1, 512, 4096]               0
           Conv1d-76            [-1, 512, 4096]          66,048
  MyConv1dPadSame-77            [-1, 512, 4096]               0
       Bottleneck-78            [-1, 512, 4096]               0
      BatchNorm1d-79            [-1, 512, 4096]           1,024
             ReLU-80            [-1, 512, 4096]               0
          Dropout-81            [-1, 512, 4096]               0
           Conv1d-82            [-1, 512, 4096]          66,048
  MyConv1dPadSame-83            [-1, 512, 4096]               0
      BatchNorm1d-84            [-1, 512, 4096]           1,024
             ReLU-85            [-1, 512, 4096]               0
          Dropout-86            [-1, 512, 4096]               0
           Conv1d-87            [-1, 512, 4096]          66,048
  MyConv1dPadSame-88            [-1, 512, 4096]               0
       Bottleneck-89            [-1, 512, 4096]               0
      BatchNorm1d-90            [-1, 512, 4096]           1,024
             ReLU-91            [-1, 512, 4096]               0
           Linear-92                    [-1, 2]           1,026
================================================================
Total params: 318,914
Trainable params: 318,914
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 652.00
Params size (MB): 1.22
Estimated Total Size (MB): 653.23
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 64, kernel_size: 16, n_block: 16
************************************************************
************************************************************
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1             [-1, 64, 4096]           1,088
   MyConv1dPadSame-2             [-1, 64, 4096]               0
       BatchNorm1d-3             [-1, 64, 4096]             128
              ReLU-4             [-1, 64, 4096]               0
            Conv1d-5             [-1, 64, 4096]           1,088
   MyConv1dPadSame-6             [-1, 64, 4096]               0
       BatchNorm1d-7             [-1, 64, 4096]             128
              ReLU-8             [-1, 64, 4096]               0
           Dropout-9             [-1, 64, 4096]               0
           Conv1d-10             [-1, 64, 4096]           1,088
  MyConv1dPadSame-11             [-1, 64, 4096]               0
       Bottleneck-12             [-1, 64, 4096]               0
      BatchNorm1d-13             [-1, 64, 4096]             128
             ReLU-14             [-1, 64, 4096]               0
          Dropout-15             [-1, 64, 4096]               0
           Conv1d-16             [-1, 64, 2048]           1,088
  MyConv1dPadSame-17             [-1, 64, 2048]               0
      BatchNorm1d-18             [-1, 64, 2048]             128
             ReLU-19             [-1, 64, 2048]               0
          Dropout-20             [-1, 64, 2048]               0
           Conv1d-21             [-1, 64, 2048]           1,088
  MyConv1dPadSame-22             [-1, 64, 2048]               0
        MaxPool1d-23             [-1, 64, 2048]               0
MyMaxPool1dPadSame-24             [-1, 64, 2048]               0
       Bottleneck-25             [-1, 64, 2048]               0
      BatchNorm1d-26             [-1, 64, 2048]             128
             ReLU-27             [-1, 64, 2048]               0
          Dropout-28             [-1, 64, 2048]               0
           Conv1d-29             [-1, 64, 2048]           1,088
  MyConv1dPadSame-30             [-1, 64, 2048]               0
      BatchNorm1d-31             [-1, 64, 2048]             128
             ReLU-32             [-1, 64, 2048]               0
          Dropout-33             [-1, 64, 2048]               0
           Conv1d-34             [-1, 64, 2048]           1,088
  MyConv1dPadSame-35             [-1, 64, 2048]               0
       Bottleneck-36             [-1, 64, 2048]               0
      BatchNorm1d-37             [-1, 64, 2048]             128
             ReLU-38             [-1, 64, 2048]               0
          Dropout-39             [-1, 64, 2048]               0
           Conv1d-40             [-1, 64, 1024]           1,088
  MyConv1dPadSame-41             [-1, 64, 1024]               0
      BatchNorm1d-42             [-1, 64, 1024]             128
             ReLU-43             [-1, 64, 1024]               0
          Dropout-44             [-1, 64, 1024]               0
           Conv1d-45             [-1, 64, 1024]           1,088
  MyConv1dPadSame-46             [-1, 64, 1024]               0
        MaxPool1d-47             [-1, 64, 1024]               0
MyMaxPool1dPadSame-48             [-1, 64, 1024]               0
       Bottleneck-49             [-1, 64, 1024]               0
      BatchNorm1d-50             [-1, 64, 1024]             128
             ReLU-51             [-1, 64, 1024]               0
          Dropout-52             [-1, 64, 1024]               0
           Conv1d-53            [-1, 128, 1024]           2,176
  MyConv1dPadSame-54            [-1, 128, 1024]               0
      BatchNorm1d-55            [-1, 128, 1024]             256
             ReLU-56            [-1, 128, 1024]               0
          Dropout-57            [-1, 128, 1024]               0
           Conv1d-58            [-1, 128, 1024]           4,224
  MyConv1dPadSame-59            [-1, 128, 1024]               0
       Bottleneck-60            [-1, 128, 1024]               0
      BatchNorm1d-61            [-1, 128, 1024]             256
             ReLU-62            [-1, 128, 1024]               0
          Dropout-63            [-1, 128, 1024]               0
           Conv1d-64             [-1, 128, 512]           4,224
  MyConv1dPadSame-65             [-1, 128, 512]               0
      BatchNorm1d-66             [-1, 128, 512]             256
             ReLU-67             [-1, 128, 512]               0
          Dropout-68             [-1, 128, 512]               0
           Conv1d-69             [-1, 128, 512]           4,224
  MyConv1dPadSame-70             [-1, 128, 512]               0
        MaxPool1d-71             [-1, 128, 512]               0
MyMaxPool1dPadSame-72             [-1, 128, 512]               0
       Bottleneck-73             [-1, 128, 512]               0
      BatchNorm1d-74             [-1, 128, 512]             256
             ReLU-75             [-1, 128, 512]               0
          Dropout-76             [-1, 128, 512]               0
           Conv1d-77             [-1, 128, 512]           4,224
  MyConv1dPadSame-78             [-1, 128, 512]               0
      BatchNorm1d-79             [-1, 128, 512]             256
             ReLU-80             [-1, 128, 512]               0
          Dropout-81             [-1, 128, 512]               0
           Conv1d-82             [-1, 128, 512]           4,224
  MyConv1dPadSame-83             [-1, 128, 512]               0
       Bottleneck-84             [-1, 128, 512]               0
      BatchNorm1d-85             [-1, 128, 512]             256
             ReLU-86             [-1, 128, 512]               0
          Dropout-87             [-1, 128, 512]               0
           Conv1d-88             [-1, 128, 256]           4,224
  MyConv1dPadSame-89             [-1, 128, 256]               0
      BatchNorm1d-90             [-1, 128, 256]             256
             ReLU-91             [-1, 128, 256]               0
          Dropout-92             [-1, 128, 256]               0
           Conv1d-93             [-1, 128, 256]           4,224
  MyConv1dPadSame-94             [-1, 128, 256]               0
        MaxPool1d-95             [-1, 128, 256]               0
MyMaxPool1dPadSame-96             [-1, 128, 256]               0
       Bottleneck-97             [-1, 128, 256]               0
      BatchNorm1d-98             [-1, 128, 256]             256
             ReLU-99             [-1, 128, 256]               0
         Dropout-100             [-1, 128, 256]               0
          Conv1d-101             [-1, 256, 256]           8,448
 MyConv1dPadSame-102             [-1, 256, 256]               0
     BatchNorm1d-103             [-1, 256, 256]             512
            ReLU-104             [-1, 256, 256]               0
         Dropout-105             [-1, 256, 256]               0
          Conv1d-106             [-1, 256, 256]          16,640
 MyConv1dPadSame-107             [-1, 256, 256]               0
      Bottleneck-108             [-1, 256, 256]               0
     BatchNorm1d-109             [-1, 256, 256]             512
            ReLU-110             [-1, 256, 256]               0
         Dropout-111             [-1, 256, 256]               0
          Conv1d-112             [-1, 256, 128]          16,640
 MyConv1dPadSame-113             [-1, 256, 128]               0
     BatchNorm1d-114             [-1, 256, 128]             512
            ReLU-115             [-1, 256, 128]               0
         Dropout-116             [-1, 256, 128]               0
          Conv1d-117             [-1, 256, 128]          16,640
 MyConv1dPadSame-118             [-1, 256, 128]               0
       MaxPool1d-119             [-1, 256, 128]               0
MyMaxPool1dPadSame-120             [-1, 256, 128]               0
      Bottleneck-121             [-1, 256, 128]               0
     BatchNorm1d-122             [-1, 256, 128]             512
            ReLU-123             [-1, 256, 128]               0
         Dropout-124             [-1, 256, 128]               0
          Conv1d-125             [-1, 256, 128]          16,640
 MyConv1dPadSame-126             [-1, 256, 128]               0
     BatchNorm1d-127             [-1, 256, 128]             512
            ReLU-128             [-1, 256, 128]               0
         Dropout-129             [-1, 256, 128]               0
          Conv1d-130             [-1, 256, 128]          16,640
 MyConv1dPadSame-131             [-1, 256, 128]               0
      Bottleneck-132             [-1, 256, 128]               0
     BatchNorm1d-133             [-1, 256, 128]             512
            ReLU-134             [-1, 256, 128]               0
         Dropout-135             [-1, 256, 128]               0
          Conv1d-136              [-1, 256, 64]          16,640
 MyConv1dPadSame-137              [-1, 256, 64]               0
     BatchNorm1d-138              [-1, 256, 64]             512
            ReLU-139              [-1, 256, 64]               0
         Dropout-140              [-1, 256, 64]               0
          Conv1d-141              [-1, 256, 64]          16,640
 MyConv1dPadSame-142              [-1, 256, 64]               0
       MaxPool1d-143              [-1, 256, 64]               0
MyMaxPool1dPadSame-144              [-1, 256, 64]               0
      Bottleneck-145              [-1, 256, 64]               0
     BatchNorm1d-146              [-1, 256, 64]             512
            ReLU-147              [-1, 256, 64]               0
         Dropout-148              [-1, 256, 64]               0
          Conv1d-149              [-1, 512, 64]          33,280
 MyConv1dPadSame-150              [-1, 512, 64]               0
     BatchNorm1d-151              [-1, 512, 64]           1,024
            ReLU-152              [-1, 512, 64]               0
         Dropout-153              [-1, 512, 64]               0
          Conv1d-154              [-1, 512, 64]          66,048
 MyConv1dPadSame-155              [-1, 512, 64]               0
      Bottleneck-156              [-1, 512, 64]               0
     BatchNorm1d-157              [-1, 512, 64]           1,024
            ReLU-158              [-1, 512, 64]               0
         Dropout-159              [-1, 512, 64]               0
          Conv1d-160              [-1, 512, 32]          66,048
 MyConv1dPadSame-161              [-1, 512, 32]               0
     BatchNorm1d-162              [-1, 512, 32]           1,024
            ReLU-163              [-1, 512, 32]               0
         Dropout-164              [-1, 512, 32]               0
          Conv1d-165              [-1, 512, 32]          66,048
 MyConv1dPadSame-166              [-1, 512, 32]               0
       MaxPool1d-167              [-1, 512, 32]               0
MyMaxPool1dPadSame-168              [-1, 512, 32]               0
      Bottleneck-169              [-1, 512, 32]               0
     BatchNorm1d-170              [-1, 512, 32]           1,024
            ReLU-171              [-1, 512, 32]               0
         Dropout-172              [-1, 512, 32]               0
          Conv1d-173              [-1, 512, 32]          66,048
 MyConv1dPadSame-174              [-1, 512, 32]               0
     BatchNorm1d-175              [-1, 512, 32]           1,024
            ReLU-176              [-1, 512, 32]               0
         Dropout-177              [-1, 512, 32]               0
          Conv1d-178              [-1, 512, 32]          66,048
 MyConv1dPadSame-179              [-1, 512, 32]               0
      Bottleneck-180              [-1, 512, 32]               0
     BatchNorm1d-181              [-1, 512, 32]           1,024
            ReLU-182              [-1, 512, 32]               0
         Dropout-183              [-1, 512, 32]               0
          Conv1d-184              [-1, 512, 16]          66,048
 MyConv1dPadSame-185              [-1, 512, 16]               0
     BatchNorm1d-186              [-1, 512, 16]           1,024
            ReLU-187              [-1, 512, 16]               0
         Dropout-188              [-1, 512, 16]               0
          Conv1d-189              [-1, 512, 16]          66,048
 MyConv1dPadSame-190              [-1, 512, 16]               0
       MaxPool1d-191              [-1, 512, 16]               0
MyMaxPool1dPadSame-192              [-1, 512, 16]               0
      Bottleneck-193              [-1, 512, 16]               0
     BatchNorm1d-194              [-1, 512, 16]           1,024
            ReLU-195              [-1, 512, 16]               0
          Linear-196                    [-1, 2]           1,026
================================================================
Total params: 678,594
Trainable params: 678,594
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 106.38
Params size (MB): 2.59
Estimated Total Size (MB): 108.98
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 128, kernel_size: 2, n_block: 2
************************************************************
************************************************************
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1            [-1, 128, 4096]             384
   MyConv1dPadSame-2            [-1, 128, 4096]               0
       BatchNorm1d-3            [-1, 128, 4096]             256
              ReLU-4            [-1, 128, 4096]               0
            Conv1d-5            [-1, 128, 4096]             384
   MyConv1dPadSame-6            [-1, 128, 4096]               0
       BatchNorm1d-7            [-1, 128, 4096]             256
              ReLU-8            [-1, 128, 4096]               0
           Dropout-9            [-1, 128, 4096]               0
           Conv1d-10            [-1, 128, 4096]             384
  MyConv1dPadSame-11            [-1, 128, 4096]               0
       Bottleneck-12            [-1, 128, 4096]               0
      BatchNorm1d-13            [-1, 128, 4096]             256
             ReLU-14            [-1, 128, 4096]               0
          Dropout-15            [-1, 128, 4096]               0
           Conv1d-16            [-1, 256, 4096]             768
  MyConv1dPadSame-17            [-1, 256, 4096]               0
      BatchNorm1d-18            [-1, 256, 4096]             512
             ReLU-19            [-1, 256, 4096]               0
          Dropout-20            [-1, 256, 4096]               0
           Conv1d-21            [-1, 256, 4096]           1,280
  MyConv1dPadSame-22            [-1, 256, 4096]               0
       Bottleneck-23            [-1, 256, 4096]               0
      BatchNorm1d-24            [-1, 256, 4096]             512
             ReLU-25            [-1, 256, 4096]               0
           Linear-26                    [-1, 2]             514
================================================================
Total params: 5,506
Trainable params: 5,506
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 140.00
Params size (MB): 0.02
Estimated Total Size (MB): 140.04
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 128, kernel_size: 2, n_block: 4
************************************************************
************************************************************
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1            [-1, 128, 4096]             384
   MyConv1dPadSame-2            [-1, 128, 4096]               0
       BatchNorm1d-3            [-1, 128, 4096]             256
              ReLU-4            [-1, 128, 4096]               0
            Conv1d-5            [-1, 128, 4096]             384
   MyConv1dPadSame-6            [-1, 128, 4096]               0
       BatchNorm1d-7            [-1, 128, 4096]             256
              ReLU-8            [-1, 128, 4096]               0
           Dropout-9            [-1, 128, 4096]               0
           Conv1d-10            [-1, 128, 4096]             384
  MyConv1dPadSame-11            [-1, 128, 4096]               0
       Bottleneck-12            [-1, 128, 4096]               0
      BatchNorm1d-13            [-1, 128, 4096]             256
             ReLU-14            [-1, 128, 4096]               0
          Dropout-15            [-1, 128, 4096]               0
           Conv1d-16            [-1, 256, 4096]             768
  MyConv1dPadSame-17            [-1, 256, 4096]               0
      BatchNorm1d-18            [-1, 256, 4096]             512
             ReLU-19            [-1, 256, 4096]               0
          Dropout-20            [-1, 256, 4096]               0
           Conv1d-21            [-1, 256, 4096]           1,280
  MyConv1dPadSame-22            [-1, 256, 4096]               0
       Bottleneck-23            [-1, 256, 4096]               0
      BatchNorm1d-24            [-1, 256, 4096]             512
             ReLU-25            [-1, 256, 4096]               0
          Dropout-26            [-1, 256, 4096]               0
           Conv1d-27            [-1, 512, 4096]           2,560
  MyConv1dPadSame-28            [-1, 512, 4096]               0
      BatchNorm1d-29            [-1, 512, 4096]           1,024
             ReLU-30            [-1, 512, 4096]               0
          Dropout-31            [-1, 512, 4096]               0
           Conv1d-32            [-1, 512, 4096]           4,608
  MyConv1dPadSame-33            [-1, 512, 4096]               0
       Bottleneck-34            [-1, 512, 4096]               0
      BatchNorm1d-35            [-1, 512, 4096]           1,024
             ReLU-36            [-1, 512, 4096]               0
          Dropout-37            [-1, 512, 4096]               0
           Conv1d-38           [-1, 1024, 4096]           9,216
  MyConv1dPadSame-39           [-1, 1024, 4096]               0
      BatchNorm1d-40           [-1, 1024, 4096]           2,048
             ReLU-41           [-1, 1024, 4096]               0
          Dropout-42           [-1, 1024, 4096]               0
           Conv1d-43           [-1, 1024, 4096]          17,408
  MyConv1dPadSame-44           [-1, 1024, 4096]               0
       Bottleneck-45           [-1, 1024, 4096]               0
      BatchNorm1d-46           [-1, 1024, 4096]           2,048
             ReLU-47           [-1, 1024, 4096]               0
           Linear-48                    [-1, 2]           2,050
================================================================
Total params: 46,978
Trainable params: 46,978
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 644.00
Params size (MB): 0.18
Estimated Total Size (MB): 644.19
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 128, kernel_size: 2, n_block: 8
************************************************************
************************************************************
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1            [-1, 128, 4096]             384
   MyConv1dPadSame-2            [-1, 128, 4096]               0
       BatchNorm1d-3            [-1, 128, 4096]             256
              ReLU-4            [-1, 128, 4096]               0
            Conv1d-5            [-1, 128, 4096]             384
   MyConv1dPadSame-6            [-1, 128, 4096]               0
       BatchNorm1d-7            [-1, 128, 4096]             256
              ReLU-8            [-1, 128, 4096]               0
           Dropout-9            [-1, 128, 4096]               0
           Conv1d-10            [-1, 128, 4096]             384
  MyConv1dPadSame-11            [-1, 128, 4096]               0
       Bottleneck-12            [-1, 128, 4096]               0
      BatchNorm1d-13            [-1, 128, 4096]             256
             ReLU-14            [-1, 128, 4096]               0
          Dropout-15            [-1, 128, 4096]               0
           Conv1d-16            [-1, 128, 4096]             384
  MyConv1dPadSame-17            [-1, 128, 4096]               0
      BatchNorm1d-18            [-1, 128, 4096]             256
             ReLU-19            [-1, 128, 4096]               0
          Dropout-20            [-1, 128, 4096]               0
           Conv1d-21            [-1, 128, 4096]             384
  MyConv1dPadSame-22            [-1, 128, 4096]               0
       Bottleneck-23            [-1, 128, 4096]               0
      BatchNorm1d-24            [-1, 128, 4096]             256
             ReLU-25            [-1, 128, 4096]               0
          Dropout-26            [-1, 128, 4096]               0
           Conv1d-27            [-1, 256, 4096]             768
  MyConv1dPadSame-28            [-1, 256, 4096]               0
      BatchNorm1d-29            [-1, 256, 4096]             512
             ReLU-30            [-1, 256, 4096]               0
          Dropout-31            [-1, 256, 4096]               0
           Conv1d-32            [-1, 256, 4096]           1,280
  MyConv1dPadSame-33            [-1, 256, 4096]               0
       Bottleneck-34            [-1, 256, 4096]               0
      BatchNorm1d-35            [-1, 256, 4096]             512
             ReLU-36            [-1, 256, 4096]               0
          Dropout-37            [-1, 256, 4096]               0
           Conv1d-38            [-1, 256, 4096]           1,280
  MyConv1dPadSame-39            [-1, 256, 4096]               0
      BatchNorm1d-40            [-1, 256, 4096]             512
             ReLU-41            [-1, 256, 4096]               0
          Dropout-42            [-1, 256, 4096]               0
           Conv1d-43            [-1, 256, 4096]           1,280
  MyConv1dPadSame-44            [-1, 256, 4096]               0
       Bottleneck-45            [-1, 256, 4096]               0
      BatchNorm1d-46            [-1, 256, 4096]             512
             ReLU-47            [-1, 256, 4096]               0
          Dropout-48            [-1, 256, 4096]               0
           Conv1d-49            [-1, 512, 4096]           2,560
  MyConv1dPadSame-50            [-1, 512, 4096]               0
      BatchNorm1d-51            [-1, 512, 4096]           1,024
             ReLU-52            [-1, 512, 4096]               0
          Dropout-53            [-1, 512, 4096]               0
           Conv1d-54            [-1, 512, 4096]           4,608
  MyConv1dPadSame-55            [-1, 512, 4096]               0
       Bottleneck-56            [-1, 512, 4096]               0
      BatchNorm1d-57            [-1, 512, 4096]           1,024
             ReLU-58            [-1, 512, 4096]               0
          Dropout-59            [-1, 512, 4096]               0
           Conv1d-60            [-1, 512, 4096]           4,608
  MyConv1dPadSame-61            [-1, 512, 4096]               0
      BatchNorm1d-62            [-1, 512, 4096]           1,024
             ReLU-63            [-1, 512, 4096]               0
          Dropout-64            [-1, 512, 4096]               0
           Conv1d-65            [-1, 512, 4096]           4,608
  MyConv1dPadSame-66            [-1, 512, 4096]               0
       Bottleneck-67            [-1, 512, 4096]               0
      BatchNorm1d-68            [-1, 512, 4096]           1,024
             ReLU-69            [-1, 512, 4096]               0
          Dropout-70            [-1, 512, 4096]               0
           Conv1d-71           [-1, 1024, 4096]           9,216
  MyConv1dPadSame-72           [-1, 1024, 4096]               0
      BatchNorm1d-73           [-1, 1024, 4096]           2,048
             ReLU-74           [-1, 1024, 4096]               0
          Dropout-75           [-1, 1024, 4096]               0
           Conv1d-76           [-1, 1024, 4096]          17,408
  MyConv1dPadSame-77           [-1, 1024, 4096]               0
       Bottleneck-78           [-1, 1024, 4096]               0
      BatchNorm1d-79           [-1, 1024, 4096]           2,048
             ReLU-80           [-1, 1024, 4096]               0
          Dropout-81           [-1, 1024, 4096]               0
           Conv1d-82           [-1, 1024, 4096]          17,408
  MyConv1dPadSame-83           [-1, 1024, 4096]               0
      BatchNorm1d-84           [-1, 1024, 4096]           2,048
             ReLU-85           [-1, 1024, 4096]               0
          Dropout-86           [-1, 1024, 4096]               0
           Conv1d-87           [-1, 1024, 4096]          17,408
  MyConv1dPadSame-88           [-1, 1024, 4096]               0
       Bottleneck-89           [-1, 1024, 4096]               0
      BatchNorm1d-90           [-1, 1024, 4096]           2,048
             ReLU-91           [-1, 1024, 4096]               0
           Linear-92                    [-1, 2]           2,050
================================================================
Total params: 102,018
Trainable params: 102,018
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 1304.00
Params size (MB): 0.39
Estimated Total Size (MB): 1304.40
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 128, kernel_size: 2, n_block: 16
************************************************************
************************************************************
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1            [-1, 128, 4096]             384
   MyConv1dPadSame-2            [-1, 128, 4096]               0
       BatchNorm1d-3            [-1, 128, 4096]             256
              ReLU-4            [-1, 128, 4096]               0
            Conv1d-5            [-1, 128, 4096]             384
   MyConv1dPadSame-6            [-1, 128, 4096]               0
       BatchNorm1d-7            [-1, 128, 4096]             256
              ReLU-8            [-1, 128, 4096]               0
           Dropout-9            [-1, 128, 4096]               0
           Conv1d-10            [-1, 128, 4096]             384
  MyConv1dPadSame-11            [-1, 128, 4096]               0
       Bottleneck-12            [-1, 128, 4096]               0
      BatchNorm1d-13            [-1, 128, 4096]             256
             ReLU-14            [-1, 128, 4096]               0
          Dropout-15            [-1, 128, 4096]               0
           Conv1d-16            [-1, 128, 2048]             384
  MyConv1dPadSame-17            [-1, 128, 2048]               0
      BatchNorm1d-18            [-1, 128, 2048]             256
             ReLU-19            [-1, 128, 2048]               0
          Dropout-20            [-1, 128, 2048]               0
           Conv1d-21            [-1, 128, 2048]             384
  MyConv1dPadSame-22            [-1, 128, 2048]               0
        MaxPool1d-23            [-1, 128, 2048]               0
MyMaxPool1dPadSame-24            [-1, 128, 2048]               0
       Bottleneck-25            [-1, 128, 2048]               0
      BatchNorm1d-26            [-1, 128, 2048]             256
             ReLU-27            [-1, 128, 2048]               0
          Dropout-28            [-1, 128, 2048]               0
           Conv1d-29            [-1, 128, 2048]             384
  MyConv1dPadSame-30            [-1, 128, 2048]               0
      BatchNorm1d-31            [-1, 128, 2048]             256
             ReLU-32            [-1, 128, 2048]               0
          Dropout-33            [-1, 128, 2048]               0
           Conv1d-34            [-1, 128, 2048]             384
  MyConv1dPadSame-35            [-1, 128, 2048]               0
       Bottleneck-36            [-1, 128, 2048]               0
      BatchNorm1d-37            [-1, 128, 2048]             256
             ReLU-38            [-1, 128, 2048]               0
          Dropout-39            [-1, 128, 2048]               0
           Conv1d-40            [-1, 128, 1024]             384
  MyConv1dPadSame-41            [-1, 128, 1024]               0
      BatchNorm1d-42            [-1, 128, 1024]             256
             ReLU-43            [-1, 128, 1024]               0
          Dropout-44            [-1, 128, 1024]               0
           Conv1d-45            [-1, 128, 1024]             384
  MyConv1dPadSame-46            [-1, 128, 1024]               0
        MaxPool1d-47            [-1, 128, 1024]               0
MyMaxPool1dPadSame-48            [-1, 128, 1024]               0
       Bottleneck-49            [-1, 128, 1024]               0
      BatchNorm1d-50            [-1, 128, 1024]             256
             ReLU-51            [-1, 128, 1024]               0
          Dropout-52            [-1, 128, 1024]               0
           Conv1d-53            [-1, 256, 1024]             768
  MyConv1dPadSame-54            [-1, 256, 1024]               0
      BatchNorm1d-55            [-1, 256, 1024]             512
             ReLU-56            [-1, 256, 1024]               0
          Dropout-57            [-1, 256, 1024]               0
           Conv1d-58            [-1, 256, 1024]           1,280
  MyConv1dPadSame-59            [-1, 256, 1024]               0
       Bottleneck-60            [-1, 256, 1024]               0
      BatchNorm1d-61            [-1, 256, 1024]             512
             ReLU-62            [-1, 256, 1024]               0
          Dropout-63            [-1, 256, 1024]               0
           Conv1d-64             [-1, 256, 512]           1,280
  MyConv1dPadSame-65             [-1, 256, 512]               0
      BatchNorm1d-66             [-1, 256, 512]             512
             ReLU-67             [-1, 256, 512]               0
          Dropout-68             [-1, 256, 512]               0
           Conv1d-69             [-1, 256, 512]           1,280
  MyConv1dPadSame-70             [-1, 256, 512]               0
        MaxPool1d-71             [-1, 256, 512]               0
MyMaxPool1dPadSame-72             [-1, 256, 512]               0
       Bottleneck-73             [-1, 256, 512]               0
      BatchNorm1d-74             [-1, 256, 512]             512
             ReLU-75             [-1, 256, 512]               0
          Dropout-76             [-1, 256, 512]               0
           Conv1d-77             [-1, 256, 512]           1,280
  MyConv1dPadSame-78             [-1, 256, 512]               0
      BatchNorm1d-79             [-1, 256, 512]             512
             ReLU-80             [-1, 256, 512]               0
          Dropout-81             [-1, 256, 512]               0
           Conv1d-82             [-1, 256, 512]           1,280
  MyConv1dPadSame-83             [-1, 256, 512]               0
       Bottleneck-84             [-1, 256, 512]               0
      BatchNorm1d-85             [-1, 256, 512]             512
             ReLU-86             [-1, 256, 512]               0
          Dropout-87             [-1, 256, 512]               0
           Conv1d-88             [-1, 256, 256]           1,280
  MyConv1dPadSame-89             [-1, 256, 256]               0
      BatchNorm1d-90             [-1, 256, 256]             512
             ReLU-91             [-1, 256, 256]               0
          Dropout-92             [-1, 256, 256]               0
           Conv1d-93             [-1, 256, 256]           1,280
  MyConv1dPadSame-94             [-1, 256, 256]               0
        MaxPool1d-95             [-1, 256, 256]               0
MyMaxPool1dPadSame-96             [-1, 256, 256]               0
       Bottleneck-97             [-1, 256, 256]               0
      BatchNorm1d-98             [-1, 256, 256]             512
             ReLU-99             [-1, 256, 256]               0
         Dropout-100             [-1, 256, 256]               0
          Conv1d-101             [-1, 512, 256]           2,560
 MyConv1dPadSame-102             [-1, 512, 256]               0
     BatchNorm1d-103             [-1, 512, 256]           1,024
            ReLU-104             [-1, 512, 256]               0
         Dropout-105             [-1, 512, 256]               0
          Conv1d-106             [-1, 512, 256]           4,608
 MyConv1dPadSame-107             [-1, 512, 256]               0
      Bottleneck-108             [-1, 512, 256]               0
     BatchNorm1d-109             [-1, 512, 256]           1,024
            ReLU-110             [-1, 512, 256]               0
         Dropout-111             [-1, 512, 256]               0
          Conv1d-112             [-1, 512, 128]           4,608
 MyConv1dPadSame-113             [-1, 512, 128]               0
     BatchNorm1d-114             [-1, 512, 128]           1,024
            ReLU-115             [-1, 512, 128]               0
         Dropout-116             [-1, 512, 128]               0
          Conv1d-117             [-1, 512, 128]           4,608
 MyConv1dPadSame-118             [-1, 512, 128]               0
       MaxPool1d-119             [-1, 512, 128]               0
MyMaxPool1dPadSame-120             [-1, 512, 128]               0
      Bottleneck-121             [-1, 512, 128]               0
     BatchNorm1d-122             [-1, 512, 128]           1,024
            ReLU-123             [-1, 512, 128]               0
         Dropout-124             [-1, 512, 128]               0
          Conv1d-125             [-1, 512, 128]           4,608
 MyConv1dPadSame-126             [-1, 512, 128]               0
     BatchNorm1d-127             [-1, 512, 128]           1,024
            ReLU-128             [-1, 512, 128]               0
         Dropout-129             [-1, 512, 128]               0
          Conv1d-130             [-1, 512, 128]           4,608
 MyConv1dPadSame-131             [-1, 512, 128]               0
      Bottleneck-132             [-1, 512, 128]               0
     BatchNorm1d-133             [-1, 512, 128]           1,024
            ReLU-134             [-1, 512, 128]               0
         Dropout-135             [-1, 512, 128]               0
          Conv1d-136              [-1, 512, 64]           4,608
 MyConv1dPadSame-137              [-1, 512, 64]               0
     BatchNorm1d-138              [-1, 512, 64]           1,024
            ReLU-139              [-1, 512, 64]               0
         Dropout-140              [-1, 512, 64]               0
          Conv1d-141              [-1, 512, 64]           4,608
 MyConv1dPadSame-142              [-1, 512, 64]               0
       MaxPool1d-143              [-1, 512, 64]               0
MyMaxPool1dPadSame-144              [-1, 512, 64]               0
      Bottleneck-145              [-1, 512, 64]               0
     BatchNorm1d-146              [-1, 512, 64]           1,024
            ReLU-147              [-1, 512, 64]               0
         Dropout-148              [-1, 512, 64]               0
          Conv1d-149             [-1, 1024, 64]           9,216
 MyConv1dPadSame-150             [-1, 1024, 64]               0
     BatchNorm1d-151             [-1, 1024, 64]           2,048
            ReLU-152             [-1, 1024, 64]               0
         Dropout-153             [-1, 1024, 64]               0
          Conv1d-154             [-1, 1024, 64]          17,408
 MyConv1dPadSame-155             [-1, 1024, 64]               0
      Bottleneck-156             [-1, 1024, 64]               0
     BatchNorm1d-157             [-1, 1024, 64]           2,048
            ReLU-158             [-1, 1024, 64]               0
         Dropout-159             [-1, 1024, 64]               0
          Conv1d-160             [-1, 1024, 32]          17,408
 MyConv1dPadSame-161             [-1, 1024, 32]               0
     BatchNorm1d-162             [-1, 1024, 32]           2,048
            ReLU-163             [-1, 1024, 32]               0
         Dropout-164             [-1, 1024, 32]               0
          Conv1d-165             [-1, 1024, 32]          17,408
 MyConv1dPadSame-166             [-1, 1024, 32]               0
       MaxPool1d-167             [-1, 1024, 32]               0
MyMaxPool1dPadSame-168             [-1, 1024, 32]               0
      Bottleneck-169             [-1, 1024, 32]               0
     BatchNorm1d-170             [-1, 1024, 32]           2,048
            ReLU-171             [-1, 1024, 32]               0
         Dropout-172             [-1, 1024, 32]               0
          Conv1d-173             [-1, 1024, 32]          17,408
 MyConv1dPadSame-174             [-1, 1024, 32]               0
     BatchNorm1d-175             [-1, 1024, 32]           2,048
            ReLU-176             [-1, 1024, 32]               0
         Dropout-177             [-1, 1024, 32]               0
          Conv1d-178             [-1, 1024, 32]          17,408
 MyConv1dPadSame-179             [-1, 1024, 32]               0
      Bottleneck-180             [-1, 1024, 32]               0
     BatchNorm1d-181             [-1, 1024, 32]           2,048
            ReLU-182             [-1, 1024, 32]               0
         Dropout-183             [-1, 1024, 32]               0
          Conv1d-184             [-1, 1024, 16]          17,408
 MyConv1dPadSame-185             [-1, 1024, 16]               0
     BatchNorm1d-186             [-1, 1024, 16]           2,048
            ReLU-187             [-1, 1024, 16]               0
         Dropout-188             [-1, 1024, 16]               0
          Conv1d-189             [-1, 1024, 16]          17,408
 MyConv1dPadSame-190             [-1, 1024, 16]               0
       MaxPool1d-191             [-1, 1024, 16]               0
MyMaxPool1dPadSame-192             [-1, 1024, 16]               0
      Bottleneck-193             [-1, 1024, 16]               0
     BatchNorm1d-194             [-1, 1024, 16]           2,048
            ReLU-195             [-1, 1024, 16]               0
          Linear-196                    [-1, 2]           2,050
================================================================
Total params: 212,098
Trainable params: 212,098
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 212.75
Params size (MB): 0.81
Estimated Total Size (MB): 213.57
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 128, kernel_size: 4, n_block: 2
************************************************************
************************************************************
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1            [-1, 128, 4096]             640
   MyConv1dPadSame-2            [-1, 128, 4096]               0
       BatchNorm1d-3            [-1, 128, 4096]             256
              ReLU-4            [-1, 128, 4096]               0
            Conv1d-5            [-1, 128, 4096]             640
   MyConv1dPadSame-6            [-1, 128, 4096]               0
       BatchNorm1d-7            [-1, 128, 4096]             256
              ReLU-8            [-1, 128, 4096]               0
           Dropout-9            [-1, 128, 4096]               0
           Conv1d-10            [-1, 128, 4096]             640
  MyConv1dPadSame-11            [-1, 128, 4096]               0
       Bottleneck-12            [-1, 128, 4096]               0
      BatchNorm1d-13            [-1, 128, 4096]             256
             ReLU-14            [-1, 128, 4096]               0
          Dropout-15            [-1, 128, 4096]               0
           Conv1d-16            [-1, 256, 4096]           1,280
  MyConv1dPadSame-17            [-1, 256, 4096]               0
      BatchNorm1d-18            [-1, 256, 4096]             512
             ReLU-19            [-1, 256, 4096]               0
          Dropout-20            [-1, 256, 4096]               0
           Conv1d-21            [-1, 256, 4096]           2,304
  MyConv1dPadSame-22            [-1, 256, 4096]               0
       Bottleneck-23            [-1, 256, 4096]               0
      BatchNorm1d-24            [-1, 256, 4096]             512
             ReLU-25            [-1, 256, 4096]               0
           Linear-26                    [-1, 2]             514
================================================================
Total params: 7,810
Trainable params: 7,810
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 140.00
Params size (MB): 0.03
Estimated Total Size (MB): 140.05
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 128, kernel_size: 4, n_block: 4
************************************************************
************************************************************
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1            [-1, 128, 4096]             640
   MyConv1dPadSame-2            [-1, 128, 4096]               0
       BatchNorm1d-3            [-1, 128, 4096]             256
              ReLU-4            [-1, 128, 4096]               0
            Conv1d-5            [-1, 128, 4096]             640
   MyConv1dPadSame-6            [-1, 128, 4096]               0
       BatchNorm1d-7            [-1, 128, 4096]             256
              ReLU-8            [-1, 128, 4096]               0
           Dropout-9            [-1, 128, 4096]               0
           Conv1d-10            [-1, 128, 4096]             640
  MyConv1dPadSame-11            [-1, 128, 4096]               0
       Bottleneck-12            [-1, 128, 4096]               0
      BatchNorm1d-13            [-1, 128, 4096]             256
             ReLU-14            [-1, 128, 4096]               0
          Dropout-15            [-1, 128, 4096]               0
           Conv1d-16            [-1, 256, 4096]           1,280
  MyConv1dPadSame-17            [-1, 256, 4096]               0
      BatchNorm1d-18            [-1, 256, 4096]             512
             ReLU-19            [-1, 256, 4096]               0
          Dropout-20            [-1, 256, 4096]               0
           Conv1d-21            [-1, 256, 4096]           2,304
  MyConv1dPadSame-22            [-1, 256, 4096]               0
       Bottleneck-23            [-1, 256, 4096]               0
      BatchNorm1d-24            [-1, 256, 4096]             512
             ReLU-25            [-1, 256, 4096]               0
          Dropout-26            [-1, 256, 4096]               0
           Conv1d-27            [-1, 512, 4096]           4,608
  MyConv1dPadSame-28            [-1, 512, 4096]               0
      BatchNorm1d-29            [-1, 512, 4096]           1,024
             ReLU-30            [-1, 512, 4096]               0
          Dropout-31            [-1, 512, 4096]               0
           Conv1d-32            [-1, 512, 4096]           8,704
  MyConv1dPadSame-33            [-1, 512, 4096]               0
       Bottleneck-34            [-1, 512, 4096]               0
      BatchNorm1d-35            [-1, 512, 4096]           1,024
             ReLU-36            [-1, 512, 4096]               0
          Dropout-37            [-1, 512, 4096]               0
           Conv1d-38           [-1, 1024, 4096]          17,408
  MyConv1dPadSame-39           [-1, 1024, 4096]               0
      BatchNorm1d-40           [-1, 1024, 4096]           2,048
             ReLU-41           [-1, 1024, 4096]               0
          Dropout-42           [-1, 1024, 4096]               0
           Conv1d-43           [-1, 1024, 4096]          33,792
  MyConv1dPadSame-44           [-1, 1024, 4096]               0
       Bottleneck-45           [-1, 1024, 4096]               0
      BatchNorm1d-46           [-1, 1024, 4096]           2,048
             ReLU-47           [-1, 1024, 4096]               0
           Linear-48                    [-1, 2]           2,050
================================================================
Total params: 80,002
Trainable params: 80,002
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 644.00
Params size (MB): 0.31
Estimated Total Size (MB): 644.32
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 128, kernel_size: 4, n_block: 8
************************************************************
************************************************************
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1            [-1, 128, 4096]             640
   MyConv1dPadSame-2            [-1, 128, 4096]               0
       BatchNorm1d-3            [-1, 128, 4096]             256
              ReLU-4            [-1, 128, 4096]               0
            Conv1d-5            [-1, 128, 4096]             640
   MyConv1dPadSame-6            [-1, 128, 4096]               0
       BatchNorm1d-7            [-1, 128, 4096]             256
              ReLU-8            [-1, 128, 4096]               0
           Dropout-9            [-1, 128, 4096]               0
           Conv1d-10            [-1, 128, 4096]             640
  MyConv1dPadSame-11            [-1, 128, 4096]               0
       Bottleneck-12            [-1, 128, 4096]               0
      BatchNorm1d-13            [-1, 128, 4096]             256
             ReLU-14            [-1, 128, 4096]               0
          Dropout-15            [-1, 128, 4096]               0
           Conv1d-16            [-1, 128, 4096]             640
  MyConv1dPadSame-17            [-1, 128, 4096]               0
      BatchNorm1d-18            [-1, 128, 4096]             256
             ReLU-19            [-1, 128, 4096]               0
          Dropout-20            [-1, 128, 4096]               0
           Conv1d-21            [-1, 128, 4096]             640
  MyConv1dPadSame-22            [-1, 128, 4096]               0
       Bottleneck-23            [-1, 128, 4096]               0
      BatchNorm1d-24            [-1, 128, 4096]             256
             ReLU-25            [-1, 128, 4096]               0
          Dropout-26            [-1, 128, 4096]               0
           Conv1d-27            [-1, 256, 4096]           1,280
  MyConv1dPadSame-28            [-1, 256, 4096]               0
      BatchNorm1d-29            [-1, 256, 4096]             512
             ReLU-30            [-1, 256, 4096]               0
          Dropout-31            [-1, 256, 4096]               0
           Conv1d-32            [-1, 256, 4096]           2,304
  MyConv1dPadSame-33            [-1, 256, 4096]               0
       Bottleneck-34            [-1, 256, 4096]               0
      BatchNorm1d-35            [-1, 256, 4096]             512
             ReLU-36            [-1, 256, 4096]               0
          Dropout-37            [-1, 256, 4096]               0
           Conv1d-38            [-1, 256, 4096]           2,304
  MyConv1dPadSame-39            [-1, 256, 4096]               0
      BatchNorm1d-40            [-1, 256, 4096]             512
             ReLU-41            [-1, 256, 4096]               0
          Dropout-42            [-1, 256, 4096]               0
           Conv1d-43            [-1, 256, 4096]           2,304
  MyConv1dPadSame-44            [-1, 256, 4096]               0
       Bottleneck-45            [-1, 256, 4096]               0
      BatchNorm1d-46            [-1, 256, 4096]             512
             ReLU-47            [-1, 256, 4096]               0
          Dropout-48            [-1, 256, 4096]               0
           Conv1d-49            [-1, 512, 4096]           4,608
  MyConv1dPadSame-50            [-1, 512, 4096]               0
      BatchNorm1d-51            [-1, 512, 4096]           1,024
             ReLU-52            [-1, 512, 4096]               0
          Dropout-53            [-1, 512, 4096]               0
           Conv1d-54            [-1, 512, 4096]           8,704
  MyConv1dPadSame-55            [-1, 512, 4096]               0
       Bottleneck-56            [-1, 512, 4096]               0
      BatchNorm1d-57            [-1, 512, 4096]           1,024
             ReLU-58            [-1, 512, 4096]               0
          Dropout-59            [-1, 512, 4096]               0
           Conv1d-60            [-1, 512, 4096]           8,704
  MyConv1dPadSame-61            [-1, 512, 4096]               0
      BatchNorm1d-62            [-1, 512, 4096]           1,024
             ReLU-63            [-1, 512, 4096]               0
          Dropout-64            [-1, 512, 4096]               0
           Conv1d-65            [-1, 512, 4096]           8,704
  MyConv1dPadSame-66            [-1, 512, 4096]               0
       Bottleneck-67            [-1, 512, 4096]               0
      BatchNorm1d-68            [-1, 512, 4096]           1,024
             ReLU-69            [-1, 512, 4096]               0
          Dropout-70            [-1, 512, 4096]               0
           Conv1d-71           [-1, 1024, 4096]          17,408
  MyConv1dPadSame-72           [-1, 1024, 4096]               0
      BatchNorm1d-73           [-1, 1024, 4096]           2,048
             ReLU-74           [-1, 1024, 4096]               0
          Dropout-75           [-1, 1024, 4096]               0
           Conv1d-76           [-1, 1024, 4096]          33,792
  MyConv1dPadSame-77           [-1, 1024, 4096]               0
       Bottleneck-78           [-1, 1024, 4096]               0
      BatchNorm1d-79           [-1, 1024, 4096]           2,048
             ReLU-80           [-1, 1024, 4096]               0
          Dropout-81           [-1, 1024, 4096]               0
           Conv1d-82           [-1, 1024, 4096]          33,792
  MyConv1dPadSame-83           [-1, 1024, 4096]               0
      BatchNorm1d-84           [-1, 1024, 4096]           2,048
             ReLU-85           [-1, 1024, 4096]               0
          Dropout-86           [-1, 1024, 4096]               0
           Conv1d-87           [-1, 1024, 4096]          33,792
  MyConv1dPadSame-88           [-1, 1024, 4096]               0
       Bottleneck-89           [-1, 1024, 4096]               0
      BatchNorm1d-90           [-1, 1024, 4096]           2,048
             ReLU-91           [-1, 1024, 4096]               0
           Linear-92                    [-1, 2]           2,050
================================================================
Total params: 178,562
Trainable params: 178,562
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 1304.00
Params size (MB): 0.68
Estimated Total Size (MB): 1304.70
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 128, kernel_size: 4, n_block: 16
************************************************************
************************************************************
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1            [-1, 128, 4096]             640
   MyConv1dPadSame-2            [-1, 128, 4096]               0
       BatchNorm1d-3            [-1, 128, 4096]             256
              ReLU-4            [-1, 128, 4096]               0
            Conv1d-5            [-1, 128, 4096]             640
   MyConv1dPadSame-6            [-1, 128, 4096]               0
       BatchNorm1d-7            [-1, 128, 4096]             256
              ReLU-8            [-1, 128, 4096]               0
           Dropout-9            [-1, 128, 4096]               0
           Conv1d-10            [-1, 128, 4096]             640
  MyConv1dPadSame-11            [-1, 128, 4096]               0
       Bottleneck-12            [-1, 128, 4096]               0
      BatchNorm1d-13            [-1, 128, 4096]             256
             ReLU-14            [-1, 128, 4096]               0
          Dropout-15            [-1, 128, 4096]               0
           Conv1d-16            [-1, 128, 2048]             640
  MyConv1dPadSame-17            [-1, 128, 2048]               0
      BatchNorm1d-18            [-1, 128, 2048]             256
             ReLU-19            [-1, 128, 2048]               0
          Dropout-20            [-1, 128, 2048]               0
           Conv1d-21            [-1, 128, 2048]             640
  MyConv1dPadSame-22            [-1, 128, 2048]               0
        MaxPool1d-23            [-1, 128, 2048]               0
MyMaxPool1dPadSame-24            [-1, 128, 2048]               0
       Bottleneck-25            [-1, 128, 2048]               0
      BatchNorm1d-26            [-1, 128, 2048]             256
             ReLU-27            [-1, 128, 2048]               0
          Dropout-28            [-1, 128, 2048]               0
           Conv1d-29            [-1, 128, 2048]             640
  MyConv1dPadSame-30            [-1, 128, 2048]               0
      BatchNorm1d-31            [-1, 128, 2048]             256
             ReLU-32            [-1, 128, 2048]               0
          Dropout-33            [-1, 128, 2048]               0
           Conv1d-34            [-1, 128, 2048]             640
  MyConv1dPadSame-35            [-1, 128, 2048]               0
       Bottleneck-36            [-1, 128, 2048]               0
      BatchNorm1d-37            [-1, 128, 2048]             256
             ReLU-38            [-1, 128, 2048]               0
          Dropout-39            [-1, 128, 2048]               0
           Conv1d-40            [-1, 128, 1024]             640
  MyConv1dPadSame-41            [-1, 128, 1024]               0
      BatchNorm1d-42            [-1, 128, 1024]             256
             ReLU-43            [-1, 128, 1024]               0
          Dropout-44            [-1, 128, 1024]               0
           Conv1d-45            [-1, 128, 1024]             640
  MyConv1dPadSame-46            [-1, 128, 1024]               0
        MaxPool1d-47            [-1, 128, 1024]               0
MyMaxPool1dPadSame-48            [-1, 128, 1024]               0
       Bottleneck-49            [-1, 128, 1024]               0
      BatchNorm1d-50            [-1, 128, 1024]             256
             ReLU-51            [-1, 128, 1024]               0
          Dropout-52            [-1, 128, 1024]               0
           Conv1d-53            [-1, 256, 1024]           1,280
  MyConv1dPadSame-54            [-1, 256, 1024]               0
      BatchNorm1d-55            [-1, 256, 1024]             512
             ReLU-56            [-1, 256, 1024]               0
          Dropout-57            [-1, 256, 1024]               0
           Conv1d-58            [-1, 256, 1024]           2,304
  MyConv1dPadSame-59            [-1, 256, 1024]               0
       Bottleneck-60            [-1, 256, 1024]               0
      BatchNorm1d-61            [-1, 256, 1024]             512
             ReLU-62            [-1, 256, 1024]               0
          Dropout-63            [-1, 256, 1024]               0
           Conv1d-64             [-1, 256, 512]           2,304
  MyConv1dPadSame-65             [-1, 256, 512]               0
      BatchNorm1d-66             [-1, 256, 512]             512
             ReLU-67             [-1, 256, 512]               0
          Dropout-68             [-1, 256, 512]               0
           Conv1d-69             [-1, 256, 512]           2,304
  MyConv1dPadSame-70             [-1, 256, 512]               0
        MaxPool1d-71             [-1, 256, 512]               0
MyMaxPool1dPadSame-72             [-1, 256, 512]               0
       Bottleneck-73             [-1, 256, 512]               0
      BatchNorm1d-74             [-1, 256, 512]             512
             ReLU-75             [-1, 256, 512]               0
          Dropout-76             [-1, 256, 512]               0
           Conv1d-77             [-1, 256, 512]           2,304
  MyConv1dPadSame-78             [-1, 256, 512]               0
      BatchNorm1d-79             [-1, 256, 512]             512
             ReLU-80             [-1, 256, 512]               0
          Dropout-81             [-1, 256, 512]               0
           Conv1d-82             [-1, 256, 512]           2,304
  MyConv1dPadSame-83             [-1, 256, 512]               0
       Bottleneck-84             [-1, 256, 512]               0
      BatchNorm1d-85             [-1, 256, 512]             512
             ReLU-86             [-1, 256, 512]               0
          Dropout-87             [-1, 256, 512]               0
           Conv1d-88             [-1, 256, 256]           2,304
  MyConv1dPadSame-89             [-1, 256, 256]               0
      BatchNorm1d-90             [-1, 256, 256]             512
             ReLU-91             [-1, 256, 256]               0
          Dropout-92             [-1, 256, 256]               0
           Conv1d-93             [-1, 256, 256]           2,304
  MyConv1dPadSame-94             [-1, 256, 256]               0
        MaxPool1d-95             [-1, 256, 256]               0
MyMaxPool1dPadSame-96             [-1, 256, 256]               0
       Bottleneck-97             [-1, 256, 256]               0
      BatchNorm1d-98             [-1, 256, 256]             512
             ReLU-99             [-1, 256, 256]               0
         Dropout-100             [-1, 256, 256]               0
          Conv1d-101             [-1, 512, 256]           4,608
 MyConv1dPadSame-102             [-1, 512, 256]               0
     BatchNorm1d-103             [-1, 512, 256]           1,024
            ReLU-104             [-1, 512, 256]               0
         Dropout-105             [-1, 512, 256]               0
          Conv1d-106             [-1, 512, 256]           8,704
 MyConv1dPadSame-107             [-1, 512, 256]               0
      Bottleneck-108             [-1, 512, 256]               0
     BatchNorm1d-109             [-1, 512, 256]           1,024
            ReLU-110             [-1, 512, 256]               0
         Dropout-111             [-1, 512, 256]               0
          Conv1d-112             [-1, 512, 128]           8,704
 MyConv1dPadSame-113             [-1, 512, 128]               0
     BatchNorm1d-114             [-1, 512, 128]           1,024
            ReLU-115             [-1, 512, 128]               0
         Dropout-116             [-1, 512, 128]               0
          Conv1d-117             [-1, 512, 128]           8,704
 MyConv1dPadSame-118             [-1, 512, 128]               0
       MaxPool1d-119             [-1, 512, 128]               0
MyMaxPool1dPadSame-120             [-1, 512, 128]               0
      Bottleneck-121             [-1, 512, 128]               0
     BatchNorm1d-122             [-1, 512, 128]           1,024
            ReLU-123             [-1, 512, 128]               0
         Dropout-124             [-1, 512, 128]               0
          Conv1d-125             [-1, 512, 128]           8,704
 MyConv1dPadSame-126             [-1, 512, 128]               0
     BatchNorm1d-127             [-1, 512, 128]           1,024
            ReLU-128             [-1, 512, 128]               0
         Dropout-129             [-1, 512, 128]               0
          Conv1d-130             [-1, 512, 128]           8,704
 MyConv1dPadSame-131             [-1, 512, 128]               0
      Bottleneck-132             [-1, 512, 128]               0
     BatchNorm1d-133             [-1, 512, 128]           1,024
            ReLU-134             [-1, 512, 128]               0
         Dropout-135             [-1, 512, 128]               0
          Conv1d-136              [-1, 512, 64]           8,704
 MyConv1dPadSame-137              [-1, 512, 64]               0
     BatchNorm1d-138              [-1, 512, 64]           1,024
            ReLU-139              [-1, 512, 64]               0
         Dropout-140              [-1, 512, 64]               0
          Conv1d-141              [-1, 512, 64]           8,704
 MyConv1dPadSame-142              [-1, 512, 64]               0
       MaxPool1d-143              [-1, 512, 64]               0
MyMaxPool1dPadSame-144              [-1, 512, 64]               0
      Bottleneck-145              [-1, 512, 64]               0
     BatchNorm1d-146              [-1, 512, 64]           1,024
            ReLU-147              [-1, 512, 64]               0
         Dropout-148              [-1, 512, 64]               0
          Conv1d-149             [-1, 1024, 64]          17,408
 MyConv1dPadSame-150             [-1, 1024, 64]               0
     BatchNorm1d-151             [-1, 1024, 64]           2,048
            ReLU-152             [-1, 1024, 64]               0
         Dropout-153             [-1, 1024, 64]               0
          Conv1d-154             [-1, 1024, 64]          33,792
 MyConv1dPadSame-155             [-1, 1024, 64]               0
      Bottleneck-156             [-1, 1024, 64]               0
     BatchNorm1d-157             [-1, 1024, 64]           2,048
            ReLU-158             [-1, 1024, 64]               0
         Dropout-159             [-1, 1024, 64]               0
          Conv1d-160             [-1, 1024, 32]          33,792
 MyConv1dPadSame-161             [-1, 1024, 32]               0
     BatchNorm1d-162             [-1, 1024, 32]           2,048
            ReLU-163             [-1, 1024, 32]               0
         Dropout-164             [-1, 1024, 32]               0
          Conv1d-165             [-1, 1024, 32]          33,792
 MyConv1dPadSame-166             [-1, 1024, 32]               0
       MaxPool1d-167             [-1, 1024, 32]               0
MyMaxPool1dPadSame-168             [-1, 1024, 32]               0
      Bottleneck-169             [-1, 1024, 32]               0
     BatchNorm1d-170             [-1, 1024, 32]           2,048
            ReLU-171             [-1, 1024, 32]               0
         Dropout-172             [-1, 1024, 32]               0
          Conv1d-173             [-1, 1024, 32]          33,792
 MyConv1dPadSame-174             [-1, 1024, 32]               0
     BatchNorm1d-175             [-1, 1024, 32]           2,048
            ReLU-176             [-1, 1024, 32]               0
         Dropout-177             [-1, 1024, 32]               0
          Conv1d-178             [-1, 1024, 32]          33,792
 MyConv1dPadSame-179             [-1, 1024, 32]               0
      Bottleneck-180             [-1, 1024, 32]               0
     BatchNorm1d-181             [-1, 1024, 32]           2,048
            ReLU-182             [-1, 1024, 32]               0
         Dropout-183             [-1, 1024, 32]               0
          Conv1d-184             [-1, 1024, 16]          33,792
 MyConv1dPadSame-185             [-1, 1024, 16]               0
     BatchNorm1d-186             [-1, 1024, 16]           2,048
            ReLU-187             [-1, 1024, 16]               0
         Dropout-188             [-1, 1024, 16]               0
          Conv1d-189             [-1, 1024, 16]          33,792
 MyConv1dPadSame-190             [-1, 1024, 16]               0
       MaxPool1d-191             [-1, 1024, 16]               0
MyMaxPool1dPadSame-192             [-1, 1024, 16]               0
      Bottleneck-193             [-1, 1024, 16]               0
     BatchNorm1d-194             [-1, 1024, 16]           2,048
            ReLU-195             [-1, 1024, 16]               0
          Linear-196                    [-1, 2]           2,050
================================================================
Total params: 375,682
Trainable params: 375,682
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 212.75
Params size (MB): 1.43
Estimated Total Size (MB): 214.20
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 128, kernel_size: 8, n_block: 2
************************************************************
************************************************************
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1            [-1, 128, 4096]           1,152
   MyConv1dPadSame-2            [-1, 128, 4096]               0
       BatchNorm1d-3            [-1, 128, 4096]             256
              ReLU-4            [-1, 128, 4096]               0
            Conv1d-5            [-1, 128, 4096]           1,152
   MyConv1dPadSame-6            [-1, 128, 4096]               0
       BatchNorm1d-7            [-1, 128, 4096]             256
              ReLU-8            [-1, 128, 4096]               0
           Dropout-9            [-1, 128, 4096]               0
           Conv1d-10            [-1, 128, 4096]           1,152
  MyConv1dPadSame-11            [-1, 128, 4096]               0
       Bottleneck-12            [-1, 128, 4096]               0
      BatchNorm1d-13            [-1, 128, 4096]             256
             ReLU-14            [-1, 128, 4096]               0
          Dropout-15            [-1, 128, 4096]               0
           Conv1d-16            [-1, 256, 4096]           2,304
  MyConv1dPadSame-17            [-1, 256, 4096]               0
      BatchNorm1d-18            [-1, 256, 4096]             512
             ReLU-19            [-1, 256, 4096]               0
          Dropout-20            [-1, 256, 4096]               0
           Conv1d-21            [-1, 256, 4096]           4,352
  MyConv1dPadSame-22            [-1, 256, 4096]               0
       Bottleneck-23            [-1, 256, 4096]               0
      BatchNorm1d-24            [-1, 256, 4096]             512
             ReLU-25            [-1, 256, 4096]               0
           Linear-26                    [-1, 2]             514
================================================================
Total params: 12,418
Trainable params: 12,418
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 140.00
Params size (MB): 0.05
Estimated Total Size (MB): 140.06
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 128, kernel_size: 8, n_block: 4
************************************************************
************************************************************
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1            [-1, 128, 4096]           1,152
   MyConv1dPadSame-2            [-1, 128, 4096]               0
       BatchNorm1d-3            [-1, 128, 4096]             256
              ReLU-4            [-1, 128, 4096]               0
            Conv1d-5            [-1, 128, 4096]           1,152
   MyConv1dPadSame-6            [-1, 128, 4096]               0
       BatchNorm1d-7            [-1, 128, 4096]             256
              ReLU-8            [-1, 128, 4096]               0
           Dropout-9            [-1, 128, 4096]               0
           Conv1d-10            [-1, 128, 4096]           1,152
  MyConv1dPadSame-11            [-1, 128, 4096]               0
       Bottleneck-12            [-1, 128, 4096]               0
      BatchNorm1d-13            [-1, 128, 4096]             256
             ReLU-14            [-1, 128, 4096]               0
          Dropout-15            [-1, 128, 4096]               0
           Conv1d-16            [-1, 256, 4096]           2,304
  MyConv1dPadSame-17            [-1, 256, 4096]               0
      BatchNorm1d-18            [-1, 256, 4096]             512
             ReLU-19            [-1, 256, 4096]               0
          Dropout-20            [-1, 256, 4096]               0
           Conv1d-21            [-1, 256, 4096]           4,352
  MyConv1dPadSame-22            [-1, 256, 4096]               0
       Bottleneck-23            [-1, 256, 4096]               0
      BatchNorm1d-24            [-1, 256, 4096]             512
             ReLU-25            [-1, 256, 4096]               0
          Dropout-26            [-1, 256, 4096]               0
           Conv1d-27            [-1, 512, 4096]           8,704
  MyConv1dPadSame-28            [-1, 512, 4096]               0
      BatchNorm1d-29            [-1, 512, 4096]           1,024
             ReLU-30            [-1, 512, 4096]               0
          Dropout-31            [-1, 512, 4096]               0
           Conv1d-32            [-1, 512, 4096]          16,896
  MyConv1dPadSame-33            [-1, 512, 4096]               0
       Bottleneck-34            [-1, 512, 4096]               0
      BatchNorm1d-35            [-1, 512, 4096]           1,024
             ReLU-36            [-1, 512, 4096]               0
          Dropout-37            [-1, 512, 4096]               0
           Conv1d-38           [-1, 1024, 4096]          33,792
  MyConv1dPadSame-39           [-1, 1024, 4096]               0
      BatchNorm1d-40           [-1, 1024, 4096]           2,048
             ReLU-41           [-1, 1024, 4096]               0
          Dropout-42           [-1, 1024, 4096]               0
           Conv1d-43           [-1, 1024, 4096]          66,560
  MyConv1dPadSame-44           [-1, 1024, 4096]               0
       Bottleneck-45           [-1, 1024, 4096]               0
      BatchNorm1d-46           [-1, 1024, 4096]           2,048
             ReLU-47           [-1, 1024, 4096]               0
           Linear-48                    [-1, 2]           2,050
================================================================
Total params: 146,050
Trainable params: 146,050
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 644.00
Params size (MB): 0.56
Estimated Total Size (MB): 644.57
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 128, kernel_size: 8, n_block: 8
************************************************************
************************************************************
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1            [-1, 128, 4096]           1,152
   MyConv1dPadSame-2            [-1, 128, 4096]               0
       BatchNorm1d-3            [-1, 128, 4096]             256
              ReLU-4            [-1, 128, 4096]               0
            Conv1d-5            [-1, 128, 4096]           1,152
   MyConv1dPadSame-6            [-1, 128, 4096]               0
       BatchNorm1d-7            [-1, 128, 4096]             256
              ReLU-8            [-1, 128, 4096]               0
           Dropout-9            [-1, 128, 4096]               0
           Conv1d-10            [-1, 128, 4096]           1,152
  MyConv1dPadSame-11            [-1, 128, 4096]               0
       Bottleneck-12            [-1, 128, 4096]               0
      BatchNorm1d-13            [-1, 128, 4096]             256
             ReLU-14            [-1, 128, 4096]               0
          Dropout-15            [-1, 128, 4096]               0
           Conv1d-16            [-1, 128, 4096]           1,152
  MyConv1dPadSame-17            [-1, 128, 4096]               0
      BatchNorm1d-18            [-1, 128, 4096]             256
             ReLU-19            [-1, 128, 4096]               0
          Dropout-20            [-1, 128, 4096]               0
           Conv1d-21            [-1, 128, 4096]           1,152
  MyConv1dPadSame-22            [-1, 128, 4096]               0
       Bottleneck-23            [-1, 128, 4096]               0
      BatchNorm1d-24            [-1, 128, 4096]             256
             ReLU-25            [-1, 128, 4096]               0
          Dropout-26            [-1, 128, 4096]               0
           Conv1d-27            [-1, 256, 4096]           2,304
  MyConv1dPadSame-28            [-1, 256, 4096]               0
      BatchNorm1d-29            [-1, 256, 4096]             512
             ReLU-30            [-1, 256, 4096]               0
          Dropout-31            [-1, 256, 4096]               0
           Conv1d-32            [-1, 256, 4096]           4,352
  MyConv1dPadSame-33            [-1, 256, 4096]               0
       Bottleneck-34            [-1, 256, 4096]               0
      BatchNorm1d-35            [-1, 256, 4096]             512
             ReLU-36            [-1, 256, 4096]               0
          Dropout-37            [-1, 256, 4096]               0
           Conv1d-38            [-1, 256, 4096]           4,352
  MyConv1dPadSame-39            [-1, 256, 4096]               0
      BatchNorm1d-40            [-1, 256, 4096]             512
             ReLU-41            [-1, 256, 4096]               0
          Dropout-42            [-1, 256, 4096]               0
           Conv1d-43            [-1, 256, 4096]           4,352
  MyConv1dPadSame-44            [-1, 256, 4096]               0
       Bottleneck-45            [-1, 256, 4096]               0
      BatchNorm1d-46            [-1, 256, 4096]             512
             ReLU-47            [-1, 256, 4096]               0
          Dropout-48            [-1, 256, 4096]               0
           Conv1d-49            [-1, 512, 4096]           8,704
  MyConv1dPadSame-50            [-1, 512, 4096]               0
      BatchNorm1d-51            [-1, 512, 4096]           1,024
             ReLU-52            [-1, 512, 4096]               0
          Dropout-53            [-1, 512, 4096]               0
           Conv1d-54            [-1, 512, 4096]          16,896
  MyConv1dPadSame-55            [-1, 512, 4096]               0
       Bottleneck-56            [-1, 512, 4096]               0
      BatchNorm1d-57            [-1, 512, 4096]           1,024
             ReLU-58            [-1, 512, 4096]               0
          Dropout-59            [-1, 512, 4096]               0
           Conv1d-60            [-1, 512, 4096]          16,896
  MyConv1dPadSame-61            [-1, 512, 4096]               0
      BatchNorm1d-62            [-1, 512, 4096]           1,024
             ReLU-63            [-1, 512, 4096]               0
          Dropout-64            [-1, 512, 4096]               0
           Conv1d-65            [-1, 512, 4096]          16,896
  MyConv1dPadSame-66            [-1, 512, 4096]               0
       Bottleneck-67            [-1, 512, 4096]               0
      BatchNorm1d-68            [-1, 512, 4096]           1,024
             ReLU-69            [-1, 512, 4096]               0
          Dropout-70            [-1, 512, 4096]               0
           Conv1d-71           [-1, 1024, 4096]          33,792
  MyConv1dPadSame-72           [-1, 1024, 4096]               0
      BatchNorm1d-73           [-1, 1024, 4096]           2,048
             ReLU-74           [-1, 1024, 4096]               0
          Dropout-75           [-1, 1024, 4096]               0
           Conv1d-76           [-1, 1024, 4096]          66,560
  MyConv1dPadSame-77           [-1, 1024, 4096]               0
       Bottleneck-78           [-1, 1024, 4096]               0
      BatchNorm1d-79           [-1, 1024, 4096]           2,048
             ReLU-80           [-1, 1024, 4096]               0
          Dropout-81           [-1, 1024, 4096]               0
           Conv1d-82           [-1, 1024, 4096]          66,560
  MyConv1dPadSame-83           [-1, 1024, 4096]               0
      BatchNorm1d-84           [-1, 1024, 4096]           2,048
             ReLU-85           [-1, 1024, 4096]               0
          Dropout-86           [-1, 1024, 4096]               0
           Conv1d-87           [-1, 1024, 4096]          66,560
  MyConv1dPadSame-88           [-1, 1024, 4096]               0
       Bottleneck-89           [-1, 1024, 4096]               0
      BatchNorm1d-90           [-1, 1024, 4096]           2,048
             ReLU-91           [-1, 1024, 4096]               0
           Linear-92                    [-1, 2]           2,050
================================================================
Total params: 331,650
Trainable params: 331,650
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 1304.00
Params size (MB): 1.27
Estimated Total Size (MB): 1305.28
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 128, kernel_size: 8, n_block: 16
************************************************************
************************************************************
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1            [-1, 128, 4096]           1,152
   MyConv1dPadSame-2            [-1, 128, 4096]               0
       BatchNorm1d-3            [-1, 128, 4096]             256
              ReLU-4            [-1, 128, 4096]               0
            Conv1d-5            [-1, 128, 4096]           1,152
   MyConv1dPadSame-6            [-1, 128, 4096]               0
       BatchNorm1d-7            [-1, 128, 4096]             256
              ReLU-8            [-1, 128, 4096]               0
           Dropout-9            [-1, 128, 4096]               0
           Conv1d-10            [-1, 128, 4096]           1,152
  MyConv1dPadSame-11            [-1, 128, 4096]               0
       Bottleneck-12            [-1, 128, 4096]               0
      BatchNorm1d-13            [-1, 128, 4096]             256
             ReLU-14            [-1, 128, 4096]               0
          Dropout-15            [-1, 128, 4096]               0
           Conv1d-16            [-1, 128, 2048]           1,152
  MyConv1dPadSame-17            [-1, 128, 2048]               0
      BatchNorm1d-18            [-1, 128, 2048]             256
             ReLU-19            [-1, 128, 2048]               0
          Dropout-20            [-1, 128, 2048]               0
           Conv1d-21            [-1, 128, 2048]           1,152
  MyConv1dPadSame-22            [-1, 128, 2048]               0
        MaxPool1d-23            [-1, 128, 2048]               0
MyMaxPool1dPadSame-24            [-1, 128, 2048]               0
       Bottleneck-25            [-1, 128, 2048]               0
      BatchNorm1d-26            [-1, 128, 2048]             256
             ReLU-27            [-1, 128, 2048]               0
          Dropout-28            [-1, 128, 2048]               0
           Conv1d-29            [-1, 128, 2048]           1,152
  MyConv1dPadSame-30            [-1, 128, 2048]               0
      BatchNorm1d-31            [-1, 128, 2048]             256
             ReLU-32            [-1, 128, 2048]               0
          Dropout-33            [-1, 128, 2048]               0
           Conv1d-34            [-1, 128, 2048]           1,152
  MyConv1dPadSame-35            [-1, 128, 2048]               0
       Bottleneck-36            [-1, 128, 2048]               0
      BatchNorm1d-37            [-1, 128, 2048]             256
             ReLU-38            [-1, 128, 2048]               0
          Dropout-39            [-1, 128, 2048]               0
           Conv1d-40            [-1, 128, 1024]           1,152
  MyConv1dPadSame-41            [-1, 128, 1024]               0
      BatchNorm1d-42            [-1, 128, 1024]             256
             ReLU-43            [-1, 128, 1024]               0
          Dropout-44            [-1, 128, 1024]               0
           Conv1d-45            [-1, 128, 1024]           1,152
  MyConv1dPadSame-46            [-1, 128, 1024]               0
        MaxPool1d-47            [-1, 128, 1024]               0
MyMaxPool1dPadSame-48            [-1, 128, 1024]               0
       Bottleneck-49            [-1, 128, 1024]               0
      BatchNorm1d-50            [-1, 128, 1024]             256
             ReLU-51            [-1, 128, 1024]               0
          Dropout-52            [-1, 128, 1024]               0
           Conv1d-53            [-1, 256, 1024]           2,304
  MyConv1dPadSame-54            [-1, 256, 1024]               0
      BatchNorm1d-55            [-1, 256, 1024]             512
             ReLU-56            [-1, 256, 1024]               0
          Dropout-57            [-1, 256, 1024]               0
           Conv1d-58            [-1, 256, 1024]           4,352
  MyConv1dPadSame-59            [-1, 256, 1024]               0
       Bottleneck-60            [-1, 256, 1024]               0
      BatchNorm1d-61            [-1, 256, 1024]             512
             ReLU-62            [-1, 256, 1024]               0
          Dropout-63            [-1, 256, 1024]               0
           Conv1d-64             [-1, 256, 512]           4,352
  MyConv1dPadSame-65             [-1, 256, 512]               0
      BatchNorm1d-66             [-1, 256, 512]             512
             ReLU-67             [-1, 256, 512]               0
          Dropout-68             [-1, 256, 512]               0
           Conv1d-69             [-1, 256, 512]           4,352
  MyConv1dPadSame-70             [-1, 256, 512]               0
        MaxPool1d-71             [-1, 256, 512]               0
MyMaxPool1dPadSame-72             [-1, 256, 512]               0
       Bottleneck-73             [-1, 256, 512]               0
      BatchNorm1d-74             [-1, 256, 512]             512
             ReLU-75             [-1, 256, 512]               0
          Dropout-76             [-1, 256, 512]               0
           Conv1d-77             [-1, 256, 512]           4,352
  MyConv1dPadSame-78             [-1, 256, 512]               0
      BatchNorm1d-79             [-1, 256, 512]             512
             ReLU-80             [-1, 256, 512]               0
          Dropout-81             [-1, 256, 512]               0
           Conv1d-82             [-1, 256, 512]           4,352
  MyConv1dPadSame-83             [-1, 256, 512]               0
       Bottleneck-84             [-1, 256, 512]               0
      BatchNorm1d-85             [-1, 256, 512]             512
             ReLU-86             [-1, 256, 512]               0
          Dropout-87             [-1, 256, 512]               0
           Conv1d-88             [-1, 256, 256]           4,352
  MyConv1dPadSame-89             [-1, 256, 256]               0
      BatchNorm1d-90             [-1, 256, 256]             512
             ReLU-91             [-1, 256, 256]               0
          Dropout-92             [-1, 256, 256]               0
           Conv1d-93             [-1, 256, 256]           4,352
  MyConv1dPadSame-94             [-1, 256, 256]               0
        MaxPool1d-95             [-1, 256, 256]               0
MyMaxPool1dPadSame-96             [-1, 256, 256]               0
       Bottleneck-97             [-1, 256, 256]               0
      BatchNorm1d-98             [-1, 256, 256]             512
             ReLU-99             [-1, 256, 256]               0
         Dropout-100             [-1, 256, 256]               0
          Conv1d-101             [-1, 512, 256]           8,704
 MyConv1dPadSame-102             [-1, 512, 256]               0
     BatchNorm1d-103             [-1, 512, 256]           1,024
            ReLU-104             [-1, 512, 256]               0
         Dropout-105             [-1, 512, 256]               0
          Conv1d-106             [-1, 512, 256]          16,896
 MyConv1dPadSame-107             [-1, 512, 256]               0
      Bottleneck-108             [-1, 512, 256]               0
     BatchNorm1d-109             [-1, 512, 256]           1,024
            ReLU-110             [-1, 512, 256]               0
         Dropout-111             [-1, 512, 256]               0
          Conv1d-112             [-1, 512, 128]          16,896
 MyConv1dPadSame-113             [-1, 512, 128]               0
     BatchNorm1d-114             [-1, 512, 128]           1,024
            ReLU-115             [-1, 512, 128]               0
         Dropout-116             [-1, 512, 128]               0
          Conv1d-117             [-1, 512, 128]          16,896
 MyConv1dPadSame-118             [-1, 512, 128]               0
       MaxPool1d-119             [-1, 512, 128]               0
MyMaxPool1dPadSame-120             [-1, 512, 128]               0
      Bottleneck-121             [-1, 512, 128]               0
     BatchNorm1d-122             [-1, 512, 128]           1,024
            ReLU-123             [-1, 512, 128]               0
         Dropout-124             [-1, 512, 128]               0
          Conv1d-125             [-1, 512, 128]          16,896
 MyConv1dPadSame-126             [-1, 512, 128]               0
     BatchNorm1d-127             [-1, 512, 128]           1,024
            ReLU-128             [-1, 512, 128]               0
         Dropout-129             [-1, 512, 128]               0
          Conv1d-130             [-1, 512, 128]          16,896
 MyConv1dPadSame-131             [-1, 512, 128]               0
      Bottleneck-132             [-1, 512, 128]               0
     BatchNorm1d-133             [-1, 512, 128]           1,024
            ReLU-134             [-1, 512, 128]               0
         Dropout-135             [-1, 512, 128]               0
          Conv1d-136              [-1, 512, 64]          16,896
 MyConv1dPadSame-137              [-1, 512, 64]               0
     BatchNorm1d-138              [-1, 512, 64]           1,024
            ReLU-139              [-1, 512, 64]               0
         Dropout-140              [-1, 512, 64]               0
          Conv1d-141              [-1, 512, 64]          16,896
 MyConv1dPadSame-142              [-1, 512, 64]               0
       MaxPool1d-143              [-1, 512, 64]               0
MyMaxPool1dPadSame-144              [-1, 512, 64]               0
      Bottleneck-145              [-1, 512, 64]               0
     BatchNorm1d-146              [-1, 512, 64]           1,024
            ReLU-147              [-1, 512, 64]               0
         Dropout-148              [-1, 512, 64]               0
          Conv1d-149             [-1, 1024, 64]          33,792
 MyConv1dPadSame-150             [-1, 1024, 64]               0
     BatchNorm1d-151             [-1, 1024, 64]           2,048
            ReLU-152             [-1, 1024, 64]               0
         Dropout-153             [-1, 1024, 64]               0
          Conv1d-154             [-1, 1024, 64]          66,560
 MyConv1dPadSame-155             [-1, 1024, 64]               0
      Bottleneck-156             [-1, 1024, 64]               0
     BatchNorm1d-157             [-1, 1024, 64]           2,048
            ReLU-158             [-1, 1024, 64]               0
         Dropout-159             [-1, 1024, 64]               0
          Conv1d-160             [-1, 1024, 32]          66,560
 MyConv1dPadSame-161             [-1, 1024, 32]               0
     BatchNorm1d-162             [-1, 1024, 32]           2,048
            ReLU-163             [-1, 1024, 32]               0
         Dropout-164             [-1, 1024, 32]               0
          Conv1d-165             [-1, 1024, 32]          66,560
 MyConv1dPadSame-166             [-1, 1024, 32]               0
       MaxPool1d-167             [-1, 1024, 32]               0
MyMaxPool1dPadSame-168             [-1, 1024, 32]               0
      Bottleneck-169             [-1, 1024, 32]               0
     BatchNorm1d-170             [-1, 1024, 32]           2,048
            ReLU-171             [-1, 1024, 32]               0
         Dropout-172             [-1, 1024, 32]               0
          Conv1d-173             [-1, 1024, 32]          66,560
 MyConv1dPadSame-174             [-1, 1024, 32]               0
     BatchNorm1d-175             [-1, 1024, 32]           2,048
            ReLU-176             [-1, 1024, 32]               0
         Dropout-177             [-1, 1024, 32]               0
          Conv1d-178             [-1, 1024, 32]          66,560
 MyConv1dPadSame-179             [-1, 1024, 32]               0
      Bottleneck-180             [-1, 1024, 32]               0
     BatchNorm1d-181             [-1, 1024, 32]           2,048
            ReLU-182             [-1, 1024, 32]               0
         Dropout-183             [-1, 1024, 32]               0
          Conv1d-184             [-1, 1024, 16]          66,560
 MyConv1dPadSame-185             [-1, 1024, 16]               0
     BatchNorm1d-186             [-1, 1024, 16]           2,048
            ReLU-187             [-1, 1024, 16]               0
         Dropout-188             [-1, 1024, 16]               0
          Conv1d-189             [-1, 1024, 16]          66,560
 MyConv1dPadSame-190             [-1, 1024, 16]               0
       MaxPool1d-191             [-1, 1024, 16]               0
MyMaxPool1dPadSame-192             [-1, 1024, 16]               0
      Bottleneck-193             [-1, 1024, 16]               0
     BatchNorm1d-194             [-1, 1024, 16]           2,048
            ReLU-195             [-1, 1024, 16]               0
          Linear-196                    [-1, 2]           2,050
================================================================
Total params: 702,850
Trainable params: 702,850
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 212.75
Params size (MB): 2.68
Estimated Total Size (MB): 215.45
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 128, kernel_size: 16, n_block: 2
************************************************************
************************************************************
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1            [-1, 128, 4096]           2,176
   MyConv1dPadSame-2            [-1, 128, 4096]               0
       BatchNorm1d-3            [-1, 128, 4096]             256
              ReLU-4            [-1, 128, 4096]               0
            Conv1d-5            [-1, 128, 4096]           2,176
   MyConv1dPadSame-6            [-1, 128, 4096]               0
       BatchNorm1d-7            [-1, 128, 4096]             256
              ReLU-8            [-1, 128, 4096]               0
           Dropout-9            [-1, 128, 4096]               0
           Conv1d-10            [-1, 128, 4096]           2,176
  MyConv1dPadSame-11            [-1, 128, 4096]               0
       Bottleneck-12            [-1, 128, 4096]               0
      BatchNorm1d-13            [-1, 128, 4096]             256
             ReLU-14            [-1, 128, 4096]               0
          Dropout-15            [-1, 128, 4096]               0
           Conv1d-16            [-1, 256, 4096]           4,352
  MyConv1dPadSame-17            [-1, 256, 4096]               0
      BatchNorm1d-18            [-1, 256, 4096]             512
             ReLU-19            [-1, 256, 4096]               0
          Dropout-20            [-1, 256, 4096]               0
           Conv1d-21            [-1, 256, 4096]           8,448
  MyConv1dPadSame-22            [-1, 256, 4096]               0
       Bottleneck-23            [-1, 256, 4096]               0
      BatchNorm1d-24            [-1, 256, 4096]             512
             ReLU-25            [-1, 256, 4096]               0
           Linear-26                    [-1, 2]             514
================================================================
Total params: 21,634
Trainable params: 21,634
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 140.00
Params size (MB): 0.08
Estimated Total Size (MB): 140.10
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 128, kernel_size: 16, n_block: 4
************************************************************
************************************************************
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1            [-1, 128, 4096]           2,176
   MyConv1dPadSame-2            [-1, 128, 4096]               0
       BatchNorm1d-3            [-1, 128, 4096]             256
              ReLU-4            [-1, 128, 4096]               0
            Conv1d-5            [-1, 128, 4096]           2,176
   MyConv1dPadSame-6            [-1, 128, 4096]               0
       BatchNorm1d-7            [-1, 128, 4096]             256
              ReLU-8            [-1, 128, 4096]               0
           Dropout-9            [-1, 128, 4096]               0
           Conv1d-10            [-1, 128, 4096]           2,176
  MyConv1dPadSame-11            [-1, 128, 4096]               0
       Bottleneck-12            [-1, 128, 4096]               0
      BatchNorm1d-13            [-1, 128, 4096]             256
             ReLU-14            [-1, 128, 4096]               0
          Dropout-15            [-1, 128, 4096]               0
           Conv1d-16            [-1, 256, 4096]           4,352
  MyConv1dPadSame-17            [-1, 256, 4096]               0
      BatchNorm1d-18            [-1, 256, 4096]             512
             ReLU-19            [-1, 256, 4096]               0
          Dropout-20            [-1, 256, 4096]               0
           Conv1d-21            [-1, 256, 4096]           8,448
  MyConv1dPadSame-22            [-1, 256, 4096]               0
       Bottleneck-23            [-1, 256, 4096]               0
      BatchNorm1d-24            [-1, 256, 4096]             512
             ReLU-25            [-1, 256, 4096]               0
          Dropout-26            [-1, 256, 4096]               0
           Conv1d-27            [-1, 512, 4096]          16,896
  MyConv1dPadSame-28            [-1, 512, 4096]               0
      BatchNorm1d-29            [-1, 512, 4096]           1,024
             ReLU-30            [-1, 512, 4096]               0
          Dropout-31            [-1, 512, 4096]               0
           Conv1d-32            [-1, 512, 4096]          33,280
  MyConv1dPadSame-33            [-1, 512, 4096]               0
       Bottleneck-34            [-1, 512, 4096]               0
      BatchNorm1d-35            [-1, 512, 4096]           1,024
             ReLU-36            [-1, 512, 4096]               0
          Dropout-37            [-1, 512, 4096]               0
           Conv1d-38           [-1, 1024, 4096]          66,560
  MyConv1dPadSame-39           [-1, 1024, 4096]               0
      BatchNorm1d-40           [-1, 1024, 4096]           2,048
             ReLU-41           [-1, 1024, 4096]               0
          Dropout-42           [-1, 1024, 4096]               0
           Conv1d-43           [-1, 1024, 4096]         132,096
  MyConv1dPadSame-44           [-1, 1024, 4096]               0
       Bottleneck-45           [-1, 1024, 4096]               0
      BatchNorm1d-46           [-1, 1024, 4096]           2,048
             ReLU-47           [-1, 1024, 4096]               0
           Linear-48                    [-1, 2]           2,050
================================================================
Total params: 278,146
Trainable params: 278,146
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 644.00
Params size (MB): 1.06
Estimated Total Size (MB): 645.08
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 128, kernel_size: 16, n_block: 8
************************************************************
************************************************************
(2000, 1, 4096) Counter({0: 1000, 1: 1000})
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1            [-1, 128, 4096]           2,176
   MyConv1dPadSame-2            [-1, 128, 4096]               0
       BatchNorm1d-3            [-1, 128, 4096]             256
              ReLU-4            [-1, 128, 4096]               0
            Conv1d-5            [-1, 128, 4096]           2,176
   MyConv1dPadSame-6            [-1, 128, 4096]               0
       BatchNorm1d-7            [-1, 128, 4096]             256
              ReLU-8            [-1, 128, 4096]               0
           Dropout-9            [-1, 128, 4096]               0
           Conv1d-10            [-1, 128, 4096]           2,176
  MyConv1dPadSame-11            [-1, 128, 4096]               0
       Bottleneck-12            [-1, 128, 4096]               0
      BatchNorm1d-13            [-1, 128, 4096]             256
             ReLU-14            [-1, 128, 4096]               0
          Dropout-15            [-1, 128, 4096]               0
           Conv1d-16            [-1, 128, 4096]           2,176
  MyConv1dPadSame-17            [-1, 128, 4096]               0
      BatchNorm1d-18            [-1, 128, 4096]             256
             ReLU-19            [-1, 128, 4096]               0
          Dropout-20            [-1, 128, 4096]               0
           Conv1d-21            [-1, 128, 4096]           2,176
  MyConv1dPadSame-22            [-1, 128, 4096]               0
       Bottleneck-23            [-1, 128, 4096]               0
      BatchNorm1d-24            [-1, 128, 4096]             256
             ReLU-25            [-1, 128, 4096]               0
          Dropout-26            [-1, 128, 4096]               0
           Conv1d-27            [-1, 256, 4096]           4,352
  MyConv1dPadSame-28            [-1, 256, 4096]               0
      BatchNorm1d-29            [-1, 256, 4096]             512
             ReLU-30            [-1, 256, 4096]               0
          Dropout-31            [-1, 256, 4096]               0
           Conv1d-32            [-1, 256, 4096]           8,448
  MyConv1dPadSame-33            [-1, 256, 4096]               0
       Bottleneck-34            [-1, 256, 4096]               0
      BatchNorm1d-35            [-1, 256, 4096]             512
             ReLU-36            [-1, 256, 4096]               0
          Dropout-37            [-1, 256, 4096]               0
           Conv1d-38            [-1, 256, 4096]           8,448
  MyConv1dPadSame-39            [-1, 256, 4096]               0
      BatchNorm1d-40            [-1, 256, 4096]             512
             ReLU-41            [-1, 256, 4096]               0
          Dropout-42            [-1, 256, 4096]               0
           Conv1d-43            [-1, 256, 4096]           8,448
  MyConv1dPadSame-44            [-1, 256, 4096]               0
       Bottleneck-45            [-1, 256, 4096]               0
      BatchNorm1d-46            [-1, 256, 4096]             512
             ReLU-47            [-1, 256, 4096]               0
          Dropout-48            [-1, 256, 4096]               0
           Conv1d-49            [-1, 512, 4096]          16,896
  MyConv1dPadSame-50            [-1, 512, 4096]               0
      BatchNorm1d-51            [-1, 512, 4096]           1,024
             ReLU-52            [-1, 512, 4096]               0
          Dropout-53            [-1, 512, 4096]               0
           Conv1d-54            [-1, 512, 4096]          33,280
  MyConv1dPadSame-55            [-1, 512, 4096]               0
       Bottleneck-56            [-1, 512, 4096]               0
      BatchNorm1d-57            [-1, 512, 4096]           1,024
             ReLU-58            [-1, 512, 4096]               0
          Dropout-59            [-1, 512, 4096]               0
           Conv1d-60            [-1, 512, 4096]          33,280
  MyConv1dPadSame-61            [-1, 512, 4096]               0
      BatchNorm1d-62            [-1, 512, 4096]           1,024
             ReLU-63            [-1, 512, 4096]               0
          Dropout-64            [-1, 512, 4096]               0
           Conv1d-65            [-1, 512, 4096]          33,280
  MyConv1dPadSame-66            [-1, 512, 4096]               0
       Bottleneck-67            [-1, 512, 4096]               0
      BatchNorm1d-68            [-1, 512, 4096]           1,024
             ReLU-69            [-1, 512, 4096]               0
          Dropout-70            [-1, 512, 4096]               0
           Conv1d-71           [-1, 1024, 4096]          66,560
  MyConv1dPadSame-72           [-1, 1024, 4096]               0
      BatchNorm1d-73           [-1, 1024, 4096]           2,048
             ReLU-74           [-1, 1024, 4096]               0
          Dropout-75           [-1, 1024, 4096]               0
           Conv1d-76           [-1, 1024, 4096]         132,096
  MyConv1dPadSame-77           [-1, 1024, 4096]               0
       Bottleneck-78           [-1, 1024, 4096]               0
      BatchNorm1d-79           [-1, 1024, 4096]           2,048
             ReLU-80           [-1, 1024, 4096]               0
          Dropout-81           [-1, 1024, 4096]               0
           Conv1d-82           [-1, 1024, 4096]         132,096
  MyConv1dPadSame-83           [-1, 1024, 4096]               0
      BatchNorm1d-84           [-1, 1024, 4096]           2,048
             ReLU-85           [-1, 1024, 4096]               0
          Dropout-86           [-1, 1024, 4096]               0
           Conv1d-87           [-1, 1024, 4096]         132,096
  MyConv1dPadSame-88           [-1, 1024, 4096]               0
       Bottleneck-89           [-1, 1024, 4096]               0
      BatchNorm1d-90           [-1, 1024, 4096]           2,048
             ReLU-91           [-1, 1024, 4096]               0
           Linear-92                    [-1, 2]           2,050
================================================================
Total params: 637,826
Trainable params: 637,826
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 1304.00
Params size (MB): 2.43
Estimated Total Size (MB): 1306.45
----------------------------------------------------------------




************************************************************
************************************************************
n_length: 4096, base_filters: 128, kernel_size: 16, n_block: 16
************************************************************
************************************************************
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
(2000, 1, 4096) Counter({1: 1000, 0: 1000})
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv1d-1            [-1, 128, 4096]           2,176
   MyConv1dPadSame-2            [-1, 128, 4096]               0
       BatchNorm1d-3            [-1, 128, 4096]             256
              ReLU-4            [-1, 128, 4096]               0
            Conv1d-5            [-1, 128, 4096]           2,176
   MyConv1dPadSame-6            [-1, 128, 4096]               0
       BatchNorm1d-7            [-1, 128, 4096]             256
              ReLU-8            [-1, 128, 4096]               0
           Dropout-9            [-1, 128, 4096]               0
           Conv1d-10            [-1, 128, 4096]           2,176
  MyConv1dPadSame-11            [-1, 128, 4096]               0
       Bottleneck-12            [-1, 128, 4096]               0
      BatchNorm1d-13            [-1, 128, 4096]             256
             ReLU-14            [-1, 128, 4096]               0
          Dropout-15            [-1, 128, 4096]               0
           Conv1d-16            [-1, 128, 2048]           2,176
  MyConv1dPadSame-17            [-1, 128, 2048]               0
      BatchNorm1d-18            [-1, 128, 2048]             256
             ReLU-19            [-1, 128, 2048]               0
          Dropout-20            [-1, 128, 2048]               0
           Conv1d-21            [-1, 128, 2048]           2,176
  MyConv1dPadSame-22            [-1, 128, 2048]               0
        MaxPool1d-23            [-1, 128, 2048]               0
MyMaxPool1dPadSame-24            [-1, 128, 2048]               0
       Bottleneck-25            [-1, 128, 2048]               0
      BatchNorm1d-26            [-1, 128, 2048]             256
             ReLU-27            [-1, 128, 2048]               0
          Dropout-28            [-1, 128, 2048]               0
           Conv1d-29            [-1, 128, 2048]           2,176
  MyConv1dPadSame-30            [-1, 128, 2048]               0
      BatchNorm1d-31            [-1, 128, 2048]             256
             ReLU-32            [-1, 128, 2048]               0
          Dropout-33            [-1, 128, 2048]               0
           Conv1d-34            [-1, 128, 2048]           2,176
  MyConv1dPadSame-35            [-1, 128, 2048]               0
       Bottleneck-36            [-1, 128, 2048]               0
      BatchNorm1d-37            [-1, 128, 2048]             256
             ReLU-38            [-1, 128, 2048]               0
          Dropout-39            [-1, 128, 2048]               0
           Conv1d-40            [-1, 128, 1024]           2,176
  MyConv1dPadSame-41            [-1, 128, 1024]               0
      BatchNorm1d-42            [-1, 128, 1024]             256
             ReLU-43            [-1, 128, 1024]               0
          Dropout-44            [-1, 128, 1024]               0
           Conv1d-45            [-1, 128, 1024]           2,176
  MyConv1dPadSame-46            [-1, 128, 1024]               0
        MaxPool1d-47            [-1, 128, 1024]               0
MyMaxPool1dPadSame-48            [-1, 128, 1024]               0
       Bottleneck-49            [-1, 128, 1024]               0
      BatchNorm1d-50            [-1, 128, 1024]             256
             ReLU-51            [-1, 128, 1024]               0
          Dropout-52            [-1, 128, 1024]               0
           Conv1d-53            [-1, 256, 1024]           4,352
  MyConv1dPadSame-54            [-1, 256, 1024]               0
      BatchNorm1d-55            [-1, 256, 1024]             512
             ReLU-56            [-1, 256, 1024]               0
          Dropout-57            [-1, 256, 1024]               0
           Conv1d-58            [-1, 256, 1024]           8,448
  MyConv1dPadSame-59            [-1, 256, 1024]               0
       Bottleneck-60            [-1, 256, 1024]               0
      BatchNorm1d-61            [-1, 256, 1024]             512
             ReLU-62            [-1, 256, 1024]               0
          Dropout-63            [-1, 256, 1024]               0
           Conv1d-64             [-1, 256, 512]           8,448
  MyConv1dPadSame-65             [-1, 256, 512]               0
      BatchNorm1d-66             [-1, 256, 512]             512
             ReLU-67             [-1, 256, 512]               0
          Dropout-68             [-1, 256, 512]               0
           Conv1d-69             [-1, 256, 512]           8,448
  MyConv1dPadSame-70             [-1, 256, 512]               0
        MaxPool1d-71             [-1, 256, 512]               0
MyMaxPool1dPadSame-72             [-1, 256, 512]               0
       Bottleneck-73             [-1, 256, 512]               0
      BatchNorm1d-74             [-1, 256, 512]             512
             ReLU-75             [-1, 256, 512]               0
          Dropout-76             [-1, 256, 512]               0
           Conv1d-77             [-1, 256, 512]           8,448
  MyConv1dPadSame-78             [-1, 256, 512]               0
      BatchNorm1d-79             [-1, 256, 512]             512
             ReLU-80             [-1, 256, 512]               0
          Dropout-81             [-1, 256, 512]               0
           Conv1d-82             [-1, 256, 512]           8,448
  MyConv1dPadSame-83             [-1, 256, 512]               0
       Bottleneck-84             [-1, 256, 512]               0
      BatchNorm1d-85             [-1, 256, 512]             512
             ReLU-86             [-1, 256, 512]               0
          Dropout-87             [-1, 256, 512]               0
           Conv1d-88             [-1, 256, 256]           8,448
  MyConv1dPadSame-89             [-1, 256, 256]               0
      BatchNorm1d-90             [-1, 256, 256]             512
             ReLU-91             [-1, 256, 256]               0
          Dropout-92             [-1, 256, 256]               0
           Conv1d-93             [-1, 256, 256]           8,448
  MyConv1dPadSame-94             [-1, 256, 256]               0
        MaxPool1d-95             [-1, 256, 256]               0
MyMaxPool1dPadSame-96             [-1, 256, 256]               0
       Bottleneck-97             [-1, 256, 256]               0
      BatchNorm1d-98             [-1, 256, 256]             512
             ReLU-99             [-1, 256, 256]               0
         Dropout-100             [-1, 256, 256]               0
          Conv1d-101             [-1, 512, 256]          16,896
 MyConv1dPadSame-102             [-1, 512, 256]               0
     BatchNorm1d-103             [-1, 512, 256]           1,024
            ReLU-104             [-1, 512, 256]               0
         Dropout-105             [-1, 512, 256]               0
          Conv1d-106             [-1, 512, 256]          33,280
 MyConv1dPadSame-107             [-1, 512, 256]               0
      Bottleneck-108             [-1, 512, 256]               0
     BatchNorm1d-109             [-1, 512, 256]           1,024
            ReLU-110             [-1, 512, 256]               0
         Dropout-111             [-1, 512, 256]               0
          Conv1d-112             [-1, 512, 128]          33,280
 MyConv1dPadSame-113             [-1, 512, 128]               0
     BatchNorm1d-114             [-1, 512, 128]           1,024
            ReLU-115             [-1, 512, 128]               0
         Dropout-116             [-1, 512, 128]               0
          Conv1d-117             [-1, 512, 128]          33,280
 MyConv1dPadSame-118             [-1, 512, 128]               0
       MaxPool1d-119             [-1, 512, 128]               0
MyMaxPool1dPadSame-120             [-1, 512, 128]               0
      Bottleneck-121             [-1, 512, 128]               0
     BatchNorm1d-122             [-1, 512, 128]           1,024
            ReLU-123             [-1, 512, 128]               0
         Dropout-124             [-1, 512, 128]               0
          Conv1d-125             [-1, 512, 128]          33,280
 MyConv1dPadSame-126             [-1, 512, 128]               0
     BatchNorm1d-127             [-1, 512, 128]           1,024
            ReLU-128             [-1, 512, 128]               0
         Dropout-129             [-1, 512, 128]               0
          Conv1d-130             [-1, 512, 128]          33,280
 MyConv1dPadSame-131             [-1, 512, 128]               0
      Bottleneck-132             [-1, 512, 128]               0
     BatchNorm1d-133             [-1, 512, 128]           1,024
            ReLU-134             [-1, 512, 128]               0
         Dropout-135             [-1, 512, 128]               0
          Conv1d-136              [-1, 512, 64]          33,280
 MyConv1dPadSame-137              [-1, 512, 64]               0
     BatchNorm1d-138              [-1, 512, 64]           1,024
            ReLU-139              [-1, 512, 64]               0
         Dropout-140              [-1, 512, 64]               0
          Conv1d-141              [-1, 512, 64]          33,280
 MyConv1dPadSame-142              [-1, 512, 64]               0
       MaxPool1d-143              [-1, 512, 64]               0
MyMaxPool1dPadSame-144              [-1, 512, 64]               0
      Bottleneck-145              [-1, 512, 64]               0
     BatchNorm1d-146              [-1, 512, 64]           1,024
            ReLU-147              [-1, 512, 64]               0
         Dropout-148              [-1, 512, 64]               0
          Conv1d-149             [-1, 1024, 64]          66,560
 MyConv1dPadSame-150             [-1, 1024, 64]               0
     BatchNorm1d-151             [-1, 1024, 64]           2,048
            ReLU-152             [-1, 1024, 64]               0
         Dropout-153             [-1, 1024, 64]               0
          Conv1d-154             [-1, 1024, 64]         132,096
 MyConv1dPadSame-155             [-1, 1024, 64]               0
      Bottleneck-156             [-1, 1024, 64]               0
     BatchNorm1d-157             [-1, 1024, 64]           2,048
            ReLU-158             [-1, 1024, 64]               0
         Dropout-159             [-1, 1024, 64]               0
          Conv1d-160             [-1, 1024, 32]         132,096
 MyConv1dPadSame-161             [-1, 1024, 32]               0
     BatchNorm1d-162             [-1, 1024, 32]           2,048
            ReLU-163             [-1, 1024, 32]               0
         Dropout-164             [-1, 1024, 32]               0
          Conv1d-165             [-1, 1024, 32]         132,096
 MyConv1dPadSame-166             [-1, 1024, 32]               0
       MaxPool1d-167             [-1, 1024, 32]               0
MyMaxPool1dPadSame-168             [-1, 1024, 32]               0
      Bottleneck-169             [-1, 1024, 32]               0
     BatchNorm1d-170             [-1, 1024, 32]           2,048
            ReLU-171             [-1, 1024, 32]               0
         Dropout-172             [-1, 1024, 32]               0
          Conv1d-173             [-1, 1024, 32]         132,096
 MyConv1dPadSame-174             [-1, 1024, 32]               0
     BatchNorm1d-175             [-1, 1024, 32]           2,048
            ReLU-176             [-1, 1024, 32]               0
         Dropout-177             [-1, 1024, 32]               0
          Conv1d-178             [-1, 1024, 32]         132,096
 MyConv1dPadSame-179             [-1, 1024, 32]               0
      Bottleneck-180             [-1, 1024, 32]               0
     BatchNorm1d-181             [-1, 1024, 32]           2,048
            ReLU-182             [-1, 1024, 32]               0
         Dropout-183             [-1, 1024, 32]               0
          Conv1d-184             [-1, 1024, 16]         132,096
 MyConv1dPadSame-185             [-1, 1024, 16]               0
     BatchNorm1d-186             [-1, 1024, 16]           2,048
            ReLU-187             [-1, 1024, 16]               0
         Dropout-188             [-1, 1024, 16]               0
          Conv1d-189             [-1, 1024, 16]         132,096
 MyConv1dPadSame-190             [-1, 1024, 16]               0
       MaxPool1d-191             [-1, 1024, 16]               0
MyMaxPool1dPadSame-192             [-1, 1024, 16]               0
      Bottleneck-193             [-1, 1024, 16]               0
     BatchNorm1d-194             [-1, 1024, 16]           2,048
            ReLU-195             [-1, 1024, 16]               0
          Linear-196                    [-1, 2]           2,050
================================================================
Total params: 1,357,186
Trainable params: 1,357,186
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.02
Forward/backward pass size (MB): 212.75
Params size (MB): 5.18
Estimated Total Size (MB): 217.94
----------------------------------------------------------------
